{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":476,"status":"ok","timestamp":1635216747753,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"TttsebXTSKyR","outputId":"ff41bd04-cc01-408a-c060-765c529c2cb1"},"outputs":[{"name":"stdout","output_type":"stream","text":["Python 3.7.12\n","GPU 0: Tesla P100-PCIE-16GB (UUID: GPU-a3f10068-13ce-2fe3-107c-d8f173223870)\n"]}],"source":["!python --version\n","!nvidia-smi -L"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"riqJXilFV4sY"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UX8TUeOtV4ux"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uAXJpNqIV4xI"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":196,"status":"ok","timestamp":1635216750275,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"Q4GZt2O-V4zn"},"outputs":[],"source":["import os"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1635216750511,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"_7NVUpVMV41x"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')\n"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":1,"status":"ok","timestamp":1635216750696,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"c3EDOnQ3c0Ib"},"outputs":[],"source":["import os \n","os.chdir('/content/drive/MyDrive/code/graduation-project/src/')"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":257,"status":"ok","timestamp":1635216752096,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"CD_NrrCDV44B","outputId":"6cf39f4f-b222-4a32-bde2-7c17e12f8fb8"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/drive/My Drive/code/graduation-project/src\n"]}],"source":["!pwd"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6678,"status":"ok","timestamp":1635216759024,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"yO1Jc3YxV46X","outputId":"ccb9bf39-c743-437d-998a-a29e2fa2abb8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Looking in links: https://data.dgl.ai/wheels/repo.html\n","Requirement already satisfied: dgl-cu111==0.6.1 in /usr/local/lib/python3.7/dist-packages (0.6.1)\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111==0.6.1) (1.19.5)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111==0.6.1) (1.4.1)\n","Requirement already satisfied: networkx>=2.1 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111==0.6.1) (2.6.3)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.7/dist-packages (from dgl-cu111==0.6.1) (2.23.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111==0.6.1) (1.24.3)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111==0.6.1) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111==0.6.1) (2021.5.30)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests>=2.19.0->dgl-cu111==0.6.1) (2.10)\n","Requirement already satisfied: ase in /usr/local/lib/python3.7/dist-packages (3.22.0)\n","Requirement already satisfied: matplotlib>=3.1.0 in /usr/local/lib/python3.7/dist-packages (from ase) (3.2.2)\n","Requirement already satisfied: scipy>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from ase) (1.4.1)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from ase) (1.19.5)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->ase) (1.3.2)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->ase) (0.10.0)\n","Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->ase) (2.8.2)\n","Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=3.1.0->ase) (2.4.7)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from cycler>=0.10->matplotlib>=3.1.0->ase) (1.15.0)\n","Requirement already satisfied: rdkit-pypi in /usr/local/lib/python3.7/dist-packages (2021.9.1)\n","Requirement already satisfied: numpy>=1.19 in /usr/local/lib/python3.7/dist-packages (from rdkit-pypi) (1.19.5)\n"]}],"source":["# !pip install dgl\n","!pip install dgl-cu111==0.6.1 -f https://data.dgl.ai/wheels/repo.html\n","!pip install ase\n","!pip install rdkit-pypi"]},{"cell_type":"markdown","metadata":{"id":"LfkNjUbTYsV_"},"source":["## 千次 epoch 训练"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OiZXYG_yYsmH","outputId":"1dd2ead4-1ec9-40d4-997b-de51e6959d8d"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n","\n","train MAE: 1.7793, evaluate MAE: 2.3878\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1572\n","\tbatch: 100, loss: 4.9870, MAE: 1.2731\n","\tbatch: 200, loss: 14.7619, MAE: 1.5046\n","Training:\t loss: 11.2279, MAE: 1.7303\n","Evaluating:\t loss: 11.5444, MAE: 1.4112\n","train MSE: 11.2279, evaluate MSE: 11.5444\n","\n","train MAE: 1.7303, evaluate MAE: 1.4112\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1573\n","\tbatch: 100, loss: 8.4808, MAE: 1.7634\n","\tbatch: 200, loss: 2.5306, MAE: 1.0308\n","Training:\t loss: 13.5606, MAE: 1.8516\n","Evaluating:\t loss: 13.0658, MAE: 2.0052\n","train MSE: 13.5606, evaluate MSE: 13.0658\n","\n","train MAE: 1.8516, evaluate MAE: 2.0052\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1574\n","\tbatch: 100, loss: 33.0739, MAE: 2.6544\n","\tbatch: 200, loss: 140.8210, MAE: 6.4925\n","Training:\t loss: 62.2719, MAE: 3.6163\n","Evaluating:\t loss: 108.4651, MAE: 6.8743\n","train MSE: 62.2719, evaluate MSE: 108.4651\n","\n","train MAE: 3.6163, evaluate MAE: 6.8743\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1575\n","\tbatch: 100, loss: 17.1974, MAE: 2.4370\n","\tbatch: 200, loss: 20.4286, MAE: 2.5055\n","Training:\t loss: 31.2666, MAE: 2.9345\n","Evaluating:\t loss: 19.1838, MAE: 2.2006\n","train MSE: 31.2666, evaluate MSE: 19.1838\n","\n","train MAE: 2.9345, evaluate MAE: 2.2006\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1576\n","\tbatch: 100, loss: 17.1696, MAE: 2.2486\n","\tbatch: 200, loss: 16.3518, MAE: 2.4589\n","Training:\t loss: 19.5401, MAE: 2.2969\n","Evaluating:\t loss: 18.0091, MAE: 2.5723\n","train MSE: 19.5401, evaluate MSE: 18.0091\n","\n","train MAE: 2.2969, evaluate MAE: 2.5723\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1577\n","\tbatch: 100, loss: 23.4710, MAE: 1.7889\n","\tbatch: 200, loss: 21.7877, MAE: 2.5382\n","Training:\t loss: 13.2082, MAE: 1.9109\n","Evaluating:\t loss: 16.1743, MAE: 2.0787\n","train MSE: 13.2082, evaluate MSE: 16.1743\n","\n","train MAE: 1.9109, evaluate MAE: 2.0787\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1578\n","\tbatch: 100, loss: 19.0614, MAE: 2.1427\n","\tbatch: 200, loss: 17.4911, MAE: 1.9942\n","Training:\t loss: 13.7873, MAE: 1.8873\n","Evaluating:\t loss: 15.3811, MAE: 2.1683\n","train MSE: 13.7873, evaluate MSE: 15.3811\n","\n","train MAE: 1.8873, evaluate MAE: 2.1683\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1579\n","\tbatch: 100, loss: 25.9027, MAE: 2.0207\n","\tbatch: 200, loss: 18.4526, MAE: 2.0154\n","Training:\t loss: 17.1186, MAE: 2.0874\n","Evaluating:\t loss: 14.4438, MAE: 1.6047\n","train MSE: 17.1186, evaluate MSE: 14.4438\n","\n","train MAE: 2.0874, evaluate MAE: 1.6047\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1580\n","\tbatch: 100, loss: 38.0940, MAE: 2.2592\n","\tbatch: 200, loss: 9.8219, MAE: 1.6761\n","Training:\t loss: 13.5245, MAE: 1.9057\n","Evaluating:\t loss: 13.1471, MAE: 1.6086\n","train MSE: 13.5245, evaluate MSE: 13.1471\n","\n","train MAE: 1.9057, evaluate MAE: 1.6086\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1581\n","\tbatch: 100, loss: 20.0017, MAE: 1.7617\n","\tbatch: 200, loss: 11.0069, MAE: 1.8846\n","Training:\t loss: 10.7822, MAE: 1.7363\n","Evaluating:\t loss: 13.5459, MAE: 1.5228\n","train MSE: 10.7822, evaluate MSE: 13.5459\n","\n","train MAE: 1.7363, evaluate MAE: 1.5228\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1582\n","\tbatch: 100, loss: 11.5514, MAE: 1.7996\n","\tbatch: 200, loss: 13.2380, MAE: 2.0849\n","Training:\t loss: 14.0686, MAE: 2.0910\n","Evaluating:\t loss: 15.1642, MAE: 1.8753\n","train MSE: 14.0686, evaluate MSE: 15.1642\n","\n","train MAE: 2.0910, evaluate MAE: 1.8753\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1583\n","\tbatch: 100, loss: 5.5148, MAE: 1.6535\n","\tbatch: 200, loss: 10.2088, MAE: 1.6742\n","Training:\t loss: 16.1082, MAE: 2.1768\n","Evaluating:\t loss: 61.8781, MAE: 3.7925\n","train MSE: 16.1082, evaluate MSE: 61.8781\n","\n","train MAE: 2.1768, evaluate MAE: 3.7925\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1584\n","\tbatch: 100, loss: 49.0037, MAE: 3.6710\n","\tbatch: 200, loss: 18.6985, MAE: 2.5271\n","Training:\t loss: 41.0251, MAE: 3.2043\n","Evaluating:\t loss: 50.0288, MAE: 3.7599\n","train MSE: 41.0251, evaluate MSE: 50.0288\n","\n","train MAE: 3.2043, evaluate MAE: 3.7599\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1585\n","\tbatch: 100, loss: 42.6064, MAE: 4.2988\n","\tbatch: 200, loss: 27.1051, MAE: 3.0472\n","Training:\t loss: 41.6636, MAE: 3.8757\n","Evaluating:\t loss: 26.0505, MAE: 3.5426\n","train MSE: 41.6636, evaluate MSE: 26.0505\n","\n","train MAE: 3.8757, evaluate MAE: 3.5426\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1586\n","\tbatch: 100, loss: 21.3172, MAE: 2.8589\n","\tbatch: 200, loss: 16.9031, MAE: 2.5277\n","Training:\t loss: 24.8996, MAE: 2.9243\n","Evaluating:\t loss: 19.3599, MAE: 2.5119\n","train MSE: 24.8996, evaluate MSE: 19.3599\n","\n","train MAE: 2.9243, evaluate MAE: 2.5119\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1587\n","\tbatch: 100, loss: 20.8955, MAE: 3.0021\n","\tbatch: 200, loss: 38.3578, MAE: 2.6375\n","Training:\t loss: 23.4801, MAE: 2.5686\n","Evaluating:\t loss: 20.4970, MAE: 2.3870\n","train MSE: 23.4801, evaluate MSE: 20.4970\n","\n","train MAE: 2.5686, evaluate MAE: 2.3870\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1588\n","\tbatch: 100, loss: 37.3120, MAE: 3.8668\n","\tbatch: 200, loss: 14.6463, MAE: 2.2433\n","Training:\t loss: 24.4832, MAE: 2.7631\n","Evaluating:\t loss: 32.5180, MAE: 3.6589\n","train MSE: 24.4832, evaluate MSE: 32.5180\n","\n","train MAE: 2.7631, evaluate MAE: 3.6589\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1589\n","\tbatch: 100, loss: 20.0964, MAE: 2.0899\n","\tbatch: 200, loss: 11.8291, MAE: 2.2419\n","Training:\t loss: 24.5216, MAE: 2.6764\n","Evaluating:\t loss: 39.1995, MAE: 2.8719\n","train MSE: 24.5216, evaluate MSE: 39.1995\n","\n","train MAE: 2.6764, evaluate MAE: 2.8719\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1590\n","\tbatch: 100, loss: 13.7353, MAE: 2.3918\n","\tbatch: 200, loss: 43.6891, MAE: 3.9576\n","Training:\t loss: 35.1035, MAE: 3.2525\n","Evaluating:\t loss: 31.9007, MAE: 3.0692\n","train MSE: 35.1035, evaluate MSE: 31.9007\n","\n","train MAE: 3.2525, evaluate MAE: 3.0692\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1591\n","\tbatch: 100, loss: 15.2867, MAE: 2.4760\n","\tbatch: 200, loss: 17.7142, MAE: 3.2002\n","Training:\t loss: 43.3848, MAE: 3.5184\n","Evaluating:\t loss: 34.5126, MAE: 3.8088\n","train MSE: 43.3848, evaluate MSE: 34.5126\n","\n","train MAE: 3.5184, evaluate MAE: 3.8088\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1592\n","\tbatch: 100, loss: 22.5301, MAE: 2.5593\n","\tbatch: 200, loss: 14.0073, MAE: 1.8837\n","Training:\t loss: 35.4516, MAE: 2.6262\n","Evaluating:\t loss: 23.1665, MAE: 2.5472\n","train MSE: 35.4516, evaluate MSE: 23.1665\n","\n","train MAE: 2.6262, evaluate MAE: 2.5472\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1593\n","\tbatch: 100, loss: 12.2886, MAE: 1.9273\n","\tbatch: 200, loss: 24.0992, MAE: 2.5146\n","Training:\t loss: 22.8507, MAE: 2.2994\n","Evaluating:\t loss: 24.1068, MAE: 2.6573\n","train MSE: 22.8507, evaluate MSE: 24.1068\n","\n","train MAE: 2.2994, evaluate MAE: 2.6573\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1594\n","\tbatch: 100, loss: 19.0077, MAE: 2.6079\n","\tbatch: 200, loss: 13.0666, MAE: 2.1059\n","Training:\t loss: 19.8607, MAE: 2.1357\n","Evaluating:\t loss: 17.9073, MAE: 2.4100\n","train MSE: 19.8607, evaluate MSE: 17.9073\n","\n","train MAE: 2.1357, evaluate MAE: 2.4100\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1595\n","\tbatch: 100, loss: 12.2942, MAE: 2.5612\n","\tbatch: 200, loss: 7.3743, MAE: 1.6428\n","Training:\t loss: 15.8649, MAE: 1.9871\n","Evaluating:\t loss: 16.4529, MAE: 2.4119\n","train MSE: 15.8649, evaluate MSE: 16.4529\n","\n","train MAE: 1.9871, evaluate MAE: 2.4119\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1596\n","\tbatch: 100, loss: 8.0588, MAE: 1.7887\n","\tbatch: 200, loss: 7.1844, MAE: 1.6826\n","Training:\t loss: 14.0828, MAE: 1.9889\n","Evaluating:\t loss: 12.7257, MAE: 1.8646\n","train MSE: 14.0828, evaluate MSE: 12.7257\n","\n","train MAE: 1.9889, evaluate MAE: 1.8646\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1597\n","\tbatch: 100, loss: 10.2652, MAE: 2.3008\n","\tbatch: 200, loss: 10.9799, MAE: 1.8848\n","Training:\t loss: 13.3447, MAE: 1.9715\n","Evaluating:\t loss: 24.4589, MAE: 3.0071\n","train MSE: 13.3447, evaluate MSE: 24.4589\n","\n","train MAE: 1.9715, evaluate MAE: 3.0071\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1598\n","\tbatch: 100, loss: 15.4999, MAE: 2.0404\n","\tbatch: 200, loss: 7.7952, MAE: 1.7674\n","Training:\t loss: 14.2632, MAE: 2.0592\n","Evaluating:\t loss: 13.5870, MAE: 2.0756\n","train MSE: 14.2632, evaluate MSE: 13.5870\n","\n","train MAE: 2.0592, evaluate MAE: 2.0756\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1599\n","\tbatch: 100, loss: 9.2299, MAE: 1.7354\n","\tbatch: 200, loss: 6.6085, MAE: 1.7993\n","Training:\t loss: 12.9890, MAE: 1.9042\n","Evaluating:\t loss: 14.7336, MAE: 1.9540\n","train MSE: 12.9890, evaluate MSE: 14.7336\n","\n","train MAE: 1.9042, evaluate MAE: 1.9540\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1600\n","\tbatch: 100, loss: 8.9204, MAE: 2.1102\n","\tbatch: 200, loss: 8.1198, MAE: 1.8113\n","Training:\t loss: 13.6582, MAE: 2.0402\n","Evaluating:\t loss: 29.2216, MAE: 2.7176\n","train MSE: 13.6582, evaluate MSE: 29.2216\n","\n","train MAE: 2.0402, evaluate MAE: 2.7176\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1601\n","\tbatch: 100, loss: 11.8118, MAE: 1.8107\n","\tbatch: 200, loss: 15.7316, MAE: 1.9531\n","Training:\t loss: 16.0469, MAE: 2.1476\n","Evaluating:\t loss: 10.5232, MAE: 1.7606\n","train MSE: 16.0469, evaluate MSE: 10.5232\n","\n","train MAE: 2.1476, evaluate MAE: 1.7606\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1602\n","\tbatch: 100, loss: 18.9493, MAE: 2.1182\n","\tbatch: 200, loss: 155.0621, MAE: 8.5332\n","Training:\t loss: 321.8842, MAE: 9.0300\n","Evaluating:\t loss: 76.3971, MAE: 6.1099\n","train MSE: 321.8842, evaluate MSE: 76.3971\n","\n","train MAE: 9.0300, evaluate MAE: 6.1099\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1603\n","\tbatch: 100, loss: 78.6060, MAE: 4.6998\n","\tbatch: 200, loss: 36.4150, MAE: 4.4248\n","Training:\t loss: 51.2291, MAE: 4.8089\n","Evaluating:\t loss: 40.7164, MAE: 4.1962\n","train MSE: 51.2291, evaluate MSE: 40.7164\n","\n","train MAE: 4.8089, evaluate MAE: 4.1962\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1604\n","\tbatch: 100, loss: 34.8272, MAE: 4.0290\n","\tbatch: 200, loss: 28.4966, MAE: 3.6354\n","Training:\t loss: 36.9133, MAE: 3.8935\n","Evaluating:\t loss: 26.9157, MAE: 3.2247\n","train MSE: 36.9133, evaluate MSE: 26.9157\n","\n","train MAE: 3.8935, evaluate MAE: 3.2247\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1605\n","\tbatch: 100, loss: 39.2804, MAE: 3.2315\n","\tbatch: 200, loss: 26.7913, MAE: 3.4393\n","Training:\t loss: 32.9841, MAE: 3.4938\n","Evaluating:\t loss: 24.1101, MAE: 2.9649\n","train MSE: 32.9841, evaluate MSE: 24.1101\n","\n","train MAE: 3.4938, evaluate MAE: 2.9649\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1606\n","\tbatch: 100, loss: 25.5456, MAE: 2.8331\n","\tbatch: 200, loss: 17.6282, MAE: 2.5242\n","Training:\t loss: 23.9988, MAE: 2.9630\n","Evaluating:\t loss: 23.0666, MAE: 2.8999\n","train MSE: 23.9988, evaluate MSE: 23.0666\n","\n","train MAE: 2.9630, evaluate MAE: 2.8999\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1607\n","\tbatch: 100, loss: 11.2903, MAE: 2.2511\n","\tbatch: 200, loss: 20.2549, MAE: 2.5561\n","Training:\t loss: 19.9419, MAE: 2.6284\n","Evaluating:\t loss: 17.6310, MAE: 2.5017\n","train MSE: 19.9419, evaluate MSE: 17.6310\n","\n","train MAE: 2.6284, evaluate MAE: 2.5017\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1608\n","\tbatch: 100, loss: 16.1325, MAE: 2.6821\n","\tbatch: 200, loss: 22.7725, MAE: 3.2707\n","Training:\t loss: 18.9532, MAE: 2.5250\n","Evaluating:\t loss: 17.4612, MAE: 2.3883\n","train MSE: 18.9532, evaluate MSE: 17.4612\n","\n","train MAE: 2.5250, evaluate MAE: 2.3883\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1609\n","\tbatch: 100, loss: 13.5221, MAE: 2.2513\n","\tbatch: 200, loss: 12.4067, MAE: 2.1199\n","Training:\t loss: 17.1743, MAE: 2.3321\n","Evaluating:\t loss: 17.0781, MAE: 2.2533\n","train MSE: 17.1743, evaluate MSE: 17.0781\n","\n","train MAE: 2.3321, evaluate MAE: 2.2533\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1610\n","\tbatch: 100, loss: 8.3872, MAE: 1.9725\n","\tbatch: 200, loss: 19.6031, MAE: 2.3089\n","Training:\t loss: 18.7843, MAE: 2.4362\n","Evaluating:\t loss: 15.9827, MAE: 2.2088\n","train MSE: 18.7843, evaluate MSE: 15.9827\n","\n","train MAE: 2.4362, evaluate MAE: 2.2088\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1611\n","\tbatch: 100, loss: 11.7162, MAE: 2.3055\n","\tbatch: 200, loss: 28.8715, MAE: 2.7755\n","Training:\t loss: 16.9096, MAE: 2.2374\n","Evaluating:\t loss: 14.9663, MAE: 2.0170\n","train MSE: 16.9096, evaluate MSE: 14.9663\n","\n","train MAE: 2.2374, evaluate MAE: 2.0170\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1612\n","\tbatch: 100, loss: 18.4806, MAE: 2.6633\n","\tbatch: 200, loss: 21.6269, MAE: 2.8594\n","Training:\t loss: 24.0889, MAE: 2.6547\n","Evaluating:\t loss: 23.9043, MAE: 2.6779\n","train MSE: 24.0889, evaluate MSE: 23.9043\n","\n","train MAE: 2.6547, evaluate MAE: 2.6779\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1613\n","\tbatch: 100, loss: 13.3090, MAE: 2.3608\n","\tbatch: 200, loss: 8.7449, MAE: 1.7720\n","Training:\t loss: 18.5886, MAE: 2.2792\n","Evaluating:\t loss: 14.9159, MAE: 2.0814\n","train MSE: 18.5886, evaluate MSE: 14.9159\n","\n","train MAE: 2.2792, evaluate MAE: 2.0814\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1614\n","\tbatch: 100, loss: 11.4509, MAE: 2.0855\n","\tbatch: 200, loss: 22.0088, MAE: 2.2371\n","Training:\t loss: 18.4919, MAE: 2.3407\n","Evaluating:\t loss: 24.8795, MAE: 2.8057\n","train MSE: 18.4919, evaluate MSE: 24.8795\n","\n","train MAE: 2.3407, evaluate MAE: 2.8057\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1615\n","\tbatch: 100, loss: 7.6960, MAE: 1.8149\n","\tbatch: 200, loss: 12.2919, MAE: 2.1859\n","Training:\t loss: 20.4865, MAE: 2.3820\n","Evaluating:\t loss: 18.8057, MAE: 2.7113\n","train MSE: 20.4865, evaluate MSE: 18.8057\n","\n","train MAE: 2.3820, evaluate MAE: 2.7113\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 1616\n","\tbatch: 100, loss: 11.0142, MAE: 1.8873\n","\tbatch: 200, loss: 8.5147, MAE: 1.7132\n","Training:\t loss: 14.5292, MAE: 2.0516\n","Evaluating:\t loss: 12.5509, MAE: 1.8130\n","train MSE: 14.5292, evaluate MSE: 12.5509\n","\n","train MAE: 2.0516, evaluate MAE: 1.8130\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1617\n","\tbatch: 100, loss: 9.1359, MAE: 1.9671\n","\tbatch: 200, loss: 15.7255, MAE: 2.1238\n","Training:\t loss: 14.0777, MAE: 2.1283\n","Evaluating:\t loss: 17.8421, MAE: 3.2082\n","train MSE: 14.0777, evaluate MSE: 17.8421\n","\n","train MAE: 2.1283, evaluate MAE: 3.2082\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1618\n","\tbatch: 100, loss: 11.5746, MAE: 2.0286\n","\tbatch: 200, loss: 17.3355, MAE: 2.5089\n","Training:\t loss: 14.9082, MAE: 2.1941\n","Evaluating:\t loss: 40.7661, MAE: 2.5777\n","train MSE: 14.9082, evaluate MSE: 40.7661\n","\n","train MAE: 2.1941, evaluate MAE: 2.5777\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1619\n","\tbatch: 100, loss: 6.1856, MAE: 1.6665\n","\tbatch: 200, loss: 16.3843, MAE: 2.1957\n","Training:\t loss: 14.5024, MAE: 2.1589\n","Evaluating:\t loss: 21.3610, MAE: 2.0169\n","train MSE: 14.5024, evaluate MSE: 21.3610\n","\n","train MAE: 2.1589, evaluate MAE: 2.0169\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1620\n","\tbatch: 100, loss: 7.9545, MAE: 1.8886\n","\tbatch: 200, loss: 11.7439, MAE: 2.1069\n","Training:\t loss: 13.7871, MAE: 2.0576\n","Evaluating:\t loss: 17.9725, MAE: 1.9037\n","train MSE: 13.7871, evaluate MSE: 17.9725\n","\n","train MAE: 2.0576, evaluate MAE: 1.9037\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1621\n","\tbatch: 100, loss: 12.4209, MAE: 2.2481\n","\tbatch: 200, loss: 8.3440, MAE: 2.2145\n","Training:\t loss: 15.3789, MAE: 2.2085\n","Evaluating:\t loss: 21.5268, MAE: 2.2374\n","train MSE: 15.3789, evaluate MSE: 21.5268\n","\n","train MAE: 2.2085, evaluate MAE: 2.2374\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1622\n","\tbatch: 100, loss: 13.3408, MAE: 1.9801\n","\tbatch: 200, loss: 9.0476, MAE: 1.8858\n","Training:\t loss: 14.9269, MAE: 2.2168\n","Evaluating:\t loss: 15.6880, MAE: 2.0740\n","train MSE: 14.9269, evaluate MSE: 15.6880\n","\n","train MAE: 2.2168, evaluate MAE: 2.0740\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1623\n","\tbatch: 100, loss: 16.2668, MAE: 2.2059\n","\tbatch: 200, loss: 16.5049, MAE: 2.3159\n","Training:\t loss: 17.8144, MAE: 2.3221\n","Evaluating:\t loss: 24.5215, MAE: 2.4958\n","train MSE: 17.8144, evaluate MSE: 24.5215\n","\n","train MAE: 2.3221, evaluate MAE: 2.4958\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1624\n","\tbatch: 100, loss: 19.3115, MAE: 2.0226\n","\tbatch: 200, loss: 13.1756, MAE: 2.2945\n","Training:\t loss: 14.7182, MAE: 2.1726\n","Evaluating:\t loss: 23.7744, MAE: 3.1574\n","train MSE: 14.7182, evaluate MSE: 23.7744\n","\n","train MAE: 2.1726, evaluate MAE: 3.1574\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1625\n","\tbatch: 100, loss: 23.5176, MAE: 2.1331\n","\tbatch: 200, loss: 10.9267, MAE: 1.8682\n","Training:\t loss: 15.7171, MAE: 2.1672\n","Evaluating:\t loss: 14.6616, MAE: 2.0086\n","train MSE: 15.7171, evaluate MSE: 14.6616\n","\n","train MAE: 2.1672, evaluate MAE: 2.0086\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1626\n","\tbatch: 100, loss: 13.2314, MAE: 2.4153\n","\tbatch: 200, loss: 14.6321, MAE: 2.5513\n","Training:\t loss: 21.1101, MAE: 2.7355\n","Evaluating:\t loss: 24.4064, MAE: 2.4577\n","train MSE: 21.1101, evaluate MSE: 24.4064\n","\n","train MAE: 2.7355, evaluate MAE: 2.4577\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1627\n","\tbatch: 100, loss: 17.5832, MAE: 2.7629\n","\tbatch: 200, loss: 16.4257, MAE: 2.8318\n","Training:\t loss: 22.4866, MAE: 2.5737\n","Evaluating:\t loss: 21.5228, MAE: 2.3163\n","train MSE: 22.4866, evaluate MSE: 21.5228\n","\n","train MAE: 2.5737, evaluate MAE: 2.3163\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1628\n","\tbatch: 100, loss: 38.6503, MAE: 4.0587\n","\tbatch: 200, loss: 47.0120, MAE: 3.3687\n","Training:\t loss: 44.6623, MAE: 4.1091\n","Evaluating:\t loss: 309.9982, MAE: 13.1617\n","train MSE: 44.6623, evaluate MSE: 309.9982\n","\n","train MAE: 4.1091, evaluate MAE: 13.1617\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1629\n","\tbatch: 100, loss: 33.7701, MAE: 3.7941\n","\tbatch: 200, loss: 23.2287, MAE: 3.3341\n","Training:\t loss: 56.7911, MAE: 4.4696\n","Evaluating:\t loss: 26.9621, MAE: 2.8736\n","train MSE: 56.7911, evaluate MSE: 26.9621\n","\n","train MAE: 4.4696, evaluate MAE: 2.8736\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1630\n","\tbatch: 100, loss: 29.6132, MAE: 3.7269\n","\tbatch: 200, loss: 21.7778, MAE: 3.1582\n","Training:\t loss: 37.3889, MAE: 3.4753\n","Evaluating:\t loss: 25.3734, MAE: 2.5417\n","train MSE: 37.3889, evaluate MSE: 25.3734\n","\n","train MAE: 3.4753, evaluate MAE: 2.5417\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1631\n","\tbatch: 100, loss: 40.9316, MAE: 2.7966\n","\tbatch: 200, loss: 24.0928, MAE: 2.8865\n","Training:\t loss: 28.9902, MAE: 2.8420\n","Evaluating:\t loss: 22.7489, MAE: 2.5477\n","train MSE: 28.9902, evaluate MSE: 22.7489\n","\n","train MAE: 2.8420, evaluate MAE: 2.5477\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1632\n","\tbatch: 100, loss: 81.1708, MAE: 3.5461\n","\tbatch: 200, loss: 20.7454, MAE: 2.3648\n","Training:\t loss: 21.0088, MAE: 2.4282\n","Evaluating:\t loss: 15.5653, MAE: 2.3233\n","train MSE: 21.0088, evaluate MSE: 15.5653\n","\n","train MAE: 2.4282, evaluate MAE: 2.3233\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1633\n","\tbatch: 100, loss: 19.8352, MAE: 2.7203\n","\tbatch: 200, loss: 23.9220, MAE: 3.4381\n","Training:\t loss: 25.9112, MAE: 2.8753\n","Evaluating:\t loss: 21.1915, MAE: 2.7878\n","train MSE: 25.9112, evaluate MSE: 21.1915\n","\n","train MAE: 2.8753, evaluate MAE: 2.7878\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1634\n","\tbatch: 100, loss: 18.1769, MAE: 2.5002\n","\tbatch: 200, loss: 33.5567, MAE: 4.0796\n","Training:\t loss: 38.2570, MAE: 3.2807\n","Evaluating:\t loss: 57.1094, MAE: 3.7659\n","train MSE: 38.2570, evaluate MSE: 57.1094\n","\n","train MAE: 3.2807, evaluate MAE: 3.7659\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1635\n","\tbatch: 100, loss: 21.4617, MAE: 3.1895\n","\tbatch: 200, loss: 31.3592, MAE: 2.8560\n","Training:\t loss: 28.8764, MAE: 3.3435\n","Evaluating:\t loss: 23.4625, MAE: 2.9828\n","train MSE: 28.8764, evaluate MSE: 23.4625\n","\n","train MAE: 3.3435, evaluate MAE: 2.9828\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1636\n","\tbatch: 100, loss: 12.8777, MAE: 2.4735\n","\tbatch: 200, loss: 18.9831, MAE: 2.7157\n","Training:\t loss: 24.0920, MAE: 3.0344\n","Evaluating:\t loss: 24.9365, MAE: 3.2538\n","train MSE: 24.0920, evaluate MSE: 24.9365\n","\n","train MAE: 3.0344, evaluate MAE: 3.2538\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1637\n","\tbatch: 100, loss: 28.9537, MAE: 3.3091\n","\tbatch: 200, loss: 15.4612, MAE: 2.4672\n","Training:\t loss: 22.8054, MAE: 2.8681\n","Evaluating:\t loss: 20.9281, MAE: 3.0396\n","train MSE: 22.8054, evaluate MSE: 20.9281\n","\n","train MAE: 2.8681, evaluate MAE: 3.0396\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1638\n","\tbatch: 100, loss: 16.6630, MAE: 2.3356\n","\tbatch: 200, loss: 15.5896, MAE: 2.1635\n","Training:\t loss: 18.9065, MAE: 2.5632\n","Evaluating:\t loss: 16.5886, MAE: 2.4130\n","train MSE: 18.9065, evaluate MSE: 16.5886\n","\n","train MAE: 2.5632, evaluate MAE: 2.4130\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1639\n","\tbatch: 100, loss: 13.5802, MAE: 2.4626\n","\tbatch: 200, loss: 19.7507, MAE: 2.7071\n","Training:\t loss: 18.2665, MAE: 2.4123\n","Evaluating:\t loss: 17.9847, MAE: 2.3609\n","train MSE: 18.2665, evaluate MSE: 17.9847\n","\n","train MAE: 2.4123, evaluate MAE: 2.3609\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1640\n","\tbatch: 100, loss: 19.7384, MAE: 2.2983\n","\tbatch: 200, loss: 45.5602, MAE: 4.4176\n","Training:\t loss: 18.5977, MAE: 2.4968\n","Evaluating:\t loss: 15.9034, MAE: 2.3439\n","train MSE: 18.5977, evaluate MSE: 15.9034\n","\n","train MAE: 2.4968, evaluate MAE: 2.3439\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1641\n","\tbatch: 100, loss: 22.0455, MAE: 2.5143\n","\tbatch: 200, loss: 12.8430, MAE: 2.1112\n","Training:\t loss: 16.6191, MAE: 2.2899\n","Evaluating:\t loss: 14.9090, MAE: 2.0413\n","train MSE: 16.6191, evaluate MSE: 14.9090\n","\n","train MAE: 2.2899, evaluate MAE: 2.0413\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1642\n","\tbatch: 100, loss: 9.6444, MAE: 2.1429\n","\tbatch: 200, loss: 14.0126, MAE: 2.3225\n","Training:\t loss: 15.6259, MAE: 2.2328\n","Evaluating:\t loss: 15.2317, MAE: 2.2474\n","train MSE: 15.6259, evaluate MSE: 15.2317\n","\n","train MAE: 2.2328, evaluate MAE: 2.2474\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1643\n","\tbatch: 100, loss: 30.7839, MAE: 2.6866\n","\tbatch: 200, loss: 31.6365, MAE: 2.3028\n","Training:\t loss: 21.0401, MAE: 2.5380\n","Evaluating:\t loss: 25.2434, MAE: 2.8036\n","train MSE: 21.0401, evaluate MSE: 25.2434\n","\n","train MAE: 2.5380, evaluate MAE: 2.8036\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1644\n","\tbatch: 100, loss: 20.5391, MAE: 3.4428\n","\tbatch: 200, loss: 22.8971, MAE: 3.0556\n","Training:\t loss: 22.4650, MAE: 2.7076\n","Evaluating:\t loss: 25.8909, MAE: 2.3042\n","train MSE: 22.4650, evaluate MSE: 25.8909\n","\n","train MAE: 2.7076, evaluate MAE: 2.3042\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1645\n","\tbatch: 100, loss: 23.3766, MAE: 2.4170\n","\tbatch: 200, loss: 10.2435, MAE: 2.0504\n","Training:\t loss: 23.6583, MAE: 2.7121\n","Evaluating:\t loss: 21.6797, MAE: 2.7579\n","train MSE: 23.6583, evaluate MSE: 21.6797\n","\n","train MAE: 2.7121, evaluate MAE: 2.7579\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1646\n","\tbatch: 100, loss: 146.0642, MAE: 7.3879\n","\tbatch: 200, loss: 26.4610, MAE: 3.0300\n","Training:\t loss: 38.3653, MAE: 3.6698\n","Evaluating:\t loss: 25.2344, MAE: 3.3196\n","train MSE: 38.3653, evaluate MSE: 25.2344\n","\n","train MAE: 3.6698, evaluate MAE: 3.3196\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1647\n","\tbatch: 100, loss: 61.8276, MAE: 3.2059\n","\tbatch: 200, loss: 9.2509, MAE: 2.1251\n","Training:\t loss: 22.0769, MAE: 2.6273\n","Evaluating:\t loss: 18.0240, MAE: 2.5384\n","train MSE: 22.0769, evaluate MSE: 18.0240\n","\n","train MAE: 2.6273, evaluate MAE: 2.5384\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1648\n","\tbatch: 100, loss: 15.2583, MAE: 2.7034\n","\tbatch: 200, loss: 36.0923, MAE: 3.5775\n","Training:\t loss: 25.0833, MAE: 2.8242\n","Evaluating:\t loss: 43.7329, MAE: 4.3451\n","train MSE: 25.0833, evaluate MSE: 43.7329\n","\n","train MAE: 2.8242, evaluate MAE: 4.3451\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1649\n","\tbatch: 100, loss: 25.0077, MAE: 2.7452\n","\tbatch: 200, loss: 12.0490, MAE: 1.9526\n","Training:\t loss: 30.0929, MAE: 2.8527\n","Evaluating:\t loss: 23.8271, MAE: 2.6936\n","train MSE: 30.0929, evaluate MSE: 23.8271\n","\n","train MAE: 2.8527, evaluate MAE: 2.6936\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1650\n","\tbatch: 100, loss: 34.4233, MAE: 2.4046\n","\tbatch: 200, loss: 20.1569, MAE: 2.7527\n","Training:\t loss: 19.1867, MAE: 2.4129\n","Evaluating:\t loss: 22.0728, MAE: 2.9322\n","train MSE: 19.1867, evaluate MSE: 22.0728\n","\n","train MAE: 2.4129, evaluate MAE: 2.9322\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1651\n","\tbatch: 100, loss: 16.5196, MAE: 2.4702\n","\tbatch: 200, loss: 10.6891, MAE: 2.1257\n","Training:\t loss: 36.7767, MAE: 3.1231\n","Evaluating:\t loss: 66.1211, MAE: 5.2204\n","train MSE: 36.7767, evaluate MSE: 66.1211\n","\n","train MAE: 3.1231, evaluate MAE: 5.2204\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1652\n","\tbatch: 100, loss: 45.7524, MAE: 3.1160\n","\tbatch: 200, loss: 12.2592, MAE: 2.2520\n","Training:\t loss: 33.2285, MAE: 3.2646\n","Evaluating:\t loss: 21.1208, MAE: 2.4044\n","train MSE: 33.2285, evaluate MSE: 21.1208\n","\n","train MAE: 3.2646, evaluate MAE: 2.4044\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1653\n","\tbatch: 100, loss: 22.2357, MAE: 2.3092\n","\tbatch: 200, loss: 36.2730, MAE: 2.7243\n","Training:\t loss: 19.4194, MAE: 2.3678\n","Evaluating:\t loss: 33.4175, MAE: 2.4718\n","train MSE: 19.4194, evaluate MSE: 33.4175\n","\n","train MAE: 2.3678, evaluate MAE: 2.4718\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1654\n","\tbatch: 100, loss: 33.8055, MAE: 2.5940\n","\tbatch: 200, loss: 37.8670, MAE: 3.5316\n","Training:\t loss: 23.2319, MAE: 2.4638\n","Evaluating:\t loss: 28.8733, MAE: 2.6498\n","train MSE: 23.2319, evaluate MSE: 28.8733\n","\n","train MAE: 2.4638, evaluate MAE: 2.6498\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1655\n","\tbatch: 100, loss: 11.7325, MAE: 2.1438\n","\tbatch: 200, loss: 19.7371, MAE: 1.9593\n","Training:\t loss: 19.1859, MAE: 2.2368\n","Evaluating:\t loss: 17.2492, MAE: 1.9129\n","train MSE: 19.1859, evaluate MSE: 17.2492\n","\n","train MAE: 2.2368, evaluate MAE: 1.9129\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1656\n","\tbatch: 100, loss: 13.5194, MAE: 2.0021\n","\tbatch: 200, loss: 61.9532, MAE: 5.3942\n","Training:\t loss: 112.2976, MAE: 5.9981\n","Evaluating:\t loss: 47.0013, MAE: 4.1173\n","train MSE: 112.2976, evaluate MSE: 47.0013\n","\n","train MAE: 5.9981, evaluate MAE: 4.1173\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1657\n","\tbatch: 100, loss: 48.9969, MAE: 4.1719\n","\tbatch: 200, loss: 32.9069, MAE: 3.8125\n","Training:\t loss: 52.9482, MAE: 4.3552\n","Evaluating:\t loss: 52.3237, MAE: 4.0000\n","train MSE: 52.9482, evaluate MSE: 52.3237\n","\n","train MAE: 4.3552, evaluate MAE: 4.0000\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1658\n","\tbatch: 100, loss: 36.6302, MAE: 3.0769\n","\tbatch: 200, loss: 20.1860, MAE: 2.6261\n","Training:\t loss: 33.2308, MAE: 3.0920\n","Evaluating:\t loss: 49.4335, MAE: 3.2271\n","train MSE: 33.2308, evaluate MSE: 49.4335\n","\n","train MAE: 3.0920, evaluate MAE: 3.2271\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1659\n","\tbatch: 100, loss: 12.1859, MAE: 2.3382\n","\tbatch: 200, loss: 12.9589, MAE: 2.3630\n","Training:\t loss: 23.3868, MAE: 2.7048\n","Evaluating:\t loss: 20.8196, MAE: 2.4971\n","train MSE: 23.3868, evaluate MSE: 20.8196\n","\n","train MAE: 2.7048, evaluate MAE: 2.4971\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1660\n","\tbatch: 100, loss: 20.9816, MAE: 2.8316\n","\tbatch: 200, loss: 22.7456, MAE: 2.4910\n","Training:\t loss: 19.0822, MAE: 2.4675\n","Evaluating:\t loss: 22.7757, MAE: 2.3572\n","train MSE: 19.0822, evaluate MSE: 22.7757\n","\n","train MAE: 2.4675, evaluate MAE: 2.3572\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1661\n","\tbatch: 100, loss: 12.3705, MAE: 2.2601\n","\tbatch: 200, loss: 18.0304, MAE: 2.2939\n","Training:\t loss: 19.4432, MAE: 2.4686\n","Evaluating:\t loss: 19.7893, MAE: 2.4804\n","train MSE: 19.4432, evaluate MSE: 19.7893\n","\n","train MAE: 2.4686, evaluate MAE: 2.4804\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1662\n","\tbatch: 100, loss: 34.5481, MAE: 3.0220\n","\tbatch: 200, loss: 17.5985, MAE: 2.7263\n","Training:\t loss: 27.9421, MAE: 2.9843\n","Evaluating:\t loss: 19.9705, MAE: 2.3706\n","train MSE: 27.9421, evaluate MSE: 19.9705\n","\n","train MAE: 2.9843, evaluate MAE: 2.3706\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1663\n","\tbatch: 100, loss: 37.0381, MAE: 2.3553\n","\tbatch: 200, loss: 12.0432, MAE: 2.1718\n","Training:\t loss: 21.2589, MAE: 2.5014\n","Evaluating:\t loss: 28.4655, MAE: 3.4479\n","train MSE: 21.2589, evaluate MSE: 28.4655\n","\n","train MAE: 2.5014, evaluate MAE: 3.4479\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1664\n","\tbatch: 100, loss: 25.7054, MAE: 2.7177\n","\tbatch: 200, loss: 35.7248, MAE: 2.3069\n","Training:\t loss: 19.1704, MAE: 2.4465\n","Evaluating:\t loss: 16.6958, MAE: 2.0585\n","train MSE: 19.1704, evaluate MSE: 16.6958\n","\n","train MAE: 2.4465, evaluate MAE: 2.0585\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1665\n","\tbatch: 100, loss: 25.7497, MAE: 3.4608\n","\tbatch: 200, loss: 15.5113, MAE: 2.2143\n","Training:\t loss: 26.6928, MAE: 2.7419\n","Evaluating:\t loss: 24.2533, MAE: 2.8308\n","train MSE: 26.6928, evaluate MSE: 24.2533\n","\n","train MAE: 2.7419, evaluate MAE: 2.8308\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1666\n","\tbatch: 100, loss: 15.5158, MAE: 2.0924\n","\tbatch: 200, loss: 21.3850, MAE: 3.7181\n","Training:\t loss: 21.2745, MAE: 2.4412\n","Evaluating:\t loss: 20.7769, MAE: 2.5651\n","train MSE: 21.2745, evaluate MSE: 20.7769\n","\n","train MAE: 2.4412, evaluate MAE: 2.5651\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1667\n","\tbatch: 100, loss: 13.2778, MAE: 2.3529\n","\tbatch: 200, loss: 12.7803, MAE: 1.9757\n","Training:\t loss: 16.7407, MAE: 2.1724\n","Evaluating:\t loss: 24.0059, MAE: 2.5235\n","train MSE: 16.7407, evaluate MSE: 24.0059\n","\n","train MAE: 2.1724, evaluate MAE: 2.5235\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1668\n","\tbatch: 100, loss: 25.4606, MAE: 2.0979\n","\tbatch: 200, loss: 19.2725, MAE: 2.3123\n","Training:\t loss: 18.0121, MAE: 2.3164\n","Evaluating:\t loss: 25.2542, MAE: 2.5006\n","train MSE: 18.0121, evaluate MSE: 25.2542\n","\n","train MAE: 2.3164, evaluate MAE: 2.5006\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1669\n","\tbatch: 100, loss: 7.1410, MAE: 1.7285\n","\tbatch: 200, loss: 18.0893, MAE: 2.2082\n","Training:\t loss: 15.2215, MAE: 2.0799\n","Evaluating:\t loss: 16.7575, MAE: 1.8869\n","train MSE: 15.2215, evaluate MSE: 16.7575\n","\n","train MAE: 2.0799, evaluate MAE: 1.8869\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1670\n","\tbatch: 100, loss: 16.5291, MAE: 1.9811\n","\tbatch: 200, loss: 11.3054, MAE: 1.8250\n","Training:\t loss: 15.9425, MAE: 2.1381\n","Evaluating:\t loss: 16.8749, MAE: 1.8784\n","train MSE: 15.9425, evaluate MSE: 16.8749\n","\n","train MAE: 2.1381, evaluate MAE: 1.8784\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1671\n","\tbatch: 100, loss: 21.4515, MAE: 2.3376\n","\tbatch: 200, loss: 11.9167, MAE: 1.6874\n","Training:\t loss: 12.7163, MAE: 2.0065\n","Evaluating:\t loss: 17.6846, MAE: 1.8855\n","train MSE: 12.7163, evaluate MSE: 17.6846\n","\n","train MAE: 2.0065, evaluate MAE: 1.8855\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1672\n","\tbatch: 100, loss: 16.1920, MAE: 2.2845\n","\tbatch: 200, loss: 18.8227, MAE: 2.9092\n","Training:\t loss: 16.2623, MAE: 2.2772\n","Evaluating:\t loss: 16.0223, MAE: 1.9529\n","train MSE: 16.2623, evaluate MSE: 16.0223\n","\n","train MAE: 2.2772, evaluate MAE: 1.9529\n","\n","--- time consumption (s): 17\n","\n","------------------------------\n","Epoch 1673\n","\tbatch: 100, loss: 16.0861, MAE: 2.3741\n","\tbatch: 200, loss: 12.4011, MAE: 2.2509\n","Training:\t loss: 14.1893, MAE: 2.0999\n","Evaluating:\t loss: 20.6406, MAE: 2.6291\n","train MSE: 14.1893, evaluate MSE: 20.6406\n","\n","train MAE: 2.0999, evaluate MAE: 2.6291\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1674\n","\tbatch: 100, loss: 19.3923, MAE: 2.4025\n","\tbatch: 200, loss: 19.7971, MAE: 2.1882\n","Training:\t loss: 18.2832, MAE: 2.3040\n","Evaluating:\t loss: 14.8228, MAE: 2.1561\n","train MSE: 18.2832, evaluate MSE: 14.8228\n","\n","train MAE: 2.3040, evaluate MAE: 2.1561\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1675\n","\tbatch: 100, loss: 9.8528, MAE: 2.1766\n","\tbatch: 200, loss: 8.0126, MAE: 2.0034\n","Training:\t loss: 15.5351, MAE: 2.1843\n","Evaluating:\t loss: 15.8148, MAE: 2.4909\n","train MSE: 15.5351, evaluate MSE: 15.8148\n","\n","train MAE: 2.1843, evaluate MAE: 2.4909\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1676\n","\tbatch: 100, loss: 11.4388, MAE: 1.8285\n","\tbatch: 200, loss: 20.3268, MAE: 3.0237\n","Training:\t loss: 15.1291, MAE: 2.2053\n","Evaluating:\t loss: 18.1632, MAE: 2.0621\n","train MSE: 15.1291, evaluate MSE: 18.1632\n","\n","train MAE: 2.2053, evaluate MAE: 2.0621\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1677\n","\tbatch: 100, loss: 8.0872, MAE: 1.9266\n","\tbatch: 200, loss: 33.6446, MAE: 3.0651\n","Training:\t loss: 22.2371, MAE: 2.6859\n","Evaluating:\t loss: 23.9736, MAE: 2.2378\n","train MSE: 22.2371, evaluate MSE: 23.9736\n","\n","train MAE: 2.6859, evaluate MAE: 2.2378\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1678\n","\tbatch: 100, loss: 39.6907, MAE: 3.7845\n","\tbatch: 200, loss: 81.6515, MAE: 4.0354\n","Training:\t loss: 39.9577, MAE: 3.3707\n","Evaluating:\t loss: 28.1800, MAE: 2.6354\n","train MSE: 39.9577, evaluate MSE: 28.1800\n","\n","train MAE: 3.3707, evaluate MAE: 2.6354\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1679\n","\tbatch: 100, loss: 41.8756, MAE: 3.4361\n","\tbatch: 200, loss: 30.9458, MAE: 3.5558\n","Training:\t loss: 34.1481, MAE: 3.0657\n","Evaluating:\t loss: 40.1908, MAE: 2.9499\n","train MSE: 34.1481, evaluate MSE: 40.1908\n","\n","train MAE: 3.0657, evaluate MAE: 2.9499\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1680\n","\tbatch: 100, loss: 53.0878, MAE: 4.2455\n","\tbatch: 200, loss: 20.2249, MAE: 2.6780\n","Training:\t loss: 31.6904, MAE: 3.1139\n","Evaluating:\t loss: 63.3828, MAE: 3.9503\n","train MSE: 31.6904, evaluate MSE: 63.3828\n","\n","train MAE: 3.1139, evaluate MAE: 3.9503\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1681\n","\tbatch: 100, loss: 23.1047, MAE: 3.1580\n","\tbatch: 200, loss: 31.7067, MAE: 3.2987\n","Training:\t loss: 28.9004, MAE: 2.8604\n","Evaluating:\t loss: 26.8116, MAE: 2.6343\n","train MSE: 28.9004, evaluate MSE: 26.8116\n","\n","train MAE: 2.8604, evaluate MAE: 2.6343\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1682\n","\tbatch: 100, loss: 115.4311, MAE: 4.6764\n","\tbatch: 200, loss: 21.7517, MAE: 2.8434\n","Training:\t loss: 44.4795, MAE: 3.5735\n","Evaluating:\t loss: 22.8514, MAE: 2.7690\n","train MSE: 44.4795, evaluate MSE: 22.8514\n","\n","train MAE: 3.5735, evaluate MAE: 2.7690\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1683\n","\tbatch: 100, loss: 14.7253, MAE: 2.7364\n","\tbatch: 200, loss: 14.5501, MAE: 2.1207\n","Training:\t loss: 19.4687, MAE: 2.4448\n","Evaluating:\t loss: 20.6944, MAE: 2.2434\n","train MSE: 19.4687, evaluate MSE: 20.6944\n","\n","train MAE: 2.4448, evaluate MAE: 2.2434\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1684\n","\tbatch: 100, loss: 11.6494, MAE: 2.0009\n","\tbatch: 200, loss: 11.9653, MAE: 2.4510\n","Training:\t loss: 16.9258, MAE: 2.3005\n","Evaluating:\t loss: 15.2973, MAE: 2.0824\n","train MSE: 16.9258, evaluate MSE: 15.2973\n","\n","train MAE: 2.3005, evaluate MAE: 2.0824\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1685\n","\tbatch: 100, loss: 18.7692, MAE: 2.7549\n","\tbatch: 200, loss: 7.6840, MAE: 1.6951\n","Training:\t loss: 17.1275, MAE: 2.3564\n","Evaluating:\t loss: 19.3391, MAE: 2.4774\n","train MSE: 17.1275, evaluate MSE: 19.3391\n","\n","train MAE: 2.3564, evaluate MAE: 2.4774\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1686\n","\tbatch: 100, loss: 69.6767, MAE: 2.7379\n","\tbatch: 200, loss: 19.9614, MAE: 2.0764\n","Training:\t loss: 18.6245, MAE: 2.4677\n","Evaluating:\t loss: 19.2609, MAE: 2.3720\n","train MSE: 18.6245, evaluate MSE: 19.2609\n","\n","train MAE: 2.4677, evaluate MAE: 2.3720\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1687\n","\tbatch: 100, loss: 15.1970, MAE: 2.0565\n","\tbatch: 200, loss: 22.7404, MAE: 2.2957\n","Training:\t loss: 23.6810, MAE: 2.6011\n","Evaluating:\t loss: 23.0589, MAE: 3.1306\n","train MSE: 23.6810, evaluate MSE: 23.0589\n","\n","train MAE: 2.6011, evaluate MAE: 3.1306\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1688\n","\tbatch: 100, loss: 28.2906, MAE: 2.9021\n","\tbatch: 200, loss: 7.9673, MAE: 1.9203\n","Training:\t loss: 19.6077, MAE: 2.4987\n","Evaluating:\t loss: 20.1914, MAE: 3.0452\n","train MSE: 19.6077, evaluate MSE: 20.1914\n","\n","train MAE: 2.4987, evaluate MAE: 3.0452\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1689\n","\tbatch: 100, loss: 18.9161, MAE: 2.0646\n","\tbatch: 200, loss: 45.5363, MAE: 4.8638\n","Training:\t loss: 22.9527, MAE: 2.4627\n","Evaluating:\t loss: 25.9664, MAE: 2.8648\n","train MSE: 22.9527, evaluate MSE: 25.9664\n","\n","train MAE: 2.4627, evaluate MAE: 2.8648\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1690\n","\tbatch: 100, loss: 10.7865, MAE: 2.1968\n","\tbatch: 200, loss: 31.2037, MAE: 2.0584\n","Training:\t loss: 17.6545, MAE: 2.3206\n","Evaluating:\t loss: 19.1477, MAE: 2.0675\n","train MSE: 17.6545, evaluate MSE: 19.1477\n","\n","train MAE: 2.3206, evaluate MAE: 2.0675\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1691\n","\tbatch: 100, loss: 9.2392, MAE: 2.0757\n","\tbatch: 200, loss: 10.3347, MAE: 1.8121\n","Training:\t loss: 12.6160, MAE: 1.9765\n","Evaluating:\t loss: 14.4953, MAE: 2.2581\n","train MSE: 12.6160, evaluate MSE: 14.4953\n","\n","train MAE: 1.9765, evaluate MAE: 2.2581\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1692\n","\tbatch: 100, loss: 32.4286, MAE: 2.7251\n","\tbatch: 200, loss: 10.1140, MAE: 1.8093\n","Training:\t loss: 14.2958, MAE: 2.1517\n","Evaluating:\t loss: 23.6858, MAE: 1.9413\n","train MSE: 14.2958, evaluate MSE: 23.6858\n","\n","train MAE: 2.1517, evaluate MAE: 1.9413\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1693\n","\tbatch: 100, loss: 8.6679, MAE: 2.1416\n","\tbatch: 200, loss: 18.0913, MAE: 2.4191\n","Training:\t loss: 13.5756, MAE: 2.0692\n","Evaluating:\t loss: 22.1782, MAE: 2.7947\n","train MSE: 13.5756, evaluate MSE: 22.1782\n","\n","train MAE: 2.0692, evaluate MAE: 2.7947\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1694\n","\tbatch: 100, loss: 8.2137, MAE: 1.7464\n","\tbatch: 200, loss: 9.4230, MAE: 2.2048\n","Training:\t loss: 19.8361, MAE: 2.4436\n","Evaluating:\t loss: 30.3222, MAE: 2.4905\n","train MSE: 19.8361, evaluate MSE: 30.3222\n","\n","train MAE: 2.4436, evaluate MAE: 2.4905\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1695\n","\tbatch: 100, loss: 34.6622, MAE: 2.6905\n","\tbatch: 200, loss: 22.7111, MAE: 3.0158\n","Training:\t loss: 23.0489, MAE: 2.7090\n","Evaluating:\t loss: 21.3414, MAE: 2.7210\n","train MSE: 23.0489, evaluate MSE: 21.3414\n","\n","train MAE: 2.7090, evaluate MAE: 2.7210\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1696\n","\tbatch: 100, loss: 15.0167, MAE: 1.8740\n","\tbatch: 200, loss: 14.0670, MAE: 2.3017\n","Training:\t loss: 18.1896, MAE: 2.3249\n","Evaluating:\t loss: 18.5230, MAE: 1.9273\n","train MSE: 18.1896, evaluate MSE: 18.5230\n","\n","train MAE: 2.3249, evaluate MAE: 1.9273\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1697\n","\tbatch: 100, loss: 35.9306, MAE: 3.4741\n","\tbatch: 200, loss: 54.6777, MAE: 2.6779\n","Training:\t loss: 31.9280, MAE: 3.0465\n","Evaluating:\t loss: 22.9106, MAE: 2.8619\n","train MSE: 31.9280, evaluate MSE: 22.9106\n","\n","train MAE: 3.0465, evaluate MAE: 2.8619\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1698\n","\tbatch: 100, loss: 16.5972, MAE: 2.2914\n","\tbatch: 200, loss: 11.8277, MAE: 2.0245\n","Training:\t loss: 17.4321, MAE: 2.2496\n","Evaluating:\t loss: 16.9066, MAE: 2.0062\n","train MSE: 17.4321, evaluate MSE: 16.9066\n","\n","train MAE: 2.2496, evaluate MAE: 2.0062\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1699\n","\tbatch: 100, loss: 14.1776, MAE: 1.8992\n","\tbatch: 200, loss: 9.8377, MAE: 2.4114\n","Training:\t loss: 12.2907, MAE: 1.9306\n","Evaluating:\t loss: 15.2536, MAE: 1.9643\n","train MSE: 12.2907, evaluate MSE: 15.2536\n","\n","train MAE: 1.9306, evaluate MAE: 1.9643\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1700\n","\tbatch: 100, loss: 7.0188, MAE: 1.7203\n","\tbatch: 200, loss: 9.3294, MAE: 1.7613\n","Training:\t loss: 14.7523, MAE: 2.0536\n","Evaluating:\t loss: 32.9412, MAE: 3.2206\n","train MSE: 14.7523, evaluate MSE: 32.9412\n","\n","train MAE: 2.0536, evaluate MAE: 3.2206\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1701\n","\tbatch: 100, loss: 31.3166, MAE: 3.9838\n","\tbatch: 200, loss: 10.2451, MAE: 2.1735\n","Training:\t loss: 19.7628, MAE: 2.5999\n","Evaluating:\t loss: 16.0284, MAE: 1.9386\n","train MSE: 19.7628, evaluate MSE: 16.0284\n","\n","train MAE: 2.5999, evaluate MAE: 1.9386\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1702\n","\tbatch: 100, loss: 10.6217, MAE: 1.7833\n","\tbatch: 200, loss: 45.9655, MAE: 3.5910\n","Training:\t loss: 31.0987, MAE: 2.9738\n","Evaluating:\t loss: 54.4148, MAE: 4.4204\n","train MSE: 31.0987, evaluate MSE: 54.4148\n","\n","train MAE: 2.9738, evaluate MAE: 4.4204\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1703\n","\tbatch: 100, loss: 29.8134, MAE: 2.6449\n","\tbatch: 200, loss: 17.4268, MAE: 2.1763\n","Training:\t loss: 32.6192, MAE: 2.7654\n","Evaluating:\t loss: 22.1438, MAE: 2.3302\n","train MSE: 32.6192, evaluate MSE: 22.1438\n","\n","train MAE: 2.7654, evaluate MAE: 2.3302\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1704\n","\tbatch: 100, loss: 17.3964, MAE: 2.2545\n","\tbatch: 200, loss: 20.2209, MAE: 2.5230\n","Training:\t loss: 32.0943, MAE: 2.9333\n","Evaluating:\t loss: 23.2445, MAE: 2.3014\n","train MSE: 32.0943, evaluate MSE: 23.2445\n","\n","train MAE: 2.9333, evaluate MAE: 2.3014\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1705\n","\tbatch: 100, loss: 17.8547, MAE: 2.3227\n","\tbatch: 200, loss: 20.0177, MAE: 3.0080\n","Training:\t loss: 18.9268, MAE: 2.3639\n","Evaluating:\t loss: 27.6180, MAE: 3.1296\n","train MSE: 18.9268, evaluate MSE: 27.6180\n","\n","train MAE: 2.3639, evaluate MAE: 3.1296\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1706\n","\tbatch: 100, loss: 14.1771, MAE: 2.1702\n","\tbatch: 200, loss: 32.6261, MAE: 3.0270\n","Training:\t loss: 17.2159, MAE: 2.2781\n","Evaluating:\t loss: 18.7438, MAE: 2.3499\n","train MSE: 17.2159, evaluate MSE: 18.7438\n","\n","train MAE: 2.2781, evaluate MAE: 2.3499\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1707\n","\tbatch: 100, loss: 6.9461, MAE: 1.6696\n","\tbatch: 200, loss: 13.5093, MAE: 1.7856\n","Training:\t loss: 16.9107, MAE: 2.3425\n","Evaluating:\t loss: 20.5965, MAE: 2.2798\n","train MSE: 16.9107, evaluate MSE: 20.5965\n","\n","train MAE: 2.3425, evaluate MAE: 2.2798\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1708\n","\tbatch: 100, loss: 47.0107, MAE: 2.5814\n","\tbatch: 200, loss: 7.8180, MAE: 1.8607\n","Training:\t loss: 15.6617, MAE: 2.1822\n","Evaluating:\t loss: 13.6503, MAE: 1.8038\n","train MSE: 15.6617, evaluate MSE: 13.6503\n","\n","train MAE: 2.1822, evaluate MAE: 1.8038\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1709\n","\tbatch: 100, loss: 22.5635, MAE: 2.8494\n","\tbatch: 200, loss: 17.2067, MAE: 2.3850\n","Training:\t loss: 20.5563, MAE: 2.2731\n","Evaluating:\t loss: 20.0687, MAE: 1.9453\n","train MSE: 20.5563, evaluate MSE: 20.0687\n","\n","train MAE: 2.2731, evaluate MAE: 1.9453\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1710\n","\tbatch: 100, loss: 13.9779, MAE: 2.7066\n","\tbatch: 200, loss: 56.2867, MAE: 2.7912\n","Training:\t loss: 28.3333, MAE: 2.5942\n","Evaluating:\t loss: 40.7604, MAE: 2.4993\n","train MSE: 28.3333, evaluate MSE: 40.7604\n","\n","train MAE: 2.5942, evaluate MAE: 2.4993\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1711\n","\tbatch: 100, loss: 19.8857, MAE: 2.8180\n","\tbatch: 200, loss: 18.8031, MAE: 2.1601\n","Training:\t loss: 42.9920, MAE: 3.1180\n","Evaluating:\t loss: 32.4165, MAE: 2.2940\n","train MSE: 42.9920, evaluate MSE: 32.4165\n","\n","train MAE: 3.1180, evaluate MAE: 2.2940\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1712\n","\tbatch: 100, loss: 24.6137, MAE: 2.5299\n","\tbatch: 200, loss: 8.6432, MAE: 2.0150\n","Training:\t loss: 32.6655, MAE: 2.5078\n","Evaluating:\t loss: 29.2165, MAE: 2.0737\n","train MSE: 32.6655, evaluate MSE: 29.2165\n","\n","train MAE: 2.5078, evaluate MAE: 2.0737\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1713\n","\tbatch: 100, loss: 27.9091, MAE: 2.3366\n","\tbatch: 200, loss: 11.7030, MAE: 2.0839\n","Training:\t loss: 26.9620, MAE: 2.2922\n","Evaluating:\t loss: 37.1139, MAE: 2.6420\n","train MSE: 26.9620, evaluate MSE: 37.1139\n","\n","train MAE: 2.2922, evaluate MAE: 2.6420\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1714\n","\tbatch: 100, loss: 31.4173, MAE: 2.3464\n","\tbatch: 200, loss: 18.2889, MAE: 3.2749\n","Training:\t loss: 49.3316, MAE: 2.5957\n","Evaluating:\t loss: 132.2422, MAE: 4.8842\n","train MSE: 49.3316, evaluate MSE: 132.2422\n","\n","train MAE: 2.5957, evaluate MAE: 4.8842\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1715\n","\tbatch: 100, loss: 29.2143, MAE: 3.5589\n","\tbatch: 200, loss: 21.8593, MAE: 2.9966\n","Training:\t loss: 126.8336, MAE: 4.5002\n","Evaluating:\t loss: 56.8117, MAE: 3.3141\n","train MSE: 126.8336, evaluate MSE: 56.8117\n","\n","train MAE: 4.5002, evaluate MAE: 3.3141\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1716\n","\tbatch: 100, loss: 210.3464, MAE: 5.0575\n","\tbatch: 200, loss: 78.4275, MAE: 4.9784\n","Training:\t loss: 70.8666, MAE: 4.7550\n","Evaluating:\t loss: 52.7944, MAE: 4.5525\n","train MSE: 70.8666, evaluate MSE: 52.7944\n","\n","train MAE: 4.7550, evaluate MAE: 4.5525\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1717\n","\tbatch: 100, loss: 32.2006, MAE: 3.8309\n","\tbatch: 200, loss: 79.9003, MAE: 3.3490\n","Training:\t loss: 46.9464, MAE: 3.4638\n","Evaluating:\t loss: 29.4306, MAE: 2.5307\n","train MSE: 46.9464, evaluate MSE: 29.4306\n","\n","train MAE: 3.4638, evaluate MAE: 2.5307\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1718\n","\tbatch: 100, loss: 25.4559, MAE: 2.3559\n","\tbatch: 200, loss: 14.5547, MAE: 3.0536\n","Training:\t loss: 26.1736, MAE: 2.6349\n","Evaluating:\t loss: 23.8409, MAE: 2.7613\n","train MSE: 26.1736, evaluate MSE: 23.8409\n","\n","train MAE: 2.6349, evaluate MAE: 2.7613\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1719\n","\tbatch: 100, loss: 49.9961, MAE: 2.4485\n","\tbatch: 200, loss: 24.1793, MAE: 2.7924\n","Training:\t loss: 31.0845, MAE: 2.7435\n","Evaluating:\t loss: 23.2498, MAE: 2.5970\n","train MSE: 31.0845, evaluate MSE: 23.2498\n","\n","train MAE: 2.7435, evaluate MAE: 2.5970\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1720\n","\tbatch: 100, loss: 10.2972, MAE: 1.9377\n","\tbatch: 200, loss: 12.8069, MAE: 2.2752\n","Training:\t loss: 23.5835, MAE: 2.4450\n","Evaluating:\t loss: 24.5679, MAE: 2.6691\n","train MSE: 23.5835, evaluate MSE: 24.5679\n","\n","train MAE: 2.4450, evaluate MAE: 2.6691\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1721\n","\tbatch: 100, loss: 19.7057, MAE: 2.9435\n","\tbatch: 200, loss: 720.5984, MAE: 7.1247\n","Training:\t loss: 124.4220, MAE: 5.0484\n","Evaluating:\t loss: 118.7552, MAE: 6.4713\n","train MSE: 124.4220, evaluate MSE: 118.7552\n","\n","train MAE: 5.0484, evaluate MAE: 6.4713\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1722\n","\tbatch: 100, loss: 59.0402, MAE: 3.6015\n","\tbatch: 200, loss: 113.8322, MAE: 4.0086\n","Training:\t loss: 124.3575, MAE: 4.1509\n","Evaluating:\t loss: 87.3229, MAE: 4.9980\n","train MSE: 124.3575, evaluate MSE: 87.3229\n","\n","train MAE: 4.1509, evaluate MAE: 4.9980\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1723\n","\tbatch: 100, loss: 41.8615, MAE: 3.9213\n","\tbatch: 200, loss: 33.0808, MAE: 3.0064\n","Training:\t loss: 110.0434, MAE: 3.6283\n","Evaluating:\t loss: 72.4661, MAE: 3.3018\n","train MSE: 110.0434, evaluate MSE: 72.4661\n","\n","train MAE: 3.6283, evaluate MAE: 3.3018\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1724\n","\tbatch: 100, loss: 41.7426, MAE: 2.9410\n","\tbatch: 200, loss: 58.7674, MAE: 2.8682\n","Training:\t loss: 149.0303, MAE: 4.8063\n","Evaluating:\t loss: 299.5497, MAE: 13.2288\n","train MSE: 149.0303, evaluate MSE: 299.5497\n","\n","train MAE: 4.8063, evaluate MAE: 13.2288\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1725\n","\tbatch: 100, loss: 546.9468, MAE: 4.6112\n","\tbatch: 200, loss: 541.2871, MAE: 4.3273\n","Training:\t loss: 111.5468, MAE: 4.1606\n","Evaluating:\t loss: 63.6022, MAE: 3.2878\n","train MSE: 111.5468, evaluate MSE: 63.6022\n","\n","train MAE: 4.1606, evaluate MAE: 3.2878\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1726\n","\tbatch: 100, loss: 485.1241, MAE: 3.9325\n","\tbatch: 200, loss: 22.2526, MAE: 2.7209\n","Training:\t loss: 93.2811, MAE: 3.2243\n","Evaluating:\t loss: 59.5520, MAE: 2.9529\n","train MSE: 93.2811, evaluate MSE: 59.5520\n","\n","train MAE: 3.2243, evaluate MAE: 2.9529\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1727\n","\tbatch: 100, loss: 32.2848, MAE: 2.8364\n","\tbatch: 200, loss: 41.2393, MAE: 2.7752\n","Training:\t loss: 87.8832, MAE: 2.9727\n","Evaluating:\t loss: 60.0666, MAE: 2.9783\n","train MSE: 87.8832, evaluate MSE: 60.0666\n","\n","train MAE: 2.9727, evaluate MAE: 2.9783\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1728\n","\tbatch: 100, loss: 18.3712, MAE: 2.4804\n","\tbatch: 200, loss: 26.2008, MAE: 2.4884\n","Training:\t loss: 82.3746, MAE: 2.7785\n","Evaluating:\t loss: 57.8599, MAE: 3.6417\n","train MSE: 82.3746, evaluate MSE: 57.8599\n","\n","train MAE: 2.7785, evaluate MAE: 3.6417\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1729\n","\tbatch: 100, loss: 11.5849, MAE: 2.2646\n","\tbatch: 200, loss: 58.1343, MAE: 4.4869\n","Training:\t loss: 81.4729, MAE: 2.9367\n","Evaluating:\t loss: 100.6960, MAE: 6.2260\n","train MSE: 81.4729, evaluate MSE: 100.6960\n","\n","train MAE: 2.9367, evaluate MAE: 6.2260\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1730\n","\tbatch: 100, loss: 19.8611, MAE: 3.2406\n","\tbatch: 200, loss: 38.5421, MAE: 3.6631\n","Training:\t loss: 92.3017, MAE: 3.5676\n","Evaluating:\t loss: 57.9149, MAE: 2.8758\n","train MSE: 92.3017, evaluate MSE: 57.9149\n","\n","train MAE: 3.5676, evaluate MAE: 2.8758\n","\n","--- time consumption (s): 17\n","\n","------------------------------\n","Epoch 1731\n","\tbatch: 100, loss: 30.1375, MAE: 3.2517\n","\tbatch: 200, loss: 27.9699, MAE: 3.0171\n","Training:\t loss: 83.7835, MAE: 3.0186\n","Evaluating:\t loss: 54.7529, MAE: 2.5471\n","train MSE: 83.7835, evaluate MSE: 54.7529\n","\n","train MAE: 3.0186, evaluate MAE: 2.5471\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1732\n","\tbatch: 100, loss: 457.0427, MAE: 3.8199\n","\tbatch: 200, loss: 426.4756, MAE: 2.9790\n","Training:\t loss: 84.1607, MAE: 3.1130\n","Evaluating:\t loss: 53.7550, MAE: 2.2233\n","train MSE: 84.1607, evaluate MSE: 53.7550\n","\n","train MAE: 3.1130, evaluate MAE: 2.2233\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1733\n","\tbatch: 100, loss: 17.8014, MAE: 2.5219\n","\tbatch: 200, loss: 13.8724, MAE: 2.6437\n","Training:\t loss: 75.5351, MAE: 2.6738\n","Evaluating:\t loss: 54.3019, MAE: 2.5149\n","train MSE: 75.5351, evaluate MSE: 54.3019\n","\n","train MAE: 2.6738, evaluate MAE: 2.5149\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1734\n","\tbatch: 100, loss: 38.6587, MAE: 4.1412\n","\tbatch: 200, loss: 15.6433, MAE: 2.6739\n","Training:\t loss: 79.2535, MAE: 3.0336\n","Evaluating:\t loss: 57.5089, MAE: 2.9166\n","train MSE: 79.2535, evaluate MSE: 57.5089\n","\n","train MAE: 3.0336, evaluate MAE: 2.9166\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1735\n","\tbatch: 100, loss: 14.7413, MAE: 2.0978\n","\tbatch: 200, loss: 365.2721, MAE: 3.7961\n","Training:\t loss: 76.1176, MAE: 2.9000\n","Evaluating:\t loss: 64.1774, MAE: 2.9483\n","train MSE: 76.1176, evaluate MSE: 64.1774\n","\n","train MAE: 2.9000, evaluate MAE: 2.9483\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1736\n","\tbatch: 100, loss: 22.9052, MAE: 2.3496\n","\tbatch: 200, loss: 25.7098, MAE: 3.5927\n","Training:\t loss: 75.1827, MAE: 2.6760\n","Evaluating:\t loss: 56.1158, MAE: 3.2103\n","train MSE: 75.1827, evaluate MSE: 56.1158\n","\n","train MAE: 2.6760, evaluate MAE: 3.2103\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1737\n","\tbatch: 100, loss: 45.4194, MAE: 3.7548\n","\tbatch: 200, loss: 76.7953, MAE: 5.7580\n","Training:\t loss: 112.6707, MAE: 4.2360\n","Evaluating:\t loss: 78.4625, MAE: 3.8815\n","train MSE: 112.6707, evaluate MSE: 78.4625\n","\n","train MAE: 4.2360, evaluate MAE: 3.8815\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1738\n","\tbatch: 100, loss: 73.5164, MAE: 4.0023\n","\tbatch: 200, loss: 34.8284, MAE: 3.4210\n","Training:\t loss: 96.3210, MAE: 3.8862\n","Evaluating:\t loss: 65.6098, MAE: 3.0994\n","train MSE: 96.3210, evaluate MSE: 65.6098\n","\n","train MAE: 3.8862, evaluate MAE: 3.0994\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1739\n","\tbatch: 100, loss: 21.4343, MAE: 2.7989\n","\tbatch: 200, loss: 24.6848, MAE: 2.9361\n","Training:\t loss: 84.6996, MAE: 3.3240\n","Evaluating:\t loss: 58.0868, MAE: 3.0586\n","train MSE: 84.6996, evaluate MSE: 58.0868\n","\n","train MAE: 3.3240, evaluate MAE: 3.0586\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1740\n","\tbatch: 100, loss: 1051.9928, MAE: 4.7935\n","\tbatch: 200, loss: 24.7435, MAE: 3.1852\n","Training:\t loss: 90.2024, MAE: 3.7649\n","Evaluating:\t loss: 39.3083, MAE: 3.0623\n","train MSE: 90.2024, evaluate MSE: 39.3083\n","\n","train MAE: 3.7649, evaluate MAE: 3.0623\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1741\n","\tbatch: 100, loss: 36.0395, MAE: 2.5900\n","\tbatch: 200, loss: 239.7935, MAE: 5.8584\n","Training:\t loss: 48.1901, MAE: 3.4378\n","Evaluating:\t loss: 62.7141, MAE: 4.1168\n","train MSE: 48.1901, evaluate MSE: 62.7141\n","\n","train MAE: 3.4378, evaluate MAE: 4.1168\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1742\n","\tbatch: 100, loss: 59.9404, MAE: 3.2217\n","\tbatch: 200, loss: 22.4715, MAE: 2.1937\n","Training:\t loss: 35.7053, MAE: 2.9750\n","Evaluating:\t loss: 26.8652, MAE: 2.2456\n","train MSE: 35.7053, evaluate MSE: 26.8652\n","\n","train MAE: 2.9750, evaluate MAE: 2.2456\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1743\n","\tbatch: 100, loss: 25.7031, MAE: 2.5444\n","\tbatch: 200, loss: 19.0586, MAE: 2.4129\n","Training:\t loss: 26.6576, MAE: 2.4435\n","Evaluating:\t loss: 28.9472, MAE: 2.3177\n","train MSE: 26.6576, evaluate MSE: 28.9472\n","\n","train MAE: 2.4435, evaluate MAE: 2.3177\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1744\n","\tbatch: 100, loss: 26.4584, MAE: 2.4857\n","\tbatch: 200, loss: 12.7766, MAE: 1.9260\n","Training:\t loss: 22.4249, MAE: 2.2743\n","Evaluating:\t loss: 22.2146, MAE: 1.7927\n","train MSE: 22.4249, evaluate MSE: 22.2146\n","\n","train MAE: 2.2743, evaluate MAE: 1.7927\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1745\n","\tbatch: 100, loss: 33.8772, MAE: 2.6954\n","\tbatch: 200, loss: 10.3601, MAE: 2.0392\n","Training:\t loss: 21.4963, MAE: 2.2154\n","Evaluating:\t loss: 45.1018, MAE: 4.5276\n","train MSE: 21.4963, evaluate MSE: 45.1018\n","\n","train MAE: 2.2154, evaluate MAE: 4.5276\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1746\n","\tbatch: 100, loss: 11.3940, MAE: 2.0422\n","\tbatch: 200, loss: 16.8789, MAE: 2.7051\n","Training:\t loss: 27.2172, MAE: 2.8703\n","Evaluating:\t loss: 21.7578, MAE: 2.2282\n","train MSE: 27.2172, evaluate MSE: 21.7578\n","\n","train MAE: 2.8703, evaluate MAE: 2.2282\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1747\n","\tbatch: 100, loss: 19.1039, MAE: 2.8208\n","\tbatch: 200, loss: 17.6438, MAE: 2.3494\n","Training:\t loss: 28.4766, MAE: 3.0327\n","Evaluating:\t loss: 34.7805, MAE: 3.4074\n","train MSE: 28.4766, evaluate MSE: 34.7805\n","\n","train MAE: 3.0327, evaluate MAE: 3.4074\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1748\n","\tbatch: 100, loss: 12.4463, MAE: 2.0489\n","\tbatch: 200, loss: 40.0073, MAE: 4.9633\n","Training:\t loss: 35.4127, MAE: 3.0283\n","Evaluating:\t loss: 29.9279, MAE: 2.9780\n","train MSE: 35.4127, evaluate MSE: 29.9279\n","\n","train MAE: 3.0283, evaluate MAE: 2.9780\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1749\n","\tbatch: 100, loss: 50.1151, MAE: 4.6133\n","\tbatch: 200, loss: 36.1239, MAE: 3.1620\n","Training:\t loss: 34.2685, MAE: 2.9599\n","Evaluating:\t loss: 26.5700, MAE: 3.3307\n","train MSE: 34.2685, evaluate MSE: 26.5700\n","\n","train MAE: 2.9599, evaluate MAE: 3.3307\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1750\n","\tbatch: 100, loss: 19.3791, MAE: 2.8685\n","\tbatch: 200, loss: 67.3979, MAE: 5.5810\n","Training:\t loss: 38.3765, MAE: 3.1331\n","Evaluating:\t loss: 42.3109, MAE: 3.6241\n","train MSE: 38.3765, evaluate MSE: 42.3109\n","\n","train MAE: 3.1331, evaluate MAE: 3.6241\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1751\n","\tbatch: 100, loss: 32.6260, MAE: 3.2169\n","\tbatch: 200, loss: 39.7902, MAE: 3.7233\n","Training:\t loss: 37.9434, MAE: 3.3736\n","Evaluating:\t loss: 29.2813, MAE: 2.7466\n","train MSE: 37.9434, evaluate MSE: 29.2813\n","\n","train MAE: 3.3736, evaluate MAE: 2.7466\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1752\n","\tbatch: 100, loss: 28.1145, MAE: 2.5344\n","\tbatch: 200, loss: 12.2251, MAE: 2.5295\n","Training:\t loss: 33.3799, MAE: 2.8225\n","Evaluating:\t loss: 221.1306, MAE: 9.7522\n","train MSE: 33.3799, evaluate MSE: 221.1306\n","\n","train MAE: 2.8225, evaluate MAE: 9.7522\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1753\n","\tbatch: 100, loss: 48.6369, MAE: 3.8274\n","\tbatch: 200, loss: 33.6881, MAE: 4.3523\n","Training:\t loss: 56.9836, MAE: 4.2618\n","Evaluating:\t loss: 38.7225, MAE: 3.2750\n","train MSE: 56.9836, evaluate MSE: 38.7225\n","\n","train MAE: 4.2618, evaluate MAE: 3.2750\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1754\n","\tbatch: 100, loss: 15.6656, MAE: 2.5060\n","\tbatch: 200, loss: 85.7387, MAE: 3.9504\n","Training:\t loss: 32.2233, MAE: 3.0994\n","Evaluating:\t loss: 30.5099, MAE: 3.0869\n","train MSE: 32.2233, evaluate MSE: 30.5099\n","\n","train MAE: 3.0994, evaluate MAE: 3.0869\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1755\n","\tbatch: 100, loss: 93.5147, MAE: 2.8980\n","\tbatch: 200, loss: 32.8520, MAE: 2.6281\n","Training:\t loss: 22.6093, MAE: 2.6088\n","Evaluating:\t loss: 22.2168, MAE: 2.6402\n","train MSE: 22.6093, evaluate MSE: 22.2168\n","\n","train MAE: 2.6088, evaluate MAE: 2.6402\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1756\n","\tbatch: 100, loss: 40.2594, MAE: 3.1182\n","\tbatch: 200, loss: 96.6250, MAE: 3.9427\n","Training:\t loss: 40.9872, MAE: 3.3672\n","Evaluating:\t loss: 25.8805, MAE: 3.1101\n","train MSE: 40.9872, evaluate MSE: 25.8805\n","\n","train MAE: 3.3672, evaluate MAE: 3.1101\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1757\n","\tbatch: 100, loss: 27.2826, MAE: 2.5839\n","\tbatch: 200, loss: 43.4188, MAE: 4.8674\n","Training:\t loss: 29.6811, MAE: 3.1874\n","Evaluating:\t loss: 32.5868, MAE: 3.5102\n","train MSE: 29.6811, evaluate MSE: 32.5868\n","\n","train MAE: 3.1874, evaluate MAE: 3.5102\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1758\n","\tbatch: 100, loss: 40.2071, MAE: 3.8343\n","\tbatch: 200, loss: 17.2254, MAE: 2.7369\n","Training:\t loss: 33.4620, MAE: 3.2283\n","Evaluating:\t loss: 20.2095, MAE: 2.5540\n","train MSE: 33.4620, evaluate MSE: 20.2095\n","\n","train MAE: 3.2283, evaluate MAE: 2.5540\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1759\n","\tbatch: 100, loss: 25.6107, MAE: 3.1301\n","\tbatch: 200, loss: 123.5462, MAE: 6.5063\n","Training:\t loss: 57.8862, MAE: 4.3078\n","Evaluating:\t loss: 152.9855, MAE: 9.1217\n","train MSE: 57.8862, evaluate MSE: 152.9855\n","\n","train MAE: 4.3078, evaluate MAE: 9.1217\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1760\n","\tbatch: 100, loss: 53.8155, MAE: 4.2011\n","\tbatch: 200, loss: 35.1887, MAE: 3.6790\n","Training:\t loss: 56.8702, MAE: 4.8497\n","Evaluating:\t loss: 38.9873, MAE: 3.9073\n","train MSE: 56.8702, evaluate MSE: 38.9873\n","\n","train MAE: 4.8497, evaluate MAE: 3.9073\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1761\n","\tbatch: 100, loss: 45.4538, MAE: 4.7174\n","\tbatch: 200, loss: 34.1012, MAE: 2.9715\n","Training:\t loss: 34.3510, MAE: 3.2796\n","Evaluating:\t loss: 26.2927, MAE: 2.9291\n","train MSE: 34.3510, evaluate MSE: 26.2927\n","\n","train MAE: 3.2796, evaluate MAE: 2.9291\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1762\n","\tbatch: 100, loss: 32.6591, MAE: 3.0554\n","\tbatch: 200, loss: 14.7683, MAE: 2.2116\n","Training:\t loss: 29.7101, MAE: 2.9544\n","Evaluating:\t loss: 24.7831, MAE: 2.5378\n","train MSE: 29.7101, evaluate MSE: 24.7831\n","\n","train MAE: 2.9544, evaluate MAE: 2.5378\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1763\n","\tbatch: 100, loss: 15.9908, MAE: 2.2106\n","\tbatch: 200, loss: 19.5725, MAE: 2.3919\n","Training:\t loss: 19.8263, MAE: 2.4437\n","Evaluating:\t loss: 18.4881, MAE: 2.3399\n","train MSE: 19.8263, evaluate MSE: 18.4881\n","\n","train MAE: 2.4437, evaluate MAE: 2.3399\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1764\n","\tbatch: 100, loss: 16.7686, MAE: 2.5846\n","\tbatch: 200, loss: 11.1892, MAE: 2.3069\n","Training:\t loss: 22.0902, MAE: 2.3912\n","Evaluating:\t loss: 19.3760, MAE: 2.0497\n","train MSE: 22.0902, evaluate MSE: 19.3760\n","\n","train MAE: 2.3912, evaluate MAE: 2.0497\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1765\n","\tbatch: 100, loss: 10.3620, MAE: 1.9372\n","\tbatch: 200, loss: 56.4653, MAE: 3.9334\n","Training:\t loss: 52.9118, MAE: 3.7426\n","Evaluating:\t loss: 92.9373, MAE: 5.0076\n","train MSE: 52.9118, evaluate MSE: 92.9373\n","\n","train MAE: 3.7426, evaluate MAE: 5.0076\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1766\n","\tbatch: 100, loss: 24.3018, MAE: 2.8743\n","\tbatch: 200, loss: 18.6783, MAE: 2.5817\n","Training:\t loss: 34.9124, MAE: 3.1190\n","Evaluating:\t loss: 27.5639, MAE: 3.4785\n","train MSE: 34.9124, evaluate MSE: 27.5639\n","\n","train MAE: 3.1190, evaluate MAE: 3.4785\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1767\n","\tbatch: 100, loss: 16.1380, MAE: 2.6133\n","\tbatch: 200, loss: 19.8893, MAE: 3.0024\n","Training:\t loss: 149.3401, MAE: 5.3653\n","Evaluating:\t loss: 195.8372, MAE: 10.8931\n","train MSE: 149.3401, evaluate MSE: 195.8372\n","\n","train MAE: 5.3653, evaluate MAE: 10.8931\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1768\n","\tbatch: 100, loss: 43.7370, MAE: 4.5990\n","\tbatch: 200, loss: 27.3397, MAE: 3.6946\n","Training:\t loss: 60.1147, MAE: 5.1813\n","Evaluating:\t loss: 41.1179, MAE: 4.1570\n","train MSE: 60.1147, evaluate MSE: 41.1179\n","\n","train MAE: 5.1813, evaluate MAE: 4.1570\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1769\n","\tbatch: 100, loss: 25.8839, MAE: 3.4280\n","\tbatch: 200, loss: 20.9566, MAE: 3.0063\n","Training:\t loss: 30.7167, MAE: 3.4130\n","Evaluating:\t loss: 24.9339, MAE: 2.8763\n","train MSE: 30.7167, evaluate MSE: 24.9339\n","\n","train MAE: 3.4130, evaluate MAE: 2.8763\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1770\n","\tbatch: 100, loss: 24.1074, MAE: 3.2336\n","\tbatch: 200, loss: 26.0212, MAE: 3.1473\n","Training:\t loss: 26.0654, MAE: 2.9557\n","Evaluating:\t loss: 25.1924, MAE: 2.8332\n","train MSE: 26.0654, evaluate MSE: 25.1924\n","\n","train MAE: 2.9557, evaluate MAE: 2.8332\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1771\n","\tbatch: 100, loss: 18.5262, MAE: 2.6789\n","\tbatch: 200, loss: 13.2501, MAE: 2.4147\n","Training:\t loss: 20.5423, MAE: 2.6519\n","Evaluating:\t loss: 20.8257, MAE: 2.5627\n","train MSE: 20.5423, evaluate MSE: 20.8257\n","\n","train MAE: 2.6519, evaluate MAE: 2.5627\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1772\n","\tbatch: 100, loss: 23.2208, MAE: 2.8808\n","\tbatch: 200, loss: 17.5737, MAE: 2.5207\n","Training:\t loss: 25.3455, MAE: 2.7615\n","Evaluating:\t loss: 33.6229, MAE: 2.9579\n","train MSE: 25.3455, evaluate MSE: 33.6229\n","\n","train MAE: 2.7615, evaluate MAE: 2.9579\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1773\n","\tbatch: 100, loss: 18.1278, MAE: 2.5180\n","\tbatch: 200, loss: 16.7553, MAE: 2.4031\n","Training:\t loss: 23.5840, MAE: 2.6111\n","Evaluating:\t loss: 27.7274, MAE: 2.8230\n","train MSE: 23.5840, evaluate MSE: 27.7274\n","\n","train MAE: 2.6111, evaluate MAE: 2.8230\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1774\n","\tbatch: 100, loss: 24.4645, MAE: 2.5728\n","\tbatch: 200, loss: 29.1742, MAE: 3.1291\n","Training:\t loss: 23.5068, MAE: 2.6500\n","Evaluating:\t loss: 25.7799, MAE: 2.9214\n","train MSE: 23.5068, evaluate MSE: 25.7799\n","\n","train MAE: 2.6500, evaluate MAE: 2.9214\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1775\n","\tbatch: 100, loss: 16.5854, MAE: 2.4256\n","\tbatch: 200, loss: 24.8247, MAE: 2.3459\n","Training:\t loss: 19.9983, MAE: 2.4445\n","Evaluating:\t loss: 29.2638, MAE: 2.5566\n","train MSE: 19.9983, evaluate MSE: 29.2638\n","\n","train MAE: 2.4445, evaluate MAE: 2.5566\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1776\n","\tbatch: 100, loss: 13.4652, MAE: 2.2237\n","\tbatch: 200, loss: 31.5383, MAE: 2.8975\n","Training:\t loss: 22.8177, MAE: 2.5863\n","Evaluating:\t loss: 46.3010, MAE: 3.7640\n","train MSE: 22.8177, evaluate MSE: 46.3010\n","\n","train MAE: 2.5863, evaluate MAE: 3.7640\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1777\n","\tbatch: 100, loss: 11.0336, MAE: 2.1322\n","\tbatch: 200, loss: 208.0283, MAE: 9.8551\n","Training:\t loss: 68.3790, MAE: 4.1234\n","Evaluating:\t loss: 166.3482, MAE: 6.7822\n","train MSE: 68.3790, evaluate MSE: 166.3482\n","\n","train MAE: 4.1234, evaluate MAE: 6.7822\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1778\n","\tbatch: 100, loss: 31.8038, MAE: 3.9487\n","\tbatch: 200, loss: 56.0617, MAE: 4.8599\n","Training:\t loss: 122.1554, MAE: 5.3799\n","Evaluating:\t loss: 41.6299, MAE: 3.9319\n","train MSE: 122.1554, evaluate MSE: 41.6299\n","\n","train MAE: 5.3799, evaluate MAE: 3.9319\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1779\n","\tbatch: 100, loss: 22.3184, MAE: 2.9770\n","\tbatch: 200, loss: 33.8810, MAE: 3.2717\n","Training:\t loss: 42.3615, MAE: 3.2363\n","Evaluating:\t loss: 54.5174, MAE: 3.8782\n","train MSE: 42.3615, evaluate MSE: 54.5174\n","\n","train MAE: 3.2363, evaluate MAE: 3.8782\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1780\n","\tbatch: 100, loss: 12.8414, MAE: 2.3617\n","\tbatch: 200, loss: 19.0006, MAE: 2.3450\n","Training:\t loss: 32.1931, MAE: 2.9982\n","Evaluating:\t loss: 37.5867, MAE: 3.1183\n","train MSE: 32.1931, evaluate MSE: 37.5867\n","\n","train MAE: 2.9982, evaluate MAE: 3.1183\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1781\n","\tbatch: 100, loss: 27.0046, MAE: 3.3229\n","\tbatch: 200, loss: 38.7343, MAE: 2.7994\n","Training:\t loss: 34.0245, MAE: 3.1596\n","Evaluating:\t loss: 30.3830, MAE: 3.6304\n","train MSE: 34.0245, evaluate MSE: 30.3830\n","\n","train MAE: 3.1596, evaluate MAE: 3.6304\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1782\n","\tbatch: 100, loss: 29.6224, MAE: 2.5923\n","\tbatch: 200, loss: 45.1085, MAE: 2.9467\n","Training:\t loss: 27.6421, MAE: 2.8375\n","Evaluating:\t loss: 34.3646, MAE: 3.4004\n","train MSE: 27.6421, evaluate MSE: 34.3646\n","\n","train MAE: 2.8375, evaluate MAE: 3.4004\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1783\n","\tbatch: 100, loss: 19.4756, MAE: 2.9474\n","\tbatch: 200, loss: 19.1060, MAE: 2.6865\n","Training:\t loss: 26.1212, MAE: 2.8448\n","Evaluating:\t loss: 30.7989, MAE: 2.8237\n","train MSE: 26.1212, evaluate MSE: 30.7989\n","\n","train MAE: 2.8448, evaluate MAE: 2.8237\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1784\n","\tbatch: 100, loss: 43.0818, MAE: 3.8324\n","\tbatch: 200, loss: 15.3716, MAE: 2.7188\n","Training:\t loss: 25.0509, MAE: 2.8673\n","Evaluating:\t loss: 20.8391, MAE: 2.5249\n","train MSE: 25.0509, evaluate MSE: 20.8391\n","\n","train MAE: 2.8673, evaluate MAE: 2.5249\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1785\n","\tbatch: 100, loss: 14.5572, MAE: 2.2010\n","\tbatch: 200, loss: 11.9544, MAE: 2.1465\n","Training:\t loss: 21.0783, MAE: 2.4844\n","Evaluating:\t loss: 16.2515, MAE: 2.3303\n","train MSE: 21.0783, evaluate MSE: 16.2515\n","\n","train MAE: 2.4844, evaluate MAE: 2.3303\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1786\n","\tbatch: 100, loss: 9.9088, MAE: 1.9875\n","\tbatch: 200, loss: 27.3782, MAE: 2.4477\n","Training:\t loss: 19.3967, MAE: 2.3933\n","Evaluating:\t loss: 18.5386, MAE: 2.5004\n","train MSE: 19.3967, evaluate MSE: 18.5386\n","\n","train MAE: 2.3933, evaluate MAE: 2.5004\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1787\n","\tbatch: 100, loss: 14.0486, MAE: 2.5358\n","\tbatch: 200, loss: 28.5420, MAE: 2.5685\n","Training:\t loss: 19.4954, MAE: 2.3859\n","Evaluating:\t loss: 18.6945, MAE: 2.5932\n","train MSE: 19.4954, evaluate MSE: 18.6945\n","\n","train MAE: 2.3859, evaluate MAE: 2.5932\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 1788\n","\tbatch: 100, loss: 36.7528, MAE: 3.5264\n","\tbatch: 200, loss: 13.4164, MAE: 2.5082\n","Training:\t loss: 20.7871, MAE: 2.5216\n","Evaluating:\t loss: 21.3535, MAE: 2.7841\n","train MSE: 20.7871, evaluate MSE: 21.3535\n","\n","train MAE: 2.5216, evaluate MAE: 2.7841\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1789\n","\tbatch: 100, loss: 15.2494, MAE: 2.6078\n","\tbatch: 200, loss: 23.3454, MAE: 2.8959\n","Training:\t loss: 19.5847, MAE: 2.5395\n","Evaluating:\t loss: 20.4007, MAE: 2.1804\n","train MSE: 19.5847, evaluate MSE: 20.4007\n","\n","train MAE: 2.5395, evaluate MAE: 2.1804\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1790\n","\tbatch: 100, loss: 114.7793, MAE: 4.8596\n","\tbatch: 200, loss: 68.3998, MAE: 6.0360\n","Training:\t loss: 52.2204, MAE: 4.0683\n","Evaluating:\t loss: 36.8777, MAE: 3.3250\n","train MSE: 52.2204, evaluate MSE: 36.8777\n","\n","train MAE: 4.0683, evaluate MAE: 3.3250\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1791\n","\tbatch: 100, loss: 15.6633, MAE: 2.7120\n","\tbatch: 200, loss: 16.2397, MAE: 2.8785\n","Training:\t loss: 29.9557, MAE: 3.0655\n","Evaluating:\t loss: 22.8629, MAE: 2.6656\n","train MSE: 29.9557, evaluate MSE: 22.8629\n","\n","train MAE: 3.0655, evaluate MAE: 2.6656\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1792\n","\tbatch: 100, loss: 16.7936, MAE: 2.1909\n","\tbatch: 200, loss: 82.0184, MAE: 4.2260\n","Training:\t loss: 36.1404, MAE: 3.2740\n","Evaluating:\t loss: 30.7742, MAE: 3.1176\n","train MSE: 36.1404, evaluate MSE: 30.7742\n","\n","train MAE: 3.2740, evaluate MAE: 3.1176\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1793\n","\tbatch: 100, loss: 37.4452, MAE: 3.5629\n","\tbatch: 200, loss: 17.8362, MAE: 2.2338\n","Training:\t loss: 24.6668, MAE: 2.7016\n","Evaluating:\t loss: 25.2091, MAE: 2.6083\n","train MSE: 24.6668, evaluate MSE: 25.2091\n","\n","train MAE: 2.7016, evaluate MAE: 2.6083\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1794\n","\tbatch: 100, loss: 19.1134, MAE: 2.8643\n","\tbatch: 200, loss: 10.4099, MAE: 2.2151\n","Training:\t loss: 21.1779, MAE: 2.4276\n","Evaluating:\t loss: 19.7250, MAE: 2.4914\n","train MSE: 21.1779, evaluate MSE: 19.7250\n","\n","train MAE: 2.4276, evaluate MAE: 2.4914\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1795\n","\tbatch: 100, loss: 25.5776, MAE: 2.9628\n","\tbatch: 200, loss: 10.8479, MAE: 2.1488\n","Training:\t loss: 19.4462, MAE: 2.3910\n","Evaluating:\t loss: 18.0271, MAE: 2.0293\n","train MSE: 19.4462, evaluate MSE: 18.0271\n","\n","train MAE: 2.3910, evaluate MAE: 2.0293\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1796\n","\tbatch: 100, loss: 17.2847, MAE: 2.1806\n","\tbatch: 200, loss: 12.5156, MAE: 1.9107\n","Training:\t loss: 18.1058, MAE: 2.2773\n","Evaluating:\t loss: 19.6507, MAE: 2.6763\n","train MSE: 18.1058, evaluate MSE: 19.6507\n","\n","train MAE: 2.2773, evaluate MAE: 2.6763\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1797\n","\tbatch: 100, loss: 18.3848, MAE: 2.4298\n","\tbatch: 200, loss: 11.2893, MAE: 2.0110\n","Training:\t loss: 17.7806, MAE: 2.2488\n","Evaluating:\t loss: 17.0277, MAE: 2.2239\n","train MSE: 17.7806, evaluate MSE: 17.0277\n","\n","train MAE: 2.2488, evaluate MAE: 2.2239\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1798\n","\tbatch: 100, loss: 60.0417, MAE: 2.6098\n","\tbatch: 200, loss: 8.9725, MAE: 2.2488\n","Training:\t loss: 20.3492, MAE: 2.3789\n","Evaluating:\t loss: 40.9786, MAE: 2.5174\n","train MSE: 20.3492, evaluate MSE: 40.9786\n","\n","train MAE: 2.3789, evaluate MAE: 2.5174\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1799\n","\tbatch: 100, loss: 13.7510, MAE: 2.3894\n","\tbatch: 200, loss: 14.4755, MAE: 2.1813\n","Training:\t loss: 27.5802, MAE: 2.8660\n","Evaluating:\t loss: 17.3444, MAE: 2.0005\n","train MSE: 27.5802, evaluate MSE: 17.3444\n","\n","train MAE: 2.8660, evaluate MAE: 2.0005\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1800\n","\tbatch: 100, loss: 41.5038, MAE: 2.2902\n","\tbatch: 200, loss: 67.2104, MAE: 3.4159\n","Training:\t loss: 25.8106, MAE: 2.6658\n","Evaluating:\t loss: 85.1155, MAE: 7.1109\n","train MSE: 25.8106, evaluate MSE: 85.1155\n","\n","train MAE: 2.6658, evaluate MAE: 7.1109\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1801\n","\tbatch: 100, loss: 37.3475, MAE: 3.3436\n","\tbatch: 200, loss: 13.7205, MAE: 2.3387\n","Training:\t loss: 34.2881, MAE: 3.1992\n","Evaluating:\t loss: 33.6304, MAE: 2.6526\n","train MSE: 34.2881, evaluate MSE: 33.6304\n","\n","train MAE: 3.1992, evaluate MAE: 2.6526\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1802\n","\tbatch: 100, loss: 30.5159, MAE: 2.8594\n","\tbatch: 200, loss: 9.8997, MAE: 1.8065\n","Training:\t loss: 21.1644, MAE: 2.4353\n","Evaluating:\t loss: 19.4453, MAE: 2.5498\n","train MSE: 21.1644, evaluate MSE: 19.4453\n","\n","train MAE: 2.4353, evaluate MAE: 2.5498\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1803\n","\tbatch: 100, loss: 21.7628, MAE: 2.1682\n","\tbatch: 200, loss: 13.7455, MAE: 2.0922\n","Training:\t loss: 26.1254, MAE: 2.4361\n","Evaluating:\t loss: 38.9846, MAE: 2.8360\n","train MSE: 26.1254, evaluate MSE: 38.9846\n","\n","train MAE: 2.4361, evaluate MAE: 2.8360\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1804\n","\tbatch: 100, loss: 50.3965, MAE: 5.4811\n","\tbatch: 200, loss: 20.2625, MAE: 2.2549\n","Training:\t loss: 39.8340, MAE: 2.9171\n","Evaluating:\t loss: 21.7654, MAE: 2.2068\n","train MSE: 39.8340, evaluate MSE: 21.7654\n","\n","train MAE: 2.9171, evaluate MAE: 2.2068\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1805\n","\tbatch: 100, loss: 15.4277, MAE: 1.9443\n","\tbatch: 200, loss: 22.1367, MAE: 1.9831\n","Training:\t loss: 21.0477, MAE: 2.3388\n","Evaluating:\t loss: 28.5576, MAE: 2.7880\n","train MSE: 21.0477, evaluate MSE: 28.5576\n","\n","train MAE: 2.3388, evaluate MAE: 2.7880\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1806\n","\tbatch: 100, loss: 57.8380, MAE: 6.2270\n","\tbatch: 200, loss: 10.4998, MAE: 1.6367\n","Training:\t loss: 22.1767, MAE: 2.3670\n","Evaluating:\t loss: 38.8578, MAE: 4.2149\n","train MSE: 22.1767, evaluate MSE: 38.8578\n","\n","train MAE: 2.3670, evaluate MAE: 4.2149\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1807\n","\tbatch: 100, loss: 32.8299, MAE: 3.7174\n","\tbatch: 200, loss: 23.8919, MAE: 3.1845\n","Training:\t loss: 35.1373, MAE: 3.3534\n","Evaluating:\t loss: 23.8609, MAE: 2.7839\n","train MSE: 35.1373, evaluate MSE: 23.8609\n","\n","train MAE: 3.3534, evaluate MAE: 2.7839\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1808\n","\tbatch: 100, loss: 15.2769, MAE: 1.9136\n","\tbatch: 200, loss: 10.8591, MAE: 1.9857\n","Training:\t loss: 17.7349, MAE: 2.1394\n","Evaluating:\t loss: 22.5642, MAE: 2.3715\n","train MSE: 17.7349, evaluate MSE: 22.5642\n","\n","train MAE: 2.1394, evaluate MAE: 2.3715\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1809\n","\tbatch: 100, loss: 33.5488, MAE: 2.7181\n","\tbatch: 200, loss: 10.8973, MAE: 1.8717\n","Training:\t loss: 17.4890, MAE: 2.0870\n","Evaluating:\t loss: 18.5415, MAE: 2.2996\n","train MSE: 17.4890, evaluate MSE: 18.5415\n","\n","train MAE: 2.0870, evaluate MAE: 2.2996\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1810\n","\tbatch: 100, loss: 10.0656, MAE: 1.6700\n","\tbatch: 200, loss: 38.6709, MAE: 2.0556\n","Training:\t loss: 18.7326, MAE: 2.2977\n","Evaluating:\t loss: 33.6195, MAE: 3.2627\n","train MSE: 18.7326, evaluate MSE: 33.6195\n","\n","train MAE: 2.2977, evaluate MAE: 3.2627\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1811\n","\tbatch: 100, loss: 17.9100, MAE: 2.5400\n","\tbatch: 200, loss: 18.2976, MAE: 2.0713\n","Training:\t loss: 27.5517, MAE: 2.7402\n","Evaluating:\t loss: 30.8909, MAE: 2.8729\n","train MSE: 27.5517, evaluate MSE: 30.8909\n","\n","train MAE: 2.7402, evaluate MAE: 2.8729\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1812\n","\tbatch: 100, loss: 13.4794, MAE: 2.3701\n","\tbatch: 200, loss: 31.4970, MAE: 2.2411\n","Training:\t loss: 21.9163, MAE: 2.3452\n","Evaluating:\t loss: 19.6010, MAE: 2.1320\n","train MSE: 21.9163, evaluate MSE: 19.6010\n","\n","train MAE: 2.3452, evaluate MAE: 2.1320\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1813\n","\tbatch: 100, loss: 10.6903, MAE: 1.7969\n","\tbatch: 200, loss: 15.2847, MAE: 2.4505\n","Training:\t loss: 18.4023, MAE: 2.0740\n","Evaluating:\t loss: 16.9994, MAE: 2.0916\n","train MSE: 18.4023, evaluate MSE: 16.9994\n","\n","train MAE: 2.0740, evaluate MAE: 2.0916\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1814\n","\tbatch: 100, loss: 51.7344, MAE: 2.6410\n","\tbatch: 200, loss: 8.2345, MAE: 1.8915\n","Training:\t loss: 21.6604, MAE: 2.3960\n","Evaluating:\t loss: 25.6901, MAE: 2.6011\n","train MSE: 21.6604, evaluate MSE: 25.6901\n","\n","train MAE: 2.3960, evaluate MAE: 2.6011\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1815\n","\tbatch: 100, loss: 1374.6349, MAE: 6.0199\n","\tbatch: 200, loss: 54.5613, MAE: 5.6687\n","Training:\t loss: 75.4846, MAE: 4.2807\n","Evaluating:\t loss: 137.1716, MAE: 7.9529\n","train MSE: 75.4846, evaluate MSE: 137.1716\n","\n","train MAE: 4.2807, evaluate MAE: 7.9529\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1816\n","\tbatch: 100, loss: 35.6481, MAE: 2.9171\n","\tbatch: 200, loss: 28.1864, MAE: 2.9026\n","Training:\t loss: 36.1701, MAE: 3.3607\n","Evaluating:\t loss: 30.2883, MAE: 2.7012\n","train MSE: 36.1701, evaluate MSE: 30.2883\n","\n","train MAE: 3.3607, evaluate MAE: 2.7012\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1817\n","\tbatch: 100, loss: 31.2670, MAE: 3.2712\n","\tbatch: 200, loss: 21.2697, MAE: 2.3394\n","Training:\t loss: 32.0356, MAE: 2.7960\n","Evaluating:\t loss: 26.3131, MAE: 2.6346\n","train MSE: 32.0356, evaluate MSE: 26.3131\n","\n","train MAE: 2.7960, evaluate MAE: 2.6346\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1818\n","\tbatch: 100, loss: 16.2493, MAE: 2.5129\n","\tbatch: 200, loss: 10.1034, MAE: 2.2147\n","Training:\t loss: 18.7003, MAE: 2.4136\n","Evaluating:\t loss: 19.7011, MAE: 2.4137\n","train MSE: 18.7003, evaluate MSE: 19.7011\n","\n","train MAE: 2.4136, evaluate MAE: 2.4137\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1819\n","\tbatch: 100, loss: 14.8405, MAE: 2.2131\n","\tbatch: 200, loss: 16.7993, MAE: 2.3812\n","Training:\t loss: 20.3892, MAE: 2.4159\n","Evaluating:\t loss: 18.2409, MAE: 2.1946\n","train MSE: 20.3892, evaluate MSE: 18.2409\n","\n","train MAE: 2.4159, evaluate MAE: 2.1946\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1820\n","\tbatch: 100, loss: 19.4601, MAE: 2.5440\n","\tbatch: 200, loss: 14.7115, MAE: 2.3265\n","Training:\t loss: 23.8197, MAE: 2.5338\n","Evaluating:\t loss: 35.8907, MAE: 3.3438\n","train MSE: 23.8197, evaluate MSE: 35.8907\n","\n","train MAE: 2.5338, evaluate MAE: 3.3438\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1821\n","\tbatch: 100, loss: 12.5099, MAE: 2.2571\n","\tbatch: 200, loss: 16.0798, MAE: 2.2325\n","Training:\t loss: 20.9665, MAE: 2.5624\n","Evaluating:\t loss: 17.4182, MAE: 2.1277\n","train MSE: 20.9665, evaluate MSE: 17.4182\n","\n","train MAE: 2.5624, evaluate MAE: 2.1277\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1822\n","\tbatch: 100, loss: 44.6068, MAE: 2.3358\n","\tbatch: 200, loss: 9.4234, MAE: 2.0624\n","Training:\t loss: 16.0852, MAE: 2.2720\n","Evaluating:\t loss: 20.8687, MAE: 2.3014\n","train MSE: 16.0852, evaluate MSE: 20.8687\n","\n","train MAE: 2.2720, evaluate MAE: 2.3014\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1823\n","\tbatch: 100, loss: 12.9634, MAE: 1.9512\n","\tbatch: 200, loss: 376.7001, MAE: 14.5775\n","Training:\t loss: 159.4583, MAE: 5.3842\n","Evaluating:\t loss: 54.3029, MAE: 4.9631\n","train MSE: 159.4583, evaluate MSE: 54.3029\n","\n","train MAE: 5.3842, evaluate MAE: 4.9631\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1824\n","\tbatch: 100, loss: 30.9963, MAE: 3.0237\n","\tbatch: 200, loss: 13.6257, MAE: 2.3681\n","Training:\t loss: 34.0982, MAE: 3.2995\n","Evaluating:\t loss: 25.4592, MAE: 2.6067\n","train MSE: 34.0982, evaluate MSE: 25.4592\n","\n","train MAE: 3.2995, evaluate MAE: 2.6067\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1825\n","\tbatch: 100, loss: 23.6207, MAE: 2.6582\n","\tbatch: 200, loss: 17.5629, MAE: 2.2182\n","Training:\t loss: 22.7278, MAE: 2.3365\n","Evaluating:\t loss: 36.2550, MAE: 2.5132\n","train MSE: 22.7278, evaluate MSE: 36.2550\n","\n","train MAE: 2.3365, evaluate MAE: 2.5132\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1826\n","\tbatch: 100, loss: 11.5912, MAE: 2.0697\n","\tbatch: 200, loss: 18.6658, MAE: 2.8475\n","Training:\t loss: 37.1722, MAE: 2.8543\n","Evaluating:\t loss: 44.1619, MAE: 3.6003\n","train MSE: 37.1722, evaluate MSE: 44.1619\n","\n","train MAE: 2.8543, evaluate MAE: 3.6003\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1827\n","\tbatch: 100, loss: 16.9346, MAE: 2.6899\n","\tbatch: 200, loss: 26.3884, MAE: 3.0888\n","Training:\t loss: 28.5373, MAE: 3.1205\n","Evaluating:\t loss: 25.8050, MAE: 2.7724\n","train MSE: 28.5373, evaluate MSE: 25.8050\n","\n","train MAE: 3.1205, evaluate MAE: 2.7724\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1828\n","\tbatch: 100, loss: 13.7524, MAE: 2.3306\n","\tbatch: 200, loss: 22.5632, MAE: 2.3139\n","Training:\t loss: 21.0558, MAE: 2.5036\n","Evaluating:\t loss: 21.9743, MAE: 2.2694\n","train MSE: 21.0558, evaluate MSE: 21.9743\n","\n","train MAE: 2.5036, evaluate MAE: 2.2694\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1829\n","\tbatch: 100, loss: 14.7638, MAE: 2.0317\n","\tbatch: 200, loss: 22.1929, MAE: 2.5267\n","Training:\t loss: 19.7095, MAE: 2.2836\n","Evaluating:\t loss: 20.2125, MAE: 2.3416\n","train MSE: 19.7095, evaluate MSE: 20.2125\n","\n","train MAE: 2.2836, evaluate MAE: 2.3416\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1830\n","\tbatch: 100, loss: 13.2964, MAE: 2.1957\n","\tbatch: 200, loss: 10.9597, MAE: 1.9773\n","Training:\t loss: 21.1347, MAE: 2.3742\n","Evaluating:\t loss: 19.6140, MAE: 2.3081\n","train MSE: 21.1347, evaluate MSE: 19.6140\n","\n","train MAE: 2.3742, evaluate MAE: 2.3081\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1831\n","\tbatch: 100, loss: 10.2179, MAE: 1.9858\n","\tbatch: 200, loss: 409.8929, MAE: 14.8101\n","Training:\t loss: 533.8515, MAE: 9.7590\n","Evaluating:\t loss: 142.3693, MAE: 7.3539\n","train MSE: 533.8515, evaluate MSE: 142.3693\n","\n","train MAE: 9.7590, evaluate MAE: 7.3539\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1832\n","\tbatch: 100, loss: 65.2607, MAE: 5.7934\n","\tbatch: 200, loss: 51.9418, MAE: 4.9820\n","Training:\t loss: 84.3249, MAE: 5.8496\n","Evaluating:\t loss: 71.5139, MAE: 5.1470\n","train MSE: 84.3249, evaluate MSE: 71.5139\n","\n","train MAE: 5.8496, evaluate MAE: 5.1470\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1833\n","\tbatch: 100, loss: 117.1525, MAE: 5.4841\n","\tbatch: 200, loss: 47.6930, MAE: 4.6148\n","Training:\t loss: 59.9368, MAE: 4.9508\n","Evaluating:\t loss: 57.5439, MAE: 5.0872\n","train MSE: 59.9368, evaluate MSE: 57.5439\n","\n","train MAE: 4.9508, evaluate MAE: 5.0872\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1834\n","\tbatch: 100, loss: 43.7211, MAE: 4.5227\n","\tbatch: 200, loss: 43.6821, MAE: 4.3565\n","Training:\t loss: 55.1872, MAE: 4.6748\n","Evaluating:\t loss: 56.1137, MAE: 4.8144\n","train MSE: 55.1872, evaluate MSE: 56.1137\n","\n","train MAE: 4.6748, evaluate MAE: 4.8144\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1835\n","\tbatch: 100, loss: 67.1711, MAE: 5.2617\n","\tbatch: 200, loss: 54.4626, MAE: 4.8795\n","Training:\t loss: 60.4352, MAE: 5.2100\n","Evaluating:\t loss: 61.9744, MAE: 4.9353\n","train MSE: 60.4352, evaluate MSE: 61.9744\n","\n","train MAE: 5.2100, evaluate MAE: 4.9353\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1836\n","\tbatch: 100, loss: 72.4971, MAE: 5.0136\n","\tbatch: 200, loss: 47.5906, MAE: 4.1531\n","Training:\t loss: 44.7044, MAE: 4.4107\n","Evaluating:\t loss: 51.5230, MAE: 4.5705\n","train MSE: 44.7044, evaluate MSE: 51.5230\n","\n","train MAE: 4.4107, evaluate MAE: 4.5705\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1837\n","\tbatch: 100, loss: 31.0385, MAE: 3.9361\n","\tbatch: 200, loss: 39.1846, MAE: 3.8871\n","Training:\t loss: 38.0243, MAE: 3.9043\n","Evaluating:\t loss: 36.2006, MAE: 3.7363\n","train MSE: 38.0243, evaluate MSE: 36.2006\n","\n","train MAE: 3.9043, evaluate MAE: 3.7363\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1838\n","\tbatch: 100, loss: 34.8630, MAE: 4.0479\n","\tbatch: 200, loss: 31.6795, MAE: 3.6806\n","Training:\t loss: 39.0045, MAE: 3.7767\n","Evaluating:\t loss: 34.7558, MAE: 3.5704\n","train MSE: 39.0045, evaluate MSE: 34.7558\n","\n","train MAE: 3.7767, evaluate MAE: 3.5704\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1839\n","\tbatch: 100, loss: 35.4089, MAE: 4.3128\n","\tbatch: 200, loss: 38.4263, MAE: 3.6764\n","Training:\t loss: 36.3246, MAE: 3.7003\n","Evaluating:\t loss: 32.1981, MAE: 3.4453\n","train MSE: 36.3246, evaluate MSE: 32.1981\n","\n","train MAE: 3.7003, evaluate MAE: 3.4453\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1840\n","\tbatch: 100, loss: 26.9667, MAE: 3.4078\n","\tbatch: 200, loss: 25.0175, MAE: 3.5963\n","Training:\t loss: 33.1319, MAE: 3.6285\n","Evaluating:\t loss: 32.8440, MAE: 3.3567\n","train MSE: 33.1319, evaluate MSE: 32.8440\n","\n","train MAE: 3.6285, evaluate MAE: 3.3567\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1841\n","\tbatch: 100, loss: 23.7947, MAE: 3.4319\n","\tbatch: 200, loss: 21.6949, MAE: 3.3087\n","Training:\t loss: 32.1430, MAE: 3.4162\n","Evaluating:\t loss: 28.7029, MAE: 3.2360\n","train MSE: 32.1430, evaluate MSE: 28.7029\n","\n","train MAE: 3.4162, evaluate MAE: 3.2360\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1842\n","\tbatch: 100, loss: 30.6989, MAE: 3.4962\n","\tbatch: 200, loss: 30.1463, MAE: 3.6052\n","Training:\t loss: 29.2421, MAE: 3.3967\n","Evaluating:\t loss: 27.9904, MAE: 3.2850\n","train MSE: 29.2421, evaluate MSE: 27.9904\n","\n","train MAE: 3.3967, evaluate MAE: 3.2850\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1843\n","\tbatch: 100, loss: 18.8116, MAE: 2.8568\n","\tbatch: 200, loss: 26.1697, MAE: 3.4439\n","Training:\t loss: 26.5919, MAE: 3.2271\n","Evaluating:\t loss: 27.6582, MAE: 3.2401\n","train MSE: 26.5919, evaluate MSE: 27.6582\n","\n","train MAE: 3.2271, evaluate MAE: 3.2401\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1844\n","\tbatch: 100, loss: 26.5814, MAE: 3.4316\n","\tbatch: 200, loss: 42.1532, MAE: 3.5200\n","Training:\t loss: 28.1803, MAE: 3.2750\n","Evaluating:\t loss: 28.1833, MAE: 3.4750\n","train MSE: 28.1803, evaluate MSE: 28.1833\n","\n","train MAE: 3.2750, evaluate MAE: 3.4750\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1845\n","\tbatch: 100, loss: 21.7904, MAE: 3.3496\n","\tbatch: 200, loss: 17.7470, MAE: 2.8326\n","Training:\t loss: 26.8585, MAE: 3.1688\n","Evaluating:\t loss: 40.2865, MAE: 3.1685\n","train MSE: 26.8585, evaluate MSE: 40.2865\n","\n","train MAE: 3.1688, evaluate MAE: 3.1685\n","\n","--- time consumption (s): 17\n","\n","------------------------------\n","Epoch 1846\n","\tbatch: 100, loss: 25.2805, MAE: 2.9785\n","\tbatch: 200, loss: 32.7986, MAE: 3.7035\n","Training:\t loss: 27.0929, MAE: 3.2966\n","Evaluating:\t loss: 37.2952, MAE: 3.8425\n","train MSE: 27.0929, evaluate MSE: 37.2952\n","\n","train MAE: 3.2966, evaluate MAE: 3.8425\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1847\n","\tbatch: 100, loss: 27.1646, MAE: 3.2468\n","\tbatch: 200, loss: 18.6244, MAE: 2.7072\n","Training:\t loss: 29.0528, MAE: 3.3775\n","Evaluating:\t loss: 26.6511, MAE: 2.9350\n","train MSE: 29.0528, evaluate MSE: 26.6511\n","\n","train MAE: 3.3775, evaluate MAE: 2.9350\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1848\n","\tbatch: 100, loss: 29.9059, MAE: 3.0697\n","\tbatch: 200, loss: 104.3981, MAE: 5.0411\n","Training:\t loss: 33.4171, MAE: 3.4619\n","Evaluating:\t loss: 46.0557, MAE: 3.6482\n","train MSE: 33.4171, evaluate MSE: 46.0557\n","\n","train MAE: 3.4619, evaluate MAE: 3.6482\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1849\n","\tbatch: 100, loss: 13.3394, MAE: 2.4952\n","\tbatch: 200, loss: 18.0337, MAE: 2.7502\n","Training:\t loss: 27.1793, MAE: 3.1932\n","Evaluating:\t loss: 24.0590, MAE: 2.8805\n","train MSE: 27.1793, evaluate MSE: 24.0590\n","\n","train MAE: 3.1932, evaluate MAE: 2.8805\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1850\n","\tbatch: 100, loss: 16.8788, MAE: 2.7673\n","\tbatch: 200, loss: 19.7767, MAE: 2.9362\n","Training:\t loss: 22.4461, MAE: 2.7947\n","Evaluating:\t loss: 26.3558, MAE: 3.1179\n","train MSE: 22.4461, evaluate MSE: 26.3558\n","\n","train MAE: 2.7947, evaluate MAE: 3.1179\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1851\n","\tbatch: 100, loss: 22.3217, MAE: 3.1786\n","\tbatch: 200, loss: 22.3286, MAE: 2.8997\n","Training:\t loss: 34.8341, MAE: 3.2155\n","Evaluating:\t loss: 36.5214, MAE: 3.6577\n","train MSE: 34.8341, evaluate MSE: 36.5214\n","\n","train MAE: 3.2155, evaluate MAE: 3.6577\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1852\n","\tbatch: 100, loss: 18.1342, MAE: 2.8822\n","\tbatch: 200, loss: 26.6797, MAE: 2.8900\n","Training:\t loss: 30.1649, MAE: 3.2946\n","Evaluating:\t loss: 20.5404, MAE: 2.6172\n","train MSE: 30.1649, evaluate MSE: 20.5404\n","\n","train MAE: 3.2946, evaluate MAE: 2.6172\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1853\n","\tbatch: 100, loss: 16.6318, MAE: 2.7648\n","\tbatch: 200, loss: 30.1386, MAE: 3.8895\n","Training:\t loss: 39.1458, MAE: 3.2488\n","Evaluating:\t loss: 132.1723, MAE: 7.8077\n","train MSE: 39.1458, evaluate MSE: 132.1723\n","\n","train MAE: 3.2488, evaluate MAE: 7.8077\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1854\n","\tbatch: 100, loss: 47.5507, MAE: 3.7922\n","\tbatch: 200, loss: 20.5270, MAE: 2.7198\n","Training:\t loss: 69.2319, MAE: 4.0521\n","Evaluating:\t loss: 32.1400, MAE: 4.0340\n","train MSE: 69.2319, evaluate MSE: 32.1400\n","\n","train MAE: 4.0521, evaluate MAE: 4.0340\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1855\n","\tbatch: 100, loss: 10.4441, MAE: 2.1489\n","\tbatch: 200, loss: 23.5622, MAE: 3.3048\n","Training:\t loss: 26.8730, MAE: 3.0639\n","Evaluating:\t loss: 23.5023, MAE: 2.7928\n","train MSE: 26.8730, evaluate MSE: 23.5023\n","\n","train MAE: 3.0639, evaluate MAE: 2.7928\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1856\n","\tbatch: 100, loss: 13.5247, MAE: 2.2570\n","\tbatch: 200, loss: 13.1864, MAE: 2.4809\n","Training:\t loss: 24.1215, MAE: 2.7529\n","Evaluating:\t loss: 28.6042, MAE: 3.4615\n","train MSE: 24.1215, evaluate MSE: 28.6042\n","\n","train MAE: 2.7529, evaluate MAE: 3.4615\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1857\n","\tbatch: 100, loss: 26.6959, MAE: 2.9562\n","\tbatch: 200, loss: 17.8158, MAE: 2.7103\n","Training:\t loss: 26.9516, MAE: 3.0504\n","Evaluating:\t loss: 27.3685, MAE: 3.1790\n","train MSE: 26.9516, evaluate MSE: 27.3685\n","\n","train MAE: 3.0504, evaluate MAE: 3.1790\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1858\n","\tbatch: 100, loss: 28.6190, MAE: 2.7956\n","\tbatch: 200, loss: 23.4559, MAE: 3.3688\n","Training:\t loss: 23.4007, MAE: 2.8398\n","Evaluating:\t loss: 23.7717, MAE: 2.6083\n","train MSE: 23.4007, evaluate MSE: 23.7717\n","\n","train MAE: 2.8398, evaluate MAE: 2.6083\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1859\n","\tbatch: 100, loss: 14.8181, MAE: 2.9342\n","\tbatch: 200, loss: 25.9801, MAE: 2.9789\n","Training:\t loss: 26.2340, MAE: 2.8584\n","Evaluating:\t loss: 29.2841, MAE: 3.0239\n","train MSE: 26.2340, evaluate MSE: 29.2841\n","\n","train MAE: 2.8584, evaluate MAE: 3.0239\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1860\n","\tbatch: 100, loss: 25.7330, MAE: 2.7554\n","\tbatch: 200, loss: 21.9918, MAE: 3.0719\n","Training:\t loss: 41.2948, MAE: 3.5648\n","Evaluating:\t loss: 21.6417, MAE: 2.3646\n","train MSE: 41.2948, evaluate MSE: 21.6417\n","\n","train MAE: 3.5648, evaluate MAE: 2.3646\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1861\n","\tbatch: 100, loss: 16.0212, MAE: 2.3050\n","\tbatch: 200, loss: 14.5264, MAE: 2.6557\n","Training:\t loss: 21.3419, MAE: 2.4796\n","Evaluating:\t loss: 17.7504, MAE: 2.2664\n","train MSE: 21.3419, evaluate MSE: 17.7504\n","\n","train MAE: 2.4796, evaluate MAE: 2.2664\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1862\n","\tbatch: 100, loss: 44.4312, MAE: 4.1222\n","\tbatch: 200, loss: 14.1575, MAE: 2.2429\n","Training:\t loss: 20.9220, MAE: 2.5305\n","Evaluating:\t loss: 20.1165, MAE: 2.1616\n","train MSE: 20.9220, evaluate MSE: 20.1165\n","\n","train MAE: 2.5305, evaluate MAE: 2.1616\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1863\n","\tbatch: 100, loss: 30.7170, MAE: 3.0742\n","\tbatch: 200, loss: 20.5387, MAE: 3.0815\n","Training:\t loss: 176.3826, MAE: 5.2807\n","Evaluating:\t loss: 438.6557, MAE: 17.2135\n","train MSE: 176.3826, evaluate MSE: 438.6557\n","\n","train MAE: 5.2807, evaluate MAE: 17.2135\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1864\n","\tbatch: 100, loss: 111.2259, MAE: 6.9126\n","\tbatch: 200, loss: 135.1714, MAE: 7.8935\n","Training:\t loss: 146.3917, MAE: 7.5860\n","Evaluating:\t loss: 65.4866, MAE: 5.3975\n","train MSE: 146.3917, evaluate MSE: 65.4866\n","\n","train MAE: 7.5860, evaluate MAE: 5.3975\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1865\n","\tbatch: 100, loss: 53.4936, MAE: 4.4117\n","\tbatch: 200, loss: 36.9386, MAE: 3.6361\n","Training:\t loss: 46.9332, MAE: 4.0445\n","Evaluating:\t loss: 30.9531, MAE: 3.1834\n","train MSE: 46.9332, evaluate MSE: 30.9531\n","\n","train MAE: 4.0445, evaluate MAE: 3.1834\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1866\n","\tbatch: 100, loss: 37.0501, MAE: 3.0744\n","\tbatch: 200, loss: 30.5064, MAE: 3.5248\n","Training:\t loss: 32.6301, MAE: 3.2082\n","Evaluating:\t loss: 27.3035, MAE: 3.1567\n","train MSE: 32.6301, evaluate MSE: 27.3035\n","\n","train MAE: 3.2082, evaluate MAE: 3.1567\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1867\n","\tbatch: 100, loss: 21.8284, MAE: 2.7095\n","\tbatch: 200, loss: 36.0199, MAE: 3.5756\n","Training:\t loss: 31.6568, MAE: 3.2232\n","Evaluating:\t loss: 30.0784, MAE: 3.2422\n","train MSE: 31.6568, evaluate MSE: 30.0784\n","\n","train MAE: 3.2232, evaluate MAE: 3.2422\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1868\n","\tbatch: 100, loss: 15.9505, MAE: 2.7053\n","\tbatch: 200, loss: 16.8939, MAE: 2.7769\n","Training:\t loss: 27.1350, MAE: 2.8503\n","Evaluating:\t loss: 20.4879, MAE: 2.4531\n","train MSE: 27.1350, evaluate MSE: 20.4879\n","\n","train MAE: 2.8503, evaluate MAE: 2.4531\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1869\n","\tbatch: 100, loss: 24.9665, MAE: 2.5795\n","\tbatch: 200, loss: 67.6324, MAE: 3.0611\n","Training:\t loss: 22.6638, MAE: 2.5392\n","Evaluating:\t loss: 33.2311, MAE: 2.9944\n","train MSE: 22.6638, evaluate MSE: 33.2311\n","\n","train MAE: 2.5392, evaluate MAE: 2.9944\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1870\n","\tbatch: 100, loss: 14.2817, MAE: 2.5650\n","\tbatch: 200, loss: 19.3874, MAE: 2.4227\n","Training:\t loss: 23.6960, MAE: 2.5466\n","Evaluating:\t loss: 22.1232, MAE: 2.2494\n","train MSE: 23.6960, evaluate MSE: 22.1232\n","\n","train MAE: 2.5466, evaluate MAE: 2.2494\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1871\n","\tbatch: 100, loss: 13.5832, MAE: 2.3841\n","\tbatch: 200, loss: 13.3990, MAE: 2.4062\n","Training:\t loss: 21.3859, MAE: 2.4286\n","Evaluating:\t loss: 22.1591, MAE: 2.5297\n","train MSE: 21.3859, evaluate MSE: 22.1591\n","\n","train MAE: 2.4286, evaluate MAE: 2.5297\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1872\n","\tbatch: 100, loss: 14.5712, MAE: 2.4524\n","\tbatch: 200, loss: 11.3824, MAE: 2.2779\n","Training:\t loss: 20.8803, MAE: 2.4379\n","Evaluating:\t loss: 20.8578, MAE: 2.4517\n","train MSE: 20.8803, evaluate MSE: 20.8578\n","\n","train MAE: 2.4379, evaluate MAE: 2.4517\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1873\n","\tbatch: 100, loss: 23.7469, MAE: 2.5320\n","\tbatch: 200, loss: 21.4130, MAE: 2.4212\n","Training:\t loss: 24.0745, MAE: 2.5763\n","Evaluating:\t loss: 31.3939, MAE: 3.0641\n","train MSE: 24.0745, evaluate MSE: 31.3939\n","\n","train MAE: 2.5763, evaluate MAE: 3.0641\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1874\n","\tbatch: 100, loss: 17.9310, MAE: 2.3684\n","\tbatch: 200, loss: 10.6310, MAE: 2.0699\n","Training:\t loss: 20.0215, MAE: 2.2928\n","Evaluating:\t loss: 19.9074, MAE: 2.1719\n","train MSE: 20.0215, evaluate MSE: 19.9074\n","\n","train MAE: 2.2928, evaluate MAE: 2.1719\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1875\n","\tbatch: 100, loss: 11.3808, MAE: 2.1551\n","\tbatch: 200, loss: 15.7158, MAE: 2.5693\n","Training:\t loss: 20.3176, MAE: 2.3837\n","Evaluating:\t loss: 47.1260, MAE: 4.5341\n","train MSE: 20.3176, evaluate MSE: 47.1260\n","\n","train MAE: 2.3837, evaluate MAE: 4.5341\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1876\n","\tbatch: 100, loss: 24.6637, MAE: 3.3595\n","\tbatch: 200, loss: 11.8166, MAE: 2.2749\n","Training:\t loss: 22.0863, MAE: 2.5288\n","Evaluating:\t loss: 20.2880, MAE: 2.5468\n","train MSE: 22.0863, evaluate MSE: 20.2880\n","\n","train MAE: 2.5288, evaluate MAE: 2.5468\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1877\n","\tbatch: 100, loss: 39.4610, MAE: 4.5046\n","\tbatch: 200, loss: 99.7771, MAE: 4.0301\n","Training:\t loss: 39.4738, MAE: 3.5017\n","Evaluating:\t loss: 29.6981, MAE: 3.2874\n","train MSE: 39.4738, evaluate MSE: 29.6981\n","\n","train MAE: 3.5017, evaluate MAE: 3.2874\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1878\n","\tbatch: 100, loss: 24.4504, MAE: 2.8242\n","\tbatch: 200, loss: 27.3137, MAE: 2.5266\n","Training:\t loss: 29.5604, MAE: 3.0240\n","Evaluating:\t loss: 23.0173, MAE: 2.6351\n","train MSE: 29.5604, evaluate MSE: 23.0173\n","\n","train MAE: 3.0240, evaluate MAE: 2.6351\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1879\n","\tbatch: 100, loss: 21.9930, MAE: 2.6855\n","\tbatch: 200, loss: 21.1160, MAE: 2.9824\n","Training:\t loss: 23.7130, MAE: 2.7279\n","Evaluating:\t loss: 17.9463, MAE: 2.6534\n","train MSE: 23.7130, evaluate MSE: 17.9463\n","\n","train MAE: 2.7279, evaluate MAE: 2.6534\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1880\n","\tbatch: 100, loss: 26.2147, MAE: 2.5820\n","\tbatch: 200, loss: 15.9842, MAE: 2.1206\n","Training:\t loss: 25.7475, MAE: 2.9352\n","Evaluating:\t loss: 21.7116, MAE: 2.4827\n","train MSE: 25.7475, evaluate MSE: 21.7116\n","\n","train MAE: 2.9352, evaluate MAE: 2.4827\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1881\n","\tbatch: 100, loss: 39.3699, MAE: 2.9886\n","\tbatch: 200, loss: 160.0327, MAE: 3.0184\n","Training:\t loss: 41.7533, MAE: 3.1317\n","Evaluating:\t loss: 32.3494, MAE: 3.6436\n","train MSE: 41.7533, evaluate MSE: 32.3494\n","\n","train MAE: 3.1317, evaluate MAE: 3.6436\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1882\n","\tbatch: 100, loss: 82.6084, MAE: 4.0098\n","\tbatch: 200, loss: 38.8558, MAE: 3.1223\n","Training:\t loss: 58.1309, MAE: 4.1903\n","Evaluating:\t loss: 57.0432, MAE: 3.2208\n","train MSE: 58.1309, evaluate MSE: 57.0432\n","\n","train MAE: 4.1903, evaluate MAE: 3.2208\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1883\n","\tbatch: 100, loss: 34.4589, MAE: 2.9340\n","\tbatch: 200, loss: 38.5031, MAE: 4.8716\n","Training:\t loss: 39.2490, MAE: 3.3410\n","Evaluating:\t loss: 39.9828, MAE: 3.8491\n","train MSE: 39.2490, evaluate MSE: 39.9828\n","\n","train MAE: 3.3410, evaluate MAE: 3.8491\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1884\n","\tbatch: 100, loss: 68.8213, MAE: 5.8746\n","\tbatch: 200, loss: 36.8434, MAE: 3.2100\n","Training:\t loss: 40.1756, MAE: 3.4759\n","Evaluating:\t loss: 34.2207, MAE: 2.8097\n","train MSE: 40.1756, evaluate MSE: 34.2207\n","\n","train MAE: 3.4759, evaluate MAE: 2.8097\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1885\n","\tbatch: 100, loss: 22.6461, MAE: 2.8927\n","\tbatch: 200, loss: 37.9962, MAE: 3.4690\n","Training:\t loss: 49.7321, MAE: 3.7340\n","Evaluating:\t loss: 61.5429, MAE: 5.1279\n","train MSE: 49.7321, evaluate MSE: 61.5429\n","\n","train MAE: 3.7340, evaluate MAE: 5.1279\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1886\n","\tbatch: 100, loss: 37.5931, MAE: 3.0501\n","\tbatch: 200, loss: 67.4956, MAE: 3.0283\n","Training:\t loss: 35.7708, MAE: 3.2092\n","Evaluating:\t loss: 22.3351, MAE: 2.4745\n","train MSE: 35.7708, evaluate MSE: 22.3351\n","\n","train MAE: 3.2092, evaluate MAE: 2.4745\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1887\n","\tbatch: 100, loss: 25.7385, MAE: 2.7673\n","\tbatch: 200, loss: 12.7610, MAE: 2.2066\n","Training:\t loss: 25.4509, MAE: 2.8384\n","Evaluating:\t loss: 20.5966, MAE: 2.2240\n","train MSE: 25.4509, evaluate MSE: 20.5966\n","\n","train MAE: 2.8384, evaluate MAE: 2.2240\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1888\n","\tbatch: 100, loss: 19.2464, MAE: 2.2720\n","\tbatch: 200, loss: 22.5712, MAE: 2.5066\n","Training:\t loss: 22.7560, MAE: 2.4272\n","Evaluating:\t loss: 23.3710, MAE: 2.2296\n","train MSE: 22.7560, evaluate MSE: 23.3710\n","\n","train MAE: 2.4272, evaluate MAE: 2.2296\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1889\n","\tbatch: 100, loss: 22.0507, MAE: 2.2564\n","\tbatch: 200, loss: 11.6806, MAE: 1.9980\n","Training:\t loss: 20.4332, MAE: 2.2493\n","Evaluating:\t loss: 21.3572, MAE: 2.4804\n","train MSE: 20.4332, evaluate MSE: 21.3572\n","\n","train MAE: 2.2493, evaluate MAE: 2.4804\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1890\n","\tbatch: 100, loss: 12.3011, MAE: 2.6643\n","\tbatch: 200, loss: 21.9183, MAE: 2.1263\n","Training:\t loss: 21.3261, MAE: 2.3973\n","Evaluating:\t loss: 16.6347, MAE: 1.8006\n","train MSE: 21.3261, evaluate MSE: 16.6347\n","\n","train MAE: 2.3973, evaluate MAE: 1.8006\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1891\n","\tbatch: 100, loss: 22.5406, MAE: 2.6102\n","\tbatch: 200, loss: 42.1332, MAE: 3.8320\n","Training:\t loss: 24.6327, MAE: 2.4977\n","Evaluating:\t loss: 29.8956, MAE: 2.7174\n","train MSE: 24.6327, evaluate MSE: 29.8956\n","\n","train MAE: 2.4977, evaluate MAE: 2.7174\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1892\n","\tbatch: 100, loss: 22.6568, MAE: 2.9073\n","\tbatch: 200, loss: 24.2927, MAE: 2.6822\n","Training:\t loss: 26.0479, MAE: 2.6030\n","Evaluating:\t loss: 22.4330, MAE: 2.8412\n","train MSE: 26.0479, evaluate MSE: 22.4330\n","\n","train MAE: 2.6030, evaluate MAE: 2.8412\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1893\n","\tbatch: 100, loss: 12.7510, MAE: 1.9461\n","\tbatch: 200, loss: 5.5562, MAE: 1.4668\n","Training:\t loss: 19.1644, MAE: 2.1200\n","Evaluating:\t loss: 19.9294, MAE: 2.5001\n","train MSE: 19.1644, evaluate MSE: 19.9294\n","\n","train MAE: 2.1200, evaluate MAE: 2.5001\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1894\n","\tbatch: 100, loss: 10.1479, MAE: 2.2591\n","\tbatch: 200, loss: 7.2925, MAE: 1.8690\n","Training:\t loss: 20.8561, MAE: 2.3249\n","Evaluating:\t loss: 19.2638, MAE: 1.8097\n","train MSE: 20.8561, evaluate MSE: 19.2638\n","\n","train MAE: 2.3249, evaluate MAE: 1.8097\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1895\n","\tbatch: 100, loss: 9.2325, MAE: 1.8940\n","\tbatch: 200, loss: 32.0736, MAE: 3.4490\n","Training:\t loss: 25.5491, MAE: 2.5947\n","Evaluating:\t loss: 33.8353, MAE: 2.5394\n","train MSE: 25.5491, evaluate MSE: 33.8353\n","\n","train MAE: 2.5947, evaluate MAE: 2.5394\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1896\n","\tbatch: 100, loss: 28.8722, MAE: 2.4744\n","\tbatch: 200, loss: 7.7050, MAE: 1.6161\n","Training:\t loss: 28.7492, MAE: 2.5414\n","Evaluating:\t loss: 30.1934, MAE: 3.1498\n","train MSE: 28.7492, evaluate MSE: 30.1934\n","\n","train MAE: 2.5414, evaluate MAE: 3.1498\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1897\n","\tbatch: 100, loss: 19.7675, MAE: 2.3225\n","\tbatch: 200, loss: 41.6562, MAE: 3.7916\n","Training:\t loss: 38.1725, MAE: 3.2543\n","Evaluating:\t loss: 23.6243, MAE: 2.6562\n","train MSE: 38.1725, evaluate MSE: 23.6243\n","\n","train MAE: 3.2543, evaluate MAE: 2.6562\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1898\n","\tbatch: 100, loss: 10.0693, MAE: 1.7830\n","\tbatch: 200, loss: 8.4921, MAE: 1.6469\n","Training:\t loss: 20.1363, MAE: 2.0754\n","Evaluating:\t loss: 16.4461, MAE: 1.8198\n","train MSE: 20.1363, evaluate MSE: 16.4461\n","\n","train MAE: 2.0754, evaluate MAE: 1.8198\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1899\n","\tbatch: 100, loss: 17.2176, MAE: 2.0991\n","\tbatch: 200, loss: 4.9135, MAE: 1.3505\n","Training:\t loss: 17.1837, MAE: 1.9415\n","Evaluating:\t loss: 14.4982, MAE: 1.7576\n","train MSE: 17.1837, evaluate MSE: 14.4982\n","\n","train MAE: 1.9415, evaluate MAE: 1.7576\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1900\n","\tbatch: 100, loss: 47.4270, MAE: 3.0167\n","\tbatch: 200, loss: 74.6063, MAE: 3.6629\n","Training:\t loss: 35.3350, MAE: 3.1086\n","Evaluating:\t loss: 26.3147, MAE: 2.3406\n","train MSE: 35.3350, evaluate MSE: 26.3147\n","\n","train MAE: 3.1086, evaluate MAE: 2.3406\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1901\n","\tbatch: 100, loss: 16.5913, MAE: 2.1166\n","\tbatch: 200, loss: 33.5146, MAE: 2.9039\n","Training:\t loss: 27.1434, MAE: 2.5105\n","Evaluating:\t loss: 25.8460, MAE: 2.9051\n","train MSE: 27.1434, evaluate MSE: 25.8460\n","\n","train MAE: 2.5105, evaluate MAE: 2.9051\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1902\n","\tbatch: 100, loss: 18.2480, MAE: 2.3379\n","\tbatch: 200, loss: 21.1625, MAE: 2.7707\n","Training:\t loss: 33.5997, MAE: 2.6359\n","Evaluating:\t loss: 31.9362, MAE: 2.7783\n","train MSE: 33.5997, evaluate MSE: 31.9362\n","\n","train MAE: 2.6359, evaluate MAE: 2.7783\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1903\n","\tbatch: 100, loss: 16.7255, MAE: 2.0242\n","\tbatch: 200, loss: 15.2985, MAE: 2.0277\n","Training:\t loss: 21.2954, MAE: 2.2356\n","Evaluating:\t loss: 30.0038, MAE: 2.2160\n","train MSE: 21.2954, evaluate MSE: 30.0038\n","\n","train MAE: 2.2356, evaluate MAE: 2.2160\n","\n","--- time consumption (s): 17\n","\n","------------------------------\n","Epoch 1904\n","\tbatch: 100, loss: 28.4608, MAE: 2.5755\n","\tbatch: 200, loss: 50.3490, MAE: 3.7428\n","Training:\t loss: 44.5306, MAE: 3.2031\n","Evaluating:\t loss: 96.3223, MAE: 7.0273\n","train MSE: 44.5306, evaluate MSE: 96.3223\n","\n","train MAE: 3.2031, evaluate MAE: 7.0273\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1905\n","\tbatch: 100, loss: 125.7163, MAE: 3.1760\n","\tbatch: 200, loss: 28.9074, MAE: 2.9454\n","Training:\t loss: 28.6761, MAE: 2.7079\n","Evaluating:\t loss: 22.8308, MAE: 2.4774\n","train MSE: 28.6761, evaluate MSE: 22.8308\n","\n","train MAE: 2.7079, evaluate MAE: 2.4774\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1906\n","\tbatch: 100, loss: 18.8527, MAE: 2.3252\n","\tbatch: 200, loss: 21.7423, MAE: 2.1761\n","Training:\t loss: 21.3277, MAE: 2.1819\n","Evaluating:\t loss: 18.7257, MAE: 1.9873\n","train MSE: 21.3277, evaluate MSE: 18.7257\n","\n","train MAE: 2.1819, evaluate MAE: 1.9873\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1907\n","\tbatch: 100, loss: 23.8259, MAE: 3.5561\n","\tbatch: 200, loss: 87.4443, MAE: 3.0770\n","Training:\t loss: 33.9235, MAE: 3.2034\n","Evaluating:\t loss: 56.3578, MAE: 4.5498\n","train MSE: 33.9235, evaluate MSE: 56.3578\n","\n","train MAE: 3.2034, evaluate MAE: 4.5498\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1908\n","\tbatch: 100, loss: 42.5340, MAE: 3.2659\n","\tbatch: 200, loss: 60.4812, MAE: 3.5514\n","Training:\t loss: 53.4072, MAE: 4.1072\n","Evaluating:\t loss: 37.5504, MAE: 3.1835\n","train MSE: 53.4072, evaluate MSE: 37.5504\n","\n","train MAE: 4.1072, evaluate MAE: 3.1835\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1909\n","\tbatch: 100, loss: 31.8956, MAE: 2.9457\n","\tbatch: 200, loss: 32.6164, MAE: 2.9189\n","Training:\t loss: 32.1024, MAE: 2.8663\n","Evaluating:\t loss: 28.1606, MAE: 2.5709\n","train MSE: 32.1024, evaluate MSE: 28.1606\n","\n","train MAE: 2.8663, evaluate MAE: 2.5709\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1910\n","\tbatch: 100, loss: 16.5295, MAE: 2.1117\n","\tbatch: 200, loss: 32.1198, MAE: 3.3828\n","Training:\t loss: 37.6338, MAE: 3.0167\n","Evaluating:\t loss: 61.0525, MAE: 4.5248\n","train MSE: 37.6338, evaluate MSE: 61.0525\n","\n","train MAE: 3.0167, evaluate MAE: 4.5248\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1911\n","\tbatch: 100, loss: 26.5266, MAE: 2.6544\n","\tbatch: 200, loss: 40.7491, MAE: 3.0610\n","Training:\t loss: 39.3478, MAE: 3.1972\n","Evaluating:\t loss: 40.3910, MAE: 2.9405\n","train MSE: 39.3478, evaluate MSE: 40.3910\n","\n","train MAE: 3.1972, evaluate MAE: 2.9405\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1912\n","\tbatch: 100, loss: 52.4487, MAE: 3.1518\n","\tbatch: 200, loss: 23.7505, MAE: 2.6940\n","Training:\t loss: 38.6298, MAE: 3.2544\n","Evaluating:\t loss: 29.9755, MAE: 2.7201\n","train MSE: 38.6298, evaluate MSE: 29.9755\n","\n","train MAE: 3.2544, evaluate MAE: 2.7201\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1913\n","\tbatch: 100, loss: 10.2343, MAE: 1.9074\n","\tbatch: 200, loss: 11.5507, MAE: 1.7576\n","Training:\t loss: 22.2750, MAE: 2.3386\n","Evaluating:\t loss: 22.2193, MAE: 2.2885\n","train MSE: 22.2750, evaluate MSE: 22.2193\n","\n","train MAE: 2.3386, evaluate MAE: 2.2885\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1914\n","\tbatch: 100, loss: 16.3891, MAE: 2.2233\n","\tbatch: 200, loss: 89.2718, MAE: 8.2007\n","Training:\t loss: 35.4940, MAE: 3.2175\n","Evaluating:\t loss: 28.2031, MAE: 2.9133\n","train MSE: 35.4940, evaluate MSE: 28.2031\n","\n","train MAE: 3.2175, evaluate MAE: 2.9133\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1915\n","\tbatch: 100, loss: 17.4359, MAE: 2.5956\n","\tbatch: 200, loss: 24.4604, MAE: 2.3201\n","Training:\t loss: 24.6043, MAE: 2.5205\n","Evaluating:\t loss: 25.2978, MAE: 2.4748\n","train MSE: 24.6043, evaluate MSE: 25.2978\n","\n","train MAE: 2.5205, evaluate MAE: 2.4748\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1916\n","\tbatch: 100, loss: 37.5794, MAE: 3.1093\n","\tbatch: 200, loss: 29.0534, MAE: 3.7654\n","Training:\t loss: 27.4467, MAE: 2.6429\n","Evaluating:\t loss: 22.4763, MAE: 2.3098\n","train MSE: 27.4467, evaluate MSE: 22.4763\n","\n","train MAE: 2.6429, evaluate MAE: 2.3098\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1917\n","\tbatch: 100, loss: 6.4098, MAE: 1.5762\n","\tbatch: 200, loss: 47.2156, MAE: 2.6424\n","Training:\t loss: 22.2113, MAE: 2.2139\n","Evaluating:\t loss: 29.7255, MAE: 2.9163\n","train MSE: 22.2113, evaluate MSE: 29.7255\n","\n","train MAE: 2.2139, evaluate MAE: 2.9163\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1918\n","\tbatch: 100, loss: 17.0505, MAE: 2.1393\n","\tbatch: 200, loss: 16.1569, MAE: 2.1618\n","Training:\t loss: 24.8344, MAE: 2.4893\n","Evaluating:\t loss: 22.0347, MAE: 2.8718\n","train MSE: 24.8344, evaluate MSE: 22.0347\n","\n","train MAE: 2.4893, evaluate MAE: 2.8718\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1919\n","\tbatch: 100, loss: 12.3567, MAE: 2.0059\n","\tbatch: 200, loss: 25.7938, MAE: 1.9949\n","Training:\t loss: 21.1489, MAE: 2.1967\n","Evaluating:\t loss: 20.8503, MAE: 1.9762\n","train MSE: 21.1489, evaluate MSE: 20.8503\n","\n","train MAE: 2.1967, evaluate MAE: 1.9762\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1920\n","\tbatch: 100, loss: 10.3304, MAE: 2.0656\n","\tbatch: 200, loss: 21.6564, MAE: 2.0496\n","Training:\t loss: 18.7430, MAE: 2.0463\n","Evaluating:\t loss: 22.5190, MAE: 2.0727\n","train MSE: 18.7430, evaluate MSE: 22.5190\n","\n","train MAE: 2.0463, evaluate MAE: 2.0727\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1921\n","\tbatch: 100, loss: 16.5662, MAE: 1.8889\n","\tbatch: 200, loss: 15.1938, MAE: 2.1714\n","Training:\t loss: 20.3886, MAE: 2.0975\n","Evaluating:\t loss: 23.5727, MAE: 3.0820\n","train MSE: 20.3886, evaluate MSE: 23.5727\n","\n","train MAE: 2.0975, evaluate MAE: 3.0820\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1922\n","\tbatch: 100, loss: 48.9083, MAE: 3.7612\n","\tbatch: 200, loss: 17.4089, MAE: 2.6812\n","Training:\t loss: 35.3317, MAE: 3.2202\n","Evaluating:\t loss: 26.9215, MAE: 2.6909\n","train MSE: 35.3317, evaluate MSE: 26.9215\n","\n","train MAE: 3.2202, evaluate MAE: 2.6909\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1923\n","\tbatch: 100, loss: 15.0756, MAE: 2.4437\n","\tbatch: 200, loss: 37.1029, MAE: 2.7921\n","Training:\t loss: 31.8041, MAE: 2.7047\n","Evaluating:\t loss: 23.0185, MAE: 2.3444\n","train MSE: 31.8041, evaluate MSE: 23.0185\n","\n","train MAE: 2.7047, evaluate MAE: 2.3444\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1924\n","\tbatch: 100, loss: 33.5968, MAE: 2.9630\n","\tbatch: 200, loss: 26.3323, MAE: 2.8600\n","Training:\t loss: 29.6676, MAE: 2.8049\n","Evaluating:\t loss: 30.7251, MAE: 3.2598\n","train MSE: 29.6676, evaluate MSE: 30.7251\n","\n","train MAE: 2.8049, evaluate MAE: 3.2598\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1925\n","\tbatch: 100, loss: 29.4949, MAE: 2.7605\n","\tbatch: 200, loss: 30.2805, MAE: 3.1374\n","Training:\t loss: 28.5513, MAE: 2.8928\n","Evaluating:\t loss: 24.9186, MAE: 2.8929\n","train MSE: 28.5513, evaluate MSE: 24.9186\n","\n","train MAE: 2.8928, evaluate MAE: 2.8929\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1926\n","\tbatch: 100, loss: 10.8037, MAE: 2.0492\n","\tbatch: 200, loss: 22.1424, MAE: 2.4442\n","Training:\t loss: 29.9192, MAE: 2.8911\n","Evaluating:\t loss: 30.3308, MAE: 2.7651\n","train MSE: 29.9192, evaluate MSE: 30.3308\n","\n","train MAE: 2.8911, evaluate MAE: 2.7651\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1927\n","\tbatch: 100, loss: 19.0448, MAE: 2.6917\n","\tbatch: 200, loss: 30.4103, MAE: 3.5724\n","Training:\t loss: 25.6392, MAE: 2.6898\n","Evaluating:\t loss: 37.8199, MAE: 2.8519\n","train MSE: 25.6392, evaluate MSE: 37.8199\n","\n","train MAE: 2.6898, evaluate MAE: 2.8519\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1928\n","\tbatch: 100, loss: 60.4792, MAE: 3.4439\n","\tbatch: 200, loss: 83.0968, MAE: 6.0775\n","Training:\t loss: 144.8614, MAE: 6.5548\n","Evaluating:\t loss: 68.8141, MAE: 5.3485\n","train MSE: 144.8614, evaluate MSE: 68.8141\n","\n","train MAE: 6.5548, evaluate MAE: 5.3485\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1929\n","\tbatch: 100, loss: 56.8029, MAE: 4.8645\n","\tbatch: 200, loss: 42.9729, MAE: 3.8127\n","Training:\t loss: 56.3453, MAE: 4.6685\n","Evaluating:\t loss: 56.9895, MAE: 4.4316\n","train MSE: 56.3453, evaluate MSE: 56.9895\n","\n","train MAE: 4.6685, evaluate MAE: 4.4316\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1930\n","\tbatch: 100, loss: 42.1298, MAE: 3.8748\n","\tbatch: 200, loss: 40.5599, MAE: 3.8128\n","Training:\t loss: 40.1864, MAE: 3.6132\n","Evaluating:\t loss: 48.2121, MAE: 3.7413\n","train MSE: 40.1864, evaluate MSE: 48.2121\n","\n","train MAE: 3.6132, evaluate MAE: 3.7413\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1931\n","\tbatch: 100, loss: 58.3204, MAE: 4.8750\n","\tbatch: 200, loss: 37.1413, MAE: 3.1919\n","Training:\t loss: 53.7171, MAE: 4.3291\n","Evaluating:\t loss: 33.0290, MAE: 3.3825\n","train MSE: 53.7171, evaluate MSE: 33.0290\n","\n","train MAE: 4.3291, evaluate MAE: 3.3825\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1932\n","\tbatch: 100, loss: 25.2182, MAE: 2.9438\n","\tbatch: 200, loss: 43.2371, MAE: 3.2913\n","Training:\t loss: 33.9813, MAE: 3.3022\n","Evaluating:\t loss: 33.4556, MAE: 3.1319\n","train MSE: 33.9813, evaluate MSE: 33.4556\n","\n","train MAE: 3.3022, evaluate MAE: 3.1319\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1933\n","\tbatch: 100, loss: 30.3787, MAE: 3.1941\n","\tbatch: 200, loss: 16.1775, MAE: 2.3630\n","Training:\t loss: 32.8786, MAE: 2.9213\n","Evaluating:\t loss: 34.7021, MAE: 3.0899\n","train MSE: 32.8786, evaluate MSE: 34.7021\n","\n","train MAE: 2.9213, evaluate MAE: 3.0899\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1934\n","\tbatch: 100, loss: 52.6902, MAE: 4.1410\n","\tbatch: 200, loss: 26.6003, MAE: 3.1718\n","Training:\t loss: 38.9101, MAE: 3.3419\n","Evaluating:\t loss: 51.2053, MAE: 5.6166\n","train MSE: 38.9101, evaluate MSE: 51.2053\n","\n","train MAE: 3.3419, evaluate MAE: 5.6166\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1935\n","\tbatch: 100, loss: 29.3867, MAE: 3.9132\n","\tbatch: 200, loss: 55.7055, MAE: 5.4027\n","Training:\t loss: 45.9784, MAE: 3.9766\n","Evaluating:\t loss: 32.4766, MAE: 3.3263\n","train MSE: 45.9784, evaluate MSE: 32.4766\n","\n","train MAE: 3.9766, evaluate MAE: 3.3263\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1936\n","\tbatch: 100, loss: 38.8115, MAE: 3.2828\n","\tbatch: 200, loss: 17.5924, MAE: 2.4959\n","Training:\t loss: 41.4376, MAE: 3.3618\n","Evaluating:\t loss: 32.3048, MAE: 3.0418\n","train MSE: 41.4376, evaluate MSE: 32.3048\n","\n","train MAE: 3.3618, evaluate MAE: 3.0418\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1937\n","\tbatch: 100, loss: 37.9286, MAE: 2.6766\n","\tbatch: 200, loss: 30.1663, MAE: 2.7395\n","Training:\t loss: 27.7574, MAE: 2.6860\n","Evaluating:\t loss: 35.5678, MAE: 3.3609\n","train MSE: 27.7574, evaluate MSE: 35.5678\n","\n","train MAE: 2.6860, evaluate MAE: 3.3609\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1938\n","\tbatch: 100, loss: 87.0617, MAE: 3.8588\n","\tbatch: 200, loss: 88.7265, MAE: 3.9663\n","Training:\t loss: 60.5385, MAE: 4.0589\n","Evaluating:\t loss: 44.2116, MAE: 3.0672\n","train MSE: 60.5385, evaluate MSE: 44.2116\n","\n","train MAE: 4.0589, evaluate MAE: 3.0672\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1939\n","\tbatch: 100, loss: 51.0003, MAE: 3.4673\n","\tbatch: 200, loss: 21.7534, MAE: 2.4635\n","Training:\t loss: 43.0348, MAE: 3.3116\n","Evaluating:\t loss: 62.1712, MAE: 4.4709\n","train MSE: 43.0348, evaluate MSE: 62.1712\n","\n","train MAE: 3.3116, evaluate MAE: 4.4709\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1940\n","\tbatch: 100, loss: 89.7490, MAE: 5.2765\n","\tbatch: 200, loss: 20.1346, MAE: 2.7306\n","Training:\t loss: 54.2917, MAE: 3.8658\n","Evaluating:\t loss: 31.2619, MAE: 2.4996\n","train MSE: 54.2917, evaluate MSE: 31.2619\n","\n","train MAE: 3.8658, evaluate MAE: 2.4996\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1941\n","\tbatch: 100, loss: 13.2129, MAE: 1.9814\n","\tbatch: 200, loss: 15.9006, MAE: 2.0470\n","Training:\t loss: 27.1956, MAE: 2.2556\n","Evaluating:\t loss: 25.1131, MAE: 2.3548\n","train MSE: 27.1956, evaluate MSE: 25.1131\n","\n","train MAE: 2.2556, evaluate MAE: 2.3548\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1942\n","\tbatch: 100, loss: 29.4330, MAE: 3.2815\n","\tbatch: 200, loss: 149.5865, MAE: 9.3792\n","Training:\t loss: 48.5091, MAE: 3.4765\n","Evaluating:\t loss: 46.1908, MAE: 4.2433\n","train MSE: 48.5091, evaluate MSE: 46.1908\n","\n","train MAE: 3.4765, evaluate MAE: 4.2433\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1943\n","\tbatch: 100, loss: 55.4431, MAE: 5.3029\n","\tbatch: 200, loss: 39.3103, MAE: 3.5788\n","Training:\t loss: 48.2454, MAE: 4.0452\n","Evaluating:\t loss: 30.0276, MAE: 3.1238\n","train MSE: 48.2454, evaluate MSE: 30.0276\n","\n","train MAE: 4.0452, evaluate MAE: 3.1238\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1944\n","\tbatch: 100, loss: 20.9145, MAE: 2.5812\n","\tbatch: 200, loss: 28.5916, MAE: 2.7966\n","Training:\t loss: 34.3074, MAE: 2.9853\n","Evaluating:\t loss: 25.9294, MAE: 2.5825\n","train MSE: 34.3074, evaluate MSE: 25.9294\n","\n","train MAE: 2.9853, evaluate MAE: 2.5825\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1945\n","\tbatch: 100, loss: 86.1466, MAE: 3.8559\n","\tbatch: 200, loss: 21.7969, MAE: 2.7987\n","Training:\t loss: 38.3939, MAE: 3.4989\n","Evaluating:\t loss: 31.4386, MAE: 2.7445\n","train MSE: 38.3939, evaluate MSE: 31.4386\n","\n","train MAE: 3.4989, evaluate MAE: 2.7445\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1946\n","\tbatch: 100, loss: 41.9418, MAE: 3.1159\n","\tbatch: 200, loss: 54.1277, MAE: 4.5948\n","Training:\t loss: 37.3482, MAE: 3.3266\n","Evaluating:\t loss: 32.1983, MAE: 3.1401\n","train MSE: 37.3482, evaluate MSE: 32.1983\n","\n","train MAE: 3.3266, evaluate MAE: 3.1401\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1947\n","\tbatch: 100, loss: 20.7378, MAE: 2.9120\n","\tbatch: 200, loss: 20.5360, MAE: 2.9167\n","Training:\t loss: 29.7676, MAE: 2.9599\n","Evaluating:\t loss: 35.2876, MAE: 3.6736\n","train MSE: 29.7676, evaluate MSE: 35.2876\n","\n","train MAE: 2.9599, evaluate MAE: 3.6736\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1948\n","\tbatch: 100, loss: 108.2987, MAE: 5.1158\n","\tbatch: 200, loss: 11.0254, MAE: 2.1761\n","Training:\t loss: 30.8456, MAE: 2.9307\n","Evaluating:\t loss: 28.1193, MAE: 3.0237\n","train MSE: 30.8456, evaluate MSE: 28.1193\n","\n","train MAE: 2.9307, evaluate MAE: 3.0237\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1949\n","\tbatch: 100, loss: 32.1034, MAE: 3.9794\n","\tbatch: 200, loss: 15.2383, MAE: 2.5753\n","Training:\t loss: 39.2403, MAE: 3.4883\n","Evaluating:\t loss: 49.2889, MAE: 3.9799\n","train MSE: 39.2403, evaluate MSE: 49.2889\n","\n","train MAE: 3.4883, evaluate MAE: 3.9799\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1950\n","\tbatch: 100, loss: 27.3475, MAE: 2.7402\n","\tbatch: 200, loss: 22.4668, MAE: 2.5367\n","Training:\t loss: 30.9056, MAE: 2.9799\n","Evaluating:\t loss: 28.6284, MAE: 2.5408\n","train MSE: 30.9056, evaluate MSE: 28.6284\n","\n","train MAE: 2.9799, evaluate MAE: 2.5408\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1951\n","\tbatch: 100, loss: 52.6988, MAE: 3.2125\n","\tbatch: 200, loss: 39.0684, MAE: 3.0660\n","Training:\t loss: 29.8984, MAE: 3.0491\n","Evaluating:\t loss: 36.5469, MAE: 3.0564\n","train MSE: 29.8984, evaluate MSE: 36.5469\n","\n","train MAE: 3.0491, evaluate MAE: 3.0564\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1952\n","\tbatch: 100, loss: 23.2402, MAE: 2.4252\n","\tbatch: 200, loss: 8.8667, MAE: 1.9743\n","Training:\t loss: 25.1510, MAE: 2.4881\n","Evaluating:\t loss: 30.4623, MAE: 2.9967\n","train MSE: 25.1510, evaluate MSE: 30.4623\n","\n","train MAE: 2.4881, evaluate MAE: 2.9967\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1953\n","\tbatch: 100, loss: 18.3483, MAE: 2.3377\n","\tbatch: 200, loss: 29.3804, MAE: 3.0500\n","Training:\t loss: 25.6967, MAE: 2.6128\n","Evaluating:\t loss: 26.4762, MAE: 2.1582\n","train MSE: 25.6967, evaluate MSE: 26.4762\n","\n","train MAE: 2.6128, evaluate MAE: 2.1582\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1954\n","\tbatch: 100, loss: 80.0336, MAE: 3.1638\n","\tbatch: 200, loss: 32.7952, MAE: 2.7046\n","Training:\t loss: 41.6067, MAE: 3.2046\n","Evaluating:\t loss: 54.9636, MAE: 3.2500\n","train MSE: 41.6067, evaluate MSE: 54.9636\n","\n","train MAE: 3.2046, evaluate MAE: 3.2500\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1955\n","\tbatch: 100, loss: 12.9619, MAE: 2.3094\n","\tbatch: 200, loss: 27.1187, MAE: 2.7187\n","Training:\t loss: 32.5489, MAE: 2.6765\n","Evaluating:\t loss: 26.1102, MAE: 2.1238\n","train MSE: 32.5489, evaluate MSE: 26.1102\n","\n","train MAE: 2.6765, evaluate MAE: 2.1238\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1956\n","\tbatch: 100, loss: 18.3085, MAE: 2.0341\n","\tbatch: 200, loss: 29.1833, MAE: 2.3365\n","Training:\t loss: 20.2849, MAE: 2.0546\n","Evaluating:\t loss: 19.6751, MAE: 2.0102\n","train MSE: 20.2849, evaluate MSE: 19.6751\n","\n","train MAE: 2.0546, evaluate MAE: 2.0102\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1957\n","\tbatch: 100, loss: 16.1944, MAE: 1.7787\n","\tbatch: 200, loss: 11.0476, MAE: 2.0962\n","Training:\t loss: 20.4254, MAE: 2.1774\n","Evaluating:\t loss: 22.5343, MAE: 2.5553\n","train MSE: 20.4254, evaluate MSE: 22.5343\n","\n","train MAE: 2.1774, evaluate MAE: 2.5553\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1958\n","\tbatch: 100, loss: 12.2213, MAE: 1.8001\n","\tbatch: 200, loss: 30.6654, MAE: 3.4969\n","Training:\t loss: 23.4572, MAE: 2.5536\n","Evaluating:\t loss: 22.5214, MAE: 2.6861\n","train MSE: 23.4572, evaluate MSE: 22.5214\n","\n","train MAE: 2.5536, evaluate MAE: 2.6861\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1959\n","\tbatch: 100, loss: 26.3650, MAE: 2.6173\n","\tbatch: 200, loss: 18.1404, MAE: 2.4657\n","Training:\t loss: 29.0227, MAE: 2.8856\n","Evaluating:\t loss: 31.3124, MAE: 2.8012\n","train MSE: 29.0227, evaluate MSE: 31.3124\n","\n","train MAE: 2.8856, evaluate MAE: 2.8012\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1960\n","\tbatch: 100, loss: 24.1387, MAE: 2.2194\n","\tbatch: 200, loss: 14.1789, MAE: 1.9406\n","Training:\t loss: 22.1810, MAE: 2.5047\n","Evaluating:\t loss: 17.8266, MAE: 1.9676\n","train MSE: 22.1810, evaluate MSE: 17.8266\n","\n","train MAE: 2.5047, evaluate MAE: 1.9676\n","\n","--- time consumption (s): 17\n","\n","------------------------------\n","Epoch 1961\n","\tbatch: 100, loss: 48.5678, MAE: 3.2612\n","\tbatch: 200, loss: 14.3778, MAE: 2.6430\n","Training:\t loss: 31.0839, MAE: 2.8555\n","Evaluating:\t loss: 40.8513, MAE: 3.8751\n","train MSE: 31.0839, evaluate MSE: 40.8513\n","\n","train MAE: 2.8555, evaluate MAE: 3.8751\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1962\n","\tbatch: 100, loss: 33.7339, MAE: 4.4422\n","\tbatch: 200, loss: 49.9620, MAE: 2.8332\n","Training:\t loss: 87.6728, MAE: 3.9374\n","Evaluating:\t loss: 62.2996, MAE: 3.2394\n","train MSE: 87.6728, evaluate MSE: 62.2996\n","\n","train MAE: 3.9374, evaluate MAE: 3.2394\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1963\n","\tbatch: 100, loss: 25.8452, MAE: 3.0466\n","\tbatch: 200, loss: 45.0255, MAE: 3.5315\n","Training:\t loss: 78.9076, MAE: 3.7223\n","Evaluating:\t loss: 49.0364, MAE: 2.9323\n","train MSE: 78.9076, evaluate MSE: 49.0364\n","\n","train MAE: 3.7223, evaluate MAE: 2.9323\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1964\n","\tbatch: 100, loss: 59.2897, MAE: 4.3722\n","\tbatch: 200, loss: 72.2670, MAE: 3.7600\n","Training:\t loss: 108.8115, MAE: 4.4052\n","Evaluating:\t loss: 93.4914, MAE: 3.3973\n","train MSE: 108.8115, evaluate MSE: 93.4914\n","\n","train MAE: 4.4052, evaluate MAE: 3.3973\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1965\n","\tbatch: 100, loss: 107.4274, MAE: 7.8874\n","\tbatch: 200, loss: 110.8929, MAE: 6.5503\n","Training:\t loss: 327.5560, MAE: 10.6466\n","Evaluating:\t loss: 118.1453, MAE: 6.3204\n","train MSE: 327.5560, evaluate MSE: 118.1453\n","\n","train MAE: 10.6466, evaluate MAE: 6.3204\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1966\n","\tbatch: 100, loss: 104.4593, MAE: 5.5884\n","\tbatch: 200, loss: 486.1290, MAE: 5.2708\n","Training:\t loss: 117.6396, MAE: 4.9466\n","Evaluating:\t loss: 123.3265, MAE: 6.6782\n","train MSE: 117.6396, evaluate MSE: 123.3265\n","\n","train MAE: 4.9466, evaluate MAE: 6.6782\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1967\n","\tbatch: 100, loss: 25.1342, MAE: 3.5013\n","\tbatch: 200, loss: 36.8206, MAE: 4.4783\n","Training:\t loss: 109.0570, MAE: 4.5811\n","Evaluating:\t loss: 121.2068, MAE: 5.9291\n","train MSE: 109.0570, evaluate MSE: 121.2068\n","\n","train MAE: 4.5811, evaluate MAE: 5.9291\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1968\n","\tbatch: 100, loss: 70.7384, MAE: 3.7912\n","\tbatch: 200, loss: 39.9014, MAE: 3.7553\n","Training:\t loss: 105.6468, MAE: 4.2989\n","Evaluating:\t loss: 83.4048, MAE: 3.8644\n","train MSE: 105.6468, evaluate MSE: 83.4048\n","\n","train MAE: 4.2989, evaluate MAE: 3.8644\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1969\n","\tbatch: 100, loss: 372.9627, MAE: 4.5129\n","\tbatch: 200, loss: 47.8151, MAE: 4.1104\n","Training:\t loss: 104.8651, MAE: 4.3100\n","Evaluating:\t loss: 87.4393, MAE: 3.9691\n","train MSE: 104.8651, evaluate MSE: 87.4393\n","\n","train MAE: 4.3100, evaluate MAE: 3.9691\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1970\n","\tbatch: 100, loss: 417.3111, MAE: 5.4058\n","\tbatch: 200, loss: 22.3317, MAE: 3.0598\n","Training:\t loss: 96.6095, MAE: 4.1710\n","Evaluating:\t loss: 97.3023, MAE: 4.3776\n","train MSE: 96.6095, evaluate MSE: 97.3023\n","\n","train MAE: 4.1710, evaluate MAE: 4.3776\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1971\n","\tbatch: 100, loss: 50.6189, MAE: 4.2365\n","\tbatch: 200, loss: 472.5785, MAE: 5.4788\n","Training:\t loss: 85.1121, MAE: 3.7227\n","Evaluating:\t loss: 65.0574, MAE: 3.5130\n","train MSE: 85.1121, evaluate MSE: 65.0574\n","\n","train MAE: 3.7227, evaluate MAE: 3.5130\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1972\n","\tbatch: 100, loss: 41.6227, MAE: 3.3781\n","\tbatch: 200, loss: 32.3395, MAE: 3.1971\n","Training:\t loss: 82.3147, MAE: 3.5861\n","Evaluating:\t loss: 68.0402, MAE: 3.5771\n","train MSE: 82.3147, evaluate MSE: 68.0402\n","\n","train MAE: 3.5861, evaluate MAE: 3.5771\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1973\n","\tbatch: 100, loss: 21.2006, MAE: 3.2197\n","\tbatch: 200, loss: 28.1039, MAE: 2.5859\n","Training:\t loss: 81.5413, MAE: 3.5393\n","Evaluating:\t loss: 66.7453, MAE: 3.3282\n","train MSE: 81.5413, evaluate MSE: 66.7453\n","\n","train MAE: 3.5393, evaluate MAE: 3.3282\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1974\n","\tbatch: 100, loss: 372.4907, MAE: 4.2950\n","\tbatch: 200, loss: 34.5831, MAE: 3.5735\n","Training:\t loss: 87.0012, MAE: 4.0363\n","Evaluating:\t loss: 88.9347, MAE: 4.4891\n","train MSE: 87.0012, evaluate MSE: 88.9347\n","\n","train MAE: 4.0363, evaluate MAE: 4.4891\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1975\n","\tbatch: 100, loss: 137.9681, MAE: 4.9134\n","\tbatch: 200, loss: 74.7128, MAE: 3.4749\n","Training:\t loss: 87.8598, MAE: 3.8606\n","Evaluating:\t loss: 61.0698, MAE: 3.5268\n","train MSE: 87.8598, evaluate MSE: 61.0698\n","\n","train MAE: 3.8606, evaluate MAE: 3.5268\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1976\n","\tbatch: 100, loss: 82.8010, MAE: 3.8986\n","\tbatch: 200, loss: 27.5144, MAE: 2.8656\n","Training:\t loss: 79.3157, MAE: 3.4232\n","Evaluating:\t loss: 61.8256, MAE: 3.2816\n","train MSE: 79.3157, evaluate MSE: 61.8256\n","\n","train MAE: 3.4232, evaluate MAE: 3.2816\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1977\n","\tbatch: 100, loss: 21.7962, MAE: 2.5902\n","\tbatch: 200, loss: 43.1185, MAE: 3.0101\n","Training:\t loss: 72.2642, MAE: 3.3360\n","Evaluating:\t loss: 81.7397, MAE: 5.7094\n","train MSE: 72.2642, evaluate MSE: 81.7397\n","\n","train MAE: 3.3360, evaluate MAE: 5.7094\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1978\n","\tbatch: 100, loss: 25.8953, MAE: 2.9231\n","\tbatch: 200, loss: 30.0655, MAE: 2.6532\n","Training:\t loss: 71.5965, MAE: 3.3370\n","Evaluating:\t loss: 61.6014, MAE: 4.5791\n","train MSE: 71.5965, evaluate MSE: 61.6014\n","\n","train MAE: 3.3370, evaluate MAE: 4.5791\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1979\n","\tbatch: 100, loss: 22.5993, MAE: 2.6347\n","\tbatch: 200, loss: 18.3631, MAE: 3.0219\n","Training:\t loss: 73.8665, MAE: 3.5262\n","Evaluating:\t loss: 64.6008, MAE: 3.5072\n","train MSE: 73.8665, evaluate MSE: 64.6008\n","\n","train MAE: 3.5262, evaluate MAE: 3.5072\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1980\n","\tbatch: 100, loss: 28.4918, MAE: 2.8674\n","\tbatch: 200, loss: 61.3305, MAE: 3.2734\n","Training:\t loss: 74.0838, MAE: 3.2872\n","Evaluating:\t loss: 49.5682, MAE: 2.4825\n","train MSE: 74.0838, evaluate MSE: 49.5682\n","\n","train MAE: 3.2872, evaluate MAE: 2.4825\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1981\n","\tbatch: 100, loss: 13.8497, MAE: 2.3419\n","\tbatch: 200, loss: 30.3425, MAE: 2.6437\n","Training:\t loss: 67.2883, MAE: 3.0917\n","Evaluating:\t loss: 70.2001, MAE: 4.8215\n","train MSE: 67.2883, evaluate MSE: 70.2001\n","\n","train MAE: 3.0917, evaluate MAE: 4.8215\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1982\n","\tbatch: 100, loss: 13.9802, MAE: 2.3776\n","\tbatch: 200, loss: 23.2026, MAE: 2.4715\n","Training:\t loss: 61.8638, MAE: 2.9170\n","Evaluating:\t loss: 42.6129, MAE: 2.5219\n","train MSE: 61.8638, evaluate MSE: 42.6129\n","\n","train MAE: 2.9170, evaluate MAE: 2.5219\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1983\n","\tbatch: 100, loss: 46.2405, MAE: 3.1371\n","\tbatch: 200, loss: 331.3333, MAE: 6.0081\n","Training:\t loss: 69.8936, MAE: 3.3906\n","Evaluating:\t loss: 50.3340, MAE: 2.6516\n","train MSE: 69.8936, evaluate MSE: 50.3340\n","\n","train MAE: 3.3906, evaluate MAE: 2.6516\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1984\n","\tbatch: 100, loss: 25.3233, MAE: 2.5276\n","\tbatch: 200, loss: 284.2633, MAE: 4.0310\n","Training:\t loss: 65.6835, MAE: 3.0725\n","Evaluating:\t loss: 74.0940, MAE: 4.7986\n","train MSE: 65.6835, evaluate MSE: 74.0940\n","\n","train MAE: 3.0725, evaluate MAE: 4.7986\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1985\n","\tbatch: 100, loss: 40.9584, MAE: 3.1264\n","\tbatch: 200, loss: 363.8038, MAE: 3.7448\n","Training:\t loss: 67.1205, MAE: 3.4900\n","Evaluating:\t loss: 46.7286, MAE: 3.3033\n","train MSE: 67.1205, evaluate MSE: 46.7286\n","\n","train MAE: 3.4900, evaluate MAE: 3.3033\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1986\n","\tbatch: 100, loss: 14.9669, MAE: 2.7857\n","\tbatch: 200, loss: 32.5399, MAE: 4.0197\n","Training:\t loss: 63.8918, MAE: 3.1164\n","Evaluating:\t loss: 55.4043, MAE: 4.5907\n","train MSE: 63.8918, evaluate MSE: 55.4043\n","\n","train MAE: 3.1164, evaluate MAE: 4.5907\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1987\n","\tbatch: 100, loss: 287.7679, MAE: 2.9205\n","\tbatch: 200, loss: 28.6474, MAE: 2.2708\n","Training:\t loss: 58.4898, MAE: 2.8270\n","Evaluating:\t loss: 52.4691, MAE: 3.6529\n","train MSE: 58.4898, evaluate MSE: 52.4691\n","\n","train MAE: 2.8270, evaluate MAE: 3.6529\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 1988\n","\tbatch: 100, loss: 46.4453, MAE: 2.8653\n"]}],"source":["!python main.py -e 2000 -lr 1e-4 -o base-base-2000-1e-4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3wF9DkPXYsxX"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"Y07NehrMoe2_"},"source":["## 神经网络模型修改"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":537634,"status":"ok","timestamp":1634430867937,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"__jOar0WodH5","outputId":"387f9e2f-b378-4ebb-9e91-35cd7caf9928"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using backend: pytorch\n","using device: cuda:0\n","....loaded....\n","../base/2021-10-17-dtnn-12/model_dtnn_conv_3_label_2021-10-17_1634430383.txt\n","==========2021-10-17 00:26:23.470359==========\n","model_type: dtnn\n","number of parameters: 596781\n","batch_size: 512\n","n_conv: 3\n","learngin rate: 0.005\n","device: cuda:0\n","--------------------\n","\n","=============== training & evaluating ===============\n","------------------------------\n","Epoch 1\n","\tbatch: 100, loss: 5395477.5000, MAE: 1855.8566\n","\tbatch: 200, loss: 2830669.0000, MAE: 1346.5411\n","Training:\t loss: 8312683.9481, MAE: 2053.3799\n","Evaluating:\t loss: 1251148.3973, MAE: 861.2621\n","train MSE: 8312683.9481, evaluate MSE: 1251148.3973\n","\n","train MAE: 2053.3799, evaluate MAE: 861.2621\n","\n","--- time consumption (s): 20\n","\n","------------------------------\n","Epoch 2\n","\tbatch: 100, loss: 813695.8750, MAE: 739.4013\n","\tbatch: 200, loss: 1070979.0000, MAE: 813.4909\n","Training:\t loss: 1060298.7489, MAE: 794.8852\n","Evaluating:\t loss: 1061690.1696, MAE: 784.5692\n","train MSE: 1060298.7489, evaluate MSE: 1061690.1696\n","\n","train MAE: 794.8852, evaluate MAE: 784.5692\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 3\n","\tbatch: 100, loss: 841786.2500, MAE: 728.1498\n","\tbatch: 200, loss: 918447.3750, MAE: 758.8618\n","Training:\t loss: 1014371.1152, MAE: 785.6674\n","Evaluating:\t loss: 796012.6161, MAE: 697.3879\n","train MSE: 1014371.1152, evaluate MSE: 796012.6161\n","\n","train MAE: 785.6674, evaluate MAE: 697.3879\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 4\n","\tbatch: 100, loss: 614045.3750, MAE: 610.4335\n","\tbatch: 200, loss: 557530.0625, MAE: 584.0078\n","Training:\t loss: 707376.0685, MAE: 658.7903\n","Evaluating:\t loss: 680216.8929, MAE: 640.9862\n","train MSE: 707376.0685, evaluate MSE: 680216.8929\n","\n","train MAE: 658.7903, evaluate MAE: 640.9862\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 5\n","\tbatch: 100, loss: 633150.8125, MAE: 631.7999\n","\tbatch: 200, loss: 782975.5000, MAE: 726.9498\n","Training:\t loss: 674907.1144, MAE: 654.3064\n","Evaluating:\t loss: 434193.2344, MAE: 515.1919\n","train MSE: 674907.1144, evaluate MSE: 434193.2344\n","\n","train MAE: 654.3064, evaluate MAE: 515.1919\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 6\n","\tbatch: 100, loss: 313413.5625, MAE: 449.5768\n","\tbatch: 200, loss: 243456.9375, MAE: 380.4417\n","Training:\t loss: 332979.0638, MAE: 459.4711\n","Evaluating:\t loss: 252292.9788, MAE: 386.8161\n","train MSE: 332979.0638, evaluate MSE: 252292.9788\n","\n","train MAE: 459.4711, evaluate MAE: 386.8161\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 7\n","\tbatch: 100, loss: 247978.0938, MAE: 395.8163\n","\tbatch: 200, loss: 177949.0938, MAE: 331.5867\n","Training:\t loss: 286922.1672, MAE: 423.5861\n","Evaluating:\t loss: 169478.2020, MAE: 329.6068\n","train MSE: 286922.1672, evaluate MSE: 169478.2020\n","\n","train MAE: 423.5861, evaluate MAE: 329.6068\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 8\n","\tbatch: 100, loss: 158349.2969, MAE: 311.1906\n","\tbatch: 200, loss: 141532.1875, MAE: 292.1049\n","Training:\t loss: 145550.8673, MAE: 299.0851\n","Evaluating:\t loss: 121354.5938, MAE: 272.9697\n","train MSE: 145550.8673, evaluate MSE: 121354.5938\n","\n","train MAE: 299.0851, evaluate MAE: 272.9697\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 9\n","\tbatch: 100, loss: 102912.5312, MAE: 254.7706\n","\tbatch: 200, loss: 90512.1172, MAE: 234.3337\n","Training:\t loss: 103516.2772, MAE: 251.3026\n","Evaluating:\t loss: 82027.0801, MAE: 222.5306\n","train MSE: 103516.2772, evaluate MSE: 82027.0801\n","\n","train MAE: 251.3026, evaluate MAE: 222.5306\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 10\n","\tbatch: 100, loss: 69753.4688, MAE: 207.9604\n","\tbatch: 200, loss: 55164.3320, MAE: 188.8017\n","Training:\t loss: 69764.5154, MAE: 206.4220\n","Evaluating:\t loss: 53434.6021, MAE: 181.3120\n","train MSE: 69764.5154, evaluate MSE: 53434.6021\n","\n","train MAE: 206.4220, evaluate MAE: 181.3120\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 11\n","\tbatch: 100, loss: 40177.9297, MAE: 157.0509\n","\tbatch: 200, loss: 29854.7383, MAE: 136.0490\n","Training:\t loss: 40788.9039, MAE: 157.9974\n","Evaluating:\t loss: 28373.7471, MAE: 131.8067\n","train MSE: 40788.9039, evaluate MSE: 28373.7471\n","\n","train MAE: 157.9974, evaluate MAE: 131.8067\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 12\n","\tbatch: 100, loss: 21092.1953, MAE: 114.9673\n","\tbatch: 200, loss: 15594.4434, MAE: 100.2343\n","Training:\t loss: 20825.8519, MAE: 113.1192\n","Evaluating:\t loss: 13779.5378, MAE: 92.3341\n","train MSE: 20825.8519, evaluate MSE: 13779.5378\n","\n","train MAE: 113.1192, evaluate MAE: 92.3341\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 13\n","\tbatch: 100, loss: 10253.5850, MAE: 80.2572\n","\tbatch: 200, loss: 7389.0840, MAE: 67.4166\n","Training:\t loss: 9622.4292, MAE: 76.8087\n","Evaluating:\t loss: 6340.6201, MAE: 62.2402\n","train MSE: 9622.4292, evaluate MSE: 6340.6201\n","\n","train MAE: 76.8087, evaluate MAE: 62.2402\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 14\n","\tbatch: 100, loss: 4859.7485, MAE: 52.0676\n","\tbatch: 200, loss: 4303.9321, MAE: 50.6104\n","Training:\t loss: 4750.4825, MAE: 53.3647\n","Evaluating:\t loss: 3994.1748, MAE: 47.2954\n","train MSE: 4750.4825, evaluate MSE: 3994.1748\n","\n","train MAE: 53.3647, evaluate MAE: 47.2954\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 15\n","\tbatch: 100, loss: 3445.2778, MAE: 45.9282\n","\tbatch: 200, loss: 3003.7437, MAE: 43.4432\n","Training:\t loss: 3105.9969, MAE: 42.8622\n","Evaluating:\t loss: 2748.0650, MAE: 39.9446\n","train MSE: 3105.9969, evaluate MSE: 2748.0650\n","\n","train MAE: 42.8622, evaluate MAE: 39.9446\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 16\n","\tbatch: 100, loss: 2706.5032, MAE: 39.2989\n","\tbatch: 200, loss: 2110.6594, MAE: 35.7816\n","Training:\t loss: 2633.1743, MAE: 39.3868\n","Evaluating:\t loss: 2476.9293, MAE: 37.4188\n","train MSE: 2633.1743, evaluate MSE: 2476.9293\n","\n","train MAE: 39.3868, evaluate MAE: 37.4188\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 17\n","\tbatch: 100, loss: 2126.4419, MAE: 35.6204\n","\tbatch: 200, loss: 2232.0935, MAE: 36.8970\n","Training:\t loss: 2130.7004, MAE: 35.0323\n","Evaluating:\t loss: 1955.5436, MAE: 33.2009\n","train MSE: 2130.7004, evaluate MSE: 1955.5436\n","\n","train MAE: 35.0323, evaluate MAE: 33.2009\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 18\n","\tbatch: 100, loss: 1935.1342, MAE: 34.8216\n","\tbatch: 200, loss: 1595.8134, MAE: 30.6600\n","Training:\t loss: 1808.2313, MAE: 32.0932\n","Evaluating:\t loss: 1687.5309, MAE: 30.6380\n","train MSE: 1808.2313, evaluate MSE: 1687.5309\n","\n","train MAE: 32.0932, evaluate MAE: 30.6380\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 19\n","\tbatch: 100, loss: 1497.9895, MAE: 30.3753\n","\tbatch: 200, loss: 1606.3042, MAE: 30.4718\n","Training:\t loss: 1544.6200, MAE: 29.4279\n","Evaluating:\t loss: 1365.0561, MAE: 27.5929\n","train MSE: 1544.6200, evaluate MSE: 1365.0561\n","\n","train MAE: 29.4279, evaluate MAE: 27.5929\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 20\n","\tbatch: 100, loss: 1269.1447, MAE: 26.0745\n","\tbatch: 200, loss: 1334.7512, MAE: 25.1040\n","Training:\t loss: 1317.0869, MAE: 26.9670\n","Evaluating:\t loss: 1026.9812, MAE: 23.2035\n","train MSE: 1317.0869, evaluate MSE: 1026.9812\n","\n","train MAE: 26.9670, evaluate MAE: 23.2035\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 21\n","\tbatch: 100, loss: 1352.7527, MAE: 27.6804\n","\tbatch: 200, loss: 733.1357, MAE: 21.5468\n","Training:\t loss: 1152.3737, MAE: 25.1849\n","Evaluating:\t loss: 2343.2942, MAE: 41.7807\n","train MSE: 1152.3737, evaluate MSE: 2343.2942\n","\n","train MAE: 25.1849, evaluate MAE: 41.7807\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 22\n","\tbatch: 100, loss: 1171.8718, MAE: 24.5971\n","\tbatch: 200, loss: 1970.4827, MAE: 38.5164\n","Training:\t loss: 971.7155, MAE: 22.9469\n","Evaluating:\t loss: 742.2831, MAE: 18.7363\n","train MSE: 971.7155, evaluate MSE: 742.2831\n","\n","train MAE: 22.9469, evaluate MAE: 18.7363\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 23\n","\tbatch: 100, loss: 587.9972, MAE: 16.3196\n","\tbatch: 200, loss: 1407.3699, MAE: 31.8734\n","Training:\t loss: 1410.5539, MAE: 29.0986\n","Evaluating:\t loss: 1155.0160, MAE: 27.9341\n","train MSE: 1410.5539, evaluate MSE: 1155.0160\n","\n","train MAE: 29.0986, evaluate MAE: 27.9341\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 24\n","\tbatch: 100, loss: 463.2726, MAE: 16.0933\n","\tbatch: 200, loss: 583.8077, MAE: 14.6456\n","Training:\t loss: 1141.4770, MAE: 26.0759\n","Evaluating:\t loss: 1017.9419, MAE: 26.5655\n","train MSE: 1141.4770, evaluate MSE: 1017.9419\n","\n","train MAE: 26.0759, evaluate MAE: 26.5655\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 25\n","\tbatch: 100, loss: 2575.3228, MAE: 46.0396\n","\tbatch: 200, loss: 534.7678, MAE: 16.1880\n","Training:\t loss: 1347.9660, MAE: 28.8450\n","Evaluating:\t loss: 634.6354, MAE: 19.1945\n","train MSE: 1347.9660, evaluate MSE: 634.6354\n","\n","train MAE: 28.8450, evaluate MAE: 19.1945\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 26\n","\tbatch: 100, loss: 1888.9115, MAE: 39.4170\n","\tbatch: 200, loss: 463.5914, MAE: 12.6003\n","Training:\t loss: 1128.4476, MAE: 25.3235\n","Evaluating:\t loss: 417.4741, MAE: 12.7098\n","train MSE: 1128.4476, evaluate MSE: 417.4741\n","\n","train MAE: 25.3235, evaluate MAE: 12.7098\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 27\n","\tbatch: 100, loss: 968.9691, MAE: 26.8495\n","\tbatch: 200, loss: 861.7394, MAE: 26.0004\n","Training:\t loss: 1489.1460, MAE: 30.1019\n","Evaluating:\t loss: 465.7538, MAE: 14.3693\n","train MSE: 1489.1460, evaluate MSE: 465.7538\n","\n","train MAE: 30.1019, evaluate MAE: 14.3693\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 28\n","\tbatch: 100, loss: 1653.6344, MAE: 37.0723\n","\tbatch: 200, loss: 1095.9249, MAE: 29.0297\n","Training:\t loss: 1306.7857, MAE: 29.2910\n","Evaluating:\t loss: 430.0303, MAE: 15.3995\n","train MSE: 1306.7857, evaluate MSE: 430.0303\n","\n","train MAE: 29.2910, evaluate MAE: 15.3995\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 29\n","\tbatch: 100, loss: 260.2301, MAE: 10.5111\n","\tbatch: 200, loss: 3991.6694, MAE: 61.0172\n","Training:\t loss: 1647.0868, MAE: 27.8668\n","Evaluating:\t loss: 282.5995, MAE: 9.7994\n","train MSE: 1647.0868, evaluate MSE: 282.5995\n","\n","train MAE: 27.8668, evaluate MAE: 9.7994\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 30\n","\tbatch: 100, loss: 472.0435, MAE: 17.1706\n","\tbatch: 200, loss: 393.4548, MAE: 16.5695\n","Training:\t loss: 790.2851, MAE: 20.6483\n","Evaluating:\t loss: 224.1143, MAE: 7.6370\n","train MSE: 790.2851, evaluate MSE: 224.1143\n","\n","train MAE: 20.6483, evaluate MAE: 7.6370\n","\n","--- time consumption (s): 15\n","\n","Best model has been saved! Best model obtained at epoch 30 with eval MAE\n","=============== testing ===============\n","MSE on test set: 198.9595\n","MAE on test set: 7.5843\n","R2 score: 0.9998\n"]}],"source":["!python main.py -e 30 -o base"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":538997,"status":"ok","timestamp":1634432671709,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"SjRI_QjbodKb","outputId":"11291846-4fc7-4f18-b4da-c508786ff91e"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using backend: pytorch\n","using device: cuda:0\n","....loaded....\n","../base-muti-read/2021-10-17-dtnn-12/model_dtnn_conv_3_label_2021-10-17_1634432175.txt\n","==========2021-10-17 00:56:15.489561==========\n","model_type: dtnn\n","number of parameters: 629549\n","batch_size: 512\n","n_conv: 3\n","learngin rate: 0.005\n","device: cuda:0\n","--------------------\n","\n","=============== training & evaluating ===============\n","------------------------------\n","Epoch 1\n","\tbatch: 100, loss: 5342438.5000, MAE: 1836.0778\n","\tbatch: 200, loss: 1085010.0000, MAE: 826.4927\n","Training:\t loss: 6926016.0885, MAE: 1784.1828\n","Evaluating:\t loss: 1101660.7054, MAE: 820.6029\n","train MSE: 6926016.0885, evaluate MSE: 1101660.7054\n","\n","train MAE: 1784.1828, evaluate MAE: 820.6029\n","\n","--- time consumption (s): 20\n","\n","------------------------------\n","Epoch 2\n","\tbatch: 100, loss: 971048.9375, MAE: 758.1868\n","\tbatch: 200, loss: 692447.5625, MAE: 670.5518\n","Training:\t loss: 986698.3832, MAE: 774.2273\n","Evaluating:\t loss: 657885.2812, MAE: 635.6499\n","train MSE: 986698.3832, evaluate MSE: 657885.2812\n","\n","train MAE: 774.2273, evaluate MAE: 635.6499\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 3\n","\tbatch: 100, loss: 900865.1875, MAE: 768.5898\n","\tbatch: 200, loss: 484882.3750, MAE: 548.2603\n","Training:\t loss: 752760.1731, MAE: 686.5262\n","Evaluating:\t loss: 511052.6161, MAE: 571.9125\n","train MSE: 752760.1731, evaluate MSE: 511052.6161\n","\n","train MAE: 686.5262, evaluate MAE: 571.9125\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 4\n","\tbatch: 100, loss: 307022.5625, MAE: 431.0829\n","\tbatch: 200, loss: 218665.8906, MAE: 375.2833\n","Training:\t loss: 327777.8226, MAE: 449.3560\n","Evaluating:\t loss: 205345.1696, MAE: 356.3402\n","train MSE: 327777.8226, evaluate MSE: 205345.1696\n","\n","train MAE: 449.3560, evaluate MAE: 356.3402\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 5\n","\tbatch: 100, loss: 127202.1562, MAE: 283.8776\n","\tbatch: 200, loss: 90038.2344, MAE: 235.1485\n","Training:\t loss: 124900.0907, MAE: 275.0124\n","Evaluating:\t loss: 135592.2706, MAE: 305.1379\n","train MSE: 124900.0907, evaluate MSE: 135592.2706\n","\n","train MAE: 275.0124, evaluate MAE: 305.1379\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 6\n","\tbatch: 100, loss: 41535.8828, MAE: 157.4530\n","\tbatch: 200, loss: 14664.3096, MAE: 92.9458\n","Training:\t loss: 39727.2105, MAE: 149.0079\n","Evaluating:\t loss: 9942.1258, MAE: 76.0509\n","train MSE: 39727.2105, evaluate MSE: 9942.1258\n","\n","train MAE: 149.0079, evaluate MAE: 76.0509\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 7\n","\tbatch: 100, loss: 5321.4092, MAE: 55.0597\n","\tbatch: 200, loss: 1535.3916, MAE: 21.0650\n","Training:\t loss: 6583.7574, MAE: 50.4123\n","Evaluating:\t loss: 10675.9796, MAE: 98.3678\n","train MSE: 6583.7574, evaluate MSE: 10675.9796\n","\n","train MAE: 50.4123, evaluate MAE: 98.3678\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 8\n","\tbatch: 100, loss: 6123.4375, MAE: 63.1146\n","\tbatch: 200, loss: 902.3861, MAE: 20.2290\n","Training:\t loss: 7243.4743, MAE: 54.6835\n","Evaluating:\t loss: 2938.7541, MAE: 45.2355\n","train MSE: 7243.4743, evaluate MSE: 2938.7541\n","\n","train MAE: 54.6835, evaluate MAE: 45.2355\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 9\n","\tbatch: 100, loss: 632.3787, MAE: 11.6551\n","\tbatch: 200, loss: 256.7603, MAE: 7.9664\n","Training:\t loss: 608.7420, MAE: 13.6277\n","Evaluating:\t loss: 286.9005, MAE: 8.2911\n","train MSE: 608.7420, evaluate MSE: 286.9005\n","\n","train MAE: 13.6277, evaluate MAE: 8.2911\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 10\n","\tbatch: 100, loss: 171.8022, MAE: 6.9239\n","\tbatch: 200, loss: 428.9106, MAE: 7.0814\n","Training:\t loss: 246.8980, MAE: 7.4838\n","Evaluating:\t loss: 214.5561, MAE: 6.8116\n","train MSE: 246.8980, evaluate MSE: 214.5561\n","\n","train MAE: 7.4838, evaluate MAE: 6.8116\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 11\n","\tbatch: 100, loss: 152.9226, MAE: 6.3448\n","\tbatch: 200, loss: 82.5715, MAE: 5.7519\n","Training:\t loss: 208.2278, MAE: 6.4696\n","Evaluating:\t loss: 202.1412, MAE: 7.4530\n","train MSE: 208.2278, evaluate MSE: 202.1412\n","\n","train MAE: 6.4696, evaluate MAE: 7.4530\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 12\n","\tbatch: 100, loss: 78.6057, MAE: 5.0536\n","\tbatch: 200, loss: 429.5638, MAE: 7.3585\n","Training:\t loss: 181.8114, MAE: 5.8031\n","Evaluating:\t loss: 224.6529, MAE: 9.2441\n","train MSE: 181.8114, evaluate MSE: 224.6529\n","\n","train MAE: 5.8031, evaluate MAE: 9.2441\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 13\n","\tbatch: 100, loss: 169.6081, MAE: 7.7621\n","\tbatch: 200, loss: 92.5947, MAE: 5.8624\n","Training:\t loss: 391.7308, MAE: 10.6558\n","Evaluating:\t loss: 147.5834, MAE: 5.4966\n","train MSE: 391.7308, evaluate MSE: 147.5834\n","\n","train MAE: 10.6558, evaluate MAE: 5.4966\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 14\n","\tbatch: 100, loss: 140.4617, MAE: 4.7845\n","\tbatch: 200, loss: 119.4840, MAE: 4.9794\n","Training:\t loss: 137.1949, MAE: 5.1549\n","Evaluating:\t loss: 121.5973, MAE: 3.8629\n","train MSE: 137.1949, evaluate MSE: 121.5973\n","\n","train MAE: 5.1549, evaluate MAE: 3.8629\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 15\n","\tbatch: 100, loss: 13.7270, MAE: 2.6168\n","\tbatch: 200, loss: 230.7666, MAE: 6.8592\n","Training:\t loss: 114.5908, MAE: 4.0240\n","Evaluating:\t loss: 110.4824, MAE: 3.4081\n","train MSE: 114.5908, evaluate MSE: 110.4824\n","\n","train MAE: 4.0240, evaluate MAE: 3.4081\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 16\n","\tbatch: 100, loss: 423363.8125, MAE: 645.6760\n","\tbatch: 200, loss: 75759.4844, MAE: 266.1239\n","Training:\t loss: 58334.8987, MAE: 143.6485\n","Evaluating:\t loss: 11109.2712, MAE: 89.4867\n","train MSE: 58334.8987, evaluate MSE: 11109.2712\n","\n","train MAE: 143.6485, evaluate MAE: 89.4867\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 17\n","\tbatch: 100, loss: 43372.8516, MAE: 196.5388\n","\tbatch: 200, loss: 1307.6886, MAE: 28.3369\n","Training:\t loss: 23732.3613, MAE: 93.4783\n","Evaluating:\t loss: 952.7235, MAE: 23.5615\n","train MSE: 23732.3613, evaluate MSE: 952.7235\n","\n","train MAE: 93.4783, evaluate MAE: 23.5615\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 18\n","\tbatch: 100, loss: 37215.1953, MAE: 190.6201\n","\tbatch: 200, loss: 1155.2983, MAE: 28.3670\n","Training:\t loss: 14973.4932, MAE: 74.2776\n","Evaluating:\t loss: 508.1246, MAE: 14.3425\n","train MSE: 14973.4932, evaluate MSE: 508.1246\n","\n","train MAE: 74.2776, evaluate MAE: 14.3425\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 19\n","\tbatch: 100, loss: 533.6385, MAE: 14.6231\n","\tbatch: 200, loss: 268.4611, MAE: 11.5257\n","Training:\t loss: 420.5023, MAE: 13.0070\n","Evaluating:\t loss: 405.7369, MAE: 12.8996\n","train MSE: 420.5023, evaluate MSE: 405.7369\n","\n","train MAE: 13.0070, evaluate MAE: 12.8996\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 20\n","\tbatch: 100, loss: 172.1941, MAE: 8.9207\n","\tbatch: 200, loss: 1806.4365, MAE: 40.3898\n","Training:\t loss: 677.4414, MAE: 14.6852\n","Evaluating:\t loss: 417.5073, MAE: 12.7466\n","train MSE: 677.4414, evaluate MSE: 417.5073\n","\n","train MAE: 14.6852, evaluate MAE: 12.7466\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 21\n","\tbatch: 100, loss: 253.0092, MAE: 9.0050\n","\tbatch: 200, loss: 2868.0234, MAE: 51.1668\n","Training:\t loss: 1122.1728, MAE: 19.3989\n","Evaluating:\t loss: 579.3753, MAE: 17.2944\n","train MSE: 1122.1728, evaluate MSE: 579.3753\n","\n","train MAE: 19.3989, evaluate MAE: 17.2944\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 22\n","\tbatch: 100, loss: 122.1717, MAE: 7.2371\n","\tbatch: 200, loss: 207.4397, MAE: 7.1035\n","Training:\t loss: 237.6389, MAE: 8.8338\n","Evaluating:\t loss: 207.9127, MAE: 6.6639\n","train MSE: 237.6389, evaluate MSE: 207.9127\n","\n","train MAE: 8.8338, evaluate MAE: 6.6639\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 23\n","\tbatch: 100, loss: 55.5673, MAE: 5.1452\n","\tbatch: 200, loss: 115.7504, MAE: 5.8917\n","Training:\t loss: 159.5614, MAE: 6.1500\n","Evaluating:\t loss: 179.5854, MAE: 5.7003\n","train MSE: 159.5614, evaluate MSE: 179.5854\n","\n","train MAE: 6.1500, evaluate MAE: 5.7003\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 24\n","\tbatch: 100, loss: 59.8009, MAE: 5.3580\n","\tbatch: 200, loss: 76.3103, MAE: 4.7653\n","Training:\t loss: 142.6881, MAE: 5.8703\n","Evaluating:\t loss: 187.2755, MAE: 8.1564\n","train MSE: 142.6881, evaluate MSE: 187.2755\n","\n","train MAE: 5.8703, evaluate MAE: 8.1564\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 25\n","\tbatch: 100, loss: 421.0906, MAE: 6.3569\n","\tbatch: 200, loss: 219.3054, MAE: 4.8669\n","Training:\t loss: 126.8212, MAE: 5.3884\n","Evaluating:\t loss: 137.1926, MAE: 4.8819\n","train MSE: 126.8212, evaluate MSE: 137.1926\n","\n","train MAE: 5.3884, evaluate MAE: 4.8819\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 26\n","\tbatch: 100, loss: 153.7534, MAE: 4.2523\n","\tbatch: 200, loss: 51.2278, MAE: 5.6200\n","Training:\t loss: 122.9954, MAE: 5.6012\n","Evaluating:\t loss: 128.7226, MAE: 4.7050\n","train MSE: 122.9954, evaluate MSE: 128.7226\n","\n","train MAE: 5.6012, evaluate MAE: 4.7050\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 27\n","\tbatch: 100, loss: 126.5149, MAE: 9.0572\n","\tbatch: 200, loss: 117.8630, MAE: 9.4341\n","Training:\t loss: 165.2521, MAE: 8.2053\n","Evaluating:\t loss: 357.3942, MAE: 16.2401\n","train MSE: 165.2521, evaluate MSE: 357.3942\n","\n","train MAE: 8.2053, evaluate MAE: 16.2401\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 28\n","\tbatch: 100, loss: 294.0912, MAE: 11.4615\n","\tbatch: 200, loss: 1497.5770, MAE: 34.8947\n","Training:\t loss: 2798.9715, MAE: 25.8168\n","Evaluating:\t loss: 149.5381, MAE: 7.3593\n","train MSE: 2798.9715, evaluate MSE: 149.5381\n","\n","train MAE: 25.8168, evaluate MAE: 7.3593\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 29\n","\tbatch: 100, loss: 85.3061, MAE: 6.1367\n","\tbatch: 200, loss: 126.0164, MAE: 6.5480\n","Training:\t loss: 114.0108, MAE: 6.3734\n","Evaluating:\t loss: 125.7384, MAE: 6.5001\n","train MSE: 114.0108, evaluate MSE: 125.7384\n","\n","train MAE: 6.3734, evaluate MAE: 6.5001\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 30\n","\tbatch: 100, loss: 190.3544, MAE: 11.3940\n","\tbatch: 200, loss: 5192.3931, MAE: 71.1601\n","Training:\t loss: 565.9772, MAE: 14.0176\n","Evaluating:\t loss: 512.3420, MAE: 21.2599\n","train MSE: 565.9772, evaluate MSE: 512.3420\n","\n","train MAE: 14.0176, evaluate MAE: 21.2599\n","\n","--- time consumption (s): 16\n","\n","Best model has been saved! Best model obtained at epoch 15 with eval MAE 3.408103108406067\n","=============== testing ===============\n","MSE on test set: 508.4359\n","MAE on test set: 21.3768\n","R2 score: 0.9996\n"]}],"source":["!python main.py -e 30 -mr True -o base-muti-read"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":529768,"status":"ok","timestamp":1634435886773,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"GUaQ1Xnhom23","outputId":"2861af47-941d-40cd-db6a-c99b1a5f6608"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using backend: pytorch\n","using device: cuda:0\n","....loaded....\n","using Xavier Uniform initialization for Conv layer\n","using Xavier Uniform initialization for Read layer\n","../base-conv-uniform/2021-10-17-dtnn-12/model_dtnn_conv_3_label_2021-10-17_1634435399.txt\n","==========2021-10-17 01:49:58.645720==========\n","model_type: dtnn\n","number of parameters: 596781\n","batch_size: 512\n","n_conv: 3\n","learngin rate: 0.005\n","device: cuda:0\n","--------------------\n","\n","=============== training & evaluating ===============\n","------------------------------\n","Epoch 1\n","\tbatch: 100, loss: 5660784.5000, MAE: 1901.5831\n","\tbatch: 200, loss: 5197870.0000, MAE: 1825.2113\n","Training:\t loss: 9640024.5869, MAE: 2274.3163\n","Evaluating:\t loss: 5036033.1786, MAE: 1783.1994\n","train MSE: 9640024.5869, evaluate MSE: 5036033.1786\n","\n","train MAE: 2274.3163, evaluate MAE: 1783.1994\n","\n","--- time consumption (s): 21\n","\n","------------------------------\n","Epoch 2\n","\tbatch: 100, loss: 3609492.5000, MAE: 1541.5221\n","\tbatch: 200, loss: 1982084.2500, MAE: 1123.3096\n","Training:\t loss: 3437280.3851, MAE: 1452.5107\n","Evaluating:\t loss: 1644647.3750, MAE: 1007.2740\n","train MSE: 3437280.3851, evaluate MSE: 1644647.3750\n","\n","train MAE: 1452.5107, evaluate MAE: 1007.2740\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 3\n","\tbatch: 100, loss: 702129.8750, MAE: 652.5806\n","\tbatch: 200, loss: 937676.5625, MAE: 819.6517\n","Training:\t loss: 846322.7760, MAE: 705.7900\n","Evaluating:\t loss: 581860.0714, MAE: 625.0828\n","train MSE: 846322.7760, evaluate MSE: 581860.0714\n","\n","train MAE: 705.7900, evaluate MAE: 625.0828\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 4\n","\tbatch: 100, loss: 382563.9375, MAE: 475.1649\n","\tbatch: 200, loss: 369644.5625, MAE: 498.9038\n","Training:\t loss: 403338.3351, MAE: 488.5558\n","Evaluating:\t loss: 320561.9297, MAE: 437.5904\n","train MSE: 403338.3351, evaluate MSE: 320561.9297\n","\n","train MAE: 488.5558, evaluate MAE: 437.5904\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 5\n","\tbatch: 100, loss: 256542.9062, MAE: 401.2224\n","\tbatch: 200, loss: 179317.5000, MAE: 337.8922\n","Training:\t loss: 247199.3601, MAE: 385.7287\n","Evaluating:\t loss: 181073.8058, MAE: 337.2114\n","train MSE: 247199.3601, evaluate MSE: 181073.8058\n","\n","train MAE: 385.7287, evaluate MAE: 337.2114\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 6\n","\tbatch: 100, loss: 140271.7812, MAE: 294.9277\n","\tbatch: 200, loss: 117481.9766, MAE: 256.2342\n","Training:\t loss: 136936.6991, MAE: 286.9146\n","Evaluating:\t loss: 91779.7188, MAE: 239.1306\n","train MSE: 136936.6991, evaluate MSE: 91779.7188\n","\n","train MAE: 286.9146, evaluate MAE: 239.1306\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 7\n","\tbatch: 100, loss: 63715.3672, MAE: 194.2718\n","\tbatch: 200, loss: 231089.4688, MAE: 421.7487\n","Training:\t loss: 139844.1233, MAE: 264.6458\n","Evaluating:\t loss: 118891.3304, MAE: 272.5857\n","train MSE: 139844.1233, evaluate MSE: 118891.3304\n","\n","train MAE: 264.6458, evaluate MAE: 272.5857\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 8\n","\tbatch: 100, loss: 55396.8789, MAE: 177.9375\n","\tbatch: 200, loss: 263323.2188, MAE: 423.0975\n","Training:\t loss: 164447.8376, MAE: 310.1175\n","Evaluating:\t loss: 100204.1490, MAE: 245.7806\n","train MSE: 164447.8376, evaluate MSE: 100204.1490\n","\n","train MAE: 310.1175, evaluate MAE: 245.7806\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 9\n","\tbatch: 100, loss: 65774.1719, MAE: 208.3177\n","\tbatch: 200, loss: 146785.6250, MAE: 333.8603\n","Training:\t loss: 118353.0330, MAE: 257.6556\n","Evaluating:\t loss: 27981.3929, MAE: 115.2688\n","train MSE: 118353.0330, evaluate MSE: 27981.3929\n","\n","train MAE: 257.6556, evaluate MAE: 115.2688\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 10\n","\tbatch: 100, loss: 14460.4375, MAE: 87.8549\n","\tbatch: 200, loss: 40999.5859, MAE: 160.1968\n","Training:\t loss: 101913.4107, MAE: 212.9340\n","Evaluating:\t loss: 90027.1624, MAE: 240.3202\n","train MSE: 101913.4107, evaluate MSE: 90027.1624\n","\n","train MAE: 212.9340, evaluate MAE: 240.3202\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 11\n","\tbatch: 100, loss: 15995.6455, MAE: 87.8384\n","\tbatch: 200, loss: 26447.8301, MAE: 124.6702\n","Training:\t loss: 25983.0084, MAE: 114.3214\n","Evaluating:\t loss: 14137.5829, MAE: 84.4196\n","train MSE: 25983.0084, evaluate MSE: 14137.5829\n","\n","train MAE: 114.3214, evaluate MAE: 84.4196\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 12\n","\tbatch: 100, loss: 8324.9902, MAE: 60.7642\n","\tbatch: 200, loss: 5284.3145, MAE: 53.9250\n","Training:\t loss: 7952.4255, MAE: 61.7883\n","Evaluating:\t loss: 5462.3560, MAE: 50.4867\n","train MSE: 7952.4255, evaluate MSE: 5462.3560\n","\n","train MAE: 61.7883, evaluate MAE: 50.4867\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 13\n","\tbatch: 100, loss: 4905.1406, MAE: 46.3611\n","\tbatch: 200, loss: 4368.4121, MAE: 45.4594\n","Training:\t loss: 16325.9187, MAE: 69.2805\n","Evaluating:\t loss: 55019.8797, MAE: 210.8377\n","train MSE: 16325.9187, evaluate MSE: 55019.8797\n","\n","train MAE: 69.2805, evaluate MAE: 210.8377\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 14\n","\tbatch: 100, loss: 4836.4062, MAE: 49.5200\n","\tbatch: 200, loss: 11184.1758, MAE: 80.8860\n","Training:\t loss: 19263.7729, MAE: 96.7242\n","Evaluating:\t loss: 6907.4757, MAE: 69.4166\n","train MSE: 19263.7729, evaluate MSE: 6907.4757\n","\n","train MAE: 96.7242, evaluate MAE: 69.4166\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 15\n","\tbatch: 100, loss: 6019.3594, MAE: 47.4708\n","\tbatch: 200, loss: 4522.3491, MAE: 49.9972\n","Training:\t loss: 9595.4564, MAE: 69.5805\n","Evaluating:\t loss: 4458.4016, MAE: 43.6417\n","train MSE: 9595.4564, evaluate MSE: 4458.4016\n","\n","train MAE: 69.5805, evaluate MAE: 43.6417\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 16\n","\tbatch: 100, loss: 14878.9902, MAE: 96.2993\n","\tbatch: 200, loss: 4161.4062, MAE: 40.5935\n","Training:\t loss: 10469.9592, MAE: 68.6432\n","Evaluating:\t loss: 3266.2192, MAE: 37.2962\n","train MSE: 10469.9592, evaluate MSE: 3266.2192\n","\n","train MAE: 68.6432, evaluate MAE: 37.2962\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 17\n","\tbatch: 100, loss: 2303.8984, MAE: 32.0360\n","\tbatch: 200, loss: 3603.3240, MAE: 33.3076\n","Training:\t loss: 2584.7427, MAE: 32.5055\n","Evaluating:\t loss: 2171.5248, MAE: 29.2248\n","train MSE: 2584.7427, evaluate MSE: 2171.5248\n","\n","train MAE: 32.5055, evaluate MAE: 29.2248\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 18\n","\tbatch: 100, loss: 6914.8799, MAE: 65.4181\n","\tbatch: 200, loss: 2180.6707, MAE: 28.8687\n","Training:\t loss: 7645.1952, MAE: 55.9776\n","Evaluating:\t loss: 2204.2284, MAE: 28.8044\n","train MSE: 7645.1952, evaluate MSE: 2204.2284\n","\n","train MAE: 55.9776, evaluate MAE: 28.8044\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 19\n","\tbatch: 100, loss: 7513.0820, MAE: 76.5968\n","\tbatch: 200, loss: 8113.1953, MAE: 70.4156\n","Training:\t loss: 44486.2157, MAE: 113.5700\n","Evaluating:\t loss: 3099.4828, MAE: 41.6801\n","train MSE: 44486.2157, evaluate MSE: 3099.4828\n","\n","train MAE: 113.5700, evaluate MAE: 41.6801\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 20\n","\tbatch: 100, loss: 1469.5884, MAE: 27.7492\n","\tbatch: 200, loss: 999.1689, MAE: 23.6416\n","Training:\t loss: 1669.5752, MAE: 28.8874\n","Evaluating:\t loss: 1033.2980, MAE: 22.5865\n","train MSE: 1669.5752, evaluate MSE: 1033.2980\n","\n","train MAE: 28.8874, evaluate MAE: 22.5865\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 21\n","\tbatch: 100, loss: 855.6973, MAE: 20.5048\n","\tbatch: 200, loss: 676.9838, MAE: 17.8971\n","Training:\t loss: 820.8025, MAE: 20.2544\n","Evaluating:\t loss: 689.0050, MAE: 18.4032\n","train MSE: 820.8025, evaluate MSE: 689.0050\n","\n","train MAE: 20.2544, evaluate MAE: 18.4032\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 22\n","\tbatch: 100, loss: 1020066.3125, MAE: 998.3633\n","\tbatch: 200, loss: 6541.6143, MAE: 65.1660\n","Training:\t loss: 69459.0683, MAE: 152.1077\n","Evaluating:\t loss: 6218.5466, MAE: 63.7944\n","train MSE: 69459.0683, evaluate MSE: 6218.5466\n","\n","train MAE: 152.1077, evaluate MAE: 63.7944\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 23\n","\tbatch: 100, loss: 2996.0547, MAE: 42.4443\n","\tbatch: 200, loss: 2271.2559, MAE: 34.1257\n","Training:\t loss: 3313.6370, MAE: 43.2556\n","Evaluating:\t loss: 2254.3893, MAE: 34.5511\n","train MSE: 3313.6370, evaluate MSE: 2254.3893\n","\n","train MAE: 43.2556, evaluate MAE: 34.5511\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 24\n","\tbatch: 100, loss: 1839.5347, MAE: 31.0490\n","\tbatch: 200, loss: 1871.7273, MAE: 30.3531\n","Training:\t loss: 1976.8421, MAE: 31.8168\n","Evaluating:\t loss: 1715.4676, MAE: 29.4333\n","train MSE: 1976.8421, evaluate MSE: 1715.4676\n","\n","train MAE: 31.8168, evaluate MAE: 29.4333\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 25\n","\tbatch: 100, loss: 1838.0385, MAE: 28.6626\n","\tbatch: 200, loss: 1773.2273, MAE: 28.5990\n","Training:\t loss: 1583.6476, MAE: 28.2049\n","Evaluating:\t loss: 1404.7396, MAE: 26.5969\n","train MSE: 1583.6476, evaluate MSE: 1404.7396\n","\n","train MAE: 28.2049, evaluate MAE: 26.5969\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 26\n","\tbatch: 100, loss: 1277.6445, MAE: 26.0541\n","\tbatch: 200, loss: 1096.2891, MAE: 22.1133\n","Training:\t loss: 1141.5698, MAE: 23.6627\n","Evaluating:\t loss: 1074.5491, MAE: 21.9289\n","train MSE: 1141.5698, evaluate MSE: 1074.5491\n","\n","train MAE: 23.6627, evaluate MAE: 21.9289\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 27\n","\tbatch: 100, loss: 820.7349, MAE: 19.8855\n","\tbatch: 200, loss: 633.5411, MAE: 17.3123\n","Training:\t loss: 767.2686, MAE: 19.0323\n","Evaluating:\t loss: 680.9987, MAE: 17.4654\n","train MSE: 767.2686, evaluate MSE: 680.9987\n","\n","train MAE: 19.0323, evaluate MAE: 17.4654\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 28\n","\tbatch: 100, loss: 730.6818, MAE: 17.5266\n","\tbatch: 200, loss: 1895.5054, MAE: 38.3010\n","Training:\t loss: 833.8306, MAE: 19.5354\n","Evaluating:\t loss: 477.8069, MAE: 15.4257\n","train MSE: 833.8306, evaluate MSE: 477.8069\n","\n","train MAE: 19.5354, evaluate MAE: 15.4257\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 29\n","\tbatch: 100, loss: 299.0580, MAE: 12.1852\n","\tbatch: 200, loss: 313.2404, MAE: 11.1885\n","Training:\t loss: 349.7384, MAE: 12.1925\n","Evaluating:\t loss: 303.7900, MAE: 11.0187\n","train MSE: 349.7384, evaluate MSE: 303.7900\n","\n","train MAE: 12.1925, evaluate MAE: 11.0187\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 30\n","\tbatch: 100, loss: 290.5447, MAE: 10.3771\n","\tbatch: 200, loss: 248.3393, MAE: 9.8504\n","Training:\t loss: 262.7350, MAE: 10.2620\n","Evaluating:\t loss: 229.3147, MAE: 9.4284\n","train MSE: 262.7350, evaluate MSE: 229.3147\n","\n","train MAE: 10.2620, evaluate MAE: 9.4284\n","\n","--- time consumption (s): 15\n","\n","Best model has been saved! Best model obtained at epoch 30 with eval MAE 9.4284\n","=============== testing ===============\n","MSE on test set: 234.9262\n","MAE on test set: 9.5264\n","R2 score: 0.9998\n"]}],"source":["!python main.py -e 30 -ci uniform -o base-conv-uniform"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":528091,"status":"ok","timestamp":1634436414861,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"MoawCkNIom5I","outputId":"2dd3b497-3278-4b86-d459-449a292124d2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using backend: pytorch\n","using device: cuda:0\n","....loaded....\n","using Xavier Normal initialization for Conv layer\n","using Xavier Normal initialization for Read layer\n","../base-read-normal/2021-10-17-dtnn-12/model_dtnn_conv_3_label_2021-10-17_1634435929.txt\n","==========2021-10-17 01:58:49.313572==========\n","model_type: dtnn\n","number of parameters: 596781\n","batch_size: 512\n","n_conv: 3\n","learngin rate: 0.005\n","device: cuda:0\n","--------------------\n","\n","=============== training & evaluating ===============\n","------------------------------\n","Epoch 1\n","\tbatch: 100, loss: 5161739.0000, MAE: 1812.5389\n","\tbatch: 200, loss: 2226350.0000, MAE: 1203.3357\n","Training:\t loss: 7616709.5683, MAE: 1906.0755\n","Evaluating:\t loss: 1683588.4821, MAE: 1020.1269\n","train MSE: 7616709.5683, evaluate MSE: 1683588.4821\n","\n","train MAE: 1906.0755, evaluate MAE: 1020.1269\n","\n","--- time consumption (s): 20\n","\n","------------------------------\n","Epoch 2\n","\tbatch: 100, loss: 1248206.2500, MAE: 899.3348\n","\tbatch: 200, loss: 1252071.6250, MAE: 886.3376\n","Training:\t loss: 1409553.2585, MAE: 934.7955\n","Evaluating:\t loss: 1310431.8839, MAE: 912.7861\n","train MSE: 1409553.2585, evaluate MSE: 1310431.8839\n","\n","train MAE: 934.7955, evaluate MAE: 912.7861\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 3\n","\tbatch: 100, loss: 3918957.7500, MAE: 1571.2797\n","\tbatch: 200, loss: 2017474.2500, MAE: 1130.4871\n","Training:\t loss: 2586169.7548, MAE: 1232.2671\n","Evaluating:\t loss: 1315875.1652, MAE: 892.4725\n","train MSE: 2586169.7548, evaluate MSE: 1315875.1652\n","\n","train MAE: 1232.2671, evaluate MAE: 892.4725\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 4\n","\tbatch: 100, loss: 465619.6875, MAE: 528.5715\n","\tbatch: 200, loss: 317859.6250, MAE: 441.5178\n","Training:\t loss: 563141.4785, MAE: 570.0480\n","Evaluating:\t loss: 350790.6897, MAE: 462.5706\n","train MSE: 563141.4785, evaluate MSE: 350790.6897\n","\n","train MAE: 570.0480, evaluate MAE: 462.5706\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 5\n","\tbatch: 100, loss: 302042.2500, MAE: 427.1573\n","\tbatch: 200, loss: 241672.9219, MAE: 394.3085\n","Training:\t loss: 299301.6614, MAE: 429.3384\n","Evaluating:\t loss: 253989.7846, MAE: 394.6112\n","train MSE: 299301.6614, evaluate MSE: 253989.7846\n","\n","train MAE: 429.3384, evaluate MAE: 394.6112\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 6\n","\tbatch: 100, loss: 227048.4219, MAE: 374.2303\n","\tbatch: 200, loss: 204438.1875, MAE: 344.1806\n","Training:\t loss: 220200.0529, MAE: 368.3925\n","Evaluating:\t loss: 180674.2221, MAE: 331.1698\n","train MSE: 220200.0529, evaluate MSE: 180674.2221\n","\n","train MAE: 368.3925, evaluate MAE: 331.1698\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 7\n","\tbatch: 100, loss: 151072.9531, MAE: 303.3840\n","\tbatch: 200, loss: 122659.7344, MAE: 276.9143\n","Training:\t loss: 145854.8357, MAE: 298.8489\n","Evaluating:\t loss: 112279.8041, MAE: 270.7785\n","train MSE: 145854.8357, evaluate MSE: 112279.8041\n","\n","train MAE: 298.8489, evaluate MAE: 270.7785\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 8\n","\tbatch: 100, loss: 94004.6953, MAE: 236.5941\n","\tbatch: 200, loss: 66711.2031, MAE: 199.4581\n","Training:\t loss: 82359.6114, MAE: 224.5487\n","Evaluating:\t loss: 56695.5206, MAE: 185.7080\n","train MSE: 82359.6114, evaluate MSE: 56695.5206\n","\n","train MAE: 224.5487, evaluate MAE: 185.7080\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 9\n","\tbatch: 100, loss: 39205.4375, MAE: 157.1319\n","\tbatch: 200, loss: 29877.6523, MAE: 133.0549\n","Training:\t loss: 38992.8057, MAE: 154.4653\n","Evaluating:\t loss: 24042.9256, MAE: 121.3327\n","train MSE: 38992.8057, evaluate MSE: 24042.9256\n","\n","train MAE: 154.4653, evaluate MAE: 121.3327\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 10\n","\tbatch: 100, loss: 17063.6797, MAE: 103.7834\n","\tbatch: 200, loss: 13617.8359, MAE: 87.2089\n","Training:\t loss: 17249.1775, MAE: 100.7799\n","Evaluating:\t loss: 11096.6436, MAE: 79.6255\n","train MSE: 17249.1775, evaluate MSE: 11096.6436\n","\n","train MAE: 100.7799, evaluate MAE: 79.6255\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 11\n","\tbatch: 100, loss: 10987.1523, MAE: 71.3316\n","\tbatch: 200, loss: 6669.2861, MAE: 61.0133\n","Training:\t loss: 8833.2216, MAE: 67.4734\n","Evaluating:\t loss: 8715.6893, MAE: 66.4596\n","train MSE: 8833.2216, evaluate MSE: 8715.6893\n","\n","train MAE: 67.4734, evaluate MAE: 66.4596\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 12\n","\tbatch: 100, loss: 5506.5029, MAE: 53.0125\n","\tbatch: 200, loss: 4049.4116, MAE: 44.6121\n","Training:\t loss: 5796.0193, MAE: 50.0274\n","Evaluating:\t loss: 4794.2498, MAE: 43.2821\n","train MSE: 5796.0193, evaluate MSE: 4794.2498\n","\n","train MAE: 50.0274, evaluate MAE: 43.2821\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 13\n","\tbatch: 100, loss: 4255.3193, MAE: 38.2359\n","\tbatch: 200, loss: 6119.4033, MAE: 40.6026\n","Training:\t loss: 4161.3123, MAE: 39.8643\n","Evaluating:\t loss: 3322.6993, MAE: 34.9214\n","train MSE: 4161.3123, evaluate MSE: 3322.6993\n","\n","train MAE: 39.8643, evaluate MAE: 34.9214\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 14\n","\tbatch: 100, loss: 5192.7944, MAE: 36.7992\n","\tbatch: 200, loss: 2604.9551, MAE: 38.4963\n","Training:\t loss: 3104.7533, MAE: 34.0499\n","Evaluating:\t loss: 3075.5799, MAE: 31.1158\n","train MSE: 3104.7533, evaluate MSE: 3075.5799\n","\n","train MAE: 34.0499, evaluate MAE: 31.1158\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 15\n","\tbatch: 100, loss: 2564.1384, MAE: 32.5003\n","\tbatch: 200, loss: 1295.8868, MAE: 24.3433\n","Training:\t loss: 2293.0414, MAE: 29.4080\n","Evaluating:\t loss: 2038.1855, MAE: 29.0981\n","train MSE: 2293.0414, evaluate MSE: 2038.1855\n","\n","train MAE: 29.4080, evaluate MAE: 29.0981\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 16\n","\tbatch: 100, loss: 1868.5310, MAE: 27.0802\n","\tbatch: 200, loss: 1905.5605, MAE: 27.0119\n","Training:\t loss: 1664.3904, MAE: 25.5722\n","Evaluating:\t loss: 1678.8003, MAE: 26.8145\n","train MSE: 1664.3904, evaluate MSE: 1678.8003\n","\n","train MAE: 25.5722, evaluate MAE: 26.8145\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 17\n","\tbatch: 100, loss: 1466.3853, MAE: 21.8869\n","\tbatch: 200, loss: 1321.0233, MAE: 21.1702\n","Training:\t loss: 1174.5211, MAE: 21.6930\n","Evaluating:\t loss: 1049.0486, MAE: 21.8897\n","train MSE: 1174.5211, evaluate MSE: 1049.0486\n","\n","train MAE: 21.6930, evaluate MAE: 21.8897\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 18\n","\tbatch: 100, loss: 676.7706, MAE: 18.9048\n","\tbatch: 200, loss: 1537.4994, MAE: 26.6230\n","Training:\t loss: 1046.4812, MAE: 22.3203\n","Evaluating:\t loss: 714.2413, MAE: 17.9085\n","train MSE: 1046.4812, evaluate MSE: 714.2413\n","\n","train MAE: 22.3203, evaluate MAE: 17.9085\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 19\n","\tbatch: 100, loss: 1711.8824, MAE: 34.9921\n","\tbatch: 200, loss: 3957.5212, MAE: 59.3175\n","Training:\t loss: 979.9432, MAE: 22.5958\n","Evaluating:\t loss: 531.3822, MAE: 16.3218\n","train MSE: 979.9432, evaluate MSE: 531.3822\n","\n","train MAE: 22.5958, evaluate MAE: 16.3218\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 20\n","\tbatch: 100, loss: 674.8759, MAE: 20.5286\n","\tbatch: 200, loss: 1442.1562, MAE: 29.1260\n","Training:\t loss: 8126.9916, MAE: 49.9008\n","Evaluating:\t loss: 809.6387, MAE: 19.7756\n","train MSE: 8126.9916, evaluate MSE: 809.6387\n","\n","train MAE: 49.9008, evaluate MAE: 19.7756\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 21\n","\tbatch: 100, loss: 744.8026, MAE: 17.6776\n","\tbatch: 200, loss: 608.9999, MAE: 15.6456\n","Training:\t loss: 876.9581, MAE: 20.2107\n","Evaluating:\t loss: 719.1158, MAE: 18.9029\n","train MSE: 876.9581, evaluate MSE: 719.1158\n","\n","train MAE: 20.2107, evaluate MAE: 18.9029\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 22\n","\tbatch: 100, loss: 583.6766, MAE: 14.5288\n","\tbatch: 200, loss: 538.8829, MAE: 14.7888\n","Training:\t loss: 551.1910, MAE: 15.3707\n","Evaluating:\t loss: 578.4587, MAE: 17.2498\n","train MSE: 551.1910, evaluate MSE: 578.4587\n","\n","train MAE: 15.3707, evaluate MAE: 17.2498\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 23\n","\tbatch: 100, loss: 473.2833, MAE: 16.0316\n","\tbatch: 200, loss: 415.6786, MAE: 13.4690\n","Training:\t loss: 591.1270, MAE: 16.9475\n","Evaluating:\t loss: 505.2044, MAE: 16.6240\n","train MSE: 591.1270, evaluate MSE: 505.2044\n","\n","train MAE: 16.9475, evaluate MAE: 16.6240\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 24\n","\tbatch: 100, loss: 3658.2568, MAE: 58.6909\n","\tbatch: 200, loss: 351.1757, MAE: 12.1707\n","Training:\t loss: 894.3649, MAE: 22.9777\n","Evaluating:\t loss: 686.9149, MAE: 21.8787\n","train MSE: 894.3649, evaluate MSE: 686.9149\n","\n","train MAE: 22.9777, evaluate MAE: 21.8787\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 25\n","\tbatch: 100, loss: 307.2357, MAE: 12.6976\n","\tbatch: 200, loss: 391.4212, MAE: 16.6729\n","Training:\t loss: 1480.9771, MAE: 29.0808\n","Evaluating:\t loss: 2651.2845, MAE: 48.9069\n","train MSE: 1480.9771, evaluate MSE: 2651.2845\n","\n","train MAE: 29.0808, evaluate MAE: 48.9069\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 26\n","\tbatch: 100, loss: 715.8791, MAE: 20.8328\n","\tbatch: 200, loss: 200.1167, MAE: 10.0461\n","Training:\t loss: 1266.6639, MAE: 26.3769\n","Evaluating:\t loss: 274.2909, MAE: 11.9142\n","train MSE: 1266.6639, evaluate MSE: 274.2909\n","\n","train MAE: 26.3769, evaluate MAE: 11.9142\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 27\n","\tbatch: 100, loss: 1597.3728, MAE: 37.9528\n","\tbatch: 200, loss: 995.1140, MAE: 28.9028\n","Training:\t loss: 1361.9017, MAE: 28.8100\n","Evaluating:\t loss: 5231.5183, MAE: 71.1326\n","train MSE: 1361.9017, evaluate MSE: 5231.5183\n","\n","train MAE: 28.8100, evaluate MAE: 71.1326\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 28\n","\tbatch: 100, loss: 198.6577, MAE: 11.4843\n","\tbatch: 200, loss: 434.9525, MAE: 17.0325\n","Training:\t loss: 1830.5350, MAE: 27.3453\n","Evaluating:\t loss: 648.3302, MAE: 22.2601\n","train MSE: 1830.5350, evaluate MSE: 648.3302\n","\n","train MAE: 27.3453, evaluate MAE: 22.2601\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 29\n","\tbatch: 100, loss: 2309.5869, MAE: 46.4645\n","\tbatch: 200, loss: 1024.7791, MAE: 29.8853\n","Training:\t loss: 1310.4262, MAE: 28.7128\n","Evaluating:\t loss: 163.1137, MAE: 9.0611\n","train MSE: 1310.4262, evaluate MSE: 163.1137\n","\n","train MAE: 28.7128, evaluate MAE: 9.0611\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 30\n","\tbatch: 100, loss: 126.9801, MAE: 7.8977\n","\tbatch: 200, loss: 161.4830, MAE: 9.5599\n","Training:\t loss: 1294.9425, MAE: 24.7222\n","Evaluating:\t loss: 136.8329, MAE: 7.4988\n","train MSE: 1294.9425, evaluate MSE: 136.8329\n","\n","train MAE: 24.7222, evaluate MAE: 7.4988\n","\n","--- time consumption (s): 15\n","\n","Best model has been saved! Best model obtained at epoch 30 with eval MAE 7.4988\n","=============== testing ===============\n","MSE on test set: 128.3027\n","MAE on test set: 7.4119\n","R2 score: 0.9999\n"]}],"source":["!python main.py -e 30 -ri normal -o base-read-normal"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":527245,"status":"ok","timestamp":1634434830055,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"mIqO1WgVom7p","outputId":"b496277e-3408-4577-88a9-490b2d48ad4c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using backend: pytorch\n","using device: cuda:0\n","....loaded....\n","using Xavier Uniform initialization for Read layer\n","../base-conv-none/2021-10-17-dtnn-12/model_dtnn_conv_3_label_2021-10-17_1634434344.txt\n","==========2021-10-17 01:32:24.328702==========\n","model_type: dtnn\n","number of parameters: 596781\n","batch_size: 512\n","n_conv: 3\n","learngin rate: 0.005\n","device: cuda:0\n","--------------------\n","\n","=============== training & evaluating ===============\n","------------------------------\n","Epoch 1\n","\tbatch: 100, loss: 5444175.5000, MAE: 1834.5760\n","\tbatch: 200, loss: 4585600.0000, MAE: 1698.0284\n","Training:\t loss: 8897665.6165, MAE: 2191.9328\n","Evaluating:\t loss: 4824191.7500, MAE: 1745.4064\n","train MSE: 8897665.6165, evaluate MSE: 4824191.7500\n","\n","train MAE: 2191.9328, evaluate MAE: 1745.4064\n","\n","--- time consumption (s): 20\n","\n","------------------------------\n","Epoch 2\n","\tbatch: 100, loss: 4704684.5000, MAE: 1762.4731\n","\tbatch: 200, loss: 2625833.7500, MAE: 1286.0297\n","Training:\t loss: 3772157.7458, MAE: 1539.4170\n","Evaluating:\t loss: 2316908.4643, MAE: 1219.8295\n","train MSE: 3772157.7458, evaluate MSE: 2316908.4643\n","\n","train MAE: 1539.4170, evaluate MAE: 1219.8295\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 3\n","\tbatch: 100, loss: 1199933.2500, MAE: 877.1484\n","\tbatch: 200, loss: 769338.1875, MAE: 692.7335\n","Training:\t loss: 1228235.8165, MAE: 852.8610\n","Evaluating:\t loss: 631585.4107, MAE: 626.2600\n","train MSE: 1228235.8165, evaluate MSE: 631585.4107\n","\n","train MAE: 852.8610, evaluate MAE: 626.2600\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 4\n","\tbatch: 100, loss: 448912.5938, MAE: 501.5219\n","\tbatch: 200, loss: 330215.5000, MAE: 423.5971\n","Training:\t loss: 439641.6724, MAE: 508.8412\n","Evaluating:\t loss: 301178.1629, MAE: 417.1145\n","train MSE: 439641.6724, evaluate MSE: 301178.1629\n","\n","train MAE: 508.8412, evaluate MAE: 417.1145\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 5\n","\tbatch: 100, loss: 1208340.1250, MAE: 904.3413\n","\tbatch: 200, loss: 278050.4375, MAE: 419.9193\n","Training:\t loss: 605247.3169, MAE: 564.9465\n","Evaluating:\t loss: 221415.7065, MAE: 369.0010\n","train MSE: 605247.3169, evaluate MSE: 221415.7065\n","\n","train MAE: 564.9465, evaluate MAE: 369.0010\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 6\n","\tbatch: 100, loss: 154303.1562, MAE: 309.6990\n","\tbatch: 200, loss: 135392.0312, MAE: 289.2935\n","Training:\t loss: 176338.2620, MAE: 327.2007\n","Evaluating:\t loss: 141404.3365, MAE: 294.3414\n","train MSE: 176338.2620, evaluate MSE: 141404.3365\n","\n","train MAE: 327.2007, evaluate MAE: 294.3414\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 7\n","\tbatch: 100, loss: 87026.2500, MAE: 216.9980\n","\tbatch: 200, loss: 45592.6055, MAE: 159.1101\n","Training:\t loss: 90289.8036, MAE: 228.1451\n","Evaluating:\t loss: 63932.7388, MAE: 197.1871\n","train MSE: 90289.8036, evaluate MSE: 63932.7388\n","\n","train MAE: 228.1451, evaluate MAE: 197.1871\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 8\n","\tbatch: 100, loss: 44808.9844, MAE: 164.0249\n","\tbatch: 200, loss: 27447.9668, MAE: 131.4772\n","Training:\t loss: 39824.9325, MAE: 152.2922\n","Evaluating:\t loss: 21380.1516, MAE: 111.3816\n","train MSE: 39824.9325, evaluate MSE: 21380.1516\n","\n","train MAE: 152.2922, evaluate MAE: 111.3816\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 9\n","\tbatch: 100, loss: 11349.7832, MAE: 81.2973\n","\tbatch: 200, loss: 8394.6914, MAE: 72.0057\n","Training:\t loss: 13482.8725, MAE: 86.7343\n","Evaluating:\t loss: 6404.3986, MAE: 59.6799\n","train MSE: 13482.8725, evaluate MSE: 6404.3986\n","\n","train MAE: 86.7343, evaluate MAE: 59.6799\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 10\n","\tbatch: 100, loss: 2553.8423, MAE: 37.0185\n","\tbatch: 200, loss: 1830.9719, MAE: 27.3063\n","Training:\t loss: 2999.9942, MAE: 39.0647\n","Evaluating:\t loss: 1195.8917, MAE: 25.3281\n","train MSE: 2999.9942, evaluate MSE: 1195.8917\n","\n","train MAE: 39.0647, evaluate MAE: 25.3281\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 11\n","\tbatch: 100, loss: 1183.3495, MAE: 22.3078\n","\tbatch: 200, loss: 2758.4294, MAE: 43.5448\n","Training:\t loss: 2581.3502, MAE: 31.6996\n","Evaluating:\t loss: 1480.1617, MAE: 29.9597\n","train MSE: 2581.3502, evaluate MSE: 1480.1617\n","\n","train MAE: 31.6996, evaluate MAE: 29.9597\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 12\n","\tbatch: 100, loss: 1234.0601, MAE: 25.7826\n","\tbatch: 200, loss: 890.5213, MAE: 22.9222\n","Training:\t loss: 1100.1942, MAE: 25.7424\n","Evaluating:\t loss: 872.0615, MAE: 22.6424\n","train MSE: 1100.1942, evaluate MSE: 872.0615\n","\n","train MAE: 25.7424, evaluate MAE: 22.6424\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 13\n","\tbatch: 100, loss: 860.7682, MAE: 21.5908\n","\tbatch: 200, loss: 672.1016, MAE: 19.4979\n","Training:\t loss: 749.8744, MAE: 20.9871\n","Evaluating:\t loss: 632.7931, MAE: 19.1264\n","train MSE: 749.8744, evaluate MSE: 632.7931\n","\n","train MAE: 20.9871, evaluate MAE: 19.1264\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 14\n","\tbatch: 100, loss: 743.2059, MAE: 18.5327\n","\tbatch: 200, loss: 400.5124, MAE: 16.1995\n","Training:\t loss: 566.4875, MAE: 17.9662\n","Evaluating:\t loss: 509.7135, MAE: 16.9769\n","train MSE: 566.4875, evaluate MSE: 509.7135\n","\n","train MAE: 17.9662, evaluate MAE: 16.9769\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 15\n","\tbatch: 100, loss: 511.2900, MAE: 16.7286\n","\tbatch: 200, loss: 521.1820, MAE: 15.0680\n","Training:\t loss: 453.3925, MAE: 15.7808\n","Evaluating:\t loss: 435.0686, MAE: 15.5680\n","train MSE: 453.3925, evaluate MSE: 435.0686\n","\n","train MAE: 15.7808, evaluate MAE: 15.5680\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 16\n","\tbatch: 100, loss: 335.9363, MAE: 13.4250\n","\tbatch: 200, loss: 242.0148, MAE: 12.2578\n","Training:\t loss: 371.1340, MAE: 13.9738\n","Evaluating:\t loss: 362.6523, MAE: 13.5306\n","train MSE: 371.1340, evaluate MSE: 362.6523\n","\n","train MAE: 13.9738, evaluate MAE: 13.5306\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 17\n","\tbatch: 100, loss: 321.6546, MAE: 13.3720\n","\tbatch: 200, loss: 400.4044, MAE: 15.2607\n","Training:\t loss: 325.5086, MAE: 12.8659\n","Evaluating:\t loss: 311.2604, MAE: 12.7074\n","train MSE: 325.5086, evaluate MSE: 311.2604\n","\n","train MAE: 12.8659, evaluate MAE: 12.7074\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 18\n","\tbatch: 100, loss: 430.2428, MAE: 12.4951\n","\tbatch: 200, loss: 227.8238, MAE: 10.5228\n","Training:\t loss: 270.9805, MAE: 11.4238\n","Evaluating:\t loss: 243.5329, MAE: 10.7527\n","train MSE: 270.9805, evaluate MSE: 243.5329\n","\n","train MAE: 11.4238, evaluate MAE: 10.7527\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 19\n","\tbatch: 100, loss: 192.2971, MAE: 10.1074\n","\tbatch: 200, loss: 164.4633, MAE: 9.4700\n","Training:\t loss: 238.4860, MAE: 10.4523\n","Evaluating:\t loss: 231.9524, MAE: 10.4168\n","train MSE: 238.4860, evaluate MSE: 231.9524\n","\n","train MAE: 10.4523, evaluate MAE: 10.4168\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 20\n","\tbatch: 100, loss: 196.4925, MAE: 9.0723\n","\tbatch: 200, loss: 131.9617, MAE: 8.6760\n","Training:\t loss: 207.9995, MAE: 9.4609\n","Evaluating:\t loss: 180.7199, MAE: 8.6568\n","train MSE: 207.9995, evaluate MSE: 180.7199\n","\n","train MAE: 9.4609, evaluate MAE: 8.6568\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 21\n","\tbatch: 100, loss: 17981.7754, MAE: 102.3319\n","\tbatch: 200, loss: 7478.5923, MAE: 66.7640\n","Training:\t loss: 54306.5445, MAE: 122.8518\n","Evaluating:\t loss: 5851.7562, MAE: 59.3935\n","train MSE: 54306.5445, evaluate MSE: 5851.7562\n","\n","train MAE: 122.8518, evaluate MAE: 59.3935\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 22\n","\tbatch: 100, loss: 2192.3613, MAE: 33.8424\n","\tbatch: 200, loss: 2946.7871, MAE: 41.3668\n","Training:\t loss: 31229.1887, MAE: 86.8941\n","Evaluating:\t loss: 2474.7421, MAE: 36.0746\n","train MSE: 31229.1887, evaluate MSE: 2474.7421\n","\n","train MAE: 86.8941, evaluate MAE: 36.0746\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 23\n","\tbatch: 100, loss: 2214.8315, MAE: 31.3182\n","\tbatch: 200, loss: 1517.0281, MAE: 26.3267\n","Training:\t loss: 1785.5942, MAE: 29.8707\n","Evaluating:\t loss: 1357.6471, MAE: 25.9703\n","train MSE: 1785.5942, evaluate MSE: 1357.6471\n","\n","train MAE: 29.8707, evaluate MAE: 25.9703\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 24\n","\tbatch: 100, loss: 1100.8389, MAE: 22.7995\n","\tbatch: 200, loss: 906.3751, MAE: 19.6610\n","Training:\t loss: 1105.4348, MAE: 22.3841\n","Evaluating:\t loss: 1047.4859, MAE: 21.3868\n","train MSE: 1105.4348, evaluate MSE: 1047.4859\n","\n","train MAE: 22.3841, evaluate MAE: 21.3868\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 25\n","\tbatch: 100, loss: 572.6777, MAE: 16.5173\n","\tbatch: 200, loss: 811.8768, MAE: 18.0773\n","Training:\t loss: 860.5482, MAE: 18.6631\n","Evaluating:\t loss: 822.6628, MAE: 17.7718\n","train MSE: 860.5482, evaluate MSE: 822.6628\n","\n","train MAE: 18.6631, evaluate MAE: 17.7718\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 26\n","\tbatch: 100, loss: 644.0310, MAE: 16.0934\n","\tbatch: 200, loss: 638.9370, MAE: 16.2839\n","Training:\t loss: 742.6433, MAE: 16.4881\n","Evaluating:\t loss: 749.3582, MAE: 16.0831\n","train MSE: 742.6433, evaluate MSE: 749.3582\n","\n","train MAE: 16.4881, evaluate MAE: 16.0831\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 27\n","\tbatch: 100, loss: 449.8175, MAE: 13.4046\n","\tbatch: 200, loss: 730.3417, MAE: 16.2175\n","Training:\t loss: 675.0949, MAE: 15.3474\n","Evaluating:\t loss: 659.6152, MAE: 14.7171\n","train MSE: 675.0949, evaluate MSE: 659.6152\n","\n","train MAE: 15.3474, evaluate MAE: 14.7171\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 28\n","\tbatch: 100, loss: 591.1820, MAE: 13.8804\n","\tbatch: 200, loss: 606.7118, MAE: 14.1532\n","Training:\t loss: 611.8132, MAE: 14.0510\n","Evaluating:\t loss: 624.6213, MAE: 13.7236\n","train MSE: 611.8132, evaluate MSE: 624.6213\n","\n","train MAE: 14.0510, evaluate MAE: 13.7236\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 29\n","\tbatch: 100, loss: 868.5491, MAE: 14.7550\n","\tbatch: 200, loss: 421.4892, MAE: 13.2233\n","Training:\t loss: 561.9871, MAE: 13.2115\n","Evaluating:\t loss: 630.4881, MAE: 15.4320\n","train MSE: 561.9871, evaluate MSE: 630.4881\n","\n","train MAE: 13.2115, evaluate MAE: 15.4320\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 30\n","\tbatch: 100, loss: 476.0163, MAE: 10.6979\n","\tbatch: 200, loss: 467.6039, MAE: 13.0087\n","Training:\t loss: 516.0875, MAE: 12.7772\n","Evaluating:\t loss: 550.1422, MAE: 14.2739\n","train MSE: 516.0875, evaluate MSE: 550.1422\n","\n","train MAE: 12.7772, evaluate MAE: 14.2739\n","\n","--- time consumption (s): 15\n","\n","Best model has been saved! Best model obtained at epoch 20 with eval MAE 8.6568\n","=============== testing ===============\n","MSE on test set: 444.5292\n","MAE on test set: 13.6932\n","R2 score: 0.9996\n"]}],"source":["!python main.py -e 30 -ci None -o base-conv-none"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xcRSNGusom9w"},"outputs":[],"source":["!python main.py -e 30 -o base-ele-mult-less"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":233,"status":"ok","timestamp":1634439875929,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"_9oObY3-NN8a","outputId":"283c7927-6b5d-4d39-e751-bc5bcf91d877"},"outputs":[{"name":"stdout","output_type":"stream","text":["        # self.fc_node_2 = nn.Linear(128, 128, bias=False)\r\n","        # m1 = self.fc_node_2(F.relu(self.fc_node_1(edges.src['h'])))  # [M,dim_node] --> [M,128]\r\n"]}],"source":["!cat dtnnlayers.py | grep self.fc_node_2"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1462973,"status":"ok","timestamp":1634448565113,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"4K8JMl_TNN-z","outputId":"7d7ac082-4ba1-435f-bdd6-30695bf7a7dc"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;30;43m流式输出内容被截断，只能显示最后 5000 行内容。\u001b[0m\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 85\n","\tbatch: 100, loss: 319.0621, MAE: 10.4336\n","\tbatch: 200, loss: 781.0861, MAE: 21.3448\n","Training:\t loss: 564.8410, MAE: 14.9834\n","Evaluating:\t loss: 902.2772, MAE: 19.8336\n","train MSE: 564.8410, evaluate MSE: 902.2772\n","\n","train MAE: 14.9834, evaluate MAE: 19.8336\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 86\n","\tbatch: 100, loss: 400.4592, MAE: 14.2076\n","\tbatch: 200, loss: 260.8674, MAE: 11.0074\n","Training:\t loss: 475.0354, MAE: 13.2722\n","Evaluating:\t loss: 724.0339, MAE: 20.2827\n","train MSE: 475.0354, evaluate MSE: 724.0339\n","\n","train MAE: 13.2722, evaluate MAE: 20.2827\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 87\n","\tbatch: 100, loss: 281.7422, MAE: 10.9213\n","\tbatch: 200, loss: 335.3666, MAE: 11.5755\n","Training:\t loss: 477.1882, MAE: 13.5635\n","Evaluating:\t loss: 354.1414, MAE: 11.3879\n","train MSE: 477.1882, evaluate MSE: 354.1414\n","\n","train MAE: 13.5635, evaluate MAE: 11.3879\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 88\n","\tbatch: 100, loss: 313.2819, MAE: 12.0027\n","\tbatch: 200, loss: 810.2322, MAE: 13.7530\n","Training:\t loss: 441.3396, MAE: 12.8228\n","Evaluating:\t loss: 364.8123, MAE: 11.8878\n","train MSE: 441.3396, evaluate MSE: 364.8123\n","\n","train MAE: 12.8228, evaluate MAE: 11.8878\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 89\n","\tbatch: 100, loss: 422.6722, MAE: 13.4993\n","\tbatch: 200, loss: 1073.4946, MAE: 27.8374\n","Training:\t loss: 468.0089, MAE: 13.4013\n","Evaluating:\t loss: 366.9906, MAE: 12.5248\n","train MSE: 468.0089, evaluate MSE: 366.9906\n","\n","train MAE: 13.4013, evaluate MAE: 12.5248\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 90\n","\tbatch: 100, loss: 239.3836, MAE: 9.9600\n","\tbatch: 200, loss: 590.7654, MAE: 18.6912\n","Training:\t loss: 441.8835, MAE: 13.0304\n","Evaluating:\t loss: 938.1366, MAE: 24.5095\n","train MSE: 441.8835, evaluate MSE: 938.1366\n","\n","train MAE: 13.0304, evaluate MAE: 24.5095\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 91\n","\tbatch: 100, loss: 220.6842, MAE: 10.4905\n","\tbatch: 200, loss: 312.5187, MAE: 10.8981\n","Training:\t loss: 406.9566, MAE: 12.5451\n","Evaluating:\t loss: 321.3536, MAE: 10.7019\n","train MSE: 406.9566, evaluate MSE: 321.3536\n","\n","train MAE: 12.5451, evaluate MAE: 10.7019\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 92\n","\tbatch: 100, loss: 150.3306, MAE: 9.0251\n","\tbatch: 200, loss: 256.0459, MAE: 11.2361\n","Training:\t loss: 350.8078, MAE: 11.3975\n","Evaluating:\t loss: 553.4145, MAE: 16.0302\n","train MSE: 350.8078, evaluate MSE: 553.4145\n","\n","train MAE: 11.3975, evaluate MAE: 16.0302\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 93\n","\tbatch: 100, loss: 541.3654, MAE: 16.8273\n","\tbatch: 200, loss: 169.7333, MAE: 9.3128\n","Training:\t loss: 16365.5843, MAE: 40.7807\n","Evaluating:\t loss: 78930.4233, MAE: 233.6938\n","train MSE: 16365.5843, evaluate MSE: 78930.4233\n","\n","train MAE: 40.7807, evaluate MAE: 233.6938\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 94\n","\tbatch: 100, loss: 2525.0398, MAE: 32.3346\n","\tbatch: 200, loss: 1882.1965, MAE: 24.8866\n","Training:\t loss: 5607.5066, MAE: 41.7467\n","Evaluating:\t loss: 1655.5347, MAE: 23.7640\n","train MSE: 5607.5066, evaluate MSE: 1655.5347\n","\n","train MAE: 41.7467, evaluate MAE: 23.7640\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 95\n","\tbatch: 100, loss: 792.5743, MAE: 20.2213\n","\tbatch: 200, loss: 798.3920, MAE: 19.6918\n","Training:\t loss: 1267.0139, MAE: 21.4360\n","Evaluating:\t loss: 1514.0792, MAE: 22.7553\n","train MSE: 1267.0139, evaluate MSE: 1514.0792\n","\n","train MAE: 21.4360, evaluate MAE: 22.7553\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 96\n","\tbatch: 100, loss: 1224.8312, MAE: 20.3838\n","\tbatch: 200, loss: 552.1047, MAE: 15.8757\n","Training:\t loss: 908.0535, MAE: 18.3167\n","Evaluating:\t loss: 893.0450, MAE: 17.1548\n","train MSE: 908.0535, evaluate MSE: 893.0450\n","\n","train MAE: 18.3167, evaluate MAE: 17.1548\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 97\n","\tbatch: 100, loss: 455.9853, MAE: 15.3803\n","\tbatch: 200, loss: 1223.1462, MAE: 16.1396\n","Training:\t loss: 741.9728, MAE: 16.5211\n","Evaluating:\t loss: 827.1537, MAE: 18.1258\n","train MSE: 741.9728, evaluate MSE: 827.1537\n","\n","train MAE: 16.5211, evaluate MAE: 18.1258\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 98\n","\tbatch: 100, loss: 7875.9619, MAE: 19.3795\n","\tbatch: 200, loss: 660.7268, MAE: 14.1770\n","Training:\t loss: 638.4946, MAE: 15.4938\n","Evaluating:\t loss: 808.0206, MAE: 17.2496\n","train MSE: 638.4946, evaluate MSE: 808.0206\n","\n","train MAE: 15.4938, evaluate MAE: 17.2496\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 99\n","\tbatch: 100, loss: 454.0075, MAE: 14.7567\n","\tbatch: 200, loss: 528.4247, MAE: 16.0937\n","Training:\t loss: 574.8578, MAE: 14.7882\n","Evaluating:\t loss: 629.8565, MAE: 15.3006\n","train MSE: 574.8578, evaluate MSE: 629.8565\n","\n","train MAE: 14.7882, evaluate MAE: 15.3006\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 100\n","\tbatch: 100, loss: 368.5510, MAE: 13.0231\n","\tbatch: 200, loss: 429.7524, MAE: 14.5324\n","Training:\t loss: 516.1216, MAE: 13.8870\n","Evaluating:\t loss: 635.9125, MAE: 16.7742\n","train MSE: 516.1216, evaluate MSE: 635.9125\n","\n","train MAE: 13.8870, evaluate MAE: 16.7742\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 101\n","\tbatch: 100, loss: 587.1540, MAE: 15.2033\n","\tbatch: 200, loss: 784.5651, MAE: 13.8553\n","Training:\t loss: 483.5495, MAE: 13.4404\n","Evaluating:\t loss: 556.9093, MAE: 14.7779\n","train MSE: 483.5495, evaluate MSE: 556.9093\n","\n","train MAE: 13.4404, evaluate MAE: 14.7779\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 102\n","\tbatch: 100, loss: 760.4490, MAE: 22.1230\n","\tbatch: 200, loss: 291.3038, MAE: 11.8687\n","Training:\t loss: 480.6512, MAE: 13.7419\n","Evaluating:\t loss: 562.4390, MAE: 14.7846\n","train MSE: 480.6512, evaluate MSE: 562.4390\n","\n","train MAE: 13.7419, evaluate MAE: 14.7846\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 103\n","\tbatch: 100, loss: 395.6378, MAE: 12.1372\n","\tbatch: 200, loss: 319.3206, MAE: 13.2084\n","Training:\t loss: 470.7813, MAE: 13.6944\n","Evaluating:\t loss: 476.9885, MAE: 12.3611\n","train MSE: 470.7813, evaluate MSE: 476.9885\n","\n","train MAE: 13.6944, evaluate MAE: 12.3611\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 104\n","\tbatch: 100, loss: 350.5973, MAE: 11.8284\n","\tbatch: 200, loss: 446.3065, MAE: 11.6838\n","Training:\t loss: 435.5485, MAE: 13.1533\n","Evaluating:\t loss: 469.7603, MAE: 13.0085\n","train MSE: 435.5485, evaluate MSE: 469.7603\n","\n","train MAE: 13.1533, evaluate MAE: 13.0085\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 105\n","\tbatch: 100, loss: 332.1333, MAE: 11.5191\n","\tbatch: 200, loss: 470.9876, MAE: 13.5872\n","Training:\t loss: 425.7861, MAE: 13.1393\n","Evaluating:\t loss: 448.6097, MAE: 12.9819\n","train MSE: 425.7861, evaluate MSE: 448.6097\n","\n","train MAE: 13.1393, evaluate MAE: 12.9819\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 106\n","\tbatch: 100, loss: 444.7675, MAE: 13.9253\n","\tbatch: 200, loss: 350.9916, MAE: 13.0391\n","Training:\t loss: 400.9650, MAE: 12.6353\n","Evaluating:\t loss: 416.5395, MAE: 12.2077\n","train MSE: 400.9650, evaluate MSE: 416.5395\n","\n","train MAE: 12.6353, evaluate MAE: 12.2077\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 107\n","\tbatch: 100, loss: 357.7298, MAE: 12.6551\n","\tbatch: 200, loss: 329.7821, MAE: 12.4147\n","Training:\t loss: 401.2065, MAE: 12.8161\n","Evaluating:\t loss: 450.2216, MAE: 13.0646\n","train MSE: 401.2065, evaluate MSE: 450.2216\n","\n","train MAE: 12.8161, evaluate MAE: 13.0646\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 108\n","\tbatch: 100, loss: 257.6016, MAE: 12.1934\n","\tbatch: 200, loss: 299.4647, MAE: 10.9281\n","Training:\t loss: 399.9798, MAE: 12.9692\n","Evaluating:\t loss: 495.3315, MAE: 14.0191\n","train MSE: 399.9798, evaluate MSE: 495.3315\n","\n","train MAE: 12.9692, evaluate MAE: 14.0191\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 109\n","\tbatch: 100, loss: 288.7930, MAE: 11.2576\n","\tbatch: 200, loss: 284.1070, MAE: 11.6653\n","Training:\t loss: 356.9405, MAE: 12.0838\n","Evaluating:\t loss: 381.6180, MAE: 11.0971\n","train MSE: 356.9405, evaluate MSE: 381.6180\n","\n","train MAE: 12.0838, evaluate MAE: 11.0971\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 110\n","\tbatch: 100, loss: 479.6533, MAE: 16.1144\n","\tbatch: 200, loss: 310.8137, MAE: 11.3824\n","Training:\t loss: 393.1734, MAE: 12.9992\n","Evaluating:\t loss: 359.1726, MAE: 11.2397\n","train MSE: 393.1734, evaluate MSE: 359.1726\n","\n","train MAE: 12.9992, evaluate MAE: 11.2397\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 111\n","\tbatch: 100, loss: 190.0347, MAE: 10.2836\n","\tbatch: 200, loss: 493.8645, MAE: 12.1927\n","Training:\t loss: 347.5605, MAE: 12.1046\n","Evaluating:\t loss: 594.5172, MAE: 16.9417\n","train MSE: 347.5605, evaluate MSE: 594.5172\n","\n","train MAE: 12.1046, evaluate MAE: 16.9417\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 112\n","\tbatch: 100, loss: 219.3001, MAE: 10.6750\n","\tbatch: 200, loss: 428.9785, MAE: 13.5618\n","Training:\t loss: 341.4193, MAE: 11.9360\n","Evaluating:\t loss: 431.9475, MAE: 13.8697\n","train MSE: 341.4193, evaluate MSE: 431.9475\n","\n","train MAE: 11.9360, evaluate MAE: 13.8697\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 113\n","\tbatch: 100, loss: 249.0580, MAE: 11.5077\n","\tbatch: 200, loss: 3937.2251, MAE: 19.1700\n","Training:\t loss: 349.8165, MAE: 12.3076\n","Evaluating:\t loss: 566.1447, MAE: 14.9897\n","train MSE: 349.8165, evaluate MSE: 566.1447\n","\n","train MAE: 12.3076, evaluate MAE: 14.9897\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 114\n","\tbatch: 100, loss: 190.3375, MAE: 10.3895\n","\tbatch: 200, loss: 305.1755, MAE: 13.5180\n","Training:\t loss: 360.5206, MAE: 12.6969\n","Evaluating:\t loss: 458.6987, MAE: 14.3340\n","train MSE: 360.5206, evaluate MSE: 458.6987\n","\n","train MAE: 12.6969, evaluate MAE: 14.3340\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 115\n","\tbatch: 100, loss: 257.1649, MAE: 12.0756\n","\tbatch: 200, loss: 279.7969, MAE: 11.8072\n","Training:\t loss: 319.8747, MAE: 11.6736\n","Evaluating:\t loss: 536.7414, MAE: 16.2652\n","train MSE: 319.8747, evaluate MSE: 536.7414\n","\n","train MAE: 11.6736, evaluate MAE: 16.2652\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 116\n","\tbatch: 100, loss: 157.9156, MAE: 9.4641\n","\tbatch: 200, loss: 373.6893, MAE: 12.7453\n","Training:\t loss: 328.4527, MAE: 11.7881\n","Evaluating:\t loss: 394.9013, MAE: 13.0101\n","train MSE: 328.4527, evaluate MSE: 394.9013\n","\n","train MAE: 11.7881, evaluate MAE: 13.0101\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 117\n","\tbatch: 100, loss: 24487.1992, MAE: 121.1750\n","\tbatch: 200, loss: 694.3275, MAE: 20.1620\n","Training:\t loss: 3327.1586, MAE: 35.6640\n","Evaluating:\t loss: 2630.7081, MAE: 38.4683\n","train MSE: 3327.1586, evaluate MSE: 2630.7081\n","\n","train MAE: 35.6640, evaluate MAE: 38.4683\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 118\n","\tbatch: 100, loss: 583.2281, MAE: 18.1486\n","\tbatch: 200, loss: 2733.5400, MAE: 17.2935\n","Training:\t loss: 761.3098, MAE: 17.6467\n","Evaluating:\t loss: 579.8808, MAE: 14.7673\n","train MSE: 761.3098, evaluate MSE: 579.8808\n","\n","train MAE: 17.6467, evaluate MAE: 14.7673\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 119\n","\tbatch: 100, loss: 472.5007, MAE: 14.8060\n","\tbatch: 200, loss: 351.6626, MAE: 12.0230\n","Training:\t loss: 479.8110, MAE: 13.5265\n","Evaluating:\t loss: 461.0380, MAE: 12.7953\n","train MSE: 479.8110, evaluate MSE: 461.0380\n","\n","train MAE: 13.5265, evaluate MAE: 12.7953\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 120\n","\tbatch: 100, loss: 324.8075, MAE: 11.6541\n","\tbatch: 200, loss: 326.7038, MAE: 12.0356\n","Training:\t loss: 403.2329, MAE: 12.3181\n","Evaluating:\t loss: 440.6206, MAE: 11.8930\n","train MSE: 403.2329, evaluate MSE: 440.6206\n","\n","train MAE: 12.3181, evaluate MAE: 11.8930\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 121\n","\tbatch: 100, loss: 217.4789, MAE: 10.8092\n","\tbatch: 200, loss: 240.1317, MAE: 9.8585\n","Training:\t loss: 343.7680, MAE: 11.3560\n","Evaluating:\t loss: 496.5681, MAE: 15.2328\n","train MSE: 343.7680, evaluate MSE: 496.5681\n","\n","train MAE: 11.3560, evaluate MAE: 15.2328\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 122\n","\tbatch: 100, loss: 278.2310, MAE: 11.6103\n","\tbatch: 200, loss: 267.8210, MAE: 12.4299\n","Training:\t loss: 342.1915, MAE: 11.4732\n","Evaluating:\t loss: 432.6698, MAE: 14.2703\n","train MSE: 342.1915, evaluate MSE: 432.6698\n","\n","train MAE: 11.4732, evaluate MAE: 14.2703\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 123\n","\tbatch: 100, loss: 263.4318, MAE: 10.4078\n","\tbatch: 200, loss: 151.3723, MAE: 9.0829\n","Training:\t loss: 297.9956, MAE: 10.6653\n","Evaluating:\t loss: 362.6558, MAE: 10.7557\n","train MSE: 297.9956, evaluate MSE: 362.6558\n","\n","train MAE: 10.6653, evaluate MAE: 10.7557\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 124\n","\tbatch: 100, loss: 150.4594, MAE: 8.7804\n","\tbatch: 200, loss: 210.1476, MAE: 10.4568\n","Training:\t loss: 283.6257, MAE: 10.5119\n","Evaluating:\t loss: 308.8182, MAE: 10.8639\n","train MSE: 283.6257, evaluate MSE: 308.8182\n","\n","train MAE: 10.5119, evaluate MAE: 10.8639\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 125\n","\tbatch: 100, loss: 239.3111, MAE: 10.0820\n","\tbatch: 200, loss: 184.3130, MAE: 9.5433\n","Training:\t loss: 295.5881, MAE: 10.8872\n","Evaluating:\t loss: 287.8713, MAE: 10.4838\n","train MSE: 295.5881, evaluate MSE: 287.8713\n","\n","train MAE: 10.8872, evaluate MAE: 10.4838\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 126\n","\tbatch: 100, loss: 312.9052, MAE: 12.9599\n","\tbatch: 200, loss: 221.2933, MAE: 9.1970\n","Training:\t loss: 281.3588, MAE: 10.5545\n","Evaluating:\t loss: 268.9824, MAE: 10.2714\n","train MSE: 281.3588, evaluate MSE: 268.9824\n","\n","train MAE: 10.5545, evaluate MAE: 10.2714\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 127\n","\tbatch: 100, loss: 166.9654, MAE: 8.8685\n","\tbatch: 200, loss: 143.6065, MAE: 8.9913\n","Training:\t loss: 253.4058, MAE: 9.8416\n","Evaluating:\t loss: 230.1203, MAE: 9.3103\n","train MSE: 253.4058, evaluate MSE: 230.1203\n","\n","train MAE: 9.8416, evaluate MAE: 9.3103\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 128\n","\tbatch: 100, loss: 291.8973, MAE: 10.1087\n","\tbatch: 200, loss: 240.3822, MAE: 9.9830\n","Training:\t loss: 252.9912, MAE: 9.9671\n","Evaluating:\t loss: 243.1468, MAE: 9.2655\n","train MSE: 252.9912, evaluate MSE: 243.1468\n","\n","train MAE: 9.9671, evaluate MAE: 9.2655\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 129\n","\tbatch: 100, loss: 139.6472, MAE: 9.0029\n","\tbatch: 200, loss: 194.0468, MAE: 9.9916\n","Training:\t loss: 227.9322, MAE: 9.3138\n","Evaluating:\t loss: 325.5327, MAE: 11.9021\n","train MSE: 227.9322, evaluate MSE: 325.5327\n","\n","train MAE: 9.3138, evaluate MAE: 11.9021\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 130\n","\tbatch: 100, loss: 170.8311, MAE: 8.9198\n","\tbatch: 200, loss: 172.9079, MAE: 8.9994\n","Training:\t loss: 305.8521, MAE: 11.2234\n","Evaluating:\t loss: 642.5309, MAE: 17.7584\n","train MSE: 305.8521, evaluate MSE: 642.5309\n","\n","train MAE: 11.2234, evaluate MAE: 17.7584\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 131\n","\tbatch: 100, loss: 220.9261, MAE: 10.7171\n","\tbatch: 200, loss: 193.5918, MAE: 9.1727\n","Training:\t loss: 269.3701, MAE: 10.4559\n","Evaluating:\t loss: 319.4725, MAE: 10.4193\n","train MSE: 269.3701, evaluate MSE: 319.4725\n","\n","train MAE: 10.4559, evaluate MAE: 10.4193\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 132\n","\tbatch: 100, loss: 222.7650, MAE: 10.3092\n","\tbatch: 200, loss: 154.6941, MAE: 8.2770\n","Training:\t loss: 241.1229, MAE: 9.6803\n","Evaluating:\t loss: 452.5050, MAE: 14.3718\n","train MSE: 241.1229, evaluate MSE: 452.5050\n","\n","train MAE: 9.6803, evaluate MAE: 14.3718\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 133\n","\tbatch: 100, loss: 270.0872, MAE: 9.6570\n","\tbatch: 200, loss: 184.2407, MAE: 7.5847\n","Training:\t loss: 219.5813, MAE: 9.1674\n","Evaluating:\t loss: 224.7775, MAE: 8.1801\n","train MSE: 219.5813, evaluate MSE: 224.7775\n","\n","train MAE: 9.1674, evaluate MAE: 8.1801\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 134\n","\tbatch: 100, loss: 4687.0625, MAE: 41.3953\n","\tbatch: 200, loss: 1285.3892, MAE: 22.9976\n","Training:\t loss: 11605.5543, MAE: 47.2695\n","Evaluating:\t loss: 1107.0588, MAE: 20.0095\n","train MSE: 11605.5543, evaluate MSE: 1107.0588\n","\n","train MAE: 47.2695, evaluate MAE: 20.0095\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 135\n","\tbatch: 100, loss: 646.4015, MAE: 16.5475\n","\tbatch: 200, loss: 545.2025, MAE: 15.8729\n","Training:\t loss: 899.8065, MAE: 18.7270\n","Evaluating:\t loss: 793.1184, MAE: 17.2632\n","train MSE: 899.8065, evaluate MSE: 793.1184\n","\n","train MAE: 18.7270, evaluate MAE: 17.2632\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 136\n","\tbatch: 100, loss: 879.2502, MAE: 21.5611\n","\tbatch: 200, loss: 274.3880, MAE: 12.2452\n","Training:\t loss: 587.3419, MAE: 14.8678\n","Evaluating:\t loss: 590.7532, MAE: 13.6499\n","train MSE: 587.3419, evaluate MSE: 590.7532\n","\n","train MAE: 14.8678, evaluate MAE: 13.6499\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 137\n","\tbatch: 100, loss: 277.6446, MAE: 12.6495\n","\tbatch: 200, loss: 438.1236, MAE: 13.0558\n","Training:\t loss: 493.1519, MAE: 13.3681\n","Evaluating:\t loss: 885.0733, MAE: 21.0843\n","train MSE: 493.1519, evaluate MSE: 885.0733\n","\n","train MAE: 13.3681, evaluate MAE: 21.0843\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 138\n","\tbatch: 100, loss: 617.0589, MAE: 13.6767\n","\tbatch: 200, loss: 557.0334, MAE: 12.2840\n","Training:\t loss: 428.2464, MAE: 12.5424\n","Evaluating:\t loss: 434.2459, MAE: 12.0648\n","train MSE: 428.2464, evaluate MSE: 434.2459\n","\n","train MAE: 12.5424, evaluate MAE: 12.0648\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 139\n","\tbatch: 100, loss: 265.3185, MAE: 10.8776\n","\tbatch: 200, loss: 269.5973, MAE: 11.5492\n","Training:\t loss: 376.8398, MAE: 11.8876\n","Evaluating:\t loss: 407.6185, MAE: 11.3902\n","train MSE: 376.8398, evaluate MSE: 407.6185\n","\n","train MAE: 11.8876, evaluate MAE: 11.3902\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 140\n","\tbatch: 100, loss: 347.0792, MAE: 11.2560\n","\tbatch: 200, loss: 262.0021, MAE: 10.9895\n","Training:\t loss: 337.0684, MAE: 11.1435\n","Evaluating:\t loss: 340.9088, MAE: 10.3513\n","train MSE: 337.0684, evaluate MSE: 340.9088\n","\n","train MAE: 11.1435, evaluate MAE: 10.3513\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 141\n","\tbatch: 100, loss: 308.0346, MAE: 11.0722\n","\tbatch: 200, loss: 243.4993, MAE: 11.1322\n","Training:\t loss: 326.7313, MAE: 11.1983\n","Evaluating:\t loss: 389.4526, MAE: 12.4746\n","train MSE: 326.7313, evaluate MSE: 389.4526\n","\n","train MAE: 11.1983, evaluate MAE: 12.4746\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 142\n","\tbatch: 100, loss: 274.9983, MAE: 11.0930\n","\tbatch: 200, loss: 239.9536, MAE: 10.0220\n","Training:\t loss: 297.5046, MAE: 10.6687\n","Evaluating:\t loss: 375.8097, MAE: 12.0771\n","train MSE: 297.5046, evaluate MSE: 375.8097\n","\n","train MAE: 10.6687, evaluate MAE: 12.0771\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 143\n","\tbatch: 100, loss: 172.5540, MAE: 9.3240\n","\tbatch: 200, loss: 396.9175, MAE: 15.4384\n","Training:\t loss: 307.7382, MAE: 11.1001\n","Evaluating:\t loss: 332.3882, MAE: 11.2497\n","train MSE: 307.7382, evaluate MSE: 332.3882\n","\n","train MAE: 11.1001, evaluate MAE: 11.2497\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 144\n","\tbatch: 100, loss: 183.5155, MAE: 9.0909\n","\tbatch: 200, loss: 204.5566, MAE: 9.7597\n","Training:\t loss: 296.5895, MAE: 11.0121\n","Evaluating:\t loss: 325.9968, MAE: 11.1412\n","train MSE: 296.5895, evaluate MSE: 325.9968\n","\n","train MAE: 11.0121, evaluate MAE: 11.1412\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 145\n","\tbatch: 100, loss: 344.7687, MAE: 11.1567\n","\tbatch: 200, loss: 216.4449, MAE: 9.7473\n","Training:\t loss: 276.7434, MAE: 10.5534\n","Evaluating:\t loss: 388.0133, MAE: 13.4756\n","train MSE: 276.7434, evaluate MSE: 388.0133\n","\n","train MAE: 10.5534, evaluate MAE: 13.4756\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 146\n","\tbatch: 100, loss: 191.5594, MAE: 9.1284\n","\tbatch: 200, loss: 406.9832, MAE: 10.5987\n","Training:\t loss: 252.8394, MAE: 10.0269\n","Evaluating:\t loss: 278.4697, MAE: 9.6664\n","train MSE: 252.8394, evaluate MSE: 278.4697\n","\n","train MAE: 10.0269, evaluate MAE: 9.6664\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 147\n","\tbatch: 100, loss: 230.9160, MAE: 10.8697\n","\tbatch: 200, loss: 154.5660, MAE: 8.8947\n","Training:\t loss: 260.0901, MAE: 10.3587\n","Evaluating:\t loss: 292.1663, MAE: 9.9858\n","train MSE: 260.0901, evaluate MSE: 292.1663\n","\n","train MAE: 10.3587, evaluate MAE: 9.9858\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 148\n","\tbatch: 100, loss: 206.0873, MAE: 8.5127\n","\tbatch: 200, loss: 193.1703, MAE: 10.5246\n","Training:\t loss: 1891.4114, MAE: 19.8942\n","Evaluating:\t loss: 2252.3126, MAE: 33.6074\n","train MSE: 1891.4114, evaluate MSE: 2252.3126\n","\n","train MAE: 19.8942, evaluate MAE: 33.6074\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 149\n","\tbatch: 100, loss: 796.9249, MAE: 18.1318\n","\tbatch: 200, loss: 736.0350, MAE: 16.4100\n","Training:\t loss: 813.6779, MAE: 18.3525\n","Evaluating:\t loss: 524.2955, MAE: 14.5278\n","train MSE: 813.6779, evaluate MSE: 524.2955\n","\n","train MAE: 18.3525, evaluate MAE: 14.5278\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 150\n","\tbatch: 100, loss: 304.3752, MAE: 12.4316\n","\tbatch: 200, loss: 381.8709, MAE: 11.6913\n","Training:\t loss: 428.2418, MAE: 12.9379\n","Evaluating:\t loss: 432.8282, MAE: 12.9074\n","train MSE: 428.2418, evaluate MSE: 432.8282\n","\n","train MAE: 12.9379, evaluate MAE: 12.9074\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 151\n","\tbatch: 100, loss: 247.9717, MAE: 11.5401\n","\tbatch: 200, loss: 275.7790, MAE: 10.6494\n","Training:\t loss: 349.2107, MAE: 11.5256\n","Evaluating:\t loss: 364.8504, MAE: 11.0794\n","train MSE: 349.2107, evaluate MSE: 364.8504\n","\n","train MAE: 11.5256, evaluate MAE: 11.0794\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 152\n","\tbatch: 100, loss: 142.0625, MAE: 9.3396\n","\tbatch: 200, loss: 280.3741, MAE: 12.0606\n","Training:\t loss: 291.3999, MAE: 10.6155\n","Evaluating:\t loss: 363.4781, MAE: 11.1751\n","train MSE: 291.3999, evaluate MSE: 363.4781\n","\n","train MAE: 10.6155, evaluate MAE: 11.1751\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 153\n","\tbatch: 100, loss: 183.8238, MAE: 9.2499\n","\tbatch: 200, loss: 223.3617, MAE: 10.1252\n","Training:\t loss: 267.4761, MAE: 10.1551\n","Evaluating:\t loss: 265.0386, MAE: 9.2709\n","train MSE: 267.4761, evaluate MSE: 265.0386\n","\n","train MAE: 10.1551, evaluate MAE: 9.2709\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 154\n","\tbatch: 100, loss: 234.4935, MAE: 11.5576\n","\tbatch: 200, loss: 249.2992, MAE: 9.0504\n","Training:\t loss: 240.4015, MAE: 9.6430\n","Evaluating:\t loss: 261.1877, MAE: 9.8534\n","train MSE: 240.4015, evaluate MSE: 261.1877\n","\n","train MAE: 9.6430, evaluate MAE: 9.8534\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 155\n","\tbatch: 100, loss: 333.3327, MAE: 9.8764\n","\tbatch: 200, loss: 205.4508, MAE: 11.0009\n","Training:\t loss: 245.0739, MAE: 9.9338\n","Evaluating:\t loss: 250.9450, MAE: 8.9733\n","train MSE: 245.0739, evaluate MSE: 250.9450\n","\n","train MAE: 9.9338, evaluate MAE: 8.9733\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 156\n","\tbatch: 100, loss: 212.6241, MAE: 9.9742\n","\tbatch: 200, loss: 172.8697, MAE: 8.5109\n","Training:\t loss: 215.3751, MAE: 9.1182\n","Evaluating:\t loss: 261.1073, MAE: 9.2692\n","train MSE: 215.3751, evaluate MSE: 261.1073\n","\n","train MAE: 9.1182, evaluate MAE: 9.2692\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 157\n","\tbatch: 100, loss: 243.0635, MAE: 10.2893\n","\tbatch: 200, loss: 314.6630, MAE: 12.2497\n","Training:\t loss: 240.0468, MAE: 9.6903\n","Evaluating:\t loss: 342.8464, MAE: 10.6707\n","train MSE: 240.0468, evaluate MSE: 342.8464\n","\n","train MAE: 9.6903, evaluate MAE: 10.6707\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 158\n","\tbatch: 100, loss: 200.2927, MAE: 8.3668\n","\tbatch: 200, loss: 144.1432, MAE: 8.4384\n","Training:\t loss: 229.0937, MAE: 9.3414\n","Evaluating:\t loss: 220.1951, MAE: 8.8793\n","train MSE: 229.0937, evaluate MSE: 220.1951\n","\n","train MAE: 9.3414, evaluate MAE: 8.8793\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 159\n","\tbatch: 100, loss: 203.4203, MAE: 9.3183\n","\tbatch: 200, loss: 128.6895, MAE: 8.3215\n","Training:\t loss: 213.5237, MAE: 9.2300\n","Evaluating:\t loss: 223.3838, MAE: 8.6596\n","train MSE: 213.5237, evaluate MSE: 223.3838\n","\n","train MAE: 9.2300, evaluate MAE: 8.6596\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 160\n","\tbatch: 100, loss: 162.0278, MAE: 9.0899\n","\tbatch: 200, loss: 132.3430, MAE: 7.7502\n","Training:\t loss: 184.7831, MAE: 8.5272\n","Evaluating:\t loss: 194.4709, MAE: 8.1618\n","train MSE: 184.7831, evaluate MSE: 194.4709\n","\n","train MAE: 8.5272, evaluate MAE: 8.1618\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 161\n","\tbatch: 100, loss: 127.7956, MAE: 8.4857\n","\tbatch: 200, loss: 179.1200, MAE: 9.9698\n","Training:\t loss: 201.3017, MAE: 9.0757\n","Evaluating:\t loss: 216.6920, MAE: 8.6353\n","train MSE: 201.3017, evaluate MSE: 216.6920\n","\n","train MAE: 9.0757, evaluate MAE: 8.6353\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 162\n","\tbatch: 100, loss: 187.7347, MAE: 10.9249\n","\tbatch: 200, loss: 125.6779, MAE: 7.4457\n","Training:\t loss: 191.2929, MAE: 8.7892\n","Evaluating:\t loss: 202.7316, MAE: 9.1896\n","train MSE: 191.2929, evaluate MSE: 202.7316\n","\n","train MAE: 8.7892, evaluate MAE: 9.1896\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 163\n","\tbatch: 100, loss: 124.6957, MAE: 7.3451\n","\tbatch: 200, loss: 274.6065, MAE: 10.1855\n","Training:\t loss: 194.1065, MAE: 8.7686\n","Evaluating:\t loss: 215.1185, MAE: 9.7130\n","train MSE: 194.1065, evaluate MSE: 215.1185\n","\n","train MAE: 8.7686, evaluate MAE: 9.7130\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 164\n","\tbatch: 100, loss: 128.0670, MAE: 8.4355\n","\tbatch: 200, loss: 221.4718, MAE: 11.0172\n","Training:\t loss: 272.7633, MAE: 10.9445\n","Evaluating:\t loss: 251.4110, MAE: 9.8144\n","train MSE: 272.7633, evaluate MSE: 251.4110\n","\n","train MAE: 10.9445, evaluate MAE: 9.8144\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 165\n","\tbatch: 100, loss: 131.4378, MAE: 8.2378\n","\tbatch: 200, loss: 226.2266, MAE: 9.8516\n","Training:\t loss: 185.4228, MAE: 8.7018\n","Evaluating:\t loss: 183.1013, MAE: 7.5901\n","train MSE: 185.4228, evaluate MSE: 183.1013\n","\n","train MAE: 8.7018, evaluate MAE: 7.5901\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 166\n","\tbatch: 100, loss: 165.7699, MAE: 8.7072\n","\tbatch: 200, loss: 122.1249, MAE: 7.0997\n","Training:\t loss: 183.8502, MAE: 8.6429\n","Evaluating:\t loss: 208.8906, MAE: 9.0276\n","train MSE: 183.8502, evaluate MSE: 208.8906\n","\n","train MAE: 8.6429, evaluate MAE: 9.0276\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 167\n","\tbatch: 100, loss: 1063.2808, MAE: 19.2993\n","\tbatch: 200, loss: 661.5125, MAE: 14.7471\n","Training:\t loss: 4101.5578, MAE: 29.4851\n","Evaluating:\t loss: 417.4323, MAE: 12.3447\n","train MSE: 4101.5578, evaluate MSE: 417.4323\n","\n","train MAE: 29.4851, evaluate MAE: 12.3447\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 168\n","\tbatch: 100, loss: 263.8150, MAE: 11.3747\n","\tbatch: 200, loss: 320.3232, MAE: 10.0815\n","Training:\t loss: 352.4648, MAE: 11.4363\n","Evaluating:\t loss: 309.3915, MAE: 10.5008\n","train MSE: 352.4648, evaluate MSE: 309.3915\n","\n","train MAE: 11.4363, evaluate MAE: 10.5008\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 169\n","\tbatch: 100, loss: 482.4891, MAE: 10.5554\n","\tbatch: 200, loss: 160.5591, MAE: 8.6922\n","Training:\t loss: 265.4704, MAE: 9.6624\n","Evaluating:\t loss: 264.4131, MAE: 9.3738\n","train MSE: 265.4704, evaluate MSE: 264.4131\n","\n","train MAE: 9.6624, evaluate MAE: 9.3738\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 170\n","\tbatch: 100, loss: 163.2389, MAE: 8.3575\n","\tbatch: 200, loss: 306.9688, MAE: 9.7257\n","Training:\t loss: 240.3960, MAE: 9.2179\n","Evaluating:\t loss: 240.9195, MAE: 8.5236\n","train MSE: 240.3960, evaluate MSE: 240.9195\n","\n","train MAE: 9.2179, evaluate MAE: 8.5236\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 171\n","\tbatch: 100, loss: 139.0192, MAE: 7.6544\n","\tbatch: 200, loss: 260.3560, MAE: 11.9781\n","Training:\t loss: 206.4488, MAE: 8.5233\n","Evaluating:\t loss: 221.8454, MAE: 8.2114\n","train MSE: 206.4488, evaluate MSE: 221.8454\n","\n","train MAE: 8.5233, evaluate MAE: 8.2114\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 172\n","\tbatch: 100, loss: 139.4657, MAE: 7.9070\n","\tbatch: 200, loss: 157.0007, MAE: 8.6026\n","Training:\t loss: 193.5743, MAE: 8.2754\n","Evaluating:\t loss: 206.9437, MAE: 8.1867\n","train MSE: 193.5743, evaluate MSE: 206.9437\n","\n","train MAE: 8.2754, evaluate MAE: 8.1867\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 173\n","\tbatch: 100, loss: 121.8210, MAE: 8.6859\n","\tbatch: 200, loss: 140.2380, MAE: 8.2128\n","Training:\t loss: 178.2932, MAE: 8.0176\n","Evaluating:\t loss: 208.8388, MAE: 8.1605\n","train MSE: 178.2932, evaluate MSE: 208.8388\n","\n","train MAE: 8.0176, evaluate MAE: 8.1605\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 174\n","\tbatch: 100, loss: 101.9855, MAE: 7.1780\n","\tbatch: 200, loss: 168.8140, MAE: 8.0582\n","Training:\t loss: 170.7920, MAE: 7.7629\n","Evaluating:\t loss: 187.4063, MAE: 7.6281\n","train MSE: 170.7920, evaluate MSE: 187.4063\n","\n","train MAE: 7.7629, evaluate MAE: 7.6281\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 175\n","\tbatch: 100, loss: 107.0030, MAE: 7.7179\n","\tbatch: 200, loss: 136.6195, MAE: 8.7662\n","Training:\t loss: 169.3551, MAE: 7.8556\n","Evaluating:\t loss: 200.3555, MAE: 8.0159\n","train MSE: 169.3551, evaluate MSE: 200.3555\n","\n","train MAE: 7.8556, evaluate MAE: 8.0159\n","\n","--- time consumption (s): 19\n","\n","------------------------------\n","Epoch 176\n","\tbatch: 100, loss: 279.0692, MAE: 9.5832\n","\tbatch: 200, loss: 200.7395, MAE: 8.4052\n","Training:\t loss: 177.9582, MAE: 8.2194\n","Evaluating:\t loss: 209.2414, MAE: 8.8081\n","train MSE: 177.9582, evaluate MSE: 209.2414\n","\n","train MAE: 8.2194, evaluate MAE: 8.8081\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 177\n","\tbatch: 100, loss: 194.3287, MAE: 11.2562\n","\tbatch: 200, loss: 119.9468, MAE: 7.7658\n","Training:\t loss: 160.5092, MAE: 7.7665\n","Evaluating:\t loss: 153.5814, MAE: 7.2463\n","train MSE: 160.5092, evaluate MSE: 153.5814\n","\n","train MAE: 7.7665, evaluate MAE: 7.2463\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 178\n","\tbatch: 100, loss: 103.1064, MAE: 7.3152\n","\tbatch: 200, loss: 151.1650, MAE: 7.6900\n","Training:\t loss: 145.5787, MAE: 7.2901\n","Evaluating:\t loss: 232.1588, MAE: 9.9313\n","train MSE: 145.5787, evaluate MSE: 232.1588\n","\n","train MAE: 7.2901, evaluate MAE: 9.9313\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 179\n","\tbatch: 100, loss: 166.3433, MAE: 7.4688\n","\tbatch: 200, loss: 72.3918, MAE: 6.1807\n","Training:\t loss: 149.5669, MAE: 7.4721\n","Evaluating:\t loss: 167.3100, MAE: 7.3090\n","train MSE: 149.5669, evaluate MSE: 167.3100\n","\n","train MAE: 7.4721, evaluate MAE: 7.3090\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 180\n","\tbatch: 100, loss: 143.9940, MAE: 9.0202\n","\tbatch: 200, loss: 111.4285, MAE: 8.1270\n","Training:\t loss: 159.5706, MAE: 7.8902\n","Evaluating:\t loss: 264.1612, MAE: 11.7398\n","train MSE: 159.5706, evaluate MSE: 264.1612\n","\n","train MAE: 7.8902, evaluate MAE: 11.7398\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 181\n","\tbatch: 100, loss: 70.1072, MAE: 6.1229\n","\tbatch: 200, loss: 114.3313, MAE: 7.2091\n","Training:\t loss: 143.8065, MAE: 7.4440\n","Evaluating:\t loss: 153.0355, MAE: 7.2856\n","train MSE: 143.8065, evaluate MSE: 153.0355\n","\n","train MAE: 7.4440, evaluate MAE: 7.2856\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 182\n","\tbatch: 100, loss: 121.5475, MAE: 7.0257\n","\tbatch: 200, loss: 94.1160, MAE: 6.7005\n","Training:\t loss: 142.9302, MAE: 7.4587\n","Evaluating:\t loss: 210.2806, MAE: 9.1693\n","train MSE: 142.9302, evaluate MSE: 210.2806\n","\n","train MAE: 7.4587, evaluate MAE: 9.1693\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 183\n","\tbatch: 100, loss: 98.0197, MAE: 6.7604\n","\tbatch: 200, loss: 180.6847, MAE: 10.5936\n","Training:\t loss: 146.8481, MAE: 7.4196\n","Evaluating:\t loss: 204.7250, MAE: 9.0184\n","train MSE: 146.8481, evaluate MSE: 204.7250\n","\n","train MAE: 7.4196, evaluate MAE: 9.0184\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 184\n","\tbatch: 100, loss: 86.0219, MAE: 6.7388\n","\tbatch: 200, loss: 102.9504, MAE: 6.8387\n","Training:\t loss: 165.3464, MAE: 8.0746\n","Evaluating:\t loss: 141.4862, MAE: 6.9527\n","train MSE: 165.3464, evaluate MSE: 141.4862\n","\n","train MAE: 8.0746, evaluate MAE: 6.9527\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 185\n","\tbatch: 100, loss: 167.6479, MAE: 7.3654\n","\tbatch: 200, loss: 96.6752, MAE: 7.2932\n","Training:\t loss: 142.3863, MAE: 7.4614\n","Evaluating:\t loss: 151.7702, MAE: 7.5865\n","train MSE: 142.3863, evaluate MSE: 151.7702\n","\n","train MAE: 7.4614, evaluate MAE: 7.5865\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 186\n","\tbatch: 100, loss: 1906.6791, MAE: 30.9890\n","\tbatch: 200, loss: 300.3072, MAE: 11.1789\n","Training:\t loss: 1383.1962, MAE: 18.9015\n","Evaluating:\t loss: 393.9943, MAE: 14.3700\n","train MSE: 1383.1962, evaluate MSE: 393.9943\n","\n","train MAE: 18.9015, evaluate MAE: 14.3700\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 187\n","\tbatch: 100, loss: 278.3802, MAE: 9.6833\n","\tbatch: 200, loss: 309.5437, MAE: 8.6566\n","Training:\t loss: 264.9231, MAE: 10.0812\n","Evaluating:\t loss: 210.9117, MAE: 8.5867\n","train MSE: 264.9231, evaluate MSE: 210.9117\n","\n","train MAE: 10.0812, evaluate MAE: 8.5867\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 188\n","\tbatch: 100, loss: 198.4448, MAE: 10.5884\n","\tbatch: 200, loss: 86.3555, MAE: 6.5574\n","Training:\t loss: 186.9451, MAE: 8.3326\n","Evaluating:\t loss: 254.7782, MAE: 10.1535\n","train MSE: 186.9451, evaluate MSE: 254.7782\n","\n","train MAE: 8.3326, evaluate MAE: 10.1535\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 189\n","\tbatch: 100, loss: 96.0389, MAE: 6.9399\n","\tbatch: 200, loss: 99.8672, MAE: 7.4222\n","Training:\t loss: 165.7179, MAE: 7.7786\n","Evaluating:\t loss: 194.3686, MAE: 8.6038\n","train MSE: 165.7179, evaluate MSE: 194.3686\n","\n","train MAE: 7.7786, evaluate MAE: 8.6038\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 190\n","\tbatch: 100, loss: 118.8023, MAE: 7.1508\n","\tbatch: 200, loss: 60.7414, MAE: 5.8352\n","Training:\t loss: 138.9845, MAE: 7.0761\n","Evaluating:\t loss: 143.9799, MAE: 7.1978\n","train MSE: 138.9845, evaluate MSE: 143.9799\n","\n","train MAE: 7.0761, evaluate MAE: 7.1978\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 191\n","\tbatch: 100, loss: 81.8504, MAE: 6.7569\n","\tbatch: 200, loss: 126.0667, MAE: 7.0977\n","Training:\t loss: 124.8398, MAE: 6.7465\n","Evaluating:\t loss: 125.2052, MAE: 6.5744\n","train MSE: 124.8398, evaluate MSE: 125.2052\n","\n","train MAE: 6.7465, evaluate MAE: 6.5744\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 192\n","\tbatch: 100, loss: 115.3797, MAE: 7.0629\n","\tbatch: 200, loss: 78.0669, MAE: 5.9547\n","Training:\t loss: 112.3801, MAE: 6.3807\n","Evaluating:\t loss: 144.5669, MAE: 6.7034\n","train MSE: 112.3801, evaluate MSE: 144.5669\n","\n","train MAE: 6.3807, evaluate MAE: 6.7034\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 193\n","\tbatch: 100, loss: 62.8830, MAE: 5.3570\n","\tbatch: 200, loss: 106.9899, MAE: 7.6301\n","Training:\t loss: 117.8020, MAE: 6.6201\n","Evaluating:\t loss: 131.5318, MAE: 6.8799\n","train MSE: 117.8020, evaluate MSE: 131.5318\n","\n","train MAE: 6.6201, evaluate MAE: 6.8799\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 194\n","\tbatch: 100, loss: 144.2593, MAE: 6.6855\n","\tbatch: 200, loss: 143.9983, MAE: 7.8372\n","Training:\t loss: 104.5863, MAE: 6.1503\n","Evaluating:\t loss: 123.7703, MAE: 6.7216\n","train MSE: 104.5863, evaluate MSE: 123.7703\n","\n","train MAE: 6.1503, evaluate MAE: 6.7216\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 195\n","\tbatch: 100, loss: 104.2311, MAE: 6.6599\n","\tbatch: 200, loss: 138.8123, MAE: 7.7668\n","Training:\t loss: 107.2521, MAE: 6.3710\n","Evaluating:\t loss: 120.9542, MAE: 6.9841\n","train MSE: 107.2521, evaluate MSE: 120.9542\n","\n","train MAE: 6.3710, evaluate MAE: 6.9841\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 196\n","\tbatch: 100, loss: 85.0576, MAE: 6.0768\n","\tbatch: 200, loss: 84.3407, MAE: 6.4632\n","Training:\t loss: 102.9002, MAE: 6.2266\n","Evaluating:\t loss: 95.4224, MAE: 5.7662\n","train MSE: 102.9002, evaluate MSE: 95.4224\n","\n","train MAE: 6.2266, evaluate MAE: 5.7662\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 197\n","\tbatch: 100, loss: 92.0637, MAE: 6.5547\n","\tbatch: 200, loss: 93.4223, MAE: 6.9838\n","Training:\t loss: 125.2622, MAE: 7.0721\n","Evaluating:\t loss: 156.4809, MAE: 7.6111\n","train MSE: 125.2622, evaluate MSE: 156.4809\n","\n","train MAE: 7.0721, evaluate MAE: 7.6111\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 198\n","\tbatch: 100, loss: 102.8531, MAE: 8.1512\n","\tbatch: 200, loss: 77.9264, MAE: 6.3777\n","Training:\t loss: 118.2766, MAE: 6.6488\n","Evaluating:\t loss: 106.1901, MAE: 5.7635\n","train MSE: 118.2766, evaluate MSE: 106.1901\n","\n","train MAE: 6.6488, evaluate MAE: 5.7635\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 199\n","\tbatch: 100, loss: 54.3337, MAE: 5.1266\n","\tbatch: 200, loss: 115.1703, MAE: 6.1449\n","Training:\t loss: 118.2777, MAE: 6.6689\n","Evaluating:\t loss: 151.2460, MAE: 8.0384\n","train MSE: 118.2777, evaluate MSE: 151.2460\n","\n","train MAE: 6.6689, evaluate MAE: 8.0384\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 200\n","\tbatch: 100, loss: 65.7258, MAE: 5.5272\n","\tbatch: 200, loss: 68.0282, MAE: 5.7667\n","Training:\t loss: 109.7580, MAE: 6.3367\n","Evaluating:\t loss: 117.3460, MAE: 6.9705\n","train MSE: 109.7580, evaluate MSE: 117.3460\n","\n","train MAE: 6.3367, evaluate MAE: 6.9705\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 201\n","\tbatch: 100, loss: 54.8637, MAE: 4.9145\n","\tbatch: 200, loss: 71.1922, MAE: 5.7406\n","Training:\t loss: 124.4405, MAE: 6.9065\n","Evaluating:\t loss: 114.1885, MAE: 6.8249\n","train MSE: 124.4405, evaluate MSE: 114.1885\n","\n","train MAE: 6.9065, evaluate MAE: 6.8249\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 202\n","\tbatch: 100, loss: 179.1318, MAE: 8.8145\n","\tbatch: 200, loss: 100.7833, MAE: 6.9850\n","Training:\t loss: 118.7847, MAE: 6.8046\n","Evaluating:\t loss: 120.4902, MAE: 6.9857\n","train MSE: 118.7847, evaluate MSE: 120.4902\n","\n","train MAE: 6.8046, evaluate MAE: 6.9857\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 203\n","\tbatch: 100, loss: 97.0097, MAE: 6.4414\n","\tbatch: 200, loss: 112.3798, MAE: 5.7897\n","Training:\t loss: 112.4244, MAE: 6.5543\n","Evaluating:\t loss: 126.0455, MAE: 6.9112\n","train MSE: 112.4244, evaluate MSE: 126.0455\n","\n","train MAE: 6.5543, evaluate MAE: 6.9112\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 204\n","\tbatch: 100, loss: 72.8329, MAE: 5.3949\n","\tbatch: 200, loss: 324.7839, MAE: 13.4392\n","Training:\t loss: 906.3340, MAE: 15.7013\n","Evaluating:\t loss: 294.8907, MAE: 11.2010\n","train MSE: 906.3340, evaluate MSE: 294.8907\n","\n","train MAE: 15.7013, evaluate MAE: 11.2010\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 205\n","\tbatch: 100, loss: 315.1616, MAE: 8.3292\n","\tbatch: 200, loss: 123.8681, MAE: 7.7848\n","Training:\t loss: 204.6243, MAE: 8.7728\n","Evaluating:\t loss: 190.8053, MAE: 8.3278\n","train MSE: 204.6243, evaluate MSE: 190.8053\n","\n","train MAE: 8.7728, evaluate MAE: 8.3278\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 206\n","\tbatch: 100, loss: 105.1443, MAE: 7.0814\n","\tbatch: 200, loss: 133.0169, MAE: 7.5537\n","Training:\t loss: 162.5018, MAE: 7.8349\n","Evaluating:\t loss: 208.9829, MAE: 9.2732\n","train MSE: 162.5018, evaluate MSE: 208.9829\n","\n","train MAE: 7.8349, evaluate MAE: 9.2732\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 207\n","\tbatch: 100, loss: 76.9851, MAE: 6.0247\n","\tbatch: 200, loss: 74.3071, MAE: 5.5834\n","Training:\t loss: 120.7132, MAE: 6.6782\n","Evaluating:\t loss: 127.3024, MAE: 6.4182\n","train MSE: 120.7132, evaluate MSE: 127.3024\n","\n","train MAE: 6.6782, evaluate MAE: 6.4182\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 208\n","\tbatch: 100, loss: 46.4935, MAE: 5.0641\n","\tbatch: 200, loss: 71.8247, MAE: 6.5716\n","Training:\t loss: 102.4678, MAE: 6.1298\n","Evaluating:\t loss: 106.4524, MAE: 6.0163\n","train MSE: 102.4678, evaluate MSE: 106.4524\n","\n","train MAE: 6.1298, evaluate MAE: 6.0163\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 209\n","\tbatch: 100, loss: 102.9365, MAE: 6.5975\n","\tbatch: 200, loss: 93.5069, MAE: 6.7291\n","Training:\t loss: 99.9491, MAE: 6.0740\n","Evaluating:\t loss: 115.5194, MAE: 6.2735\n","train MSE: 99.9491, evaluate MSE: 115.5194\n","\n","train MAE: 6.0740, evaluate MAE: 6.2735\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 210\n","\tbatch: 100, loss: 67.4919, MAE: 6.0397\n","\tbatch: 200, loss: 103.4298, MAE: 7.5655\n","Training:\t loss: 105.6994, MAE: 6.3760\n","Evaluating:\t loss: 165.4685, MAE: 6.9725\n","train MSE: 105.6994, evaluate MSE: 165.4685\n","\n","train MAE: 6.3760, evaluate MAE: 6.9725\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 211\n","\tbatch: 100, loss: 61.9910, MAE: 5.9218\n","\tbatch: 200, loss: 56.9937, MAE: 5.3216\n","Training:\t loss: 96.9741, MAE: 6.0283\n","Evaluating:\t loss: 145.5524, MAE: 7.2659\n","train MSE: 96.9741, evaluate MSE: 145.5524\n","\n","train MAE: 6.0283, evaluate MAE: 7.2659\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 212\n","\tbatch: 100, loss: 146.5024, MAE: 9.1152\n","\tbatch: 200, loss: 43.2743, MAE: 4.6581\n","Training:\t loss: 95.7703, MAE: 6.0844\n","Evaluating:\t loss: 172.0494, MAE: 8.4835\n","train MSE: 95.7703, evaluate MSE: 172.0494\n","\n","train MAE: 6.0844, evaluate MAE: 8.4835\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 213\n","\tbatch: 100, loss: 64.3451, MAE: 5.2290\n","\tbatch: 200, loss: 195.2605, MAE: 7.2461\n","Training:\t loss: 87.0589, MAE: 5.7849\n","Evaluating:\t loss: 89.6934, MAE: 5.3240\n","train MSE: 87.0589, evaluate MSE: 89.6934\n","\n","train MAE: 5.7849, evaluate MAE: 5.3240\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 214\n","\tbatch: 100, loss: 59.0717, MAE: 5.6181\n","\tbatch: 200, loss: 75.9774, MAE: 6.0636\n","Training:\t loss: 122.9355, MAE: 6.9971\n","Evaluating:\t loss: 189.6947, MAE: 8.6387\n","train MSE: 122.9355, evaluate MSE: 189.6947\n","\n","train MAE: 6.9971, evaluate MAE: 8.6387\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 215\n","\tbatch: 100, loss: 498.7222, MAE: 14.8551\n","\tbatch: 200, loss: 269.2952, MAE: 10.9686\n","Training:\t loss: 1968.3853, MAE: 24.0201\n","Evaluating:\t loss: 270.4949, MAE: 10.2762\n","train MSE: 1968.3853, evaluate MSE: 270.4949\n","\n","train MAE: 24.0201, evaluate MAE: 10.2762\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 216\n","\tbatch: 100, loss: 177.4656, MAE: 9.9488\n","\tbatch: 200, loss: 136.4399, MAE: 8.2424\n","Training:\t loss: 216.4693, MAE: 9.3279\n","Evaluating:\t loss: 192.4110, MAE: 8.7075\n","train MSE: 216.4693, evaluate MSE: 192.4110\n","\n","train MAE: 9.3279, evaluate MAE: 8.7075\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 217\n","\tbatch: 100, loss: 84.8807, MAE: 7.0062\n","\tbatch: 200, loss: 111.6132, MAE: 7.5117\n","Training:\t loss: 164.8474, MAE: 8.0130\n","Evaluating:\t loss: 170.2947, MAE: 7.8231\n","train MSE: 164.8474, evaluate MSE: 170.2947\n","\n","train MAE: 8.0130, evaluate MAE: 7.8231\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 218\n","\tbatch: 100, loss: 93.5220, MAE: 6.9936\n","\tbatch: 200, loss: 84.7983, MAE: 6.7088\n","Training:\t loss: 145.9199, MAE: 7.5055\n","Evaluating:\t loss: 124.2054, MAE: 7.3295\n","train MSE: 145.9199, evaluate MSE: 124.2054\n","\n","train MAE: 7.5055, evaluate MAE: 7.3295\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 219\n","\tbatch: 100, loss: 125.8389, MAE: 7.3538\n","\tbatch: 200, loss: 90.8480, MAE: 6.9301\n","Training:\t loss: 120.2221, MAE: 6.8637\n","Evaluating:\t loss: 187.7618, MAE: 10.3187\n","train MSE: 120.2221, evaluate MSE: 187.7618\n","\n","train MAE: 6.8637, evaluate MAE: 10.3187\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 220\n","\tbatch: 100, loss: 118.3529, MAE: 6.6311\n","\tbatch: 200, loss: 75.0997, MAE: 5.8806\n","Training:\t loss: 114.5207, MAE: 6.7941\n","Evaluating:\t loss: 136.9126, MAE: 7.1418\n","train MSE: 114.5207, evaluate MSE: 136.9126\n","\n","train MAE: 6.7941, evaluate MAE: 7.1418\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 221\n","\tbatch: 100, loss: 103.3357, MAE: 7.3040\n","\tbatch: 200, loss: 71.0385, MAE: 5.9490\n","Training:\t loss: 108.9647, MAE: 6.5663\n","Evaluating:\t loss: 141.2001, MAE: 6.5861\n","train MSE: 108.9647, evaluate MSE: 141.2001\n","\n","train MAE: 6.5663, evaluate MAE: 6.5861\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 222\n","\tbatch: 100, loss: 104.3048, MAE: 6.8249\n","\tbatch: 200, loss: 111.8941, MAE: 6.8908\n","Training:\t loss: 100.2295, MAE: 6.3716\n","Evaluating:\t loss: 108.3048, MAE: 6.1336\n","train MSE: 100.2295, evaluate MSE: 108.3048\n","\n","train MAE: 6.3716, evaluate MAE: 6.1336\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 223\n","\tbatch: 100, loss: 94.8231, MAE: 5.9946\n","\tbatch: 200, loss: 78.9940, MAE: 6.0109\n","Training:\t loss: 95.0589, MAE: 6.2241\n","Evaluating:\t loss: 99.0753, MAE: 6.1405\n","train MSE: 95.0589, evaluate MSE: 99.0753\n","\n","train MAE: 6.2241, evaluate MAE: 6.1405\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 224\n","\tbatch: 100, loss: 87.8305, MAE: 6.6189\n","\tbatch: 200, loss: 57.2423, MAE: 5.6388\n","Training:\t loss: 99.2058, MAE: 6.4092\n","Evaluating:\t loss: 107.5856, MAE: 7.0865\n","train MSE: 99.2058, evaluate MSE: 107.5856\n","\n","train MAE: 6.4092, evaluate MAE: 7.0865\n","\n","--- time consumption (s): 17\n","\n","------------------------------\n","Epoch 225\n","\tbatch: 100, loss: 70.2030, MAE: 6.0049\n","\tbatch: 200, loss: 124.9704, MAE: 9.0041\n","Training:\t loss: 95.4425, MAE: 6.3577\n","Evaluating:\t loss: 89.9725, MAE: 6.1153\n","train MSE: 95.4425, evaluate MSE: 89.9725\n","\n","train MAE: 6.3577, evaluate MAE: 6.1153\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 226\n","\tbatch: 100, loss: 122.9013, MAE: 6.6594\n","\tbatch: 200, loss: 90.6132, MAE: 6.0252\n","Training:\t loss: 98.4430, MAE: 6.4285\n","Evaluating:\t loss: 105.3407, MAE: 6.9942\n","train MSE: 98.4430, evaluate MSE: 105.3407\n","\n","train MAE: 6.4285, evaluate MAE: 6.9942\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 227\n","\tbatch: 100, loss: 55.8358, MAE: 5.2310\n","\tbatch: 200, loss: 120.9893, MAE: 8.6082\n","Training:\t loss: 98.0244, MAE: 6.4125\n","Evaluating:\t loss: 123.2426, MAE: 7.4908\n","train MSE: 98.0244, evaluate MSE: 123.2426\n","\n","train MAE: 6.4125, evaluate MAE: 7.4908\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 228\n","\tbatch: 100, loss: 91.3982, MAE: 6.8440\n","\tbatch: 200, loss: 70.3553, MAE: 6.0408\n","Training:\t loss: 93.3469, MAE: 6.2139\n","Evaluating:\t loss: 96.7327, MAE: 6.0862\n","train MSE: 93.3469, evaluate MSE: 96.7327\n","\n","train MAE: 6.2139, evaluate MAE: 6.0862\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 229\n","\tbatch: 100, loss: 59.6795, MAE: 5.4239\n","\tbatch: 200, loss: 138.5890, MAE: 9.3737\n","Training:\t loss: 92.6502, MAE: 6.3043\n","Evaluating:\t loss: 102.8550, MAE: 6.8313\n","train MSE: 92.6502, evaluate MSE: 102.8550\n","\n","train MAE: 6.3043, evaluate MAE: 6.8313\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 230\n","\tbatch: 100, loss: 70.7167, MAE: 5.6380\n","\tbatch: 200, loss: 101.0177, MAE: 6.0647\n","Training:\t loss: 103.7744, MAE: 6.7568\n","Evaluating:\t loss: 99.4687, MAE: 6.0836\n","train MSE: 103.7744, evaluate MSE: 99.4687\n","\n","train MAE: 6.7568, evaluate MAE: 6.0836\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 231\n","\tbatch: 100, loss: 74.8673, MAE: 5.9177\n","\tbatch: 200, loss: 94.2919, MAE: 7.2899\n","Training:\t loss: 108.2287, MAE: 6.8981\n","Evaluating:\t loss: 108.6693, MAE: 6.4344\n","train MSE: 108.2287, evaluate MSE: 108.6693\n","\n","train MAE: 6.8981, evaluate MAE: 6.4344\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 232\n","\tbatch: 100, loss: 108.9713, MAE: 8.1368\n","\tbatch: 200, loss: 80.5619, MAE: 6.0972\n","Training:\t loss: 99.9138, MAE: 6.5558\n","Evaluating:\t loss: 88.6394, MAE: 5.9376\n","train MSE: 99.9138, evaluate MSE: 88.6394\n","\n","train MAE: 6.5558, evaluate MAE: 5.9376\n","\n","--- time consumption (s): 19\n","\n","------------------------------\n","Epoch 233\n","\tbatch: 100, loss: 73.0080, MAE: 5.8862\n","\tbatch: 200, loss: 65.0318, MAE: 5.5523\n","Training:\t loss: 86.7449, MAE: 6.0013\n","Evaluating:\t loss: 162.9845, MAE: 7.7981\n","train MSE: 86.7449, evaluate MSE: 162.9845\n","\n","train MAE: 6.0013, evaluate MAE: 7.7981\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 234\n","\tbatch: 100, loss: 54.6090, MAE: 4.9586\n","\tbatch: 200, loss: 69.7419, MAE: 5.9305\n","Training:\t loss: 87.1175, MAE: 5.9179\n","Evaluating:\t loss: 105.0080, MAE: 6.4542\n","train MSE: 87.1175, evaluate MSE: 105.0080\n","\n","train MAE: 5.9179, evaluate MAE: 6.4542\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 235\n","\tbatch: 100, loss: 126.5987, MAE: 5.7857\n","\tbatch: 200, loss: 491.1282, MAE: 13.6040\n","Training:\t loss: 743.6225, MAE: 13.9849\n","Evaluating:\t loss: 256.0890, MAE: 10.5167\n","train MSE: 743.6225, evaluate MSE: 256.0890\n","\n","train MAE: 13.9849, evaluate MAE: 10.5167\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 236\n","\tbatch: 100, loss: 109.2289, MAE: 7.9337\n","\tbatch: 200, loss: 145.3475, MAE: 8.5835\n","Training:\t loss: 199.2014, MAE: 8.6834\n","Evaluating:\t loss: 215.9040, MAE: 8.6585\n","train MSE: 199.2014, evaluate MSE: 215.9040\n","\n","train MAE: 8.6834, evaluate MAE: 8.6585\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 237\n","\tbatch: 100, loss: 117.8811, MAE: 7.1940\n","\tbatch: 200, loss: 115.5645, MAE: 7.1060\n","Training:\t loss: 148.1874, MAE: 7.4081\n","Evaluating:\t loss: 124.2831, MAE: 7.1716\n","train MSE: 148.1874, evaluate MSE: 124.2831\n","\n","train MAE: 7.4081, evaluate MAE: 7.1716\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 238\n","\tbatch: 100, loss: 85.0734, MAE: 6.9768\n","\tbatch: 200, loss: 117.0745, MAE: 6.2498\n","Training:\t loss: 112.0183, MAE: 6.4231\n","Evaluating:\t loss: 105.8820, MAE: 6.5171\n","train MSE: 112.0183, evaluate MSE: 105.8820\n","\n","train MAE: 6.4231, evaluate MAE: 6.5171\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 239\n","\tbatch: 100, loss: 78.5943, MAE: 5.9578\n","\tbatch: 200, loss: 58.9112, MAE: 5.2481\n","Training:\t loss: 93.0245, MAE: 5.7813\n","Evaluating:\t loss: 87.6712, MAE: 5.8570\n","train MSE: 93.0245, evaluate MSE: 87.6712\n","\n","train MAE: 5.7813, evaluate MAE: 5.8570\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 240\n","\tbatch: 100, loss: 110.9626, MAE: 5.8412\n","\tbatch: 200, loss: 58.6226, MAE: 5.2044\n","Training:\t loss: 86.3361, MAE: 5.6198\n","Evaluating:\t loss: 102.3270, MAE: 6.2325\n","train MSE: 86.3361, evaluate MSE: 102.3270\n","\n","train MAE: 5.6198, evaluate MAE: 6.2325\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 241\n","\tbatch: 100, loss: 53.0620, MAE: 5.0372\n","\tbatch: 200, loss: 95.1210, MAE: 5.2518\n","Training:\t loss: 82.6902, MAE: 5.4368\n","Evaluating:\t loss: 95.2758, MAE: 6.0216\n","train MSE: 82.6902, evaluate MSE: 95.2758\n","\n","train MAE: 5.4368, evaluate MAE: 6.0216\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 242\n","\tbatch: 100, loss: 74.0433, MAE: 6.1452\n","\tbatch: 200, loss: 79.8170, MAE: 6.1159\n","Training:\t loss: 85.6915, MAE: 5.7520\n","Evaluating:\t loss: 81.4372, MAE: 5.8474\n","train MSE: 85.6915, evaluate MSE: 81.4372\n","\n","train MAE: 5.7520, evaluate MAE: 5.8474\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 243\n","\tbatch: 100, loss: 42.8079, MAE: 4.8724\n","\tbatch: 200, loss: 52.3538, MAE: 4.9869\n","Training:\t loss: 74.9630, MAE: 5.1733\n","Evaluating:\t loss: 163.0386, MAE: 9.4955\n","train MSE: 74.9630, evaluate MSE: 163.0386\n","\n","train MAE: 5.1733, evaluate MAE: 9.4955\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 244\n","\tbatch: 100, loss: 50.7101, MAE: 4.7784\n","\tbatch: 200, loss: 64.6132, MAE: 4.3006\n","Training:\t loss: 70.0810, MAE: 5.0129\n","Evaluating:\t loss: 70.6321, MAE: 4.7952\n","train MSE: 70.0810, evaluate MSE: 70.6321\n","\n","train MAE: 5.0129, evaluate MAE: 4.7952\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 245\n","\tbatch: 100, loss: 52.3234, MAE: 5.0504\n","\tbatch: 200, loss: 82.4093, MAE: 6.6499\n","Training:\t loss: 74.6445, MAE: 5.2348\n","Evaluating:\t loss: 76.1216, MAE: 5.2024\n","train MSE: 74.6445, evaluate MSE: 76.1216\n","\n","train MAE: 5.2348, evaluate MAE: 5.2024\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 246\n","\tbatch: 100, loss: 46.3610, MAE: 4.7363\n","\tbatch: 200, loss: 43.0573, MAE: 4.4678\n","Training:\t loss: 69.4205, MAE: 5.0322\n","Evaluating:\t loss: 72.3229, MAE: 5.1589\n","train MSE: 69.4205, evaluate MSE: 72.3229\n","\n","train MAE: 5.0322, evaluate MAE: 5.1589\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 247\n","\tbatch: 100, loss: 56.5246, MAE: 5.0273\n","\tbatch: 200, loss: 77.6539, MAE: 7.1683\n","Training:\t loss: 85.1935, MAE: 5.4759\n","Evaluating:\t loss: 873.5992, MAE: 19.4325\n","train MSE: 85.1935, evaluate MSE: 873.5992\n","\n","train MAE: 5.4759, evaluate MAE: 19.4325\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 248\n","\tbatch: 100, loss: 172.5647, MAE: 9.1140\n","\tbatch: 200, loss: 184.7188, MAE: 7.1267\n","Training:\t loss: 513.3194, MAE: 13.5021\n","Evaluating:\t loss: 153.1911, MAE: 7.3958\n","train MSE: 513.3194, evaluate MSE: 153.1911\n","\n","train MAE: 13.5021, evaluate MAE: 7.3958\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 249\n","\tbatch: 100, loss: 89.7449, MAE: 6.2174\n","\tbatch: 200, loss: 84.8892, MAE: 5.6145\n","Training:\t loss: 102.2373, MAE: 5.8096\n","Evaluating:\t loss: 107.3214, MAE: 5.4713\n","train MSE: 102.2373, evaluate MSE: 107.3214\n","\n","train MAE: 5.8096, evaluate MAE: 5.4713\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 250\n","\tbatch: 100, loss: 84.9545, MAE: 5.9752\n","\tbatch: 200, loss: 69.7505, MAE: 5.2953\n","Training:\t loss: 107.1107, MAE: 5.9223\n","Evaluating:\t loss: 98.5952, MAE: 5.5599\n","train MSE: 107.1107, evaluate MSE: 98.5952\n","\n","train MAE: 5.9223, evaluate MAE: 5.5599\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 251\n","\tbatch: 100, loss: 68.5952, MAE: 4.5317\n","\tbatch: 200, loss: 55.5478, MAE: 4.7629\n","Training:\t loss: 80.8784, MAE: 4.9458\n","Evaluating:\t loss: 110.2573, MAE: 6.5156\n","train MSE: 80.8784, evaluate MSE: 110.2573\n","\n","train MAE: 4.9458, evaluate MAE: 6.5156\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 252\n","\tbatch: 100, loss: 67.3118, MAE: 4.3409\n","\tbatch: 200, loss: 72.5981, MAE: 5.1523\n","Training:\t loss: 68.4415, MAE: 4.5973\n","Evaluating:\t loss: 81.9508, MAE: 5.6107\n","train MSE: 68.4415, evaluate MSE: 81.9508\n","\n","train MAE: 4.5973, evaluate MAE: 5.6107\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 253\n","\tbatch: 100, loss: 2049.7512, MAE: 5.4178\n","\tbatch: 200, loss: 45.8140, MAE: 4.2150\n","Training:\t loss: 58.3520, MAE: 4.1871\n","Evaluating:\t loss: 83.2649, MAE: 5.5810\n","train MSE: 58.3520, evaluate MSE: 83.2649\n","\n","train MAE: 4.1871, evaluate MAE: 5.5810\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 254\n","\tbatch: 100, loss: 28.1787, MAE: 3.5866\n","\tbatch: 200, loss: 39.0190, MAE: 4.4248\n","Training:\t loss: 58.0191, MAE: 4.3500\n","Evaluating:\t loss: 60.1655, MAE: 3.9921\n","train MSE: 58.0191, evaluate MSE: 60.1655\n","\n","train MAE: 4.3500, evaluate MAE: 3.9921\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 255\n","\tbatch: 100, loss: 61.5101, MAE: 4.7858\n","\tbatch: 200, loss: 56.0346, MAE: 4.2789\n","Training:\t loss: 51.8838, MAE: 4.0164\n","Evaluating:\t loss: 75.6119, MAE: 4.5078\n","train MSE: 51.8838, evaluate MSE: 75.6119\n","\n","train MAE: 4.0164, evaluate MAE: 4.5078\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 256\n","\tbatch: 100, loss: 28.4931, MAE: 3.3283\n","\tbatch: 200, loss: 52.1695, MAE: 4.1049\n","Training:\t loss: 52.8550, MAE: 4.0306\n","Evaluating:\t loss: 82.6774, MAE: 4.8122\n","train MSE: 52.8550, evaluate MSE: 82.6774\n","\n","train MAE: 4.0306, evaluate MAE: 4.8122\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 257\n","\tbatch: 100, loss: 38.9310, MAE: 4.2595\n","\tbatch: 200, loss: 44.6303, MAE: 5.1836\n","Training:\t loss: 57.7254, MAE: 4.3083\n","Evaluating:\t loss: 59.0045, MAE: 3.7393\n","train MSE: 57.7254, evaluate MSE: 59.0045\n","\n","train MAE: 4.3083, evaluate MAE: 3.7393\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 258\n","\tbatch: 100, loss: 46.9388, MAE: 4.7748\n","\tbatch: 200, loss: 38.5322, MAE: 4.0983\n","Training:\t loss: 52.9433, MAE: 4.0341\n","Evaluating:\t loss: 105.1076, MAE: 5.9483\n","train MSE: 52.9433, evaluate MSE: 105.1076\n","\n","train MAE: 4.0341, evaluate MAE: 5.9483\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 259\n","\tbatch: 100, loss: 41.7619, MAE: 3.3333\n","\tbatch: 200, loss: 37.3625, MAE: 3.4463\n","Training:\t loss: 58.9977, MAE: 4.3844\n","Evaluating:\t loss: 58.2712, MAE: 3.9816\n","train MSE: 58.9977, evaluate MSE: 58.2712\n","\n","train MAE: 4.3844, evaluate MAE: 3.9816\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 260\n","\tbatch: 100, loss: 66.2330, MAE: 6.2824\n","\tbatch: 200, loss: 43.8884, MAE: 4.5941\n","Training:\t loss: 58.6178, MAE: 4.5126\n","Evaluating:\t loss: 64.4723, MAE: 4.2090\n","train MSE: 58.6178, evaluate MSE: 64.4723\n","\n","train MAE: 4.5126, evaluate MAE: 4.2090\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 261\n","\tbatch: 100, loss: 35.5860, MAE: 4.3568\n","\tbatch: 200, loss: 52.3109, MAE: 4.9377\n","Training:\t loss: 58.6463, MAE: 4.3415\n","Evaluating:\t loss: 64.9210, MAE: 3.9555\n","train MSE: 58.6463, evaluate MSE: 64.9210\n","\n","train MAE: 4.3415, evaluate MAE: 3.9555\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 262\n","\tbatch: 100, loss: 50.4996, MAE: 4.6600\n","\tbatch: 200, loss: 35.2962, MAE: 3.8882\n","Training:\t loss: 50.5926, MAE: 3.9896\n","Evaluating:\t loss: 56.5488, MAE: 4.4148\n","train MSE: 50.5926, evaluate MSE: 56.5488\n","\n","train MAE: 3.9896, evaluate MAE: 4.4148\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 263\n","\tbatch: 100, loss: 31.9046, MAE: 3.7703\n","\tbatch: 200, loss: 31.1745, MAE: 4.2470\n","Training:\t loss: 52.0521, MAE: 4.1817\n","Evaluating:\t loss: 51.7127, MAE: 3.7199\n","train MSE: 52.0521, evaluate MSE: 51.7127\n","\n","train MAE: 4.1817, evaluate MAE: 3.7199\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 264\n","\tbatch: 100, loss: 28.5484, MAE: 3.3662\n","\tbatch: 200, loss: 15.8158, MAE: 2.6326\n","Training:\t loss: 45.6191, MAE: 3.8473\n","Evaluating:\t loss: 64.3024, MAE: 4.6529\n","train MSE: 45.6191, evaluate MSE: 64.3024\n","\n","train MAE: 3.8473, evaluate MAE: 4.6529\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 265\n","\tbatch: 100, loss: 19.8569, MAE: 3.0819\n","\tbatch: 200, loss: 67.0719, MAE: 4.7794\n","Training:\t loss: 55.4582, MAE: 4.2028\n","Evaluating:\t loss: 97.7337, MAE: 6.4351\n","train MSE: 55.4582, evaluate MSE: 97.7337\n","\n","train MAE: 4.2028, evaluate MAE: 6.4351\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 266\n","\tbatch: 100, loss: 45.0482, MAE: 3.5575\n","\tbatch: 200, loss: 34.3936, MAE: 4.1201\n","Training:\t loss: 60.3347, MAE: 4.4310\n","Evaluating:\t loss: 60.8113, MAE: 4.6885\n","train MSE: 60.3347, evaluate MSE: 60.8113\n","\n","train MAE: 4.4310, evaluate MAE: 4.6885\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 267\n","\tbatch: 100, loss: 112.2630, MAE: 4.5788\n","\tbatch: 200, loss: 1989.4811, MAE: 34.1159\n","Training:\t loss: 4417.7099, MAE: 26.7286\n","Evaluating:\t loss: 752.8324, MAE: 18.5176\n","train MSE: 4417.7099, evaluate MSE: 752.8324\n","\n","train MAE: 26.7286, evaluate MAE: 18.5176\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 268\n","\tbatch: 100, loss: 286.2565, MAE: 12.1627\n","\tbatch: 200, loss: 257.6424, MAE: 10.8451\n","Training:\t loss: 409.6331, MAE: 12.6424\n","Evaluating:\t loss: 319.8287, MAE: 10.3779\n","train MSE: 409.6331, evaluate MSE: 319.8287\n","\n","train MAE: 12.6424, evaluate MAE: 10.3779\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 269\n","\tbatch: 100, loss: 166.4819, MAE: 9.1057\n","\tbatch: 200, loss: 190.7180, MAE: 8.9112\n","Training:\t loss: 240.0921, MAE: 9.3531\n","Evaluating:\t loss: 239.4456, MAE: 9.6325\n","train MSE: 240.0921, evaluate MSE: 239.4456\n","\n","train MAE: 9.3531, evaluate MAE: 9.6325\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 270\n","\tbatch: 100, loss: 334.3629, MAE: 8.5222\n","\tbatch: 200, loss: 96.9143, MAE: 7.1013\n","Training:\t loss: 189.0683, MAE: 8.2794\n","Evaluating:\t loss: 228.9548, MAE: 9.1279\n","train MSE: 189.0683, evaluate MSE: 228.9548\n","\n","train MAE: 8.2794, evaluate MAE: 9.1279\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 271\n","\tbatch: 100, loss: 156.3736, MAE: 7.6687\n","\tbatch: 200, loss: 86.8779, MAE: 6.6471\n","Training:\t loss: 157.9712, MAE: 7.5711\n","Evaluating:\t loss: 151.1638, MAE: 7.1218\n","train MSE: 157.9712, evaluate MSE: 151.1638\n","\n","train MAE: 7.5711, evaluate MAE: 7.1218\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 272\n","\tbatch: 100, loss: 105.6236, MAE: 7.4648\n","\tbatch: 200, loss: 107.0735, MAE: 7.0134\n","Training:\t loss: 137.5099, MAE: 7.0760\n","Evaluating:\t loss: 157.8816, MAE: 7.5070\n","train MSE: 137.5099, evaluate MSE: 157.8816\n","\n","train MAE: 7.0760, evaluate MAE: 7.5070\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 273\n","\tbatch: 100, loss: 209.7419, MAE: 8.1589\n","\tbatch: 200, loss: 116.2573, MAE: 6.7296\n","Training:\t loss: 125.3993, MAE: 6.7386\n","Evaluating:\t loss: 130.2028, MAE: 6.4860\n","train MSE: 125.3993, evaluate MSE: 130.2028\n","\n","train MAE: 6.7386, evaluate MAE: 6.4860\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 274\n","\tbatch: 100, loss: 104.3274, MAE: 7.0207\n","\tbatch: 200, loss: 120.0904, MAE: 6.6805\n","Training:\t loss: 115.1247, MAE: 6.5214\n","Evaluating:\t loss: 150.8293, MAE: 7.4953\n","train MSE: 115.1247, evaluate MSE: 150.8293\n","\n","train MAE: 6.5214, evaluate MAE: 7.4953\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 275\n","\tbatch: 100, loss: 194.9830, MAE: 6.5865\n","\tbatch: 200, loss: 55.7409, MAE: 5.6316\n","Training:\t loss: 106.9422, MAE: 6.2968\n","Evaluating:\t loss: 128.6805, MAE: 6.4680\n","train MSE: 106.9422, evaluate MSE: 128.6805\n","\n","train MAE: 6.2968, evaluate MAE: 6.4680\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 276\n","\tbatch: 100, loss: 93.0407, MAE: 6.7844\n","\tbatch: 200, loss: 77.0265, MAE: 5.7548\n","Training:\t loss: 106.0057, MAE: 6.3736\n","Evaluating:\t loss: 127.0408, MAE: 6.3173\n","train MSE: 106.0057, evaluate MSE: 127.0408\n","\n","train MAE: 6.3736, evaluate MAE: 6.3173\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 277\n","\tbatch: 100, loss: 66.0381, MAE: 5.9003\n","\tbatch: 200, loss: 75.1915, MAE: 5.8011\n","Training:\t loss: 95.1005, MAE: 5.9485\n","Evaluating:\t loss: 110.6952, MAE: 5.8446\n","train MSE: 95.1005, evaluate MSE: 110.6952\n","\n","train MAE: 5.9485, evaluate MAE: 5.8446\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 278\n","\tbatch: 100, loss: 75.7187, MAE: 5.5446\n","\tbatch: 200, loss: 87.9445, MAE: 6.9967\n","Training:\t loss: 89.4699, MAE: 5.8153\n","Evaluating:\t loss: 124.6978, MAE: 6.8047\n","train MSE: 89.4699, evaluate MSE: 124.6978\n","\n","train MAE: 5.8153, evaluate MAE: 6.8047\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 279\n","\tbatch: 100, loss: 93.3215, MAE: 6.1075\n","\tbatch: 200, loss: 75.9152, MAE: 5.3562\n","Training:\t loss: 85.6470, MAE: 5.7505\n","Evaluating:\t loss: 104.7695, MAE: 5.4779\n","train MSE: 85.6470, evaluate MSE: 104.7695\n","\n","train MAE: 5.7505, evaluate MAE: 5.4779\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 280\n","\tbatch: 100, loss: 41.8248, MAE: 4.3770\n","\tbatch: 200, loss: 136.7963, MAE: 7.1780\n","Training:\t loss: 81.8696, MAE: 5.5963\n","Evaluating:\t loss: 152.5709, MAE: 7.7863\n","train MSE: 81.8696, evaluate MSE: 152.5709\n","\n","train MAE: 5.5963, evaluate MAE: 7.7863\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 281\n","\tbatch: 100, loss: 94.6598, MAE: 5.8926\n","\tbatch: 200, loss: 119.2561, MAE: 8.1960\n","Training:\t loss: 79.3724, MAE: 5.4925\n","Evaluating:\t loss: 93.7719, MAE: 5.3055\n","train MSE: 79.3724, evaluate MSE: 93.7719\n","\n","train MAE: 5.4925, evaluate MAE: 5.3055\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 282\n","\tbatch: 100, loss: 195.2273, MAE: 5.2577\n","\tbatch: 200, loss: 80.0601, MAE: 5.0592\n","Training:\t loss: 70.8882, MAE: 5.0032\n","Evaluating:\t loss: 114.6382, MAE: 6.6630\n","train MSE: 70.8882, evaluate MSE: 114.6382\n","\n","train MAE: 5.0032, evaluate MAE: 6.6630\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 283\n","\tbatch: 100, loss: 71.5195, MAE: 5.5347\n","\tbatch: 200, loss: 157.1943, MAE: 7.0345\n","Training:\t loss: 75.2992, MAE: 5.3400\n","Evaluating:\t loss: 98.7468, MAE: 5.3379\n","train MSE: 75.2992, evaluate MSE: 98.7468\n","\n","train MAE: 5.3400, evaluate MAE: 5.3379\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 284\n","\tbatch: 100, loss: 51.3094, MAE: 4.9179\n","\tbatch: 200, loss: 49.9479, MAE: 4.9511\n","Training:\t loss: 72.2720, MAE: 5.1967\n","Evaluating:\t loss: 93.6628, MAE: 4.9084\n","train MSE: 72.2720, evaluate MSE: 93.6628\n","\n","train MAE: 5.1967, evaluate MAE: 4.9084\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 285\n","\tbatch: 100, loss: 48.5007, MAE: 4.5482\n","\tbatch: 200, loss: 53.7568, MAE: 4.9189\n","Training:\t loss: 70.6157, MAE: 5.0832\n","Evaluating:\t loss: 85.0417, MAE: 5.2721\n","train MSE: 70.6157, evaluate MSE: 85.0417\n","\n","train MAE: 5.0832, evaluate MAE: 5.2721\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 286\n","\tbatch: 100, loss: 43.0277, MAE: 4.1119\n","\tbatch: 200, loss: 97.4557, MAE: 7.9937\n","Training:\t loss: 73.3199, MAE: 5.3974\n","Evaluating:\t loss: 95.4914, MAE: 5.7153\n","train MSE: 73.3199, evaluate MSE: 95.4914\n","\n","train MAE: 5.3974, evaluate MAE: 5.7153\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 287\n","\tbatch: 100, loss: 83.1057, MAE: 5.4011\n","\tbatch: 200, loss: 73.9674, MAE: 4.9096\n","Training:\t loss: 64.1944, MAE: 4.9571\n","Evaluating:\t loss: 95.5039, MAE: 5.5296\n","train MSE: 64.1944, evaluate MSE: 95.5039\n","\n","train MAE: 4.9571, evaluate MAE: 5.5296\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 288\n","\tbatch: 100, loss: 51.7358, MAE: 4.8675\n","\tbatch: 200, loss: 53.8589, MAE: 5.2162\n","Training:\t loss: 68.3807, MAE: 5.2384\n","Evaluating:\t loss: 94.1192, MAE: 6.1917\n","train MSE: 68.3807, evaluate MSE: 94.1192\n","\n","train MAE: 5.2384, evaluate MAE: 6.1917\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 289\n","\tbatch: 100, loss: 47.9165, MAE: 4.6623\n","\tbatch: 200, loss: 71.5699, MAE: 6.2202\n","Training:\t loss: 61.6158, MAE: 4.8330\n","Evaluating:\t loss: 175.1889, MAE: 9.6471\n","train MSE: 61.6158, evaluate MSE: 175.1889\n","\n","train MAE: 4.8330, evaluate MAE: 9.6471\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 290\n","\tbatch: 100, loss: 75.5684, MAE: 5.7015\n","\tbatch: 200, loss: 94.3298, MAE: 4.9290\n","Training:\t loss: 85.1066, MAE: 5.8086\n","Evaluating:\t loss: 98.6014, MAE: 5.6676\n","train MSE: 85.1066, evaluate MSE: 98.6014\n","\n","train MAE: 5.8086, evaluate MAE: 5.6676\n","\n","--- time consumption (s): 19\n","\n","------------------------------\n","Epoch 291\n","\tbatch: 100, loss: 34.8942, MAE: 4.2130\n","\tbatch: 200, loss: 74.3557, MAE: 5.5832\n","Training:\t loss: 71.5197, MAE: 5.3668\n","Evaluating:\t loss: 122.1223, MAE: 6.3316\n","train MSE: 71.5197, evaluate MSE: 122.1223\n","\n","train MAE: 5.3668, evaluate MAE: 6.3316\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 292\n","\tbatch: 100, loss: 52.7967, MAE: 5.5049\n","\tbatch: 200, loss: 54.8051, MAE: 4.9406\n","Training:\t loss: 72.9722, MAE: 5.3768\n","Evaluating:\t loss: 68.0494, MAE: 4.8206\n","train MSE: 72.9722, evaluate MSE: 68.0494\n","\n","train MAE: 5.3768, evaluate MAE: 4.8206\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 293\n","\tbatch: 100, loss: 32.8716, MAE: 4.1439\n","\tbatch: 200, loss: 86.5103, MAE: 6.9530\n","Training:\t loss: 78.5553, MAE: 5.5663\n","Evaluating:\t loss: 103.3207, MAE: 6.0679\n","train MSE: 78.5553, evaluate MSE: 103.3207\n","\n","train MAE: 5.5663, evaluate MAE: 6.0679\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 294\n","\tbatch: 100, loss: 160.1448, MAE: 8.3294\n","\tbatch: 200, loss: 235.9277, MAE: 12.7514\n","Training:\t loss: 113.9291, MAE: 6.7006\n","Evaluating:\t loss: 207.2058, MAE: 10.0595\n","train MSE: 113.9291, evaluate MSE: 207.2058\n","\n","train MAE: 6.7006, evaluate MAE: 10.0595\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 295\n","\tbatch: 100, loss: 74.1650, MAE: 5.9584\n","\tbatch: 200, loss: 86.5190, MAE: 5.1795\n","Training:\t loss: 83.9226, MAE: 5.5888\n","Evaluating:\t loss: 109.7799, MAE: 5.4690\n","train MSE: 83.9226, evaluate MSE: 109.7799\n","\n","train MAE: 5.5888, evaluate MAE: 5.4690\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 296\n","\tbatch: 100, loss: 104.5474, MAE: 5.5132\n","\tbatch: 200, loss: 129.6044, MAE: 8.8633\n","Training:\t loss: 77.3213, MAE: 5.4696\n","Evaluating:\t loss: 75.6515, MAE: 4.6979\n","train MSE: 77.3213, evaluate MSE: 75.6515\n","\n","train MAE: 5.4696, evaluate MAE: 4.6979\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 297\n","\tbatch: 100, loss: 73.3741, MAE: 5.6331\n","\tbatch: 200, loss: 81.0599, MAE: 5.1143\n","Training:\t loss: 70.3583, MAE: 5.2637\n","Evaluating:\t loss: 88.4528, MAE: 5.1776\n","train MSE: 70.3583, evaluate MSE: 88.4528\n","\n","train MAE: 5.2637, evaluate MAE: 5.1776\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 298\n","\tbatch: 100, loss: 73.2578, MAE: 5.0918\n","\tbatch: 200, loss: 49.8367, MAE: 4.8909\n","Training:\t loss: 62.5852, MAE: 4.9450\n","Evaluating:\t loss: 101.0641, MAE: 6.0906\n","train MSE: 62.5852, evaluate MSE: 101.0641\n","\n","train MAE: 4.9450, evaluate MAE: 6.0906\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 299\n","\tbatch: 100, loss: 76.9800, MAE: 6.0083\n","\tbatch: 200, loss: 68.9515, MAE: 6.1388\n","Training:\t loss: 81.8765, MAE: 5.7133\n","Evaluating:\t loss: 136.7260, MAE: 6.4572\n","train MSE: 81.8765, evaluate MSE: 136.7260\n","\n","train MAE: 5.7133, evaluate MAE: 6.4572\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 300\n","\tbatch: 100, loss: 60.5371, MAE: 4.8359\n","\tbatch: 200, loss: 68.7121, MAE: 4.5972\n","Training:\t loss: 69.2533, MAE: 5.0651\n","Evaluating:\t loss: 124.0684, MAE: 6.4679\n","train MSE: 69.2533, evaluate MSE: 124.0684\n","\n","train MAE: 5.0651, evaluate MAE: 6.4679\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 301\n","\tbatch: 100, loss: 39.7406, MAE: 4.0836\n","\tbatch: 200, loss: 64.9491, MAE: 5.7276\n","Training:\t loss: 76.7274, MAE: 5.5183\n","Evaluating:\t loss: 280.3160, MAE: 12.5218\n","train MSE: 76.7274, evaluate MSE: 280.3160\n","\n","train MAE: 5.5183, evaluate MAE: 12.5218\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 302\n","\tbatch: 100, loss: 430.7970, MAE: 15.5241\n","\tbatch: 200, loss: 192.5979, MAE: 9.1734\n","Training:\t loss: 2153.0940, MAE: 23.1413\n","Evaluating:\t loss: 240.9793, MAE: 9.5838\n","train MSE: 2153.0940, evaluate MSE: 240.9793\n","\n","train MAE: 23.1413, evaluate MAE: 9.5838\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 303\n","\tbatch: 100, loss: 195.0889, MAE: 7.9990\n","\tbatch: 200, loss: 87.7607, MAE: 6.7233\n","Training:\t loss: 170.6689, MAE: 7.9936\n","Evaluating:\t loss: 145.9882, MAE: 7.0344\n","train MSE: 170.6689, evaluate MSE: 145.9882\n","\n","train MAE: 7.9936, evaluate MAE: 7.0344\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 304\n","\tbatch: 100, loss: 142.5082, MAE: 7.2770\n","\tbatch: 200, loss: 103.8063, MAE: 6.2312\n","Training:\t loss: 121.9188, MAE: 6.7052\n","Evaluating:\t loss: 172.8446, MAE: 7.6353\n","train MSE: 121.9188, evaluate MSE: 172.8446\n","\n","train MAE: 6.7052, evaluate MAE: 7.6353\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 305\n","\tbatch: 100, loss: 95.4072, MAE: 6.0560\n","\tbatch: 200, loss: 101.0619, MAE: 6.1754\n","Training:\t loss: 101.6207, MAE: 6.2608\n","Evaluating:\t loss: 101.2388, MAE: 5.9526\n","train MSE: 101.6207, evaluate MSE: 101.2388\n","\n","train MAE: 6.2608, evaluate MAE: 5.9526\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 306\n","\tbatch: 100, loss: 101.0882, MAE: 6.3561\n","\tbatch: 200, loss: 43.1442, MAE: 4.7881\n","Training:\t loss: 89.0412, MAE: 5.8234\n","Evaluating:\t loss: 92.4968, MAE: 5.6045\n","train MSE: 89.0412, evaluate MSE: 92.4968\n","\n","train MAE: 5.8234, evaluate MAE: 5.6045\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 307\n","\tbatch: 100, loss: 61.1555, MAE: 5.5169\n","\tbatch: 200, loss: 101.5496, MAE: 6.5559\n","Training:\t loss: 79.7680, MAE: 5.5714\n","Evaluating:\t loss: 108.1934, MAE: 5.7250\n","train MSE: 79.7680, evaluate MSE: 108.1934\n","\n","train MAE: 5.5714, evaluate MAE: 5.7250\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 308\n","\tbatch: 100, loss: 101.4005, MAE: 5.3929\n","\tbatch: 200, loss: 79.1750, MAE: 5.7617\n","Training:\t loss: 73.8034, MAE: 5.3214\n","Evaluating:\t loss: 108.2366, MAE: 6.4687\n","train MSE: 73.8034, evaluate MSE: 108.2366\n","\n","train MAE: 5.3214, evaluate MAE: 6.4687\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 309\n","\tbatch: 100, loss: 46.8207, MAE: 4.6688\n","\tbatch: 200, loss: 82.8560, MAE: 5.8776\n","Training:\t loss: 66.6706, MAE: 5.0944\n","Evaluating:\t loss: 85.6382, MAE: 5.0660\n","train MSE: 66.6706, evaluate MSE: 85.6382\n","\n","train MAE: 5.0944, evaluate MAE: 5.0660\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 310\n","\tbatch: 100, loss: 68.3506, MAE: 5.7469\n","\tbatch: 200, loss: 36.6226, MAE: 4.4313\n","Training:\t loss: 64.1013, MAE: 4.9587\n","Evaluating:\t loss: 83.6202, MAE: 5.5511\n","train MSE: 64.1013, evaluate MSE: 83.6202\n","\n","train MAE: 4.9587, evaluate MAE: 5.5511\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 311\n","\tbatch: 100, loss: 51.0183, MAE: 4.2937\n","\tbatch: 200, loss: 111.5202, MAE: 5.6660\n","Training:\t loss: 60.9039, MAE: 4.8776\n","Evaluating:\t loss: 84.4721, MAE: 5.8607\n","train MSE: 60.9039, evaluate MSE: 84.4721\n","\n","train MAE: 4.8776, evaluate MAE: 5.8607\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 312\n","\tbatch: 100, loss: 82.1858, MAE: 5.3074\n","\tbatch: 200, loss: 85.1176, MAE: 4.8099\n","Training:\t loss: 61.3558, MAE: 4.9194\n","Evaluating:\t loss: 70.8224, MAE: 4.6300\n","train MSE: 61.3558, evaluate MSE: 70.8224\n","\n","train MAE: 4.9194, evaluate MAE: 4.6300\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 313\n","\tbatch: 100, loss: 30.6310, MAE: 3.9700\n","\tbatch: 200, loss: 45.6668, MAE: 5.1099\n","Training:\t loss: 56.9377, MAE: 4.7110\n","Evaluating:\t loss: 69.2256, MAE: 4.9258\n","train MSE: 56.9377, evaluate MSE: 69.2256\n","\n","train MAE: 4.7110, evaluate MAE: 4.9258\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 314\n","\tbatch: 100, loss: 36.8579, MAE: 4.1368\n","\tbatch: 200, loss: 47.5422, MAE: 4.5149\n","Training:\t loss: 58.8295, MAE: 4.8843\n","Evaluating:\t loss: 70.4402, MAE: 5.0823\n","train MSE: 58.8295, evaluate MSE: 70.4402\n","\n","train MAE: 4.8843, evaluate MAE: 5.0823\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 315\n","\tbatch: 100, loss: 60.4964, MAE: 5.5523\n","\tbatch: 200, loss: 49.4116, MAE: 4.3498\n","Training:\t loss: 53.7860, MAE: 4.6818\n","Evaluating:\t loss: 62.4274, MAE: 4.8919\n","train MSE: 53.7860, evaluate MSE: 62.4274\n","\n","train MAE: 4.6818, evaluate MAE: 4.8919\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 316\n","\tbatch: 100, loss: 91.5376, MAE: 6.9341\n","\tbatch: 200, loss: 48.8527, MAE: 4.9723\n","Training:\t loss: 65.7077, MAE: 5.3346\n","Evaluating:\t loss: 70.9183, MAE: 5.2108\n","train MSE: 65.7077, evaluate MSE: 70.9183\n","\n","train MAE: 5.3346, evaluate MAE: 5.2108\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 317\n","\tbatch: 100, loss: 39.6099, MAE: 4.1488\n","\tbatch: 200, loss: 48.5996, MAE: 5.1517\n","Training:\t loss: 54.2283, MAE: 4.7345\n","Evaluating:\t loss: 58.4269, MAE: 4.6627\n","train MSE: 54.2283, evaluate MSE: 58.4269\n","\n","train MAE: 4.7345, evaluate MAE: 4.6627\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 318\n","\tbatch: 100, loss: 68.0327, MAE: 6.2372\n","\tbatch: 200, loss: 45.1294, MAE: 4.0898\n","Training:\t loss: 61.6664, MAE: 5.1635\n","Evaluating:\t loss: 64.3852, MAE: 4.6727\n","train MSE: 61.6664, evaluate MSE: 64.3852\n","\n","train MAE: 5.1635, evaluate MAE: 4.6727\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 319\n","\tbatch: 100, loss: 49.0664, MAE: 4.6239\n","\tbatch: 200, loss: 63.0909, MAE: 5.5425\n","Training:\t loss: 58.5811, MAE: 4.6850\n","Evaluating:\t loss: 71.4095, MAE: 5.0270\n","train MSE: 58.5811, evaluate MSE: 71.4095\n","\n","train MAE: 4.6850, evaluate MAE: 5.0270\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 320\n","\tbatch: 100, loss: 61.3449, MAE: 5.0170\n","\tbatch: 200, loss: 40.9334, MAE: 4.4013\n","Training:\t loss: 54.8313, MAE: 4.5234\n","Evaluating:\t loss: 82.8672, MAE: 5.9106\n","train MSE: 54.8313, evaluate MSE: 82.8672\n","\n","train MAE: 4.5234, evaluate MAE: 5.9106\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 321\n","\tbatch: 100, loss: 59.9055, MAE: 4.7625\n","\tbatch: 200, loss: 393.3327, MAE: 14.9243\n","Training:\t loss: 521.7721, MAE: 10.8694\n","Evaluating:\t loss: 240.5646, MAE: 10.2757\n","train MSE: 521.7721, evaluate MSE: 240.5646\n","\n","train MAE: 10.8694, evaluate MAE: 10.2757\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 322\n","\tbatch: 100, loss: 104.8945, MAE: 7.2893\n","\tbatch: 200, loss: 93.5119, MAE: 6.3755\n","Training:\t loss: 136.0289, MAE: 7.4762\n","Evaluating:\t loss: 117.4681, MAE: 6.3299\n","train MSE: 136.0289, evaluate MSE: 117.4681\n","\n","train MAE: 7.4762, evaluate MAE: 6.3299\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 323\n","\tbatch: 100, loss: 102.9789, MAE: 5.7881\n","\tbatch: 200, loss: 142.8004, MAE: 5.9244\n","Training:\t loss: 83.8182, MAE: 5.7796\n","Evaluating:\t loss: 100.3497, MAE: 6.0623\n","train MSE: 83.8182, evaluate MSE: 100.3497\n","\n","train MAE: 5.7796, evaluate MAE: 6.0623\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 324\n","\tbatch: 100, loss: 48.3823, MAE: 5.1348\n","\tbatch: 200, loss: 98.3335, MAE: 5.2497\n","Training:\t loss: 70.5599, MAE: 5.3622\n","Evaluating:\t loss: 84.2940, MAE: 5.5188\n","train MSE: 70.5599, evaluate MSE: 84.2940\n","\n","train MAE: 5.3622, evaluate MAE: 5.5188\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 325\n","\tbatch: 100, loss: 50.0903, MAE: 4.9423\n","\tbatch: 200, loss: 38.0364, MAE: 4.5033\n","Training:\t loss: 59.8239, MAE: 4.9462\n","Evaluating:\t loss: 79.0791, MAE: 5.7562\n","train MSE: 59.8239, evaluate MSE: 79.0791\n","\n","train MAE: 4.9462, evaluate MAE: 5.7562\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 326\n","\tbatch: 100, loss: 35.4175, MAE: 4.0752\n","\tbatch: 200, loss: 45.7916, MAE: 4.6627\n","Training:\t loss: 56.1146, MAE: 4.7250\n","Evaluating:\t loss: 93.4298, MAE: 5.0522\n","train MSE: 56.1146, evaluate MSE: 93.4298\n","\n","train MAE: 4.7250, evaluate MAE: 5.0522\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 327\n","\tbatch: 100, loss: 50.7928, MAE: 4.7165\n","\tbatch: 200, loss: 29.1996, MAE: 3.9013\n","Training:\t loss: 52.6117, MAE: 4.5635\n","Evaluating:\t loss: 65.7877, MAE: 4.4837\n","train MSE: 52.6117, evaluate MSE: 65.7877\n","\n","train MAE: 4.5635, evaluate MAE: 4.4837\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 328\n","\tbatch: 100, loss: 58.5186, MAE: 5.0522\n","\tbatch: 200, loss: 45.1333, MAE: 4.5701\n","Training:\t loss: 46.6494, MAE: 4.2939\n","Evaluating:\t loss: 64.0960, MAE: 4.7002\n","train MSE: 46.6494, evaluate MSE: 64.0960\n","\n","train MAE: 4.2939, evaluate MAE: 4.7002\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 329\n","\tbatch: 100, loss: 68.1615, MAE: 4.5261\n","\tbatch: 200, loss: 43.3697, MAE: 4.5108\n","Training:\t loss: 46.5980, MAE: 4.3385\n","Evaluating:\t loss: 83.5049, MAE: 6.1419\n","train MSE: 46.5980, evaluate MSE: 83.5049\n","\n","train MAE: 4.3385, evaluate MAE: 6.1419\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 330\n","\tbatch: 100, loss: 56.2550, MAE: 4.5365\n","\tbatch: 200, loss: 40.0399, MAE: 4.5866\n","Training:\t loss: 46.5107, MAE: 4.3906\n","Evaluating:\t loss: 55.3132, MAE: 4.1725\n","train MSE: 46.5107, evaluate MSE: 55.3132\n","\n","train MAE: 4.3906, evaluate MAE: 4.1725\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 331\n","\tbatch: 100, loss: 39.8565, MAE: 4.4031\n","\tbatch: 200, loss: 44.2891, MAE: 4.2679\n","Training:\t loss: 44.7257, MAE: 4.2962\n","Evaluating:\t loss: 65.9217, MAE: 5.0785\n","train MSE: 44.7257, evaluate MSE: 65.9217\n","\n","train MAE: 4.2962, evaluate MAE: 5.0785\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 332\n","\tbatch: 100, loss: 29.5253, MAE: 3.8711\n","\tbatch: 200, loss: 69.7517, MAE: 5.4782\n","Training:\t loss: 49.6716, MAE: 4.6307\n","Evaluating:\t loss: 58.9331, MAE: 4.6451\n","train MSE: 49.6716, evaluate MSE: 58.9331\n","\n","train MAE: 4.6307, evaluate MAE: 4.6451\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 333\n","\tbatch: 100, loss: 56.0566, MAE: 5.5249\n","\tbatch: 200, loss: 49.2724, MAE: 4.7689\n","Training:\t loss: 48.4216, MAE: 4.5300\n","Evaluating:\t loss: 67.2993, MAE: 4.9191\n","train MSE: 48.4216, evaluate MSE: 67.2993\n","\n","train MAE: 4.5300, evaluate MAE: 4.9191\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 334\n","\tbatch: 100, loss: 26.0319, MAE: 3.5730\n","\tbatch: 200, loss: 47.0348, MAE: 4.1557\n","Training:\t loss: 53.5700, MAE: 4.6638\n","Evaluating:\t loss: 89.8151, MAE: 6.0611\n","train MSE: 53.5700, evaluate MSE: 89.8151\n","\n","train MAE: 4.6638, evaluate MAE: 6.0611\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 335\n","\tbatch: 100, loss: 68.6362, MAE: 5.7518\n","\tbatch: 200, loss: 192.2343, MAE: 10.4275\n","Training:\t loss: 762.4113, MAE: 13.2284\n","Evaluating:\t loss: 193.4960, MAE: 8.7845\n","train MSE: 762.4113, evaluate MSE: 193.4960\n","\n","train MAE: 13.2284, evaluate MAE: 8.7845\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 336\n","\tbatch: 100, loss: 94.3748, MAE: 6.4937\n","\tbatch: 200, loss: 188.6992, MAE: 7.1790\n","Training:\t loss: 135.6654, MAE: 7.1351\n","Evaluating:\t loss: 165.1677, MAE: 7.0039\n","train MSE: 135.6654, evaluate MSE: 165.1677\n","\n","train MAE: 7.1351, evaluate MAE: 7.0039\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 337\n","\tbatch: 100, loss: 69.2198, MAE: 5.8420\n","\tbatch: 200, loss: 66.9501, MAE: 4.8556\n","Training:\t loss: 83.5015, MAE: 5.5868\n","Evaluating:\t loss: 109.5634, MAE: 5.6059\n","train MSE: 83.5015, evaluate MSE: 109.5634\n","\n","train MAE: 5.5868, evaluate MAE: 5.6059\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 338\n","\tbatch: 100, loss: 97.6244, MAE: 5.6028\n","\tbatch: 200, loss: 81.5951, MAE: 5.4353\n","Training:\t loss: 69.0986, MAE: 5.1085\n","Evaluating:\t loss: 101.3595, MAE: 6.0300\n","train MSE: 69.0986, evaluate MSE: 101.3595\n","\n","train MAE: 5.1085, evaluate MAE: 6.0300\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 339\n","\tbatch: 100, loss: 54.3873, MAE: 4.4045\n","\tbatch: 200, loss: 88.8760, MAE: 5.4683\n","Training:\t loss: 61.7965, MAE: 4.8570\n","Evaluating:\t loss: 75.7555, MAE: 4.8373\n","train MSE: 61.7965, evaluate MSE: 75.7555\n","\n","train MAE: 4.8570, evaluate MAE: 4.8373\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 340\n","\tbatch: 100, loss: 44.5858, MAE: 4.3765\n","\tbatch: 200, loss: 42.1934, MAE: 4.5085\n","Training:\t loss: 54.2476, MAE: 4.5862\n","Evaluating:\t loss: 82.3897, MAE: 5.7594\n","train MSE: 54.2476, evaluate MSE: 82.3897\n","\n","train MAE: 4.5862, evaluate MAE: 5.7594\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 341\n","\tbatch: 100, loss: 43.4441, MAE: 4.4103\n","\tbatch: 200, loss: 60.2355, MAE: 4.7358\n","Training:\t loss: 52.3682, MAE: 4.4576\n","Evaluating:\t loss: 68.8791, MAE: 5.0480\n","train MSE: 52.3682, evaluate MSE: 68.8791\n","\n","train MAE: 4.4576, evaluate MAE: 5.0480\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 342\n","\tbatch: 100, loss: 52.4504, MAE: 4.3900\n","\tbatch: 200, loss: 32.8004, MAE: 3.7849\n","Training:\t loss: 46.5635, MAE: 4.2133\n","Evaluating:\t loss: 52.8996, MAE: 4.1054\n","train MSE: 46.5635, evaluate MSE: 52.8996\n","\n","train MAE: 4.2133, evaluate MAE: 4.1054\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 343\n","\tbatch: 100, loss: 46.1583, MAE: 4.8003\n","\tbatch: 200, loss: 37.1892, MAE: 4.6096\n","Training:\t loss: 47.8649, MAE: 4.4113\n","Evaluating:\t loss: 61.8041, MAE: 4.2983\n","train MSE: 47.8649, evaluate MSE: 61.8041\n","\n","train MAE: 4.4113, evaluate MAE: 4.2983\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 344\n","\tbatch: 100, loss: 39.4390, MAE: 4.0902\n","\tbatch: 200, loss: 39.1877, MAE: 4.2616\n","Training:\t loss: 52.4239, MAE: 4.4099\n","Evaluating:\t loss: 58.8283, MAE: 4.3137\n","train MSE: 52.4239, evaluate MSE: 58.8283\n","\n","train MAE: 4.4099, evaluate MAE: 4.3137\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 345\n","\tbatch: 100, loss: 35.4857, MAE: 4.2155\n","\tbatch: 200, loss: 51.2318, MAE: 3.9293\n","Training:\t loss: 44.6955, MAE: 4.1197\n","Evaluating:\t loss: 59.7194, MAE: 4.5866\n","train MSE: 44.6955, evaluate MSE: 59.7194\n","\n","train MAE: 4.1197, evaluate MAE: 4.5866\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 346\n","\tbatch: 100, loss: 50.3557, MAE: 3.4658\n","\tbatch: 200, loss: 33.8666, MAE: 3.6750\n","Training:\t loss: 46.2973, MAE: 4.2604\n","Evaluating:\t loss: 51.7754, MAE: 4.2399\n","train MSE: 46.2973, evaluate MSE: 51.7754\n","\n","train MAE: 4.2604, evaluate MAE: 4.2399\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 347\n","\tbatch: 100, loss: 48.5292, MAE: 3.9663\n","\tbatch: 200, loss: 42.9782, MAE: 3.7350\n","Training:\t loss: 43.0638, MAE: 4.0963\n","Evaluating:\t loss: 55.8486, MAE: 4.2636\n","train MSE: 43.0638, evaluate MSE: 55.8486\n","\n","train MAE: 4.0963, evaluate MAE: 4.2636\n","\n","--- time consumption (s): 19\n","\n","------------------------------\n","Epoch 348\n","\tbatch: 100, loss: 32.4908, MAE: 3.7010\n","\tbatch: 200, loss: 47.1350, MAE: 4.0921\n","Training:\t loss: 46.6743, MAE: 4.4197\n","Evaluating:\t loss: 61.7046, MAE: 4.8359\n","train MSE: 46.6743, evaluate MSE: 61.7046\n","\n","train MAE: 4.4197, evaluate MAE: 4.8359\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 349\n","\tbatch: 100, loss: 69.5392, MAE: 6.3169\n","\tbatch: 200, loss: 57.7123, MAE: 4.3076\n","Training:\t loss: 73.4033, MAE: 5.7118\n","Evaluating:\t loss: 52.2769, MAE: 4.1342\n","train MSE: 73.4033, evaluate MSE: 52.2769\n","\n","train MAE: 5.7118, evaluate MAE: 4.1342\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 350\n","\tbatch: 100, loss: 29.9610, MAE: 3.9897\n","\tbatch: 200, loss: 41.5818, MAE: 4.0378\n","Training:\t loss: 39.6321, MAE: 3.9359\n","Evaluating:\t loss: 46.2604, MAE: 3.6050\n","train MSE: 39.6321, evaluate MSE: 46.2604\n","\n","train MAE: 3.9359, evaluate MAE: 3.6050\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 351\n","\tbatch: 100, loss: 31.4258, MAE: 3.9126\n","\tbatch: 200, loss: 29.9079, MAE: 3.6606\n","Training:\t loss: 37.6906, MAE: 3.6768\n","Evaluating:\t loss: 54.3984, MAE: 4.6437\n","train MSE: 37.6906, evaluate MSE: 54.3984\n","\n","train MAE: 3.6768, evaluate MAE: 4.6437\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 352\n","\tbatch: 100, loss: 36.0596, MAE: 4.1111\n","\tbatch: 200, loss: 38.9384, MAE: 3.4068\n","Training:\t loss: 35.2593, MAE: 3.6701\n","Evaluating:\t loss: 54.3827, MAE: 4.0303\n","train MSE: 35.2593, evaluate MSE: 54.3827\n","\n","train MAE: 3.6701, evaluate MAE: 4.0303\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 353\n","\tbatch: 100, loss: 31.8606, MAE: 3.4521\n","\tbatch: 200, loss: 36.6243, MAE: 3.6244\n","Training:\t loss: 58.8048, MAE: 4.5508\n","Evaluating:\t loss: 8692.4141, MAE: 87.0593\n","train MSE: 58.8048, evaluate MSE: 8692.4141\n","\n","train MAE: 4.5508, evaluate MAE: 87.0593\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 354\n","\tbatch: 100, loss: 282.9961, MAE: 9.6465\n","\tbatch: 200, loss: 73.6764, MAE: 5.8105\n","Training:\t loss: 921.2337, MAE: 15.8692\n","Evaluating:\t loss: 128.1546, MAE: 6.9671\n","train MSE: 921.2337, evaluate MSE: 128.1546\n","\n","train MAE: 15.8692, evaluate MAE: 6.9671\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 355\n","\tbatch: 100, loss: 158.1594, MAE: 6.8480\n","\tbatch: 200, loss: 161.9216, MAE: 6.8766\n","Training:\t loss: 95.8200, MAE: 5.8533\n","Evaluating:\t loss: 80.1162, MAE: 5.3050\n","train MSE: 95.8200, evaluate MSE: 80.1162\n","\n","train MAE: 5.8533, evaluate MAE: 5.3050\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 356\n","\tbatch: 100, loss: 40.9112, MAE: 4.2965\n","\tbatch: 200, loss: 60.1590, MAE: 4.6829\n","Training:\t loss: 67.5776, MAE: 4.8433\n","Evaluating:\t loss: 71.7088, MAE: 4.6964\n","train MSE: 67.5776, evaluate MSE: 71.7088\n","\n","train MAE: 4.8433, evaluate MAE: 4.6964\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 357\n","\tbatch: 100, loss: 47.4322, MAE: 4.4465\n","\tbatch: 200, loss: 34.4287, MAE: 4.1144\n","Training:\t loss: 56.1220, MAE: 4.4670\n","Evaluating:\t loss: 64.8613, MAE: 4.5237\n","train MSE: 56.1220, evaluate MSE: 64.8613\n","\n","train MAE: 4.4670, evaluate MAE: 4.5237\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 358\n","\tbatch: 100, loss: 33.5159, MAE: 4.2639\n","\tbatch: 200, loss: 52.0582, MAE: 4.0254\n","Training:\t loss: 51.3822, MAE: 4.2335\n","Evaluating:\t loss: 63.0030, MAE: 4.3575\n","train MSE: 51.3822, evaluate MSE: 63.0030\n","\n","train MAE: 4.2335, evaluate MAE: 4.3575\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 359\n","\tbatch: 100, loss: 46.6037, MAE: 3.8754\n","\tbatch: 200, loss: 49.5477, MAE: 4.3423\n","Training:\t loss: 48.9194, MAE: 4.1863\n","Evaluating:\t loss: 61.9027, MAE: 4.1502\n","train MSE: 48.9194, evaluate MSE: 61.9027\n","\n","train MAE: 4.1863, evaluate MAE: 4.1502\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 360\n","\tbatch: 100, loss: 31.0241, MAE: 3.8504\n","\tbatch: 200, loss: 29.1063, MAE: 3.6451\n","Training:\t loss: 40.3572, MAE: 3.7854\n","Evaluating:\t loss: 55.1604, MAE: 3.9886\n","train MSE: 40.3572, evaluate MSE: 55.1604\n","\n","train MAE: 3.7854, evaluate MAE: 3.9886\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 361\n","\tbatch: 100, loss: 30.9643, MAE: 3.6467\n","\tbatch: 200, loss: 34.0331, MAE: 3.9341\n","Training:\t loss: 37.1490, MAE: 3.7508\n","Evaluating:\t loss: 45.4119, MAE: 3.8194\n","train MSE: 37.1490, evaluate MSE: 45.4119\n","\n","train MAE: 3.7508, evaluate MAE: 3.8194\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 362\n","\tbatch: 100, loss: 34.6185, MAE: 3.8288\n","\tbatch: 200, loss: 29.0133, MAE: 3.6566\n","Training:\t loss: 34.6629, MAE: 3.5994\n","Evaluating:\t loss: 64.2657, MAE: 5.1808\n","train MSE: 34.6629, evaluate MSE: 64.2657\n","\n","train MAE: 3.5994, evaluate MAE: 5.1808\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 363\n","\tbatch: 100, loss: 56.5337, MAE: 3.8297\n","\tbatch: 200, loss: 26.0352, MAE: 3.1315\n","Training:\t loss: 34.2295, MAE: 3.6173\n","Evaluating:\t loss: 48.6045, MAE: 3.9825\n","train MSE: 34.2295, evaluate MSE: 48.6045\n","\n","train MAE: 3.6173, evaluate MAE: 3.9825\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 364\n","\tbatch: 100, loss: 31.2470, MAE: 3.2697\n","\tbatch: 200, loss: 27.7149, MAE: 3.4258\n","Training:\t loss: 32.8603, MAE: 3.5280\n","Evaluating:\t loss: 53.8518, MAE: 3.9293\n","train MSE: 32.8603, evaluate MSE: 53.8518\n","\n","train MAE: 3.5280, evaluate MAE: 3.9293\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 365\n","\tbatch: 100, loss: 21.0549, MAE: 3.2710\n","\tbatch: 200, loss: 31.0651, MAE: 3.7328\n","Training:\t loss: 35.4667, MAE: 3.6538\n","Evaluating:\t loss: 52.9514, MAE: 4.5211\n","train MSE: 35.4667, evaluate MSE: 52.9514\n","\n","train MAE: 3.6538, evaluate MAE: 4.5211\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 366\n","\tbatch: 100, loss: 34.1453, MAE: 3.8166\n","\tbatch: 200, loss: 33.3349, MAE: 3.5254\n","Training:\t loss: 31.3357, MAE: 3.4719\n","Evaluating:\t loss: 41.5604, MAE: 3.5025\n","train MSE: 31.3357, evaluate MSE: 41.5604\n","\n","train MAE: 3.4719, evaluate MAE: 3.5025\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 367\n","\tbatch: 100, loss: 24.8547, MAE: 3.1621\n","\tbatch: 200, loss: 20.3280, MAE: 3.2737\n","Training:\t loss: 30.4072, MAE: 3.3897\n","Evaluating:\t loss: 47.7707, MAE: 3.2763\n","train MSE: 30.4072, evaluate MSE: 47.7707\n","\n","train MAE: 3.3897, evaluate MAE: 3.2763\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 368\n","\tbatch: 100, loss: 32.0381, MAE: 3.5281\n","\tbatch: 200, loss: 23.4777, MAE: 3.3256\n","Training:\t loss: 34.7298, MAE: 3.5879\n","Evaluating:\t loss: 55.6310, MAE: 4.8153\n","train MSE: 34.7298, evaluate MSE: 55.6310\n","\n","train MAE: 3.5879, evaluate MAE: 4.8153\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 369\n","\tbatch: 100, loss: 39.7233, MAE: 4.1808\n","\tbatch: 200, loss: 31.5516, MAE: 3.6620\n","Training:\t loss: 37.8813, MAE: 3.8257\n","Evaluating:\t loss: 40.9158, MAE: 3.5357\n","train MSE: 37.8813, evaluate MSE: 40.9158\n","\n","train MAE: 3.8257, evaluate MAE: 3.5357\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 370\n","\tbatch: 100, loss: 31.9312, MAE: 3.3015\n","\tbatch: 200, loss: 43.8724, MAE: 3.7984\n","Training:\t loss: 38.0820, MAE: 3.8708\n","Evaluating:\t loss: 56.8651, MAE: 4.3330\n","train MSE: 38.0820, evaluate MSE: 56.8651\n","\n","train MAE: 3.8708, evaluate MAE: 4.3330\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 371\n","\tbatch: 100, loss: 67.5140, MAE: 4.2823\n","\tbatch: 200, loss: 35.9149, MAE: 4.0426\n","Training:\t loss: 40.0205, MAE: 3.8387\n","Evaluating:\t loss: 53.1732, MAE: 4.1949\n","train MSE: 40.0205, evaluate MSE: 53.1732\n","\n","train MAE: 3.8387, evaluate MAE: 4.1949\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 372\n","\tbatch: 100, loss: 26.8776, MAE: 2.9577\n","\tbatch: 200, loss: 71.2864, MAE: 4.3984\n","Training:\t loss: 35.8029, MAE: 3.6953\n","Evaluating:\t loss: 33.9245, MAE: 3.4188\n","train MSE: 35.8029, evaluate MSE: 33.9245\n","\n","train MAE: 3.6953, evaluate MAE: 3.4188\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 373\n","\tbatch: 100, loss: 24.1044, MAE: 3.1241\n","\tbatch: 200, loss: 153.1342, MAE: 8.8534\n","Training:\t loss: 53.3189, MAE: 4.4424\n","Evaluating:\t loss: 86.4826, MAE: 5.4918\n","train MSE: 53.3189, evaluate MSE: 86.4826\n","\n","train MAE: 4.4424, evaluate MAE: 5.4918\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 374\n","\tbatch: 100, loss: 1214.3287, MAE: 26.7864\n","\tbatch: 200, loss: 394.7127, MAE: 10.7599\n","Training:\t loss: 1816.9255, MAE: 20.5412\n","Evaluating:\t loss: 186.1558, MAE: 9.1682\n","train MSE: 1816.9255, evaluate MSE: 186.1558\n","\n","train MAE: 20.5412, evaluate MAE: 9.1682\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 375\n","\tbatch: 100, loss: 106.5642, MAE: 7.0751\n","\tbatch: 200, loss: 105.4336, MAE: 6.9331\n","Training:\t loss: 132.7312, MAE: 7.7905\n","Evaluating:\t loss: 140.1103, MAE: 7.8766\n","train MSE: 132.7312, evaluate MSE: 140.1103\n","\n","train MAE: 7.7905, evaluate MAE: 7.8766\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 376\n","\tbatch: 100, loss: 68.8291, MAE: 6.1320\n","\tbatch: 200, loss: 58.8948, MAE: 5.7115\n","Training:\t loss: 98.3728, MAE: 6.6885\n","Evaluating:\t loss: 115.9395, MAE: 6.5093\n","train MSE: 98.3728, evaluate MSE: 115.9395\n","\n","train MAE: 6.6885, evaluate MAE: 6.5093\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 377\n","\tbatch: 100, loss: 67.6490, MAE: 5.9060\n","\tbatch: 200, loss: 75.0289, MAE: 5.7729\n","Training:\t loss: 84.2976, MAE: 6.1694\n","Evaluating:\t loss: 94.6530, MAE: 6.0518\n","train MSE: 84.2976, evaluate MSE: 94.6530\n","\n","train MAE: 6.1694, evaluate MAE: 6.0518\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 378\n","\tbatch: 100, loss: 97.0015, MAE: 5.8197\n","\tbatch: 200, loss: 61.8878, MAE: 5.4636\n","Training:\t loss: 71.5270, MAE: 5.6582\n","Evaluating:\t loss: 86.7574, MAE: 5.6636\n","train MSE: 71.5270, evaluate MSE: 86.7574\n","\n","train MAE: 5.6582, evaluate MAE: 5.6636\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 379\n","\tbatch: 100, loss: 61.9489, MAE: 5.2888\n","\tbatch: 200, loss: 49.7262, MAE: 4.9909\n","Training:\t loss: 66.5687, MAE: 5.4872\n","Evaluating:\t loss: 81.6054, MAE: 5.7177\n","train MSE: 66.5687, evaluate MSE: 81.6054\n","\n","train MAE: 5.4872, evaluate MAE: 5.7177\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 380\n","\tbatch: 100, loss: 43.7054, MAE: 4.5973\n","\tbatch: 200, loss: 56.0358, MAE: 4.9244\n","Training:\t loss: 58.9510, MAE: 5.0547\n","Evaluating:\t loss: 69.1145, MAE: 4.9575\n","train MSE: 58.9510, evaluate MSE: 69.1145\n","\n","train MAE: 5.0547, evaluate MAE: 4.9575\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 381\n","\tbatch: 100, loss: 43.2742, MAE: 4.7550\n","\tbatch: 200, loss: 66.3172, MAE: 4.7563\n","Training:\t loss: 54.1406, MAE: 4.8194\n","Evaluating:\t loss: 75.0534, MAE: 5.2714\n","train MSE: 54.1406, evaluate MSE: 75.0534\n","\n","train MAE: 4.8194, evaluate MAE: 5.2714\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 382\n","\tbatch: 100, loss: 65.0827, MAE: 5.1729\n","\tbatch: 200, loss: 53.8747, MAE: 4.8728\n","Training:\t loss: 49.8295, MAE: 4.6861\n","Evaluating:\t loss: 70.9733, MAE: 4.9529\n","train MSE: 49.8295, evaluate MSE: 70.9733\n","\n","train MAE: 4.6861, evaluate MAE: 4.9529\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 383\n","\tbatch: 100, loss: 33.8032, MAE: 4.0990\n","\tbatch: 200, loss: 54.6409, MAE: 4.9536\n","Training:\t loss: 46.7944, MAE: 4.4775\n","Evaluating:\t loss: 63.5244, MAE: 4.7248\n","train MSE: 46.7944, evaluate MSE: 63.5244\n","\n","train MAE: 4.4775, evaluate MAE: 4.7248\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 384\n","\tbatch: 100, loss: 42.0329, MAE: 4.6271\n","\tbatch: 200, loss: 48.7015, MAE: 4.6684\n","Training:\t loss: 46.2095, MAE: 4.5139\n","Evaluating:\t loss: 77.2259, MAE: 5.7851\n","train MSE: 46.2095, evaluate MSE: 77.2259\n","\n","train MAE: 4.5139, evaluate MAE: 5.7851\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 385\n","\tbatch: 100, loss: 50.1855, MAE: 4.4556\n","\tbatch: 200, loss: 50.1996, MAE: 4.6022\n","Training:\t loss: 44.6531, MAE: 4.4773\n","Evaluating:\t loss: 68.4662, MAE: 4.6753\n","train MSE: 44.6531, evaluate MSE: 68.4662\n","\n","train MAE: 4.4773, evaluate MAE: 4.6753\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 386\n","\tbatch: 100, loss: 39.0702, MAE: 4.5178\n","\tbatch: 200, loss: 39.6904, MAE: 4.1491\n","Training:\t loss: 45.1849, MAE: 4.5094\n","Evaluating:\t loss: 60.7851, MAE: 4.4941\n","train MSE: 45.1849, evaluate MSE: 60.7851\n","\n","train MAE: 4.5094, evaluate MAE: 4.4941\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 387\n","\tbatch: 100, loss: 31.0347, MAE: 4.1360\n","\tbatch: 200, loss: 34.9949, MAE: 4.1057\n","Training:\t loss: 47.9676, MAE: 4.6526\n","Evaluating:\t loss: 61.1318, MAE: 4.4693\n","train MSE: 47.9676, evaluate MSE: 61.1318\n","\n","train MAE: 4.6526, evaluate MAE: 4.4693\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 388\n","\tbatch: 100, loss: 43.9940, MAE: 3.9534\n","\tbatch: 200, loss: 59.8062, MAE: 4.9853\n","Training:\t loss: 46.0066, MAE: 4.5213\n","Evaluating:\t loss: 63.4482, MAE: 4.2981\n","train MSE: 46.0066, evaluate MSE: 63.4482\n","\n","train MAE: 4.5213, evaluate MAE: 4.2981\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 389\n","\tbatch: 100, loss: 46.9637, MAE: 4.6790\n","\tbatch: 200, loss: 49.1920, MAE: 4.5562\n","Training:\t loss: 48.0479, MAE: 4.5870\n","Evaluating:\t loss: 59.7446, MAE: 4.6143\n","train MSE: 48.0479, evaluate MSE: 59.7446\n","\n","train MAE: 4.5870, evaluate MAE: 4.6143\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 390\n","\tbatch: 100, loss: 32.7380, MAE: 4.1101\n","\tbatch: 200, loss: 41.4151, MAE: 4.2247\n","Training:\t loss: 52.2990, MAE: 4.8636\n","Evaluating:\t loss: 75.6189, MAE: 5.8611\n","train MSE: 52.2990, evaluate MSE: 75.6189\n","\n","train MAE: 4.8636, evaluate MAE: 5.8611\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 391\n","\tbatch: 100, loss: 34.8029, MAE: 4.1491\n","\tbatch: 200, loss: 48.5031, MAE: 4.8963\n","Training:\t loss: 44.4127, MAE: 4.4613\n","Evaluating:\t loss: 54.4086, MAE: 3.8624\n","train MSE: 44.4127, evaluate MSE: 54.4086\n","\n","train MAE: 4.4613, evaluate MAE: 3.8624\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 392\n","\tbatch: 100, loss: 54.4836, MAE: 4.2518\n","\tbatch: 200, loss: 45.5311, MAE: 5.0872\n","Training:\t loss: 44.9079, MAE: 4.4162\n","Evaluating:\t loss: 55.3442, MAE: 4.1321\n","train MSE: 44.9079, evaluate MSE: 55.3442\n","\n","train MAE: 4.4162, evaluate MAE: 4.1321\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 393\n","\tbatch: 100, loss: 42.7334, MAE: 4.0873\n","\tbatch: 200, loss: 39.2211, MAE: 4.0005\n","Training:\t loss: 41.4295, MAE: 4.1634\n","Evaluating:\t loss: 52.4415, MAE: 3.9526\n","train MSE: 41.4295, evaluate MSE: 52.4415\n","\n","train MAE: 4.1634, evaluate MAE: 3.9526\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 394\n","\tbatch: 100, loss: 52.9809, MAE: 3.8469\n","\tbatch: 200, loss: 45.6748, MAE: 3.3023\n","Training:\t loss: 41.0794, MAE: 4.1234\n","Evaluating:\t loss: 70.8078, MAE: 5.1402\n","train MSE: 41.0794, evaluate MSE: 70.8078\n","\n","train MAE: 4.1234, evaluate MAE: 5.1402\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 395\n","\tbatch: 100, loss: 40.3515, MAE: 4.3910\n","\tbatch: 200, loss: 94.8630, MAE: 8.0664\n","Training:\t loss: 46.4944, MAE: 4.4964\n","Evaluating:\t loss: 76.0817, MAE: 5.2736\n","train MSE: 46.4944, evaluate MSE: 76.0817\n","\n","train MAE: 4.4964, evaluate MAE: 5.2736\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 396\n","\tbatch: 100, loss: 62.2843, MAE: 5.7330\n","\tbatch: 200, loss: 45.0846, MAE: 4.3923\n","Training:\t loss: 58.3402, MAE: 5.2120\n","Evaluating:\t loss: 66.1774, MAE: 4.9927\n","train MSE: 58.3402, evaluate MSE: 66.1774\n","\n","train MAE: 5.2120, evaluate MAE: 4.9927\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 397\n","\tbatch: 100, loss: 43.1314, MAE: 3.8124\n","\tbatch: 200, loss: 38.5540, MAE: 3.7275\n","Training:\t loss: 38.0513, MAE: 4.0183\n","Evaluating:\t loss: 75.2060, MAE: 5.6205\n","train MSE: 38.0513, evaluate MSE: 75.2060\n","\n","train MAE: 4.0183, evaluate MAE: 5.6205\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 398\n","\tbatch: 100, loss: 67.7978, MAE: 5.5858\n","\tbatch: 200, loss: 35.1019, MAE: 3.7983\n","Training:\t loss: 41.5566, MAE: 4.1977\n","Evaluating:\t loss: 51.7919, MAE: 3.9134\n","train MSE: 41.5566, evaluate MSE: 51.7919\n","\n","train MAE: 4.1977, evaluate MAE: 3.9134\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 399\n","\tbatch: 100, loss: 27.7039, MAE: 3.8305\n","\tbatch: 200, loss: 21.6792, MAE: 3.3004\n","Training:\t loss: 37.3470, MAE: 3.8617\n","Evaluating:\t loss: 41.6269, MAE: 3.3912\n","train MSE: 37.3470, evaluate MSE: 41.6269\n","\n","train MAE: 3.8617, evaluate MAE: 3.3912\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 400\n","\tbatch: 100, loss: 24.6621, MAE: 3.1809\n","\tbatch: 200, loss: 24.1452, MAE: 3.3438\n","Training:\t loss: 40.4106, MAE: 4.0082\n","Evaluating:\t loss: 44.4668, MAE: 3.5374\n","train MSE: 40.4106, evaluate MSE: 44.4668\n","\n","train MAE: 4.0082, evaluate MAE: 3.5374\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 401\n","\tbatch: 100, loss: 49.0076, MAE: 4.7369\n","\tbatch: 200, loss: 23.2756, MAE: 3.1310\n","Training:\t loss: 51.3127, MAE: 4.5631\n","Evaluating:\t loss: 46.4860, MAE: 4.1196\n","train MSE: 51.3127, evaluate MSE: 46.4860\n","\n","train MAE: 4.5631, evaluate MAE: 4.1196\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 402\n","\tbatch: 100, loss: 34.5882, MAE: 3.3990\n","\tbatch: 200, loss: 22.0335, MAE: 3.2911\n","Training:\t loss: 41.0599, MAE: 4.0136\n","Evaluating:\t loss: 54.9671, MAE: 4.0476\n","train MSE: 41.0599, evaluate MSE: 54.9671\n","\n","train MAE: 4.0136, evaluate MAE: 4.0476\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 403\n","\tbatch: 100, loss: 76.4347, MAE: 5.9031\n","\tbatch: 200, loss: 362.0178, MAE: 14.5736\n","Training:\t loss: 1024.5750, MAE: 16.4580\n","Evaluating:\t loss: 266.8777, MAE: 10.3617\n","train MSE: 1024.5750, evaluate MSE: 266.8777\n","\n","train MAE: 16.4580, evaluate MAE: 10.3617\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 404\n","\tbatch: 100, loss: 176.0506, MAE: 8.3538\n","\tbatch: 200, loss: 127.2239, MAE: 6.8919\n","Training:\t loss: 157.6992, MAE: 8.0153\n","Evaluating:\t loss: 119.9700, MAE: 6.7848\n","train MSE: 157.6992, evaluate MSE: 119.9700\n","\n","train MAE: 8.0153, evaluate MAE: 6.7848\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 405\n","\tbatch: 100, loss: 76.6301, MAE: 6.2942\n","\tbatch: 200, loss: 166.2974, MAE: 7.0692\n","Training:\t loss: 95.3867, MAE: 6.2394\n","Evaluating:\t loss: 89.1069, MAE: 5.9940\n","train MSE: 95.3867, evaluate MSE: 89.1069\n","\n","train MAE: 6.2394, evaluate MAE: 5.9940\n","\n","--- time consumption (s): 19\n","\n","------------------------------\n","Epoch 406\n","\tbatch: 100, loss: 111.5780, MAE: 5.4215\n","\tbatch: 200, loss: 59.4259, MAE: 5.8265\n","Training:\t loss: 78.0364, MAE: 5.6733\n","Evaluating:\t loss: 95.5302, MAE: 6.2256\n","train MSE: 78.0364, evaluate MSE: 95.5302\n","\n","train MAE: 5.6733, evaluate MAE: 6.2256\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 407\n","\tbatch: 100, loss: 53.0982, MAE: 5.2334\n","\tbatch: 200, loss: 58.3517, MAE: 5.0129\n","Training:\t loss: 68.3648, MAE: 5.2706\n","Evaluating:\t loss: 80.9425, MAE: 5.2915\n","train MSE: 68.3648, evaluate MSE: 80.9425\n","\n","train MAE: 5.2706, evaluate MAE: 5.2915\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 408\n","\tbatch: 100, loss: 56.2449, MAE: 4.6418\n","\tbatch: 200, loss: 61.6161, MAE: 4.7188\n","Training:\t loss: 61.9899, MAE: 5.0087\n","Evaluating:\t loss: 82.3682, MAE: 5.3329\n","train MSE: 61.9899, evaluate MSE: 82.3682\n","\n","train MAE: 5.0087, evaluate MAE: 5.3329\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 409\n","\tbatch: 100, loss: 39.8760, MAE: 4.5609\n","\tbatch: 200, loss: 52.0418, MAE: 4.8198\n","Training:\t loss: 61.1239, MAE: 5.0562\n","Evaluating:\t loss: 63.7409, MAE: 4.8474\n","train MSE: 61.1239, evaluate MSE: 63.7409\n","\n","train MAE: 5.0562, evaluate MAE: 4.8474\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 410\n","\tbatch: 100, loss: 39.9858, MAE: 4.7452\n","\tbatch: 200, loss: 84.3606, MAE: 5.3396\n","Training:\t loss: 56.1034, MAE: 4.8251\n","Evaluating:\t loss: 70.7946, MAE: 5.1762\n","train MSE: 56.1034, evaluate MSE: 70.7946\n","\n","train MAE: 4.8251, evaluate MAE: 5.1762\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 411\n","\tbatch: 100, loss: 70.0533, MAE: 4.7371\n","\tbatch: 200, loss: 33.1374, MAE: 4.1104\n","Training:\t loss: 52.6317, MAE: 4.7376\n","Evaluating:\t loss: 69.0573, MAE: 4.5183\n","train MSE: 52.6317, evaluate MSE: 69.0573\n","\n","train MAE: 4.7376, evaluate MAE: 4.5183\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 412\n","\tbatch: 100, loss: 37.8367, MAE: 4.4455\n","\tbatch: 200, loss: 42.0982, MAE: 4.9560\n","Training:\t loss: 44.8998, MAE: 4.3056\n","Evaluating:\t loss: 54.2989, MAE: 4.1198\n","train MSE: 44.8998, evaluate MSE: 54.2989\n","\n","train MAE: 4.3056, evaluate MAE: 4.1198\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 413\n","\tbatch: 100, loss: 39.2155, MAE: 4.6612\n","\tbatch: 200, loss: 50.9909, MAE: 5.1040\n","Training:\t loss: 44.2337, MAE: 4.3647\n","Evaluating:\t loss: 81.6388, MAE: 5.7111\n","train MSE: 44.2337, evaluate MSE: 81.6388\n","\n","train MAE: 4.3647, evaluate MAE: 5.7111\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 414\n","\tbatch: 100, loss: 35.0974, MAE: 3.9343\n","\tbatch: 200, loss: 61.3234, MAE: 4.5274\n","Training:\t loss: 42.5864, MAE: 4.2826\n","Evaluating:\t loss: 62.6497, MAE: 5.0777\n","train MSE: 42.5864, evaluate MSE: 62.6497\n","\n","train MAE: 4.2826, evaluate MAE: 5.0777\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 415\n","\tbatch: 100, loss: 53.6246, MAE: 4.4763\n","\tbatch: 200, loss: 52.7945, MAE: 4.6416\n","Training:\t loss: 41.9926, MAE: 4.2472\n","Evaluating:\t loss: 55.3332, MAE: 4.2762\n","train MSE: 41.9926, evaluate MSE: 55.3332\n","\n","train MAE: 4.2472, evaluate MAE: 4.2762\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 416\n","\tbatch: 100, loss: 31.5602, MAE: 3.8813\n","\tbatch: 200, loss: 34.8543, MAE: 3.7367\n","Training:\t loss: 42.3663, MAE: 4.3073\n","Evaluating:\t loss: 47.6683, MAE: 4.0546\n","train MSE: 42.3663, evaluate MSE: 47.6683\n","\n","train MAE: 4.3073, evaluate MAE: 4.0546\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 417\n","\tbatch: 100, loss: 50.8117, MAE: 4.3373\n","\tbatch: 200, loss: 37.8585, MAE: 4.0380\n","Training:\t loss: 41.3913, MAE: 4.2286\n","Evaluating:\t loss: 95.7689, MAE: 6.5944\n","train MSE: 41.3913, evaluate MSE: 95.7689\n","\n","train MAE: 4.2286, evaluate MAE: 6.5944\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 418\n","\tbatch: 100, loss: 31.8631, MAE: 4.0780\n","\tbatch: 200, loss: 44.4956, MAE: 3.5228\n","Training:\t loss: 42.1982, MAE: 4.3005\n","Evaluating:\t loss: 50.5715, MAE: 3.7423\n","train MSE: 42.1982, evaluate MSE: 50.5715\n","\n","train MAE: 4.3005, evaluate MAE: 3.7423\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 419\n","\tbatch: 100, loss: 36.1337, MAE: 4.0109\n","\tbatch: 200, loss: 50.2859, MAE: 4.0255\n","Training:\t loss: 37.4274, MAE: 3.9448\n","Evaluating:\t loss: 78.4221, MAE: 5.2868\n","train MSE: 37.4274, evaluate MSE: 78.4221\n","\n","train MAE: 3.9448, evaluate MAE: 5.2868\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 420\n","\tbatch: 100, loss: 40.8719, MAE: 4.4121\n","\tbatch: 200, loss: 29.1329, MAE: 3.7705\n","Training:\t loss: 49.1539, MAE: 4.6338\n","Evaluating:\t loss: 44.7321, MAE: 4.1294\n","train MSE: 49.1539, evaluate MSE: 44.7321\n","\n","train MAE: 4.6338, evaluate MAE: 4.1294\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 421\n","\tbatch: 100, loss: 68.3411, MAE: 6.6325\n","\tbatch: 200, loss: 42.2091, MAE: 3.9727\n","Training:\t loss: 43.8278, MAE: 4.4158\n","Evaluating:\t loss: 53.9566, MAE: 4.1012\n","train MSE: 43.8278, evaluate MSE: 53.9566\n","\n","train MAE: 4.4158, evaluate MAE: 4.1012\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 422\n","\tbatch: 100, loss: 42.6834, MAE: 4.6941\n","\tbatch: 200, loss: 42.9590, MAE: 4.8904\n","Training:\t loss: 54.7332, MAE: 4.8119\n","Evaluating:\t loss: 59.2169, MAE: 4.6654\n","train MSE: 54.7332, evaluate MSE: 59.2169\n","\n","train MAE: 4.8119, evaluate MAE: 4.6654\n","\n","--- time consumption (s): 15\n","\n","------------------------------\n","Epoch 423\n","\tbatch: 100, loss: 163.8070, MAE: 6.0243\n","\tbatch: 200, loss: 41.2235, MAE: 4.6447\n","Training:\t loss: 60.8829, MAE: 5.0676\n","Evaluating:\t loss: 63.4746, MAE: 4.4734\n","train MSE: 60.8829, evaluate MSE: 63.4746\n","\n","train MAE: 5.0676, evaluate MAE: 4.4734\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 424\n","\tbatch: 100, loss: 60.0381, MAE: 4.8573\n","\tbatch: 200, loss: 100.1470, MAE: 7.1889\n","Training:\t loss: 54.6221, MAE: 4.7427\n","Evaluating:\t loss: 74.3882, MAE: 5.3002\n","train MSE: 54.6221, evaluate MSE: 74.3882\n","\n","train MAE: 4.7427, evaluate MAE: 5.3002\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 425\n","\tbatch: 100, loss: 46.4138, MAE: 3.9140\n","\tbatch: 200, loss: 27.6899, MAE: 3.9482\n","Training:\t loss: 51.5521, MAE: 4.5473\n","Evaluating:\t loss: 79.5071, MAE: 5.3717\n","train MSE: 51.5521, evaluate MSE: 79.5071\n","\n","train MAE: 4.5473, evaluate MAE: 5.3717\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 426\n","\tbatch: 100, loss: 57.6380, MAE: 4.7377\n","\tbatch: 200, loss: 74.2712, MAE: 6.8085\n","Training:\t loss: 56.6289, MAE: 4.8300\n","Evaluating:\t loss: 79.3275, MAE: 6.0136\n","train MSE: 56.6289, evaluate MSE: 79.3275\n","\n","train MAE: 4.8300, evaluate MAE: 6.0136\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 427\n","\tbatch: 100, loss: 55.3291, MAE: 4.8833\n","\tbatch: 200, loss: 43.9953, MAE: 4.8509\n","Training:\t loss: 52.2452, MAE: 4.5950\n","Evaluating:\t loss: 45.0014, MAE: 3.8710\n","train MSE: 52.2452, evaluate MSE: 45.0014\n","\n","train MAE: 4.5950, evaluate MAE: 3.8710\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 428\n","\tbatch: 100, loss: 50.6520, MAE: 4.4520\n","\tbatch: 200, loss: 29.3164, MAE: 3.5147\n","Training:\t loss: 45.4824, MAE: 4.3473\n","Evaluating:\t loss: 53.3192, MAE: 4.6353\n","train MSE: 45.4824, evaluate MSE: 53.3192\n","\n","train MAE: 4.3473, evaluate MAE: 4.6353\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 429\n","\tbatch: 100, loss: 18.7030, MAE: 3.0905\n","\tbatch: 200, loss: 42.4423, MAE: 4.2519\n","Training:\t loss: 49.5983, MAE: 4.4908\n","Evaluating:\t loss: 77.8534, MAE: 6.5865\n","train MSE: 49.5983, evaluate MSE: 77.8534\n","\n","train MAE: 4.4908, evaluate MAE: 6.5865\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 430\n","\tbatch: 100, loss: 53.4501, MAE: 4.7678\n","\tbatch: 200, loss: 51.9933, MAE: 4.9490\n","Training:\t loss: 56.8347, MAE: 4.8390\n","Evaluating:\t loss: 57.7683, MAE: 4.7526\n","train MSE: 56.8347, evaluate MSE: 57.7683\n","\n","train MAE: 4.8390, evaluate MAE: 4.7526\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 431\n","\tbatch: 100, loss: 72.4456, MAE: 5.1870\n","\tbatch: 200, loss: 65.1450, MAE: 4.7645\n","Training:\t loss: 43.3194, MAE: 4.1699\n","Evaluating:\t loss: 44.6458, MAE: 4.0188\n","train MSE: 43.3194, evaluate MSE: 44.6458\n","\n","train MAE: 4.1699, evaluate MAE: 4.0188\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 432\n","\tbatch: 100, loss: 30.1182, MAE: 3.8979\n","\tbatch: 200, loss: 18.0252, MAE: 2.9129\n","Training:\t loss: 38.4055, MAE: 3.9908\n","Evaluating:\t loss: 38.5003, MAE: 4.2368\n","train MSE: 38.4055, evaluate MSE: 38.5003\n","\n","train MAE: 3.9908, evaluate MAE: 4.2368\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 433\n","\tbatch: 100, loss: 48.8925, MAE: 4.6316\n","\tbatch: 200, loss: 80.2398, MAE: 6.3817\n","Training:\t loss: 44.0551, MAE: 4.3495\n","Evaluating:\t loss: 49.0708, MAE: 4.8133\n","train MSE: 44.0551, evaluate MSE: 49.0708\n","\n","train MAE: 4.3495, evaluate MAE: 4.8133\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 434\n","\tbatch: 100, loss: 616.3960, MAE: 16.4617\n","\tbatch: 200, loss: 159.8618, MAE: 8.3134\n","Training:\t loss: 1097.5750, MAE: 15.8544\n","Evaluating:\t loss: 132.2753, MAE: 7.4258\n","train MSE: 1097.5750, evaluate MSE: 132.2753\n","\n","train MAE: 15.8544, evaluate MAE: 7.4258\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 435\n","\tbatch: 100, loss: 104.1787, MAE: 6.4776\n","\tbatch: 200, loss: 82.1309, MAE: 5.5255\n","Training:\t loss: 122.7500, MAE: 6.7543\n","Evaluating:\t loss: 84.2697, MAE: 5.6592\n","train MSE: 122.7500, evaluate MSE: 84.2697\n","\n","train MAE: 6.7543, evaluate MAE: 5.6592\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 436\n","\tbatch: 100, loss: 181.9341, MAE: 5.8653\n","\tbatch: 200, loss: 54.4718, MAE: 4.9236\n","Training:\t loss: 69.3941, MAE: 5.2002\n","Evaluating:\t loss: 76.5081, MAE: 5.5947\n","train MSE: 69.3941, evaluate MSE: 76.5081\n","\n","train MAE: 5.2002, evaluate MAE: 5.5947\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 437\n","\tbatch: 100, loss: 44.7708, MAE: 4.6904\n","\tbatch: 200, loss: 62.1852, MAE: 4.6296\n","Training:\t loss: 53.9933, MAE: 4.6498\n","Evaluating:\t loss: 58.7164, MAE: 4.6278\n","train MSE: 53.9933, evaluate MSE: 58.7164\n","\n","train MAE: 4.6498, evaluate MAE: 4.6278\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 438\n","\tbatch: 100, loss: 52.3935, MAE: 4.5065\n","\tbatch: 200, loss: 42.1192, MAE: 4.1378\n","Training:\t loss: 45.3615, MAE: 4.3814\n","Evaluating:\t loss: 54.1811, MAE: 4.4232\n","train MSE: 45.3615, evaluate MSE: 54.1811\n","\n","train MAE: 4.3814, evaluate MAE: 4.4232\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 439\n","\tbatch: 100, loss: 32.6407, MAE: 4.1268\n","\tbatch: 200, loss: 34.2377, MAE: 4.2086\n","Training:\t loss: 40.8397, MAE: 4.2044\n","Evaluating:\t loss: 54.9566, MAE: 4.4938\n","train MSE: 40.8397, evaluate MSE: 54.9566\n","\n","train MAE: 4.2044, evaluate MAE: 4.4938\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 440\n","\tbatch: 100, loss: 36.6436, MAE: 4.1981\n","\tbatch: 200, loss: 35.0786, MAE: 4.0134\n","Training:\t loss: 38.6958, MAE: 4.0737\n","Evaluating:\t loss: 51.1932, MAE: 4.3617\n","train MSE: 38.6958, evaluate MSE: 51.1932\n","\n","train MAE: 4.0737, evaluate MAE: 4.3617\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 441\n","\tbatch: 100, loss: 23.9948, MAE: 3.5559\n","\tbatch: 200, loss: 32.9778, MAE: 3.8137\n","Training:\t loss: 36.6494, MAE: 4.0343\n","Evaluating:\t loss: 52.0717, MAE: 4.5697\n","train MSE: 36.6494, evaluate MSE: 52.0717\n","\n","train MAE: 4.0343, evaluate MAE: 4.5697\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 442\n","\tbatch: 100, loss: 25.2840, MAE: 3.7746\n","\tbatch: 200, loss: 26.3032, MAE: 3.5910\n","Training:\t loss: 34.1087, MAE: 3.8831\n","Evaluating:\t loss: 51.6576, MAE: 3.8652\n","train MSE: 34.1087, evaluate MSE: 51.6576\n","\n","train MAE: 3.8831, evaluate MAE: 3.8652\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 443\n","\tbatch: 100, loss: 65.4707, MAE: 4.9443\n","\tbatch: 200, loss: 31.8923, MAE: 3.8343\n","Training:\t loss: 35.9645, MAE: 4.0246\n","Evaluating:\t loss: 62.0864, MAE: 5.4462\n","train MSE: 35.9645, evaluate MSE: 62.0864\n","\n","train MAE: 4.0246, evaluate MAE: 5.4462\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 444\n","\tbatch: 100, loss: 68.2857, MAE: 3.9698\n","\tbatch: 200, loss: 48.3427, MAE: 4.1940\n","Training:\t loss: 34.5954, MAE: 4.0044\n","Evaluating:\t loss: 46.3465, MAE: 4.0311\n","train MSE: 34.5954, evaluate MSE: 46.3465\n","\n","train MAE: 4.0044, evaluate MAE: 4.0311\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 445\n","\tbatch: 100, loss: 31.6131, MAE: 3.6298\n","\tbatch: 200, loss: 35.2072, MAE: 3.6479\n","Training:\t loss: 34.6113, MAE: 3.9496\n","Evaluating:\t loss: 49.9583, MAE: 4.4184\n","train MSE: 34.6113, evaluate MSE: 49.9583\n","\n","train MAE: 3.9496, evaluate MAE: 4.4184\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 446\n","\tbatch: 100, loss: 46.3238, MAE: 5.1805\n","\tbatch: 200, loss: 32.0201, MAE: 3.7796\n","Training:\t loss: 41.9470, MAE: 4.4282\n","Evaluating:\t loss: 47.6426, MAE: 4.3337\n","train MSE: 41.9470, evaluate MSE: 47.6426\n","\n","train MAE: 4.4282, evaluate MAE: 4.3337\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 447\n","\tbatch: 100, loss: 33.5047, MAE: 4.4912\n","\tbatch: 200, loss: 55.6872, MAE: 5.3095\n","Training:\t loss: 38.6342, MAE: 4.2348\n","Evaluating:\t loss: 52.6015, MAE: 4.3767\n","train MSE: 38.6342, evaluate MSE: 52.6015\n","\n","train MAE: 4.2348, evaluate MAE: 4.3767\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 448\n","\tbatch: 100, loss: 31.5067, MAE: 3.9511\n","\tbatch: 200, loss: 34.4999, MAE: 4.6605\n","Training:\t loss: 39.9426, MAE: 4.2752\n","Evaluating:\t loss: 80.7046, MAE: 5.0079\n","train MSE: 39.9426, evaluate MSE: 80.7046\n","\n","train MAE: 4.2752, evaluate MAE: 5.0079\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 449\n","\tbatch: 100, loss: 28.2521, MAE: 3.7104\n","\tbatch: 200, loss: 32.2957, MAE: 4.0598\n","Training:\t loss: 41.7038, MAE: 4.1842\n","Evaluating:\t loss: 57.6484, MAE: 4.7000\n","train MSE: 41.7038, evaluate MSE: 57.6484\n","\n","train MAE: 4.1842, evaluate MAE: 4.7000\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 450\n","\tbatch: 100, loss: 47.8938, MAE: 4.9255\n","\tbatch: 200, loss: 192.3936, MAE: 7.6851\n","Training:\t loss: 78.1396, MAE: 5.4615\n","Evaluating:\t loss: 281.0558, MAE: 13.3499\n","train MSE: 78.1396, evaluate MSE: 281.0558\n","\n","train MAE: 5.4615, evaluate MAE: 13.3499\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 451\n","\tbatch: 100, loss: 59.8103, MAE: 4.9744\n","\tbatch: 200, loss: 81.1575, MAE: 5.7527\n","Training:\t loss: 73.1501, MAE: 5.7049\n","Evaluating:\t loss: 69.0150, MAE: 5.3387\n","train MSE: 73.1501, evaluate MSE: 69.0150\n","\n","train MAE: 5.7049, evaluate MAE: 5.3387\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 452\n","\tbatch: 100, loss: 36.6681, MAE: 4.0410\n","\tbatch: 200, loss: 27.6858, MAE: 3.6820\n","Training:\t loss: 45.0738, MAE: 4.3790\n","Evaluating:\t loss: 47.0407, MAE: 4.2743\n","train MSE: 45.0738, evaluate MSE: 47.0407\n","\n","train MAE: 4.3790, evaluate MAE: 4.2743\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 453\n","\tbatch: 100, loss: 29.4136, MAE: 3.6000\n","\tbatch: 200, loss: 30.5011, MAE: 3.2766\n","Training:\t loss: 33.6598, MAE: 3.6335\n","Evaluating:\t loss: 41.9033, MAE: 3.7387\n","train MSE: 33.6598, evaluate MSE: 41.9033\n","\n","train MAE: 3.6335, evaluate MAE: 3.7387\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 454\n","\tbatch: 100, loss: 113.7957, MAE: 3.9941\n","\tbatch: 200, loss: 24.7897, MAE: 3.3068\n","Training:\t loss: 29.6325, MAE: 3.3095\n","Evaluating:\t loss: 44.5621, MAE: 3.8950\n","train MSE: 29.6325, evaluate MSE: 44.5621\n","\n","train MAE: 3.3095, evaluate MAE: 3.8950\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 455\n","\tbatch: 100, loss: 21.4100, MAE: 3.1015\n","\tbatch: 200, loss: 34.1446, MAE: 3.8504\n","Training:\t loss: 33.3246, MAE: 3.5352\n","Evaluating:\t loss: 38.2893, MAE: 3.1342\n","train MSE: 33.3246, evaluate MSE: 38.2893\n","\n","train MAE: 3.5352, evaluate MAE: 3.1342\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 456\n","\tbatch: 100, loss: 14.5002, MAE: 2.8253\n","\tbatch: 200, loss: 35.5011, MAE: 3.7673\n","Training:\t loss: 31.8718, MAE: 3.4566\n","Evaluating:\t loss: 34.8195, MAE: 3.7108\n","train MSE: 31.8718, evaluate MSE: 34.8195\n","\n","train MAE: 3.4566, evaluate MAE: 3.7108\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 457\n","\tbatch: 100, loss: 30.0022, MAE: 2.8399\n","\tbatch: 200, loss: 35.1544, MAE: 3.5645\n","Training:\t loss: 93.9118, MAE: 4.4441\n","Evaluating:\t loss: 3249.0757, MAE: 47.9031\n","train MSE: 93.9118, evaluate MSE: 3249.0757\n","\n","train MAE: 4.4441, evaluate MAE: 47.9031\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 458\n","\tbatch: 100, loss: 92.9240, MAE: 6.9905\n","\tbatch: 200, loss: 68.3485, MAE: 5.2091\n","Training:\t loss: 527.3569, MAE: 12.5128\n","Evaluating:\t loss: 76.8345, MAE: 5.0875\n","train MSE: 527.3569, evaluate MSE: 76.8345\n","\n","train MAE: 12.5128, evaluate MAE: 5.0875\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 459\n","\tbatch: 100, loss: 33.6464, MAE: 4.1290\n","\tbatch: 200, loss: 44.9025, MAE: 4.5176\n","Training:\t loss: 54.6824, MAE: 4.4123\n","Evaluating:\t loss: 52.5823, MAE: 4.1390\n","train MSE: 54.6824, evaluate MSE: 52.5823\n","\n","train MAE: 4.4123, evaluate MAE: 4.1390\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 460\n","\tbatch: 100, loss: 40.1450, MAE: 4.0382\n","\tbatch: 200, loss: 29.1800, MAE: 3.4667\n","Training:\t loss: 44.5904, MAE: 3.8409\n","Evaluating:\t loss: 61.0249, MAE: 4.7635\n","train MSE: 44.5904, evaluate MSE: 61.0249\n","\n","train MAE: 3.8409, evaluate MAE: 4.7635\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 461\n","\tbatch: 100, loss: 62.8887, MAE: 3.5377\n","\tbatch: 200, loss: 41.4241, MAE: 3.7382\n","Training:\t loss: 41.3581, MAE: 3.7889\n","Evaluating:\t loss: 40.3835, MAE: 3.5751\n","train MSE: 41.3581, evaluate MSE: 40.3835\n","\n","train MAE: 3.7889, evaluate MAE: 3.5751\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 462\n","\tbatch: 100, loss: 38.6844, MAE: 3.3754\n","\tbatch: 200, loss: 34.8759, MAE: 3.2389\n","Training:\t loss: 33.3261, MAE: 3.4280\n","Evaluating:\t loss: 36.5940, MAE: 3.2767\n","train MSE: 33.3261, evaluate MSE: 36.5940\n","\n","train MAE: 3.4280, evaluate MAE: 3.2767\n","\n","--- time consumption (s): 19\n","\n","------------------------------\n","Epoch 463\n","\tbatch: 100, loss: 42.4323, MAE: 3.2356\n","\tbatch: 200, loss: 38.3963, MAE: 3.5553\n","Training:\t loss: 30.1174, MAE: 3.2717\n","Evaluating:\t loss: 37.0030, MAE: 3.2057\n","train MSE: 30.1174, evaluate MSE: 37.0030\n","\n","train MAE: 3.2717, evaluate MAE: 3.2057\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 464\n","\tbatch: 100, loss: 26.3654, MAE: 3.0580\n","\tbatch: 200, loss: 48.5971, MAE: 3.1562\n","Training:\t loss: 29.8383, MAE: 3.2466\n","Evaluating:\t loss: 55.7929, MAE: 4.4315\n","train MSE: 29.8383, evaluate MSE: 55.7929\n","\n","train MAE: 3.2466, evaluate MAE: 4.4315\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 465\n","\tbatch: 100, loss: 16.6114, MAE: 2.8261\n","\tbatch: 200, loss: 39.5742, MAE: 5.1406\n","Training:\t loss: 27.3483, MAE: 3.1599\n","Evaluating:\t loss: 32.3569, MAE: 3.3455\n","train MSE: 27.3483, evaluate MSE: 32.3569\n","\n","train MAE: 3.1599, evaluate MAE: 3.3455\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 466\n","\tbatch: 100, loss: 16.3962, MAE: 2.9965\n","\tbatch: 200, loss: 27.1849, MAE: 2.8775\n","Training:\t loss: 24.0410, MAE: 2.9130\n","Evaluating:\t loss: 33.7740, MAE: 3.0806\n","train MSE: 24.0410, evaluate MSE: 33.7740\n","\n","train MAE: 2.9130, evaluate MAE: 3.0806\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 467\n","\tbatch: 100, loss: 26.8440, MAE: 3.2001\n","\tbatch: 200, loss: 15.4912, MAE: 2.5142\n","Training:\t loss: 27.2267, MAE: 3.0485\n","Evaluating:\t loss: 85.3472, MAE: 6.8611\n","train MSE: 27.2267, evaluate MSE: 85.3472\n","\n","train MAE: 3.0485, evaluate MAE: 6.8611\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 468\n","\tbatch: 100, loss: 21.7228, MAE: 2.7889\n","\tbatch: 200, loss: 25.5840, MAE: 3.3836\n","Training:\t loss: 28.7419, MAE: 3.2050\n","Evaluating:\t loss: 37.6072, MAE: 3.8779\n","train MSE: 28.7419, evaluate MSE: 37.6072\n","\n","train MAE: 3.2050, evaluate MAE: 3.8779\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 469\n","\tbatch: 100, loss: 13.8132, MAE: 2.7287\n","\tbatch: 200, loss: 21.6294, MAE: 2.6688\n","Training:\t loss: 27.5047, MAE: 3.1918\n","Evaluating:\t loss: 36.2430, MAE: 3.5468\n","train MSE: 27.5047, evaluate MSE: 36.2430\n","\n","train MAE: 3.1918, evaluate MAE: 3.5468\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 470\n","\tbatch: 100, loss: 20.9163, MAE: 2.4424\n","\tbatch: 200, loss: 32.7205, MAE: 3.1711\n","Training:\t loss: 26.4817, MAE: 3.0668\n","Evaluating:\t loss: 40.7188, MAE: 3.3209\n","train MSE: 26.4817, evaluate MSE: 40.7188\n","\n","train MAE: 3.0668, evaluate MAE: 3.3209\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 471\n","\tbatch: 100, loss: 21.1527, MAE: 2.6935\n","\tbatch: 200, loss: 43.3899, MAE: 4.4260\n","Training:\t loss: 25.9757, MAE: 3.1008\n","Evaluating:\t loss: 30.4859, MAE: 2.9646\n","train MSE: 25.9757, evaluate MSE: 30.4859\n","\n","train MAE: 3.1008, evaluate MAE: 2.9646\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 472\n","\tbatch: 100, loss: 24.9263, MAE: 2.7888\n","\tbatch: 200, loss: 23.0294, MAE: 2.7899\n","Training:\t loss: 24.4525, MAE: 2.9588\n","Evaluating:\t loss: 36.9649, MAE: 3.4536\n","train MSE: 24.4525, evaluate MSE: 36.9649\n","\n","train MAE: 2.9588, evaluate MAE: 3.4536\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 473\n","\tbatch: 100, loss: 54.7610, MAE: 3.8492\n","\tbatch: 200, loss: 22.4416, MAE: 2.5168\n","Training:\t loss: 29.3612, MAE: 3.2652\n","Evaluating:\t loss: 29.1388, MAE: 2.9611\n","train MSE: 29.3612, evaluate MSE: 29.1388\n","\n","train MAE: 3.2652, evaluate MAE: 2.9611\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 474\n","\tbatch: 100, loss: 39.7375, MAE: 3.7533\n","\tbatch: 200, loss: 42.2220, MAE: 3.1870\n","Training:\t loss: 35.2494, MAE: 3.6449\n","Evaluating:\t loss: 39.5109, MAE: 3.9934\n","train MSE: 35.2494, evaluate MSE: 39.5109\n","\n","train MAE: 3.6449, evaluate MAE: 3.9934\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 475\n","\tbatch: 100, loss: 7480.7900, MAE: 74.1787\n","\tbatch: 200, loss: 101.7665, MAE: 7.5910\n","Training:\t loss: 698.8493, MAE: 13.6921\n","Evaluating:\t loss: 123.3491, MAE: 7.5418\n","train MSE: 698.8493, evaluate MSE: 123.3491\n","\n","train MAE: 13.6921, evaluate MAE: 7.5418\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 476\n","\tbatch: 100, loss: 64.7166, MAE: 6.3472\n","\tbatch: 200, loss: 79.3956, MAE: 5.9251\n","Training:\t loss: 89.9180, MAE: 6.5502\n","Evaluating:\t loss: 72.3429, MAE: 5.7183\n","train MSE: 89.9180, evaluate MSE: 72.3429\n","\n","train MAE: 6.5502, evaluate MAE: 5.7183\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 477\n","\tbatch: 100, loss: 54.1121, MAE: 5.2806\n","\tbatch: 200, loss: 36.3142, MAE: 4.6601\n","Training:\t loss: 55.9671, MAE: 5.2020\n","Evaluating:\t loss: 61.0204, MAE: 5.1931\n","train MSE: 55.9671, evaluate MSE: 61.0204\n","\n","train MAE: 5.2020, evaluate MAE: 5.1931\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 478\n","\tbatch: 100, loss: 30.5035, MAE: 4.2030\n","\tbatch: 200, loss: 31.3527, MAE: 4.1328\n","Training:\t loss: 42.6042, MAE: 4.4648\n","Evaluating:\t loss: 53.9752, MAE: 5.1530\n","train MSE: 42.6042, evaluate MSE: 53.9752\n","\n","train MAE: 4.4648, evaluate MAE: 5.1530\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 479\n","\tbatch: 100, loss: 30.0258, MAE: 3.8326\n","\tbatch: 200, loss: 32.4124, MAE: 4.2638\n","Training:\t loss: 37.7864, MAE: 4.1866\n","Evaluating:\t loss: 41.7082, MAE: 4.0784\n","train MSE: 37.7864, evaluate MSE: 41.7082\n","\n","train MAE: 4.1866, evaluate MAE: 4.0784\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 480\n","\tbatch: 100, loss: 40.8415, MAE: 4.0856\n","\tbatch: 200, loss: 53.8099, MAE: 5.4882\n","Training:\t loss: 35.9557, MAE: 4.1408\n","Evaluating:\t loss: 41.3464, MAE: 4.0867\n","train MSE: 35.9557, evaluate MSE: 41.3464\n","\n","train MAE: 4.1408, evaluate MAE: 4.0867\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 481\n","\tbatch: 100, loss: 30.1185, MAE: 3.5890\n","\tbatch: 200, loss: 24.0892, MAE: 3.3984\n","Training:\t loss: 30.8861, MAE: 3.7931\n","Evaluating:\t loss: 40.2037, MAE: 4.0904\n","train MSE: 30.8861, evaluate MSE: 40.2037\n","\n","train MAE: 3.7931, evaluate MAE: 4.0904\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 482\n","\tbatch: 100, loss: 37.1908, MAE: 3.8452\n","\tbatch: 200, loss: 33.7425, MAE: 3.5483\n","Training:\t loss: 30.1410, MAE: 3.7853\n","Evaluating:\t loss: 41.5459, MAE: 4.4375\n","train MSE: 30.1410, evaluate MSE: 41.5459\n","\n","train MAE: 3.7853, evaluate MAE: 4.4375\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 483\n","\tbatch: 100, loss: 23.5901, MAE: 3.6302\n","\tbatch: 200, loss: 28.0443, MAE: 3.6135\n","Training:\t loss: 29.1308, MAE: 3.7427\n","Evaluating:\t loss: 36.0970, MAE: 3.5502\n","train MSE: 29.1308, evaluate MSE: 36.0970\n","\n","train MAE: 3.7427, evaluate MAE: 3.5502\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 484\n","\tbatch: 100, loss: 24.4684, MAE: 3.4007\n","\tbatch: 200, loss: 35.3678, MAE: 4.2226\n","Training:\t loss: 33.0735, MAE: 4.0137\n","Evaluating:\t loss: 34.3258, MAE: 3.7178\n","train MSE: 33.0735, evaluate MSE: 34.3258\n","\n","train MAE: 4.0137, evaluate MAE: 3.7178\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 485\n","\tbatch: 100, loss: 22.1633, MAE: 3.6385\n","\tbatch: 200, loss: 21.7268, MAE: 3.2300\n","Training:\t loss: 26.9714, MAE: 3.4833\n","Evaluating:\t loss: 29.2900, MAE: 3.2403\n","train MSE: 26.9714, evaluate MSE: 29.2900\n","\n","train MAE: 3.4833, evaluate MAE: 3.2403\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 486\n","\tbatch: 100, loss: 15.9466, MAE: 2.8242\n","\tbatch: 200, loss: 18.0298, MAE: 3.1430\n","Training:\t loss: 25.9758, MAE: 3.4753\n","Evaluating:\t loss: 47.8409, MAE: 4.8512\n","train MSE: 25.9758, evaluate MSE: 47.8409\n","\n","train MAE: 3.4753, evaluate MAE: 4.8512\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 487\n","\tbatch: 100, loss: 20.4188, MAE: 3.3993\n","\tbatch: 200, loss: 22.8171, MAE: 3.1428\n","Training:\t loss: 25.7440, MAE: 3.5260\n","Evaluating:\t loss: 27.0741, MAE: 3.0594\n","train MSE: 25.7440, evaluate MSE: 27.0741\n","\n","train MAE: 3.5260, evaluate MAE: 3.0594\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 488\n","\tbatch: 100, loss: 34.3628, MAE: 3.9003\n","\tbatch: 200, loss: 21.3248, MAE: 3.0907\n","Training:\t loss: 24.4811, MAE: 3.3738\n","Evaluating:\t loss: 26.9267, MAE: 3.1448\n","train MSE: 24.4811, evaluate MSE: 26.9267\n","\n","train MAE: 3.3738, evaluate MAE: 3.1448\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 489\n","\tbatch: 100, loss: 18.1242, MAE: 3.3234\n","\tbatch: 200, loss: 30.4621, MAE: 4.0054\n","Training:\t loss: 25.3254, MAE: 3.4043\n","Evaluating:\t loss: 25.9367, MAE: 2.9494\n","train MSE: 25.3254, evaluate MSE: 25.9367\n","\n","train MAE: 3.4043, evaluate MAE: 2.9494\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 490\n","\tbatch: 100, loss: 29.0676, MAE: 3.0534\n","\tbatch: 200, loss: 27.0446, MAE: 3.3657\n","Training:\t loss: 22.6305, MAE: 3.1368\n","Evaluating:\t loss: 30.8042, MAE: 3.5958\n","train MSE: 22.6305, evaluate MSE: 30.8042\n","\n","train MAE: 3.1368, evaluate MAE: 3.5958\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 491\n","\tbatch: 100, loss: 23.1326, MAE: 2.9812\n","\tbatch: 200, loss: 29.1461, MAE: 3.9445\n","Training:\t loss: 25.0165, MAE: 3.3180\n","Evaluating:\t loss: 39.0497, MAE: 3.9935\n","train MSE: 25.0165, evaluate MSE: 39.0497\n","\n","train MAE: 3.3180, evaluate MAE: 3.9935\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 492\n","\tbatch: 100, loss: 122.7769, MAE: 8.0096\n","\tbatch: 200, loss: 53.1864, MAE: 4.3789\n","Training:\t loss: 45.5986, MAE: 4.5758\n","Evaluating:\t loss: 44.4649, MAE: 4.6465\n","train MSE: 45.5986, evaluate MSE: 44.4649\n","\n","train MAE: 4.5758, evaluate MAE: 4.6465\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 493\n","\tbatch: 100, loss: 123.1746, MAE: 7.6775\n","\tbatch: 200, loss: 45.6657, MAE: 4.4950\n","Training:\t loss: 323.6441, MAE: 10.2463\n","Evaluating:\t loss: 66.0804, MAE: 4.8328\n","train MSE: 323.6441, evaluate MSE: 66.0804\n","\n","train MAE: 10.2463, evaluate MAE: 4.8328\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 494\n","\tbatch: 100, loss: 33.6947, MAE: 3.8831\n","\tbatch: 200, loss: 53.8927, MAE: 3.9914\n","Training:\t loss: 46.8525, MAE: 4.2123\n","Evaluating:\t loss: 46.2120, MAE: 4.0278\n","train MSE: 46.8525, evaluate MSE: 46.2120\n","\n","train MAE: 4.2123, evaluate MAE: 4.0278\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 495\n","\tbatch: 100, loss: 39.2603, MAE: 3.4941\n","\tbatch: 200, loss: 50.5894, MAE: 3.5281\n","Training:\t loss: 38.4982, MAE: 3.7460\n","Evaluating:\t loss: 38.8518, MAE: 3.4042\n","train MSE: 38.4982, evaluate MSE: 38.8518\n","\n","train MAE: 3.7460, evaluate MAE: 3.4042\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 496\n","\tbatch: 100, loss: 47.6272, MAE: 3.4632\n","\tbatch: 200, loss: 28.6767, MAE: 3.1039\n","Training:\t loss: 32.8355, MAE: 3.3857\n","Evaluating:\t loss: 27.8913, MAE: 3.2069\n","train MSE: 32.8355, evaluate MSE: 27.8913\n","\n","train MAE: 3.3857, evaluate MAE: 3.2069\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 497\n","\tbatch: 100, loss: 15.6368, MAE: 2.7881\n","\tbatch: 200, loss: 20.0639, MAE: 2.8503\n","Training:\t loss: 23.3417, MAE: 2.9249\n","Evaluating:\t loss: 28.0241, MAE: 3.3094\n","train MSE: 23.3417, evaluate MSE: 28.0241\n","\n","train MAE: 2.9249, evaluate MAE: 3.3094\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 498\n","\tbatch: 100, loss: 18.0184, MAE: 2.6061\n","\tbatch: 200, loss: 16.9054, MAE: 2.5290\n","Training:\t loss: 21.3596, MAE: 2.8062\n","Evaluating:\t loss: 24.3809, MAE: 2.6661\n","train MSE: 21.3596, evaluate MSE: 24.3809\n","\n","train MAE: 2.8062, evaluate MAE: 2.6661\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 499\n","\tbatch: 100, loss: 17.7377, MAE: 2.5482\n","\tbatch: 200, loss: 18.9285, MAE: 2.9930\n","Training:\t loss: 19.2810, MAE: 2.6926\n","Evaluating:\t loss: 23.5614, MAE: 2.6375\n","train MSE: 19.2810, evaluate MSE: 23.5614\n","\n","train MAE: 2.6926, evaluate MAE: 2.6375\n","\n","--- time consumption (s): 16\n","\n","------------------------------\n","Epoch 500\n","\tbatch: 100, loss: 30.7524, MAE: 3.6602\n","\tbatch: 200, loss: 9.7476, MAE: 2.1834\n","Training:\t loss: 17.7270, MAE: 2.6071\n","Evaluating:\t loss: 30.1127, MAE: 3.4730\n","train MSE: 17.7270, evaluate MSE: 30.1127\n","\n","train MAE: 2.6071, evaluate MAE: 3.4730\n","\n","--- time consumption (s): 16\n","\n","Best model has been saved! Best model obtained at epoch 499 with eval MAE 2.6375\n","=============== testing ===============\n","MSE on test set: 31.4778\n","MAE on test set: 3.4620\n","R2 score: 1.0000\n"]}],"source":["!python main.py -e 500 -lr 1e-4 -o base-multi-read-500-1e-4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"eAnSh8tBNOBM"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":210,"status":"ok","timestamp":1634431870797,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"Gl_J9k4ronAS","outputId":"aa008748-b68d-4963-ddfd-87d256ff68cf"},"outputs":[{"name":"stdout","output_type":"stream","text":["    parser.add_argument('-mr', '--multi_read', type=bool, default=False,\r\n","    multi_read = args.multi_read\r\n","                          width=np.ceil(dist_max) / 30, n_conv=n_conv, norm=norm, multi_read=multi_read)\r\n"]}],"source":["!cat main.py | grep multi_read"]},{"cell_type":"markdown","metadata":{"id":"XpSl5y9IPL8b"},"source":["## 官方MGCN对比"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"vc0K52enocix","outputId":"4b6c9916-3ab8-4631-f9ff-6c289a029d3a"},"outputs":[{"name":"stdout","output_type":"stream","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 85\n","\tbatch: 100, loss: 0.3963, MAE: 0.4128\n","\tbatch: 200, loss: 0.7955, MAE: 0.8484\n","Training:\t loss: 0.9983, MAE: 0.7795\n","Evaluating:\t loss: 2.6217, MAE: 1.5574\n","train MSE: 0.9983, evaluate MSE: 2.6217\n","\n","train MAE: 0.7795, evaluate MAE: 1.5574\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 86\n","\tbatch: 100, loss: 1.9806, MAE: 1.3901\n","\tbatch: 200, loss: 0.1986, MAE: 0.4039\n","Training:\t loss: 1.6606, MAE: 0.8736\n","Evaluating:\t loss: 6.6282, MAE: 2.4887\n","train MSE: 1.6606, evaluate MSE: 6.6282\n","\n","train MAE: 0.8736, evaluate MAE: 2.4887\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 87\n","\tbatch: 100, loss: 0.0975, MAE: 0.2582\n","\tbatch: 200, loss: 0.2678, MAE: 0.3899\n","Training:\t loss: 1.5677, MAE: 0.8007\n","Evaluating:\t loss: 0.8149, MAE: 0.7768\n","train MSE: 1.5677, evaluate MSE: 0.8149\n","\n","train MAE: 0.8007, evaluate MAE: 0.7768\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 88\n","\tbatch: 100, loss: 2.7875, MAE: 1.6487\n","\tbatch: 200, loss: 0.1041, MAE: 0.2113\n","Training:\t loss: 1.0303, MAE: 0.7258\n","Evaluating:\t loss: 0.1817, MAE: 0.3143\n","train MSE: 1.0303, evaluate MSE: 0.1817\n","\n","train MAE: 0.7258, evaluate MAE: 0.3143\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 89\n","\tbatch: 100, loss: 2.6184, MAE: 1.5877\n","\tbatch: 200, loss: 12.2689, MAE: 3.4878\n","Training:\t loss: 1.6698, MAE: 0.9465\n","Evaluating:\t loss: 0.0864, MAE: 0.1549\n","train MSE: 1.6698, evaluate MSE: 0.0864\n","\n","train MAE: 0.9465, evaluate MAE: 0.1549\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 90\n","\tbatch: 100, loss: 1.8945, MAE: 1.3510\n","\tbatch: 200, loss: 0.4867, MAE: 0.5367\n","Training:\t loss: 0.9722, MAE: 0.7395\n","Evaluating:\t loss: 5.9486, MAE: 2.4047\n","train MSE: 0.9722, evaluate MSE: 5.9486\n","\n","train MAE: 0.7395, evaluate MAE: 2.4047\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 91\n","\tbatch: 100, loss: 2.4955, MAE: 1.5121\n","\tbatch: 200, loss: 0.0761, MAE: 0.1980\n","Training:\t loss: 1.4439, MAE: 0.9220\n","Evaluating:\t loss: 0.3422, MAE: 0.5184\n","train MSE: 1.4439, evaluate MSE: 0.3422\n","\n","train MAE: 0.9220, evaluate MAE: 0.5184\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 92\n","\tbatch: 100, loss: 0.2312, MAE: 0.4404\n","\tbatch: 200, loss: 0.4646, MAE: 0.3209\n","Training:\t loss: 1.2239, MAE: 0.8220\n","Evaluating:\t loss: 0.1499, MAE: 0.1949\n","train MSE: 1.2239, evaluate MSE: 0.1499\n","\n","train MAE: 0.8220, evaluate MAE: 0.1949\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 93\n","\tbatch: 100, loss: 4.0242, MAE: 1.9373\n","\tbatch: 200, loss: 0.0259, MAE: 0.1306\n","Training:\t loss: 1.5160, MAE: 0.8634\n","Evaluating:\t loss: 16.1925, MAE: 3.9214\n","train MSE: 1.5160, evaluate MSE: 16.1925\n","\n","train MAE: 0.8634, evaluate MAE: 3.9214\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 94\n","\tbatch: 100, loss: 0.0347, MAE: 0.1663\n","\tbatch: 200, loss: 0.0870, MAE: 0.2641\n","Training:\t loss: 1.3838, MAE: 0.6771\n","Evaluating:\t loss: 0.1044, MAE: 0.1970\n","train MSE: 1.3838, evaluate MSE: 0.1044\n","\n","train MAE: 0.6771, evaluate MAE: 0.1970\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 95\n","\tbatch: 100, loss: 6.5392, MAE: 2.5127\n","\tbatch: 200, loss: 0.0238, MAE: 0.0904\n","Training:\t loss: 1.1853, MAE: 0.6172\n","Evaluating:\t loss: 0.2597, MAE: 0.4104\n","train MSE: 1.1853, evaluate MSE: 0.2597\n","\n","train MAE: 0.6172, evaluate MAE: 0.4104\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 96\n","\tbatch: 100, loss: 0.0403, MAE: 0.1511\n","\tbatch: 200, loss: 0.8382, MAE: 0.9026\n","Training:\t loss: 1.9071, MAE: 0.8259\n","Evaluating:\t loss: 1.0495, MAE: 0.7476\n","train MSE: 1.9071, evaluate MSE: 1.0495\n","\n","train MAE: 0.8259, evaluate MAE: 0.7476\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 97\n","\tbatch: 100, loss: 0.2497, MAE: 0.4367\n","\tbatch: 200, loss: 0.1234, MAE: 0.2620\n","Training:\t loss: 1.3799, MAE: 0.7895\n","Evaluating:\t loss: 0.1468, MAE: 0.2624\n","train MSE: 1.3799, evaluate MSE: 0.1468\n","\n","train MAE: 0.7895, evaluate MAE: 0.2624\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 98\n","\tbatch: 100, loss: 0.5768, MAE: 0.7386\n","\tbatch: 200, loss: 0.3325, MAE: 0.5039\n","Training:\t loss: 1.0145, MAE: 0.7311\n","Evaluating:\t loss: 1.5657, MAE: 1.1829\n","train MSE: 1.0145, evaluate MSE: 1.5657\n","\n","train MAE: 0.7311, evaluate MAE: 1.1829\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 99\n","\tbatch: 100, loss: 2.6442, MAE: 1.5912\n","\tbatch: 200, loss: 0.3819, MAE: 0.6054\n","Training:\t loss: 1.0864, MAE: 0.7110\n","Evaluating:\t loss: 13.2459, MAE: 3.5545\n","train MSE: 1.0864, evaluate MSE: 13.2459\n","\n","train MAE: 0.7110, evaluate MAE: 3.5545\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 100\n","\tbatch: 100, loss: 0.1617, MAE: 0.3445\n","\tbatch: 200, loss: 1.7311, MAE: 1.2386\n","Training:\t loss: 1.1082, MAE: 0.7409\n","Evaluating:\t loss: 0.5145, MAE: 0.6675\n","train MSE: 1.1082, evaluate MSE: 0.5145\n","\n","train MAE: 0.7409, evaluate MAE: 0.6675\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 101\n","\tbatch: 100, loss: 0.5640, MAE: 0.7305\n","\tbatch: 200, loss: 0.7324, MAE: 0.8113\n","Training:\t loss: 1.2581, MAE: 0.8955\n","Evaluating:\t loss: 0.4213, MAE: 0.3091\n","train MSE: 1.2581, evaluate MSE: 0.4213\n","\n","train MAE: 0.8955, evaluate MAE: 0.3091\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 102\n","\tbatch: 100, loss: 6.8461, MAE: 2.5934\n","\tbatch: 200, loss: 0.0319, MAE: 0.1401\n","Training:\t loss: 1.3232, MAE: 0.7986\n","Evaluating:\t loss: 2.0556, MAE: 1.3659\n","train MSE: 1.3232, evaluate MSE: 2.0556\n","\n","train MAE: 0.7986, evaluate MAE: 1.3659\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 103\n","\tbatch: 100, loss: 0.7317, MAE: 0.8424\n","\tbatch: 200, loss: 1.4589, MAE: 1.1856\n","Training:\t loss: 1.0264, MAE: 0.7468\n","Evaluating:\t loss: 0.4928, MAE: 0.4912\n","train MSE: 1.0264, evaluate MSE: 0.4928\n","\n","train MAE: 0.7468, evaluate MAE: 0.4912\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 104\n","\tbatch: 100, loss: 0.8110, MAE: 0.8495\n","\tbatch: 200, loss: 3.8946, MAE: 1.9522\n","Training:\t loss: 1.2590, MAE: 0.8966\n","Evaluating:\t loss: 1.4444, MAE: 1.0878\n","train MSE: 1.2590, evaluate MSE: 1.4444\n","\n","train MAE: 0.8966, evaluate MAE: 1.0878\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 105\n","\tbatch: 100, loss: 0.0745, MAE: 0.2377\n","\tbatch: 200, loss: 0.1339, MAE: 0.3147\n","Training:\t loss: 1.1565, MAE: 0.6165\n","Evaluating:\t loss: 0.0875, MAE: 0.1582\n","train MSE: 1.1565, evaluate MSE: 0.0875\n","\n","train MAE: 0.6165, evaluate MAE: 0.1582\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 106\n","\tbatch: 100, loss: 0.6905, MAE: 0.2571\n","\tbatch: 200, loss: 0.0745, MAE: 0.2248\n","Training:\t loss: 1.0652, MAE: 0.7128\n","Evaluating:\t loss: 0.3134, MAE: 0.5130\n","train MSE: 1.0652, evaluate MSE: 0.3134\n","\n","train MAE: 0.7128, evaluate MAE: 0.5130\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 107\n","\tbatch: 100, loss: 0.0944, MAE: 0.2674\n","\tbatch: 200, loss: 0.0624, MAE: 0.2009\n","Training:\t loss: 1.1512, MAE: 0.7732\n","Evaluating:\t loss: 0.0467, MAE: 0.0790\n","train MSE: 1.1512, evaluate MSE: 0.0467\n","\n","train MAE: 0.7732, evaluate MAE: 0.0790\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 108\n","\tbatch: 100, loss: 0.0744, MAE: 0.2339\n","\tbatch: 200, loss: 0.0779, MAE: 0.2441\n","Training:\t loss: 1.2087, MAE: 0.6897\n","Evaluating:\t loss: 0.2265, MAE: 0.3977\n","train MSE: 1.2087, evaluate MSE: 0.2265\n","\n","train MAE: 0.6897, evaluate MAE: 0.3977\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 109\n","\tbatch: 100, loss: 0.0266, MAE: 0.1182\n","\tbatch: 200, loss: 0.5360, MAE: 0.7035\n","Training:\t loss: 1.0737, MAE: 0.8178\n","Evaluating:\t loss: 0.5040, MAE: 0.5181\n","train MSE: 1.0737, evaluate MSE: 0.5040\n","\n","train MAE: 0.8178, evaluate MAE: 0.5181\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 110\n","\tbatch: 100, loss: 5.2304, MAE: 2.2394\n","\tbatch: 200, loss: 0.1045, MAE: 0.2572\n","Training:\t loss: 1.0004, MAE: 0.7640\n","Evaluating:\t loss: 0.7898, MAE: 0.8513\n","train MSE: 1.0004, evaluate MSE: 0.7898\n","\n","train MAE: 0.7640, evaluate MAE: 0.8513\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 111\n","\tbatch: 100, loss: 1.1759, MAE: 1.0151\n","\tbatch: 200, loss: 10.5612, MAE: 3.1922\n","Training:\t loss: 93.6777, MAE: 3.5864\n","Evaluating:\t loss: 172.6570, MAE: 11.4015\n","train MSE: 93.6777, evaluate MSE: 172.6570\n","\n","train MAE: 3.5864, evaluate MAE: 11.4015\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 112\n","\tbatch: 100, loss: 5.4207, MAE: 0.8138\n","\tbatch: 200, loss: 0.7392, MAE: 0.5197\n","Training:\t loss: 11.4866, MAE: 1.4533\n","Evaluating:\t loss: 1.6155, MAE: 0.7766\n","train MSE: 11.4866, evaluate MSE: 1.6155\n","\n","train MAE: 1.4533, evaluate MAE: 0.7766\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 113\n","\tbatch: 100, loss: 1.4918, MAE: 1.0285\n","\tbatch: 200, loss: 0.4210, MAE: 0.4432\n","Training:\t loss: 1.1379, MAE: 0.4568\n","Evaluating:\t loss: 0.5328, MAE: 0.3305\n","train MSE: 1.1379, evaluate MSE: 0.5328\n","\n","train MAE: 0.4568, evaluate MAE: 0.3305\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 114\n","\tbatch: 100, loss: 0.3521, MAE: 0.3160\n","\tbatch: 200, loss: 0.1830, MAE: 0.2487\n","Training:\t loss: 0.4358, MAE: 0.3294\n","Evaluating:\t loss: 0.4608, MAE: 0.3193\n","train MSE: 0.4358, evaluate MSE: 0.4608\n","\n","train MAE: 0.3294, evaluate MAE: 0.3193\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 115\n","\tbatch: 100, loss: 0.2676, MAE: 0.2824\n","\tbatch: 200, loss: 0.2396, MAE: 0.2998\n","Training:\t loss: 0.2426, MAE: 0.2788\n","Evaluating:\t loss: 0.1584, MAE: 0.1963\n","train MSE: 0.2426, evaluate MSE: 0.1584\n","\n","train MAE: 0.2788, evaluate MAE: 0.1963\n","\n","--- time consumption (s): 27\n","\n","------------------------------\n","Epoch 116\n","\tbatch: 100, loss: 0.2008, MAE: 0.2271\n","\tbatch: 200, loss: 0.0762, MAE: 0.1621\n","Training:\t loss: 0.2300, MAE: 0.2495\n","Evaluating:\t loss: 0.1260, MAE: 0.1641\n","train MSE: 0.2300, evaluate MSE: 0.1260\n","\n","train MAE: 0.2495, evaluate MAE: 0.1641\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 117\n","\tbatch: 100, loss: 0.0954, MAE: 0.2318\n","\tbatch: 200, loss: 0.0731, MAE: 0.1731\n","Training:\t loss: 0.1358, MAE: 0.2224\n","Evaluating:\t loss: 0.1374, MAE: 0.2371\n","train MSE: 0.1358, evaluate MSE: 0.1374\n","\n","train MAE: 0.2224, evaluate MAE: 0.2371\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 118\n","\tbatch: 100, loss: 0.0860, MAE: 0.2158\n","\tbatch: 200, loss: 0.1314, MAE: 0.2117\n","Training:\t loss: 0.1602, MAE: 0.2350\n","Evaluating:\t loss: 0.1118, MAE: 0.1600\n","train MSE: 0.1602, evaluate MSE: 0.1118\n","\n","train MAE: 0.2350, evaluate MAE: 0.1600\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 119\n","\tbatch: 100, loss: 0.0352, MAE: 0.1363\n","\tbatch: 200, loss: 0.1471, MAE: 0.2842\n","Training:\t loss: 0.1443, MAE: 0.2458\n","Evaluating:\t loss: 0.1138, MAE: 0.1869\n","train MSE: 0.1443, evaluate MSE: 0.1138\n","\n","train MAE: 0.2458, evaluate MAE: 0.1869\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 120\n","\tbatch: 100, loss: 0.0353, MAE: 0.1150\n","\tbatch: 200, loss: 0.3507, MAE: 0.5605\n","Training:\t loss: 0.1497, MAE: 0.2900\n","Evaluating:\t loss: 0.2784, MAE: 0.4484\n","train MSE: 0.1497, evaluate MSE: 0.2784\n","\n","train MAE: 0.2900, evaluate MAE: 0.4484\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 121\n","\tbatch: 100, loss: 0.0682, MAE: 0.1897\n","\tbatch: 200, loss: 0.6846, MAE: 0.7913\n","Training:\t loss: 0.6350, MAE: 0.6025\n","Evaluating:\t loss: 0.1118, MAE: 0.2241\n","train MSE: 0.6350, evaluate MSE: 0.1118\n","\n","train MAE: 0.6025, evaluate MAE: 0.2241\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 122\n","\tbatch: 100, loss: 0.1311, MAE: 0.3024\n","\tbatch: 200, loss: 0.2159, MAE: 0.3440\n","Training:\t loss: 0.7417, MAE: 0.6241\n","Evaluating:\t loss: 0.0748, MAE: 0.1622\n","train MSE: 0.7417, evaluate MSE: 0.0748\n","\n","train MAE: 0.6241, evaluate MAE: 0.1622\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 123\n","\tbatch: 100, loss: 0.3160, MAE: 0.5176\n","\tbatch: 200, loss: 0.1763, MAE: 0.3479\n","Training:\t loss: 1.2107, MAE: 0.6818\n","Evaluating:\t loss: 0.2149, MAE: 0.3922\n","train MSE: 1.2107, evaluate MSE: 0.2149\n","\n","train MAE: 0.6818, evaluate MAE: 0.3922\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 124\n","\tbatch: 100, loss: 3.1301, MAE: 1.7500\n","\tbatch: 200, loss: 0.1898, MAE: 0.4024\n","Training:\t loss: 0.7757, MAE: 0.6416\n","Evaluating:\t loss: 2.0111, MAE: 1.3720\n","train MSE: 0.7757, evaluate MSE: 2.0111\n","\n","train MAE: 0.6416, evaluate MAE: 1.3720\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 125\n","\tbatch: 100, loss: 0.5219, MAE: 0.6679\n","\tbatch: 200, loss: 0.6051, MAE: 0.7280\n","Training:\t loss: 1.1375, MAE: 0.7421\n","Evaluating:\t loss: 0.0998, MAE: 0.1714\n","train MSE: 1.1375, evaluate MSE: 0.0998\n","\n","train MAE: 0.7421, evaluate MAE: 0.1714\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 126\n","\tbatch: 100, loss: 1.9327, MAE: 1.1177\n","\tbatch: 200, loss: 0.0856, MAE: 0.2676\n","Training:\t loss: 0.9711, MAE: 0.6782\n","Evaluating:\t loss: 0.5293, MAE: 0.6587\n","train MSE: 0.9711, evaluate MSE: 0.5293\n","\n","train MAE: 0.6782, evaluate MAE: 0.6587\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 127\n","\tbatch: 100, loss: 0.1878, MAE: 0.3833\n","\tbatch: 200, loss: 2.0956, MAE: 1.4134\n","Training:\t loss: 0.9075, MAE: 0.7868\n","Evaluating:\t loss: 0.9140, MAE: 0.9113\n","train MSE: 0.9075, evaluate MSE: 0.9140\n","\n","train MAE: 0.7868, evaluate MAE: 0.9113\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 128\n","\tbatch: 100, loss: 0.4930, MAE: 0.6482\n","\tbatch: 200, loss: 1.9611, MAE: 1.3354\n","Training:\t loss: 1.2860, MAE: 0.7421\n","Evaluating:\t loss: 1.2092, MAE: 1.0617\n","train MSE: 1.2860, evaluate MSE: 1.2092\n","\n","train MAE: 0.7421, evaluate MAE: 1.0617\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 129\n","\tbatch: 100, loss: 0.1880, MAE: 0.4103\n","\tbatch: 200, loss: 1.0806, MAE: 1.0088\n","Training:\t loss: 0.8636, MAE: 0.7425\n","Evaluating:\t loss: 0.0525, MAE: 0.1322\n","train MSE: 0.8636, evaluate MSE: 0.0525\n","\n","train MAE: 0.7425, evaluate MAE: 0.1322\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 130\n","\tbatch: 100, loss: 0.0264, MAE: 0.1082\n","\tbatch: 200, loss: 0.2618, MAE: 0.4899\n","Training:\t loss: 0.8826, MAE: 0.7060\n","Evaluating:\t loss: 0.5694, MAE: 0.7229\n","train MSE: 0.8826, evaluate MSE: 0.5694\n","\n","train MAE: 0.7060, evaluate MAE: 0.7229\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 131\n","\tbatch: 100, loss: 0.2975, MAE: 0.4361\n","\tbatch: 200, loss: 0.1504, MAE: 0.2841\n","Training:\t loss: 1.2613, MAE: 0.8531\n","Evaluating:\t loss: 0.7861, MAE: 0.8412\n","train MSE: 1.2613, evaluate MSE: 0.7861\n","\n","train MAE: 0.8531, evaluate MAE: 0.8412\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 132\n","\tbatch: 100, loss: 0.0857, MAE: 0.1951\n","\tbatch: 200, loss: 0.3102, MAE: 0.5369\n","Training:\t loss: 0.8066, MAE: 0.6321\n","Evaluating:\t loss: 1.0487, MAE: 0.9851\n","train MSE: 0.8066, evaluate MSE: 1.0487\n","\n","train MAE: 0.6321, evaluate MAE: 0.9851\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 133\n","\tbatch: 100, loss: 0.1121, MAE: 0.2865\n","\tbatch: 200, loss: 7.5479, MAE: 2.7081\n","Training:\t loss: 1.2608, MAE: 0.7937\n","Evaluating:\t loss: 0.1152, MAE: 0.2298\n","train MSE: 1.2608, evaluate MSE: 0.1152\n","\n","train MAE: 0.7937, evaluate MAE: 0.2298\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 134\n","\tbatch: 100, loss: 1.0699, MAE: 0.9471\n","\tbatch: 200, loss: 0.0639, MAE: 0.1816\n","Training:\t loss: 0.8282, MAE: 0.6760\n","Evaluating:\t loss: 0.5164, MAE: 0.6419\n","train MSE: 0.8282, evaluate MSE: 0.5164\n","\n","train MAE: 0.6760, evaluate MAE: 0.6419\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 135\n","\tbatch: 100, loss: 1.3573, MAE: 1.1366\n","\tbatch: 200, loss: 0.7177, MAE: 0.7632\n","Training:\t loss: 0.9698, MAE: 0.7718\n","Evaluating:\t loss: 0.0559, MAE: 0.1225\n","train MSE: 0.9698, evaluate MSE: 0.0559\n","\n","train MAE: 0.7718, evaluate MAE: 0.1225\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 136\n","\tbatch: 100, loss: 0.1850, MAE: 0.3541\n","\tbatch: 200, loss: 0.0461, MAE: 0.1855\n","Training:\t loss: 0.9132, MAE: 0.5355\n","Evaluating:\t loss: 0.0611, MAE: 0.1688\n","train MSE: 0.9132, evaluate MSE: 0.0611\n","\n","train MAE: 0.5355, evaluate MAE: 0.1688\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 137\n","\tbatch: 100, loss: 0.1586, MAE: 0.3000\n","\tbatch: 200, loss: 0.0784, MAE: 0.2253\n","Training:\t loss: 1.0128, MAE: 0.8020\n","Evaluating:\t loss: 1.3966, MAE: 1.1299\n","train MSE: 1.0128, evaluate MSE: 1.3966\n","\n","train MAE: 0.8020, evaluate MAE: 1.1299\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 138\n","\tbatch: 100, loss: 2.0715, MAE: 1.4262\n","\tbatch: 200, loss: 0.0723, MAE: 0.2339\n","Training:\t loss: 0.7155, MAE: 0.6718\n","Evaluating:\t loss: 1.6638, MAE: 1.2379\n","train MSE: 0.7155, evaluate MSE: 1.6638\n","\n","train MAE: 0.6718, evaluate MAE: 1.2379\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 139\n","\tbatch: 100, loss: 1.0585, MAE: 1.0070\n","\tbatch: 200, loss: 0.1327, MAE: 0.2153\n","Training:\t loss: 1.1219, MAE: 0.7592\n","Evaluating:\t loss: 0.0850, MAE: 0.1943\n","train MSE: 1.1219, evaluate MSE: 0.0850\n","\n","train MAE: 0.7592, evaluate MAE: 0.1943\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 140\n","\tbatch: 100, loss: 0.9642, MAE: 0.9720\n","\tbatch: 200, loss: 0.1825, MAE: 0.3944\n","Training:\t loss: 0.8001, MAE: 0.6792\n","Evaluating:\t loss: 19.3497, MAE: 4.2665\n","train MSE: 0.8001, evaluate MSE: 19.3497\n","\n","train MAE: 0.6792, evaluate MAE: 4.2665\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 141\n","\tbatch: 100, loss: 0.3393, MAE: 0.4469\n","\tbatch: 200, loss: 0.0742, MAE: 0.2327\n","Training:\t loss: 1.6553, MAE: 0.6609\n","Evaluating:\t loss: 0.2860, MAE: 0.3846\n","train MSE: 1.6553, evaluate MSE: 0.2860\n","\n","train MAE: 0.6609, evaluate MAE: 0.3846\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 142\n","\tbatch: 100, loss: 0.0966, MAE: 0.2363\n","\tbatch: 200, loss: 0.1612, MAE: 0.3686\n","Training:\t loss: 0.9356, MAE: 0.6839\n","Evaluating:\t loss: 0.2259, MAE: 0.4234\n","train MSE: 0.9356, evaluate MSE: 0.2259\n","\n","train MAE: 0.6839, evaluate MAE: 0.4234\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 143\n","\tbatch: 100, loss: 1.8208, MAE: 1.3344\n","\tbatch: 200, loss: 0.1033, MAE: 0.2671\n","Training:\t loss: 0.6933, MAE: 0.6691\n","Evaluating:\t loss: 0.1391, MAE: 0.3038\n","train MSE: 0.6933, evaluate MSE: 0.1391\n","\n","train MAE: 0.6691, evaluate MAE: 0.3038\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 144\n","\tbatch: 100, loss: 1.1437, MAE: 0.9041\n","\tbatch: 200, loss: 0.3535, MAE: 0.5838\n","Training:\t loss: 0.8352, MAE: 0.7175\n","Evaluating:\t loss: 0.9457, MAE: 0.9401\n","train MSE: 0.8352, evaluate MSE: 0.9457\n","\n","train MAE: 0.7175, evaluate MAE: 0.9401\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 145\n","\tbatch: 100, loss: 0.1093, MAE: 0.2997\n","\tbatch: 200, loss: 0.3644, MAE: 0.5835\n","Training:\t loss: 0.8452, MAE: 0.6975\n","Evaluating:\t loss: 1.0052, MAE: 0.9123\n","train MSE: 0.8452, evaluate MSE: 1.0052\n","\n","train MAE: 0.6975, evaluate MAE: 0.9123\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 146\n","\tbatch: 100, loss: 0.4737, MAE: 0.6429\n","\tbatch: 200, loss: 0.1177, MAE: 0.3052\n","Training:\t loss: 0.9706, MAE: 0.7361\n","Evaluating:\t loss: 9.2102, MAE: 2.9700\n","train MSE: 0.9706, evaluate MSE: 9.2102\n","\n","train MAE: 0.7361, evaluate MAE: 2.9700\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 147\n","\tbatch: 100, loss: 0.0497, MAE: 0.2049\n","\tbatch: 200, loss: 2.5853, MAE: 1.5799\n","Training:\t loss: 0.6258, MAE: 0.4638\n","Evaluating:\t loss: 0.1174, MAE: 0.2854\n","train MSE: 0.6258, evaluate MSE: 0.1174\n","\n","train MAE: 0.4638, evaluate MAE: 0.2854\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 148\n","\tbatch: 100, loss: 0.0498, MAE: 0.1695\n","\tbatch: 200, loss: 0.0933, MAE: 0.2442\n","Training:\t loss: 0.8702, MAE: 0.7448\n","Evaluating:\t loss: 0.1267, MAE: 0.2729\n","train MSE: 0.8702, evaluate MSE: 0.1267\n","\n","train MAE: 0.7448, evaluate MAE: 0.2729\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 149\n","\tbatch: 100, loss: 0.0318, MAE: 0.1263\n","\tbatch: 200, loss: 0.0797, MAE: 0.2648\n","Training:\t loss: 0.6314, MAE: 0.5561\n","Evaluating:\t loss: 0.2591, MAE: 0.4867\n","train MSE: 0.6314, evaluate MSE: 0.2591\n","\n","train MAE: 0.5561, evaluate MAE: 0.4867\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 150\n","\tbatch: 100, loss: 0.0308, MAE: 0.1201\n","\tbatch: 200, loss: 0.0272, MAE: 0.1219\n","Training:\t loss: 0.9899, MAE: 0.5548\n","Evaluating:\t loss: 4.3458, MAE: 2.0311\n","train MSE: 0.9899, evaluate MSE: 4.3458\n","\n","train MAE: 0.5548, evaluate MAE: 2.0311\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 151\n","\tbatch: 100, loss: 1.2946, MAE: 1.1209\n","\tbatch: 200, loss: 0.0300, MAE: 0.1357\n","Training:\t loss: 0.6966, MAE: 0.5530\n","Evaluating:\t loss: 0.2936, MAE: 0.5185\n","train MSE: 0.6966, evaluate MSE: 0.2936\n","\n","train MAE: 0.5530, evaluate MAE: 0.5185\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 152\n","\tbatch: 100, loss: 0.1075, MAE: 0.2632\n","\tbatch: 200, loss: 0.0931, MAE: 0.1897\n","Training:\t loss: 0.8487, MAE: 0.6040\n","Evaluating:\t loss: 1.1664, MAE: 1.0604\n","train MSE: 0.8487, evaluate MSE: 1.1664\n","\n","train MAE: 0.6040, evaluate MAE: 1.0604\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 153\n","\tbatch: 100, loss: 0.5328, MAE: 0.6873\n","\tbatch: 200, loss: 0.6217, MAE: 0.7230\n","Training:\t loss: 0.7321, MAE: 0.7249\n","Evaluating:\t loss: 1.3690, MAE: 1.1200\n","train MSE: 0.7321, evaluate MSE: 1.3690\n","\n","train MAE: 0.7249, evaluate MAE: 1.1200\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 154\n","\tbatch: 100, loss: 0.0490, MAE: 0.1709\n","\tbatch: 200, loss: 0.7925, MAE: 0.8749\n","Training:\t loss: 0.9571, MAE: 0.6899\n","Evaluating:\t loss: 0.8925, MAE: 0.8693\n","train MSE: 0.9571, evaluate MSE: 0.8925\n","\n","train MAE: 0.6899, evaluate MAE: 0.8693\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 155\n","\tbatch: 100, loss: 4.1799, MAE: 2.0303\n","\tbatch: 200, loss: 0.3072, MAE: 0.5247\n","Training:\t loss: 0.6941, MAE: 0.6288\n","Evaluating:\t loss: 0.4177, MAE: 0.5791\n","train MSE: 0.6941, evaluate MSE: 0.4177\n","\n","train MAE: 0.6288, evaluate MAE: 0.5791\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 156\n","\tbatch: 100, loss: 0.3669, MAE: 0.5779\n","\tbatch: 200, loss: 2.6932, MAE: 1.6265\n","Training:\t loss: 0.6629, MAE: 0.6341\n","Evaluating:\t loss: 0.8307, MAE: 0.8876\n","train MSE: 0.6629, evaluate MSE: 0.8307\n","\n","train MAE: 0.6341, evaluate MAE: 0.8876\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 157\n","\tbatch: 100, loss: 7.3067, MAE: 2.6734\n","\tbatch: 200, loss: 0.0191, MAE: 0.0837\n","Training:\t loss: 0.7391, MAE: 0.6605\n","Evaluating:\t loss: 0.8187, MAE: 0.8671\n","train MSE: 0.7391, evaluate MSE: 0.8187\n","\n","train MAE: 0.6605, evaluate MAE: 0.8671\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 158\n","\tbatch: 100, loss: 0.1596, MAE: 0.3716\n","\tbatch: 200, loss: 0.1495, MAE: 0.3498\n","Training:\t loss: 0.8270, MAE: 0.5833\n","Evaluating:\t loss: 0.0411, MAE: 0.1272\n","train MSE: 0.8270, evaluate MSE: 0.0411\n","\n","train MAE: 0.5833, evaluate MAE: 0.1272\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 159\n","\tbatch: 100, loss: 0.5641, MAE: 0.5886\n","\tbatch: 200, loss: 2.7760, MAE: 1.6458\n","Training:\t loss: 0.5733, MAE: 0.5113\n","Evaluating:\t loss: 0.0315, MAE: 0.1130\n","train MSE: 0.5733, evaluate MSE: 0.0315\n","\n","train MAE: 0.5113, evaluate MAE: 0.1130\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 160\n","\tbatch: 100, loss: 0.3310, MAE: 0.5474\n","\tbatch: 200, loss: 0.6154, MAE: 0.6168\n","Training:\t loss: 0.7939, MAE: 0.6937\n","Evaluating:\t loss: 0.6722, MAE: 0.6840\n","train MSE: 0.7939, evaluate MSE: 0.6722\n","\n","train MAE: 0.6937, evaluate MAE: 0.6840\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 161\n","\tbatch: 100, loss: 0.3257, MAE: 0.3805\n","\tbatch: 200, loss: 0.2046, MAE: 0.1643\n","Training:\t loss: 15.1375, MAE: 1.6017\n","Evaluating:\t loss: 0.1350, MAE: 0.2002\n","train MSE: 15.1375, evaluate MSE: 0.1350\n","\n","train MAE: 1.6017, evaluate MAE: 0.2002\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 162\n","\tbatch: 100, loss: 0.0350, MAE: 0.1137\n","\tbatch: 200, loss: 0.0274, MAE: 0.1062\n","Training:\t loss: 0.0571, MAE: 0.1309\n","Evaluating:\t loss: 0.0953, MAE: 0.1160\n","train MSE: 0.0571, evaluate MSE: 0.0953\n","\n","train MAE: 0.1309, evaluate MAE: 0.1160\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 163\n","\tbatch: 100, loss: 0.0292, MAE: 0.0983\n","\tbatch: 200, loss: 0.0256, MAE: 0.1051\n","Training:\t loss: 0.0363, MAE: 0.1106\n","Evaluating:\t loss: 0.0700, MAE: 0.1104\n","train MSE: 0.0363, evaluate MSE: 0.0700\n","\n","train MAE: 0.1106, evaluate MAE: 0.1104\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 164\n","\tbatch: 100, loss: 0.0410, MAE: 0.0953\n","\tbatch: 200, loss: 0.0280, MAE: 0.1124\n","Training:\t loss: 0.0237, MAE: 0.0939\n","Evaluating:\t loss: 0.0306, MAE: 0.0761\n","train MSE: 0.0237, evaluate MSE: 0.0306\n","\n","train MAE: 0.0939, evaluate MAE: 0.0761\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 165\n","\tbatch: 100, loss: 0.0296, MAE: 0.0919\n","\tbatch: 200, loss: 0.0168, MAE: 0.0911\n","Training:\t loss: 0.0248, MAE: 0.1054\n","Evaluating:\t loss: 0.0639, MAE: 0.0848\n","train MSE: 0.0248, evaluate MSE: 0.0639\n","\n","train MAE: 0.1054, evaluate MAE: 0.0848\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 166\n","\tbatch: 100, loss: 0.0235, MAE: 0.0972\n","\tbatch: 200, loss: 0.1762, MAE: 0.4044\n","Training:\t loss: 0.1224, MAE: 0.2267\n","Evaluating:\t loss: 0.0665, MAE: 0.1734\n","train MSE: 0.1224, evaluate MSE: 0.0665\n","\n","train MAE: 0.2267, evaluate MAE: 0.1734\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 167\n","\tbatch: 100, loss: 0.4626, MAE: 0.6617\n","\tbatch: 200, loss: 0.1650, MAE: 0.3671\n","Training:\t loss: 0.3161, MAE: 0.4152\n","Evaluating:\t loss: 0.0980, MAE: 0.2623\n","train MSE: 0.3161, evaluate MSE: 0.0980\n","\n","train MAE: 0.4152, evaluate MAE: 0.2623\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 168\n","\tbatch: 100, loss: 0.8472, MAE: 0.9006\n","\tbatch: 200, loss: 0.7742, MAE: 0.8700\n","Training:\t loss: 0.6169, MAE: 0.6230\n","Evaluating:\t loss: 0.1682, MAE: 0.3081\n","train MSE: 0.6169, evaluate MSE: 0.1682\n","\n","train MAE: 0.6230, evaluate MAE: 0.3081\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 169\n","\tbatch: 100, loss: 0.1927, MAE: 0.3835\n","\tbatch: 200, loss: 0.2227, MAE: 0.4412\n","Training:\t loss: 0.5424, MAE: 0.5368\n","Evaluating:\t loss: 0.1016, MAE: 0.2696\n","train MSE: 0.5424, evaluate MSE: 0.1016\n","\n","train MAE: 0.5368, evaluate MAE: 0.2696\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 170\n","\tbatch: 100, loss: 0.4231, MAE: 0.6317\n","\tbatch: 200, loss: 0.0751, MAE: 0.2505\n","Training:\t loss: 0.7805, MAE: 0.5570\n","Evaluating:\t loss: 0.1359, MAE: 0.3099\n","train MSE: 0.7805, evaluate MSE: 0.1359\n","\n","train MAE: 0.5570, evaluate MAE: 0.3099\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 171\n","\tbatch: 100, loss: 0.0503, MAE: 0.1877\n","\tbatch: 200, loss: 0.0328, MAE: 0.1403\n","Training:\t loss: 0.4772, MAE: 0.5468\n","Evaluating:\t loss: 0.5088, MAE: 0.6905\n","train MSE: 0.4772, evaluate MSE: 0.5088\n","\n","train MAE: 0.5468, evaluate MAE: 0.6905\n","\n","--- time consumption (s): 27\n","\n","------------------------------\n","Epoch 172\n","\tbatch: 100, loss: 0.5132, MAE: 0.6942\n","\tbatch: 200, loss: 0.5301, MAE: 0.6983\n","Training:\t loss: 0.7206, MAE: 0.5906\n","Evaluating:\t loss: 0.4973, MAE: 0.6625\n","train MSE: 0.7206, evaluate MSE: 0.4973\n","\n","train MAE: 0.5906, evaluate MAE: 0.6625\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 173\n","\tbatch: 100, loss: 0.0283, MAE: 0.1316\n","\tbatch: 200, loss: 0.6867, MAE: 0.6352\n","Training:\t loss: 0.8085, MAE: 0.7627\n","Evaluating:\t loss: 0.2200, MAE: 0.2937\n","train MSE: 0.8085, evaluate MSE: 0.2200\n","\n","train MAE: 0.7627, evaluate MAE: 0.2937\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 174\n","\tbatch: 100, loss: 0.4481, MAE: 0.5680\n","\tbatch: 200, loss: 0.2276, MAE: 0.4661\n","Training:\t loss: 0.7019, MAE: 0.5907\n","Evaluating:\t loss: 2.1109, MAE: 1.4164\n","train MSE: 0.7019, evaluate MSE: 2.1109\n","\n","train MAE: 0.5907, evaluate MAE: 1.4164\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 175\n","\tbatch: 100, loss: 1.2897, MAE: 1.1048\n","\tbatch: 200, loss: 0.2443, MAE: 0.4384\n","Training:\t loss: 0.4644, MAE: 0.5291\n","Evaluating:\t loss: 0.0372, MAE: 0.1173\n","train MSE: 0.4644, evaluate MSE: 0.0372\n","\n","train MAE: 0.5291, evaluate MAE: 0.1173\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 176\n","\tbatch: 100, loss: 0.5023, MAE: 0.6910\n","\tbatch: 200, loss: 0.6143, MAE: 0.7453\n","Training:\t loss: 0.6000, MAE: 0.6321\n","Evaluating:\t loss: 0.1092, MAE: 0.2962\n","train MSE: 0.6000, evaluate MSE: 0.1092\n","\n","train MAE: 0.6321, evaluate MAE: 0.2962\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 177\n","\tbatch: 100, loss: 0.1821, MAE: 0.4094\n","\tbatch: 200, loss: 0.0234, MAE: 0.1313\n","Training:\t loss: 0.5650, MAE: 0.5255\n","Evaluating:\t loss: 0.0408, MAE: 0.1194\n","train MSE: 0.5650, evaluate MSE: 0.0408\n","\n","train MAE: 0.5255, evaluate MAE: 0.1194\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 178\n","\tbatch: 100, loss: 0.0164, MAE: 0.0930\n","\tbatch: 200, loss: 0.2232, MAE: 0.4431\n","Training:\t loss: 0.6368, MAE: 0.5231\n","Evaluating:\t loss: 3.0329, MAE: 1.7294\n","train MSE: 0.6368, evaluate MSE: 3.0329\n","\n","train MAE: 0.5231, evaluate MAE: 1.7294\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 179\n","\tbatch: 100, loss: 0.2324, MAE: 0.4700\n","\tbatch: 200, loss: 0.0753, MAE: 0.2527\n","Training:\t loss: 0.8016, MAE: 0.6005\n","Evaluating:\t loss: 0.7423, MAE: 0.8107\n","train MSE: 0.8016, evaluate MSE: 0.7423\n","\n","train MAE: 0.6005, evaluate MAE: 0.8107\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 180\n","\tbatch: 100, loss: 0.6761, MAE: 0.8019\n","\tbatch: 200, loss: 1.1918, MAE: 1.0810\n","Training:\t loss: 0.6295, MAE: 0.5478\n","Evaluating:\t loss: 0.7188, MAE: 0.7853\n","train MSE: 0.6295, evaluate MSE: 0.7188\n","\n","train MAE: 0.5478, evaluate MAE: 0.7853\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 181\n","\tbatch: 100, loss: 0.0192, MAE: 0.0865\n","\tbatch: 200, loss: 0.5995, MAE: 0.7437\n","Training:\t loss: 0.5257, MAE: 0.5833\n","Evaluating:\t loss: 0.1754, MAE: 0.3817\n","train MSE: 0.5257, evaluate MSE: 0.1754\n","\n","train MAE: 0.5833, evaluate MAE: 0.3817\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 182\n","\tbatch: 100, loss: 0.4241, MAE: 0.6208\n","\tbatch: 200, loss: 0.1137, MAE: 0.2975\n","Training:\t loss: 0.5549, MAE: 0.4885\n","Evaluating:\t loss: 3.0501, MAE: 1.6820\n","train MSE: 0.5549, evaluate MSE: 3.0501\n","\n","train MAE: 0.4885, evaluate MAE: 1.6820\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 183\n","\tbatch: 100, loss: 0.0451, MAE: 0.1436\n","\tbatch: 200, loss: 0.2254, MAE: 0.3543\n","Training:\t loss: 2.0603, MAE: 0.9379\n","Evaluating:\t loss: 1.5791, MAE: 1.0798\n","train MSE: 2.0603, evaluate MSE: 1.5791\n","\n","train MAE: 0.9379, evaluate MAE: 1.0798\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 184\n","\tbatch: 100, loss: 0.0163, MAE: 0.1058\n","\tbatch: 200, loss: 0.0616, MAE: 0.1662\n","Training:\t loss: 0.0663, MAE: 0.1457\n","Evaluating:\t loss: 0.0179, MAE: 0.0646\n","train MSE: 0.0663, evaluate MSE: 0.0179\n","\n","train MAE: 0.1457, evaluate MAE: 0.0646\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 185\n","\tbatch: 100, loss: 0.0179, MAE: 0.1147\n","\tbatch: 200, loss: 0.0465, MAE: 0.1955\n","Training:\t loss: 0.2150, MAE: 0.2852\n","Evaluating:\t loss: 0.9728, MAE: 0.9673\n","train MSE: 0.2150, evaluate MSE: 0.9728\n","\n","train MAE: 0.2852, evaluate MAE: 0.9673\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 186\n","\tbatch: 100, loss: 0.6274, MAE: 0.7623\n","\tbatch: 200, loss: 0.0131, MAE: 0.0831\n","Training:\t loss: 0.5493, MAE: 0.6043\n","Evaluating:\t loss: 0.2934, MAE: 0.5060\n","train MSE: 0.5493, evaluate MSE: 0.2934\n","\n","train MAE: 0.6043, evaluate MAE: 0.5060\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 187\n","\tbatch: 100, loss: 2.0489, MAE: 1.4212\n","\tbatch: 200, loss: 0.2378, MAE: 0.4605\n","Training:\t loss: 0.5518, MAE: 0.6120\n","Evaluating:\t loss: 0.0503, MAE: 0.1340\n","train MSE: 0.5518, evaluate MSE: 0.0503\n","\n","train MAE: 0.6120, evaluate MAE: 0.1340\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 188\n","\tbatch: 100, loss: 0.0917, MAE: 0.2826\n","\tbatch: 200, loss: 0.0962, MAE: 0.2642\n","Training:\t loss: 0.5388, MAE: 0.5372\n","Evaluating:\t loss: 0.2443, MAE: 0.4351\n","train MSE: 0.5388, evaluate MSE: 0.2443\n","\n","train MAE: 0.5372, evaluate MAE: 0.4351\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 189\n","\tbatch: 100, loss: 0.0222, MAE: 0.0886\n","\tbatch: 200, loss: 0.0323, MAE: 0.1566\n","Training:\t loss: 0.5754, MAE: 0.5789\n","Evaluating:\t loss: 0.0341, MAE: 0.1195\n","train MSE: 0.5754, evaluate MSE: 0.0341\n","\n","train MAE: 0.5789, evaluate MAE: 0.1195\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 190\n","\tbatch: 100, loss: 0.3310, MAE: 0.4718\n","\tbatch: 200, loss: 0.0218, MAE: 0.1024\n","Training:\t loss: 0.6541, MAE: 0.5650\n","Evaluating:\t loss: 0.0180, MAE: 0.0652\n","train MSE: 0.6541, evaluate MSE: 0.0180\n","\n","train MAE: 0.5650, evaluate MAE: 0.0652\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 191\n","\tbatch: 100, loss: 0.0168, MAE: 0.0811\n","\tbatch: 200, loss: 0.2910, MAE: 0.3716\n","Training:\t loss: 0.5214, MAE: 0.5277\n","Evaluating:\t loss: 0.0286, MAE: 0.0850\n","train MSE: 0.5214, evaluate MSE: 0.0286\n","\n","train MAE: 0.5277, evaluate MAE: 0.0850\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 192\n","\tbatch: 100, loss: 0.1412, MAE: 0.3103\n","\tbatch: 200, loss: 2.0376, MAE: 1.3516\n","Training:\t loss: 0.5386, MAE: 0.4602\n","Evaluating:\t loss: 0.2885, MAE: 0.4758\n","train MSE: 0.5386, evaluate MSE: 0.2885\n","\n","train MAE: 0.4602, evaluate MAE: 0.4758\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 193\n","\tbatch: 100, loss: 0.2298, MAE: 0.2928\n","\tbatch: 200, loss: 0.1676, MAE: 0.3823\n","Training:\t loss: 0.7061, MAE: 0.6115\n","Evaluating:\t loss: 0.0446, MAE: 0.1513\n","train MSE: 0.7061, evaluate MSE: 0.0446\n","\n","train MAE: 0.6115, evaluate MAE: 0.1513\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 194\n","\tbatch: 100, loss: 0.2977, MAE: 0.5030\n","\tbatch: 200, loss: 0.0204, MAE: 0.1179\n","Training:\t loss: 0.4845, MAE: 0.4605\n","Evaluating:\t loss: 4.0019, MAE: 1.8952\n","train MSE: 0.4845, evaluate MSE: 4.0019\n","\n","train MAE: 0.4605, evaluate MAE: 1.8952\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 195\n","\tbatch: 100, loss: 0.0151, MAE: 0.0944\n","\tbatch: 200, loss: 0.3078, MAE: 0.5161\n","Training:\t loss: 0.6029, MAE: 0.5540\n","Evaluating:\t loss: 0.1511, MAE: 0.3063\n","train MSE: 0.6029, evaluate MSE: 0.1511\n","\n","train MAE: 0.5540, evaluate MAE: 0.3063\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 196\n","\tbatch: 100, loss: 0.0711, MAE: 0.2282\n","\tbatch: 200, loss: 0.6576, MAE: 0.4857\n","Training:\t loss: 19.3368, MAE: 1.8603\n","Evaluating:\t loss: 0.1490, MAE: 0.2107\n","train MSE: 19.3368, evaluate MSE: 0.1490\n","\n","train MAE: 1.8603, evaluate MAE: 0.2107\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 197\n","\tbatch: 100, loss: 0.0488, MAE: 0.1107\n","\tbatch: 200, loss: 0.0433, MAE: 0.1115\n","Training:\t loss: 0.0682, MAE: 0.1410\n","Evaluating:\t loss: 0.0491, MAE: 0.0983\n","train MSE: 0.0682, evaluate MSE: 0.0491\n","\n","train MAE: 0.1410, evaluate MAE: 0.0983\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 198\n","\tbatch: 100, loss: 0.0223, MAE: 0.0932\n","\tbatch: 200, loss: 0.0214, MAE: 0.0891\n","Training:\t loss: 0.0278, MAE: 0.0956\n","Evaluating:\t loss: 0.0328, MAE: 0.0893\n","train MSE: 0.0278, evaluate MSE: 0.0328\n","\n","train MAE: 0.0956, evaluate MAE: 0.0893\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 199\n","\tbatch: 100, loss: 0.0157, MAE: 0.0885\n","\tbatch: 200, loss: 0.0131, MAE: 0.0834\n","Training:\t loss: 0.0194, MAE: 0.0831\n","Evaluating:\t loss: 0.0305, MAE: 0.0880\n","train MSE: 0.0194, evaluate MSE: 0.0305\n","\n","train MAE: 0.0831, evaluate MAE: 0.0880\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 200\n","\tbatch: 100, loss: 0.0153, MAE: 0.0719\n","\tbatch: 200, loss: 0.0141, MAE: 0.0734\n","Training:\t loss: 0.0156, MAE: 0.0751\n","Evaluating:\t loss: 0.0302, MAE: 0.0790\n","train MSE: 0.0156, evaluate MSE: 0.0302\n","\n","train MAE: 0.0751, evaluate MAE: 0.0790\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 201\n","\tbatch: 100, loss: 0.0236, MAE: 0.0724\n","\tbatch: 200, loss: 0.0072, MAE: 0.0588\n","Training:\t loss: 0.0141, MAE: 0.0729\n","Evaluating:\t loss: 0.0193, MAE: 0.0723\n","train MSE: 0.0141, evaluate MSE: 0.0193\n","\n","train MAE: 0.0729, evaluate MAE: 0.0723\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 202\n","\tbatch: 100, loss: 0.0183, MAE: 0.0891\n","\tbatch: 200, loss: 0.0147, MAE: 0.0711\n","Training:\t loss: 0.0144, MAE: 0.0729\n","Evaluating:\t loss: 0.0296, MAE: 0.0721\n","train MSE: 0.0144, evaluate MSE: 0.0296\n","\n","train MAE: 0.0729, evaluate MAE: 0.0721\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 203\n","\tbatch: 100, loss: 0.0074, MAE: 0.0497\n","\tbatch: 200, loss: 0.0106, MAE: 0.0587\n","Training:\t loss: 0.0128, MAE: 0.0731\n","Evaluating:\t loss: 0.0233, MAE: 0.0824\n","train MSE: 0.0128, evaluate MSE: 0.0233\n","\n","train MAE: 0.0731, evaluate MAE: 0.0824\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 204\n","\tbatch: 100, loss: 0.0091, MAE: 0.0745\n","\tbatch: 200, loss: 0.0853, MAE: 0.2720\n","Training:\t loss: 0.0372, MAE: 0.1341\n","Evaluating:\t loss: 0.0151, MAE: 0.0582\n","train MSE: 0.0372, evaluate MSE: 0.0151\n","\n","train MAE: 0.1341, evaluate MAE: 0.0582\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 205\n","\tbatch: 100, loss: 0.0324, MAE: 0.1555\n","\tbatch: 200, loss: 0.0423, MAE: 0.1927\n","Training:\t loss: 0.3585, MAE: 0.3525\n","Evaluating:\t loss: 1.8242, MAE: 1.3236\n","train MSE: 0.3585, evaluate MSE: 1.8242\n","\n","train MAE: 0.3525, evaluate MAE: 1.3236\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 206\n","\tbatch: 100, loss: 0.1544, MAE: 0.3709\n","\tbatch: 200, loss: 0.0715, MAE: 0.2518\n","Training:\t loss: 0.3577, MAE: 0.4437\n","Evaluating:\t loss: 0.0641, MAE: 0.1749\n","train MSE: 0.3577, evaluate MSE: 0.0641\n","\n","train MAE: 0.4437, evaluate MAE: 0.1749\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 207\n","\tbatch: 100, loss: 0.4524, MAE: 0.6560\n","\tbatch: 200, loss: 0.1140, MAE: 0.3156\n","Training:\t loss: 0.4595, MAE: 0.5075\n","Evaluating:\t loss: 0.1594, MAE: 0.3766\n","train MSE: 0.4595, evaluate MSE: 0.1594\n","\n","train MAE: 0.5075, evaluate MAE: 0.3766\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 208\n","\tbatch: 100, loss: 0.2247, MAE: 0.4559\n","\tbatch: 200, loss: 0.1258, MAE: 0.3405\n","Training:\t loss: 0.3614, MAE: 0.4746\n","Evaluating:\t loss: 0.8485, MAE: 0.9007\n","train MSE: 0.3614, evaluate MSE: 0.8485\n","\n","train MAE: 0.4746, evaluate MAE: 0.9007\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 209\n","\tbatch: 100, loss: 0.0144, MAE: 0.0849\n","\tbatch: 200, loss: 0.0238, MAE: 0.1100\n","Training:\t loss: 0.4710, MAE: 0.5339\n","Evaluating:\t loss: 3.2455, MAE: 1.7578\n","train MSE: 0.4710, evaluate MSE: 3.2455\n","\n","train MAE: 0.5339, evaluate MAE: 1.7578\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 210\n","\tbatch: 100, loss: 0.0110, MAE: 0.0604\n","\tbatch: 200, loss: 3.7447, MAE: 1.8901\n","Training:\t loss: 0.5857, MAE: 0.5493\n","Evaluating:\t loss: 0.0460, MAE: 0.1412\n","train MSE: 0.5857, evaluate MSE: 0.0460\n","\n","train MAE: 0.5493, evaluate MAE: 0.1412\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 211\n","\tbatch: 100, loss: 0.1918, MAE: 0.4240\n","\tbatch: 200, loss: 0.0431, MAE: 0.1515\n","Training:\t loss: 0.4540, MAE: 0.5055\n","Evaluating:\t loss: 0.3636, MAE: 0.5498\n","train MSE: 0.4540, evaluate MSE: 0.3636\n","\n","train MAE: 0.5055, evaluate MAE: 0.5498\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 212\n","\tbatch: 100, loss: 0.0224, MAE: 0.1152\n","\tbatch: 200, loss: 0.1381, MAE: 0.3182\n","Training:\t loss: 0.4795, MAE: 0.4045\n","Evaluating:\t loss: 0.0529, MAE: 0.1422\n","train MSE: 0.4795, evaluate MSE: 0.0529\n","\n","train MAE: 0.4045, evaluate MAE: 0.1422\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 213\n","\tbatch: 100, loss: 1.7061, MAE: 1.2567\n","\tbatch: 200, loss: 0.1385, MAE: 0.3273\n","Training:\t loss: 0.5415, MAE: 0.5430\n","Evaluating:\t loss: 0.0359, MAE: 0.1268\n","train MSE: 0.5415, evaluate MSE: 0.0359\n","\n","train MAE: 0.5430, evaluate MAE: 0.1268\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 214\n","\tbatch: 100, loss: 0.9690, MAE: 0.9611\n","\tbatch: 200, loss: 0.0461, MAE: 0.1750\n","Training:\t loss: 0.4151, MAE: 0.4575\n","Evaluating:\t loss: 0.0553, MAE: 0.1639\n","train MSE: 0.4151, evaluate MSE: 0.0553\n","\n","train MAE: 0.4575, evaluate MAE: 0.1639\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 215\n","\tbatch: 100, loss: 0.9286, MAE: 0.9383\n","\tbatch: 200, loss: 0.3618, MAE: 0.5877\n","Training:\t loss: 0.4311, MAE: 0.4074\n","Evaluating:\t loss: 0.0828, MAE: 0.2503\n","train MSE: 0.4311, evaluate MSE: 0.0828\n","\n","train MAE: 0.4074, evaluate MAE: 0.2503\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 216\n","\tbatch: 100, loss: 0.0307, MAE: 0.1334\n","\tbatch: 200, loss: 0.0573, MAE: 0.2089\n","Training:\t loss: 0.4591, MAE: 0.5082\n","Evaluating:\t loss: 0.0448, MAE: 0.1817\n","train MSE: 0.4591, evaluate MSE: 0.0448\n","\n","train MAE: 0.5082, evaluate MAE: 0.1817\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 217\n","\tbatch: 100, loss: 0.0924, MAE: 0.1792\n","\tbatch: 200, loss: 0.2901, MAE: 0.4335\n","Training:\t loss: 0.6887, MAE: 0.5407\n","Evaluating:\t loss: 0.0192, MAE: 0.0805\n","train MSE: 0.6887, evaluate MSE: 0.0192\n","\n","train MAE: 0.5407, evaluate MAE: 0.0805\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 218\n","\tbatch: 100, loss: 0.2292, MAE: 0.4307\n","\tbatch: 200, loss: 0.1994, MAE: 0.3961\n","Training:\t loss: 0.2579, MAE: 0.3639\n","Evaluating:\t loss: 0.1154, MAE: 0.3033\n","train MSE: 0.2579, evaluate MSE: 0.1154\n","\n","train MAE: 0.3639, evaluate MAE: 0.3033\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 219\n","\tbatch: 100, loss: 0.1373, MAE: 0.2744\n","\tbatch: 200, loss: 0.4841, MAE: 0.6471\n","Training:\t loss: 0.6250, MAE: 0.5857\n","Evaluating:\t loss: 0.0820, MAE: 0.1759\n","train MSE: 0.6250, evaluate MSE: 0.0820\n","\n","train MAE: 0.5857, evaluate MAE: 0.1759\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 220\n","\tbatch: 100, loss: 0.6776, MAE: 0.8007\n","\tbatch: 200, loss: 0.0504, MAE: 0.1551\n","Training:\t loss: 0.3992, MAE: 0.5116\n","Evaluating:\t loss: 1.2631, MAE: 1.0635\n","train MSE: 0.3992, evaluate MSE: 1.2631\n","\n","train MAE: 0.5116, evaluate MAE: 1.0635\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 221\n","\tbatch: 100, loss: 0.1491, MAE: 0.3276\n","\tbatch: 200, loss: 0.2339, MAE: 0.4717\n","Training:\t loss: 0.5928, MAE: 0.5690\n","Evaluating:\t loss: 0.4615, MAE: 0.6291\n","train MSE: 0.5928, evaluate MSE: 0.4615\n","\n","train MAE: 0.5690, evaluate MAE: 0.6291\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 222\n","\tbatch: 100, loss: 0.0248, MAE: 0.1420\n","\tbatch: 200, loss: 0.0585, MAE: 0.1979\n","Training:\t loss: 0.4085, MAE: 0.4215\n","Evaluating:\t loss: 0.1198, MAE: 0.2884\n","train MSE: 0.4085, evaluate MSE: 0.1198\n","\n","train MAE: 0.4215, evaluate MAE: 0.2884\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 223\n","\tbatch: 100, loss: 1.1690, MAE: 1.0675\n","\tbatch: 200, loss: 3.1965, MAE: 1.6060\n","Training:\t loss: 2.5110, MAE: 0.9116\n","Evaluating:\t loss: 0.3217, MAE: 0.3692\n","train MSE: 2.5110, evaluate MSE: 0.3217\n","\n","train MAE: 0.9116, evaluate MAE: 0.3692\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 224\n","\tbatch: 100, loss: 0.0071, MAE: 0.0625\n","\tbatch: 200, loss: 0.0185, MAE: 0.0595\n","Training:\t loss: 0.0538, MAE: 0.1210\n","Evaluating:\t loss: 0.0200, MAE: 0.0632\n","train MSE: 0.0538, evaluate MSE: 0.0200\n","\n","train MAE: 0.1210, evaluate MAE: 0.0632\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 225\n","\tbatch: 100, loss: 0.0127, MAE: 0.0871\n","\tbatch: 200, loss: 0.0102, MAE: 0.0670\n","Training:\t loss: 0.0101, MAE: 0.0674\n","Evaluating:\t loss: 0.0126, MAE: 0.0616\n","train MSE: 0.0101, evaluate MSE: 0.0126\n","\n","train MAE: 0.0674, evaluate MAE: 0.0616\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 226\n","\tbatch: 100, loss: 0.0746, MAE: 0.2535\n","\tbatch: 200, loss: 0.0705, MAE: 0.2534\n","Training:\t loss: 0.0514, MAE: 0.1311\n","Evaluating:\t loss: 2.0524, MAE: 1.4212\n","train MSE: 0.0514, evaluate MSE: 2.0524\n","\n","train MAE: 0.1311, evaluate MAE: 1.4212\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 227\n","\tbatch: 100, loss: 0.1434, MAE: 0.3542\n","\tbatch: 200, loss: 0.1829, MAE: 0.3456\n","Training:\t loss: 0.4648, MAE: 0.4908\n","Evaluating:\t loss: 0.0401, MAE: 0.1288\n","train MSE: 0.4648, evaluate MSE: 0.0401\n","\n","train MAE: 0.4908, evaluate MAE: 0.1288\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 228\n","\tbatch: 100, loss: 0.8005, MAE: 0.7568\n","\tbatch: 200, loss: 0.4704, MAE: 0.3952\n","Training:\t loss: 0.5424, MAE: 0.4654\n","Evaluating:\t loss: 0.2324, MAE: 0.4080\n","train MSE: 0.5424, evaluate MSE: 0.2324\n","\n","train MAE: 0.4654, evaluate MAE: 0.4080\n","\n","--- time consumption (s): 27\n","\n","------------------------------\n","Epoch 229\n","\tbatch: 100, loss: 0.2189, MAE: 0.4104\n","\tbatch: 200, loss: 0.0348, MAE: 0.1330\n","Training:\t loss: 9.5237, MAE: 1.2622\n","Evaluating:\t loss: 0.0612, MAE: 0.1135\n","train MSE: 9.5237, evaluate MSE: 0.0612\n","\n","train MAE: 1.2622, evaluate MAE: 0.1135\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 230\n","\tbatch: 100, loss: 0.0305, MAE: 0.1058\n","\tbatch: 200, loss: 0.0306, MAE: 0.1154\n","Training:\t loss: 0.0382, MAE: 0.1034\n","Evaluating:\t loss: 0.0453, MAE: 0.0879\n","train MSE: 0.0382, evaluate MSE: 0.0453\n","\n","train MAE: 0.1034, evaluate MAE: 0.0879\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 231\n","\tbatch: 100, loss: 0.0223, MAE: 0.0853\n","\tbatch: 200, loss: 0.0129, MAE: 0.0625\n","Training:\t loss: 0.0197, MAE: 0.0823\n","Evaluating:\t loss: 0.0325, MAE: 0.0880\n","train MSE: 0.0197, evaluate MSE: 0.0325\n","\n","train MAE: 0.0823, evaluate MAE: 0.0880\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 232\n","\tbatch: 100, loss: 0.0203, MAE: 0.0701\n","\tbatch: 200, loss: 0.0088, MAE: 0.0697\n","Training:\t loss: 0.0146, MAE: 0.0723\n","Evaluating:\t loss: 0.0255, MAE: 0.0667\n","train MSE: 0.0146, evaluate MSE: 0.0255\n","\n","train MAE: 0.0723, evaluate MAE: 0.0667\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 233\n","\tbatch: 100, loss: 0.0136, MAE: 0.0645\n","\tbatch: 200, loss: 0.0081, MAE: 0.0673\n","Training:\t loss: 0.0137, MAE: 0.0706\n","Evaluating:\t loss: 0.0482, MAE: 0.0691\n","train MSE: 0.0137, evaluate MSE: 0.0482\n","\n","train MAE: 0.0706, evaluate MAE: 0.0691\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 234\n","\tbatch: 100, loss: 0.0081, MAE: 0.0624\n","\tbatch: 200, loss: 0.0382, MAE: 0.1706\n","Training:\t loss: 0.0240, MAE: 0.1080\n","Evaluating:\t loss: 0.0203, MAE: 0.0842\n","train MSE: 0.0240, evaluate MSE: 0.0203\n","\n","train MAE: 0.1080, evaluate MAE: 0.0842\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 235\n","\tbatch: 100, loss: 0.0145, MAE: 0.0899\n","\tbatch: 200, loss: 0.1578, MAE: 0.3672\n","Training:\t loss: 0.2370, MAE: 0.3887\n","Evaluating:\t loss: 0.3916, MAE: 0.5972\n","train MSE: 0.2370, evaluate MSE: 0.3916\n","\n","train MAE: 0.3887, evaluate MAE: 0.5972\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 236\n","\tbatch: 100, loss: 0.5404, MAE: 0.7176\n","\tbatch: 200, loss: 0.3684, MAE: 0.5732\n","Training:\t loss: 0.2833, MAE: 0.4288\n","Evaluating:\t loss: 0.0280, MAE: 0.0901\n","train MSE: 0.2833, evaluate MSE: 0.0280\n","\n","train MAE: 0.4288, evaluate MAE: 0.0901\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 237\n","\tbatch: 100, loss: 0.0088, MAE: 0.0599\n","\tbatch: 200, loss: 0.0181, MAE: 0.1126\n","Training:\t loss: 0.6134, MAE: 0.3613\n","Evaluating:\t loss: 0.0155, MAE: 0.0601\n","train MSE: 0.6134, evaluate MSE: 0.0155\n","\n","train MAE: 0.3613, evaluate MAE: 0.0601\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 238\n","\tbatch: 100, loss: 0.1089, MAE: 0.3090\n","\tbatch: 200, loss: 0.0679, MAE: 0.1952\n","Training:\t loss: 0.2943, MAE: 0.3814\n","Evaluating:\t loss: 0.6436, MAE: 0.7885\n","train MSE: 0.2943, evaluate MSE: 0.6436\n","\n","train MAE: 0.3814, evaluate MAE: 0.7885\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 239\n","\tbatch: 100, loss: 0.1212, MAE: 0.3323\n","\tbatch: 200, loss: 0.2492, MAE: 0.4850\n","Training:\t loss: 0.3496, MAE: 0.4840\n","Evaluating:\t loss: 0.3629, MAE: 0.5799\n","train MSE: 0.3496, evaluate MSE: 0.3629\n","\n","train MAE: 0.4840, evaluate MAE: 0.5799\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 240\n","\tbatch: 100, loss: 0.3079, MAE: 0.5258\n","\tbatch: 200, loss: 3.7349, MAE: 1.8874\n","Training:\t loss: 0.6758, MAE: 0.6139\n","Evaluating:\t loss: 0.0484, MAE: 0.1611\n","train MSE: 0.6758, evaluate MSE: 0.0484\n","\n","train MAE: 0.6139, evaluate MAE: 0.1611\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 241\n","\tbatch: 100, loss: 0.0082, MAE: 0.0645\n","\tbatch: 200, loss: 0.1001, MAE: 0.2954\n","Training:\t loss: 0.1970, MAE: 0.2730\n","Evaluating:\t loss: 0.0223, MAE: 0.0857\n","train MSE: 0.1970, evaluate MSE: 0.0223\n","\n","train MAE: 0.2730, evaluate MAE: 0.0857\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 242\n","\tbatch: 100, loss: 0.0138, MAE: 0.0696\n","\tbatch: 200, loss: 0.6449, MAE: 0.7880\n","Training:\t loss: 0.4748, MAE: 0.4818\n","Evaluating:\t loss: 0.0632, MAE: 0.1777\n","train MSE: 0.4748, evaluate MSE: 0.0632\n","\n","train MAE: 0.4818, evaluate MAE: 0.1777\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 243\n","\tbatch: 100, loss: 0.0979, MAE: 0.2692\n","\tbatch: 200, loss: 0.0571, MAE: 0.2262\n","Training:\t loss: 0.3697, MAE: 0.4578\n","Evaluating:\t loss: 0.0733, MAE: 0.2133\n","train MSE: 0.3697, evaluate MSE: 0.0733\n","\n","train MAE: 0.4578, evaluate MAE: 0.2133\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 244\n","\tbatch: 100, loss: 0.1235, MAE: 0.2529\n","\tbatch: 200, loss: 0.2640, MAE: 0.4709\n","Training:\t loss: 0.4799, MAE: 0.5068\n","Evaluating:\t loss: 0.6118, MAE: 0.7148\n","train MSE: 0.4799, evaluate MSE: 0.6118\n","\n","train MAE: 0.5068, evaluate MAE: 0.7148\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 245\n","\tbatch: 100, loss: 0.0521, MAE: 0.2048\n","\tbatch: 200, loss: 0.0528, MAE: 0.1664\n","Training:\t loss: 0.3033, MAE: 0.3959\n","Evaluating:\t loss: 0.0199, MAE: 0.0592\n","train MSE: 0.3033, evaluate MSE: 0.0199\n","\n","train MAE: 0.3959, evaluate MAE: 0.0592\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 246\n","\tbatch: 100, loss: 0.0125, MAE: 0.0882\n","\tbatch: 200, loss: 0.2310, MAE: 0.4729\n","Training:\t loss: 0.4106, MAE: 0.4040\n","Evaluating:\t loss: 0.3692, MAE: 0.4045\n","train MSE: 0.4106, evaluate MSE: 0.3692\n","\n","train MAE: 0.4040, evaluate MAE: 0.4045\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 247\n","\tbatch: 100, loss: 0.0536, MAE: 0.2229\n","\tbatch: 200, loss: 0.0303, MAE: 0.1184\n","Training:\t loss: 0.5409, MAE: 0.5149\n","Evaluating:\t loss: 0.0208, MAE: 0.0887\n","train MSE: 0.5409, evaluate MSE: 0.0208\n","\n","train MAE: 0.5149, evaluate MAE: 0.0887\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 248\n","\tbatch: 100, loss: 1.1039, MAE: 1.0220\n","\tbatch: 200, loss: 0.2969, MAE: 0.5046\n","Training:\t loss: 0.3595, MAE: 0.3980\n","Evaluating:\t loss: 0.0264, MAE: 0.1222\n","train MSE: 0.3595, evaluate MSE: 0.0264\n","\n","train MAE: 0.3980, evaluate MAE: 0.1222\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 249\n","\tbatch: 100, loss: 0.2542, MAE: 0.4463\n","\tbatch: 200, loss: 0.0551, MAE: 0.1954\n","Training:\t loss: 0.3433, MAE: 0.3671\n","Evaluating:\t loss: 1.3874, MAE: 1.1337\n","train MSE: 0.3433, evaluate MSE: 1.3874\n","\n","train MAE: 0.3671, evaluate MAE: 1.1337\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 250\n","\tbatch: 100, loss: 0.0066, MAE: 0.0602\n","\tbatch: 200, loss: 0.0116, MAE: 0.0859\n","Training:\t loss: 0.4791, MAE: 0.4298\n","Evaluating:\t loss: 0.0124, MAE: 0.0506\n","train MSE: 0.4791, evaluate MSE: 0.0124\n","\n","train MAE: 0.4298, evaluate MAE: 0.0506\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 251\n","\tbatch: 100, loss: 0.0129, MAE: 0.0712\n","\tbatch: 200, loss: 2.3829, MAE: 1.5185\n","Training:\t loss: 0.3657, MAE: 0.4082\n","Evaluating:\t loss: 0.1074, MAE: 0.2718\n","train MSE: 0.3657, evaluate MSE: 0.1074\n","\n","train MAE: 0.4082, evaluate MAE: 0.2718\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 252\n","\tbatch: 100, loss: 4.7655, MAE: 2.1208\n","\tbatch: 200, loss: 0.0830, MAE: 0.2788\n","Training:\t loss: 0.4267, MAE: 0.4777\n","Evaluating:\t loss: 0.0438, MAE: 0.1406\n","train MSE: 0.4267, evaluate MSE: 0.0438\n","\n","train MAE: 0.4777, evaluate MAE: 0.1406\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 253\n","\tbatch: 100, loss: 0.0317, MAE: 0.1573\n","\tbatch: 200, loss: 0.3318, MAE: 0.5418\n","Training:\t loss: 0.3552, MAE: 0.4421\n","Evaluating:\t loss: 0.0677, MAE: 0.2212\n","train MSE: 0.3552, evaluate MSE: 0.0677\n","\n","train MAE: 0.4421, evaluate MAE: 0.2212\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 254\n","\tbatch: 100, loss: 1.0454, MAE: 0.9533\n","\tbatch: 200, loss: 0.0087, MAE: 0.0745\n","Training:\t loss: 0.3659, MAE: 0.4184\n","Evaluating:\t loss: 0.4707, MAE: 0.6673\n","train MSE: 0.3659, evaluate MSE: 0.4707\n","\n","train MAE: 0.4184, evaluate MAE: 0.6673\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 255\n","\tbatch: 100, loss: 0.1718, MAE: 0.3567\n","\tbatch: 200, loss: 0.0440, MAE: 0.1963\n","Training:\t loss: 0.5251, MAE: 0.5186\n","Evaluating:\t loss: 0.0247, MAE: 0.0562\n","train MSE: 0.5251, evaluate MSE: 0.0247\n","\n","train MAE: 0.5186, evaluate MAE: 0.0562\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 256\n","\tbatch: 100, loss: 0.6511, MAE: 0.7070\n","\tbatch: 200, loss: 2.5309, MAE: 1.5700\n","Training:\t loss: 0.3754, MAE: 0.4078\n","Evaluating:\t loss: 0.1815, MAE: 0.2681\n","train MSE: 0.3754, evaluate MSE: 0.1815\n","\n","train MAE: 0.4078, evaluate MAE: 0.2681\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 257\n","\tbatch: 100, loss: 0.1277, MAE: 0.2877\n","\tbatch: 200, loss: 0.0852, MAE: 0.2694\n","Training:\t loss: 0.3304, MAE: 0.3815\n","Evaluating:\t loss: 0.7068, MAE: 0.8275\n","train MSE: 0.3304, evaluate MSE: 0.7068\n","\n","train MAE: 0.3815, evaluate MAE: 0.8275\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 258\n","\tbatch: 100, loss: 1.7747, MAE: 1.3085\n","\tbatch: 200, loss: 0.0077, MAE: 0.0654\n","Training:\t loss: 0.3885, MAE: 0.4831\n","Evaluating:\t loss: 1.2034, MAE: 1.0381\n","train MSE: 0.3885, evaluate MSE: 1.2034\n","\n","train MAE: 0.4831, evaluate MAE: 1.0381\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 259\n","\tbatch: 100, loss: 0.3126, MAE: 0.5111\n","\tbatch: 200, loss: 0.2486, MAE: 0.4845\n","Training:\t loss: 0.3617, MAE: 0.4983\n","Evaluating:\t loss: 0.5341, MAE: 0.7069\n","train MSE: 0.3617, evaluate MSE: 0.5341\n","\n","train MAE: 0.4983, evaluate MAE: 0.7069\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 260\n","\tbatch: 100, loss: 0.0357, MAE: 0.1670\n","\tbatch: 200, loss: 0.3908, MAE: 0.5162\n","Training:\t loss: 17.7579, MAE: 1.6667\n","Evaluating:\t loss: 0.1600, MAE: 0.2301\n","train MSE: 17.7579, evaluate MSE: 0.1600\n","\n","train MAE: 1.6667, evaluate MAE: 0.2301\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 261\n","\tbatch: 100, loss: 0.0563, MAE: 0.1527\n","\tbatch: 200, loss: 0.0288, MAE: 0.0990\n","Training:\t loss: 0.0646, MAE: 0.1324\n","Evaluating:\t loss: 0.0532, MAE: 0.1482\n","train MSE: 0.0646, evaluate MSE: 0.0532\n","\n","train MAE: 0.1324, evaluate MAE: 0.1482\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 262\n","\tbatch: 100, loss: 0.0241, MAE: 0.0927\n","\tbatch: 200, loss: 0.0204, MAE: 0.0887\n","Training:\t loss: 0.0278, MAE: 0.0932\n","Evaluating:\t loss: 0.0285, MAE: 0.0811\n","train MSE: 0.0278, evaluate MSE: 0.0285\n","\n","train MAE: 0.0932, evaluate MAE: 0.0811\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 263\n","\tbatch: 100, loss: 0.0194, MAE: 0.0880\n","\tbatch: 200, loss: 0.0596, MAE: 0.1013\n","Training:\t loss: 0.0196, MAE: 0.0804\n","Evaluating:\t loss: 0.0273, MAE: 0.0937\n","train MSE: 0.0196, evaluate MSE: 0.0273\n","\n","train MAE: 0.0804, evaluate MAE: 0.0937\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 264\n","\tbatch: 100, loss: 0.0108, MAE: 0.0733\n","\tbatch: 200, loss: 0.0088, MAE: 0.0579\n","Training:\t loss: 0.0132, MAE: 0.0679\n","Evaluating:\t loss: 0.0139, MAE: 0.0619\n","train MSE: 0.0132, evaluate MSE: 0.0139\n","\n","train MAE: 0.0679, evaluate MAE: 0.0619\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 265\n","\tbatch: 100, loss: 0.0085, MAE: 0.0676\n","\tbatch: 200, loss: 0.0084, MAE: 0.0539\n","Training:\t loss: 0.0128, MAE: 0.0651\n","Evaluating:\t loss: 0.0144, MAE: 0.0597\n","train MSE: 0.0128, evaluate MSE: 0.0144\n","\n","train MAE: 0.0651, evaluate MAE: 0.0597\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 266\n","\tbatch: 100, loss: 0.0129, MAE: 0.0560\n","\tbatch: 200, loss: 0.0062, MAE: 0.0565\n","Training:\t loss: 0.0108, MAE: 0.0627\n","Evaluating:\t loss: 0.0313, MAE: 0.0734\n","train MSE: 0.0108, evaluate MSE: 0.0313\n","\n","train MAE: 0.0627, evaluate MAE: 0.0734\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 267\n","\tbatch: 100, loss: 0.0102, MAE: 0.0718\n","\tbatch: 200, loss: 0.0049, MAE: 0.0508\n","Training:\t loss: 0.0129, MAE: 0.0719\n","Evaluating:\t loss: 0.0169, MAE: 0.0610\n","train MSE: 0.0129, evaluate MSE: 0.0169\n","\n","train MAE: 0.0719, evaluate MAE: 0.0610\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 268\n","\tbatch: 100, loss: 0.0084, MAE: 0.0599\n","\tbatch: 200, loss: 0.0051, MAE: 0.0542\n","Training:\t loss: 0.0398, MAE: 0.1195\n","Evaluating:\t loss: 0.3328, MAE: 0.5467\n","train MSE: 0.0398, evaluate MSE: 0.3328\n","\n","train MAE: 0.1195, evaluate MAE: 0.5467\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 269\n","\tbatch: 100, loss: 0.0063, MAE: 0.0548\n","\tbatch: 200, loss: 0.0083, MAE: 0.0592\n","Training:\t loss: 0.1309, MAE: 0.2395\n","Evaluating:\t loss: 0.0173, MAE: 0.0984\n","train MSE: 0.1309, evaluate MSE: 0.0173\n","\n","train MAE: 0.2395, evaluate MAE: 0.0984\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 270\n","\tbatch: 100, loss: 0.0104, MAE: 0.0759\n","\tbatch: 200, loss: 0.0074, MAE: 0.0603\n","Training:\t loss: 0.2238, MAE: 0.3116\n","Evaluating:\t loss: 0.0614, MAE: 0.2039\n","train MSE: 0.2238, evaluate MSE: 0.0614\n","\n","train MAE: 0.3116, evaluate MAE: 0.2039\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 271\n","\tbatch: 100, loss: 0.0289, MAE: 0.1340\n","\tbatch: 200, loss: 0.0940, MAE: 0.2873\n","Training:\t loss: 0.2435, MAE: 0.3668\n","Evaluating:\t loss: 0.0857, MAE: 0.2678\n","train MSE: 0.2435, evaluate MSE: 0.0857\n","\n","train MAE: 0.3668, evaluate MAE: 0.2678\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 272\n","\tbatch: 100, loss: 0.0184, MAE: 0.1199\n","\tbatch: 200, loss: 0.0678, MAE: 0.1838\n","Training:\t loss: 0.4118, MAE: 0.4518\n","Evaluating:\t loss: 0.1105, MAE: 0.1426\n","train MSE: 0.4118, evaluate MSE: 0.1105\n","\n","train MAE: 0.4518, evaluate MAE: 0.1426\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 273\n","\tbatch: 100, loss: 0.3413, MAE: 0.5687\n","\tbatch: 200, loss: 1.9230, MAE: 1.3716\n","Training:\t loss: 0.3675, MAE: 0.4197\n","Evaluating:\t loss: 0.0442, MAE: 0.1565\n","train MSE: 0.3675, evaluate MSE: 0.0442\n","\n","train MAE: 0.4197, evaluate MAE: 0.1565\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 274\n","\tbatch: 100, loss: 0.0324, MAE: 0.1581\n","\tbatch: 200, loss: 0.0311, MAE: 0.1574\n","Training:\t loss: 0.1680, MAE: 0.3179\n","Evaluating:\t loss: 0.0645, MAE: 0.2162\n","train MSE: 0.1680, evaluate MSE: 0.0645\n","\n","train MAE: 0.3179, evaluate MAE: 0.2162\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 275\n","\tbatch: 100, loss: 0.0116, MAE: 0.0808\n","\tbatch: 200, loss: 0.4719, MAE: 0.6518\n","Training:\t loss: 0.4840, MAE: 0.4571\n","Evaluating:\t loss: 0.0380, MAE: 0.1293\n","train MSE: 0.4840, evaluate MSE: 0.0380\n","\n","train MAE: 0.4571, evaluate MAE: 0.1293\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 276\n","\tbatch: 100, loss: 0.0885, MAE: 0.2833\n","\tbatch: 200, loss: 0.1042, MAE: 0.3110\n","Training:\t loss: 0.2370, MAE: 0.3612\n","Evaluating:\t loss: 3.7757, MAE: 1.8577\n","train MSE: 0.2370, evaluate MSE: 3.7757\n","\n","train MAE: 0.3612, evaluate MAE: 1.8577\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 277\n","\tbatch: 100, loss: 0.0185, MAE: 0.1211\n","\tbatch: 200, loss: 0.0811, MAE: 0.2680\n","Training:\t loss: 0.3318, MAE: 0.3749\n","Evaluating:\t loss: 0.0678, MAE: 0.2391\n","train MSE: 0.3318, evaluate MSE: 0.0678\n","\n","train MAE: 0.3749, evaluate MAE: 0.2391\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 278\n","\tbatch: 100, loss: 0.1348, MAE: 0.1581\n","\tbatch: 200, loss: 0.1071, MAE: 0.2795\n","Training:\t loss: 0.3818, MAE: 0.4499\n","Evaluating:\t loss: 0.2119, MAE: 0.4179\n","train MSE: 0.3818, evaluate MSE: 0.2119\n","\n","train MAE: 0.4499, evaluate MAE: 0.4179\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 279\n","\tbatch: 100, loss: 0.4011, MAE: 0.6169\n","\tbatch: 200, loss: 0.3593, MAE: 0.5131\n","Training:\t loss: 0.4962, MAE: 0.5073\n","Evaluating:\t loss: 0.1654, MAE: 0.3591\n","train MSE: 0.4962, evaluate MSE: 0.1654\n","\n","train MAE: 0.5073, evaluate MAE: 0.3591\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 280\n","\tbatch: 100, loss: 0.0140, MAE: 0.0842\n","\tbatch: 200, loss: 0.1889, MAE: 0.4043\n","Training:\t loss: 0.1788, MAE: 0.2940\n","Evaluating:\t loss: 0.0497, MAE: 0.1695\n","train MSE: 0.1788, evaluate MSE: 0.0497\n","\n","train MAE: 0.2940, evaluate MAE: 0.1695\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 281\n","\tbatch: 100, loss: 0.0781, MAE: 0.2065\n","\tbatch: 200, loss: 0.0595, MAE: 0.2305\n","Training:\t loss: 0.3677, MAE: 0.3561\n","Evaluating:\t loss: 0.0489, MAE: 0.1898\n","train MSE: 0.3677, evaluate MSE: 0.0489\n","\n","train MAE: 0.3561, evaluate MAE: 0.1898\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 282\n","\tbatch: 100, loss: 0.0498, MAE: 0.2102\n","\tbatch: 200, loss: 0.1408, MAE: 0.3524\n","Training:\t loss: 0.3389, MAE: 0.4344\n","Evaluating:\t loss: 0.5098, MAE: 0.6099\n","train MSE: 0.3389, evaluate MSE: 0.5098\n","\n","train MAE: 0.4344, evaluate MAE: 0.6099\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 283\n","\tbatch: 100, loss: 0.0200, MAE: 0.1255\n","\tbatch: 200, loss: 0.8642, MAE: 0.8765\n","Training:\t loss: 0.4245, MAE: 0.5030\n","Evaluating:\t loss: 0.1680, MAE: 0.3603\n","train MSE: 0.4245, evaluate MSE: 0.1680\n","\n","train MAE: 0.5030, evaluate MAE: 0.3603\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 284\n","\tbatch: 100, loss: 0.7536, MAE: 0.8588\n","\tbatch: 200, loss: 0.2794, MAE: 0.5165\n","Training:\t loss: 0.3005, MAE: 0.3781\n","Evaluating:\t loss: 0.0611, MAE: 0.2272\n","train MSE: 0.3005, evaluate MSE: 0.0611\n","\n","train MAE: 0.3781, evaluate MAE: 0.2272\n","\n","--- time consumption (s): 27\n","\n","------------------------------\n","Epoch 285\n","\tbatch: 100, loss: 0.0804, MAE: 0.2666\n","\tbatch: 200, loss: 0.2517, MAE: 0.4340\n","Training:\t loss: 0.4290, MAE: 0.4152\n","Evaluating:\t loss: 0.1575, MAE: 0.3708\n","train MSE: 0.4290, evaluate MSE: 0.1575\n","\n","train MAE: 0.4152, evaluate MAE: 0.3708\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 286\n","\tbatch: 100, loss: 0.0326, MAE: 0.1391\n","\tbatch: 200, loss: 0.0153, MAE: 0.1009\n","Training:\t loss: 0.3035, MAE: 0.3457\n","Evaluating:\t loss: 0.0145, MAE: 0.0681\n","train MSE: 0.3035, evaluate MSE: 0.0145\n","\n","train MAE: 0.3457, evaluate MAE: 0.0681\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 287\n","\tbatch: 100, loss: 0.0907, MAE: 0.2643\n","\tbatch: 200, loss: 0.0315, MAE: 0.1595\n","Training:\t loss: 0.2395, MAE: 0.3795\n","Evaluating:\t loss: 0.1121, MAE: 0.3048\n","train MSE: 0.2395, evaluate MSE: 0.1121\n","\n","train MAE: 0.3795, evaluate MAE: 0.3048\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 288\n","\tbatch: 100, loss: 0.0424, MAE: 0.1957\n","\tbatch: 200, loss: 0.0342, MAE: 0.1253\n","Training:\t loss: 0.3552, MAE: 0.4708\n","Evaluating:\t loss: 2.2219, MAE: 1.4794\n","train MSE: 0.3552, evaluate MSE: 2.2219\n","\n","train MAE: 0.4708, evaluate MAE: 1.4794\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 289\n","\tbatch: 100, loss: 0.0724, MAE: 0.2516\n","\tbatch: 200, loss: 0.0970, MAE: 0.2973\n","Training:\t loss: 0.5003, MAE: 0.4656\n","Evaluating:\t loss: 5.4504, MAE: 2.2215\n","train MSE: 0.5003, evaluate MSE: 5.4504\n","\n","train MAE: 0.4656, evaluate MAE: 2.2215\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 290\n","\tbatch: 100, loss: 0.0274, MAE: 0.1555\n","\tbatch: 200, loss: 0.0097, MAE: 0.0654\n","Training:\t loss: 0.1682, MAE: 0.1886\n","Evaluating:\t loss: 0.0539, MAE: 0.1739\n","train MSE: 0.1682, evaluate MSE: 0.0539\n","\n","train MAE: 0.1886, evaluate MAE: 0.1739\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 291\n","\tbatch: 100, loss: 0.0201, MAE: 0.1043\n","\tbatch: 200, loss: 5.1735, MAE: 2.1228\n","Training:\t loss: 0.5655, MAE: 0.4548\n","Evaluating:\t loss: 0.0823, MAE: 0.2198\n","train MSE: 0.5655, evaluate MSE: 0.0823\n","\n","train MAE: 0.4548, evaluate MAE: 0.2198\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 292\n","\tbatch: 100, loss: 0.0393, MAE: 0.1730\n","\tbatch: 200, loss: 0.0821, MAE: 0.2602\n","Training:\t loss: 0.1274, MAE: 0.2551\n","Evaluating:\t loss: 0.1924, MAE: 0.3982\n","train MSE: 0.1274, evaluate MSE: 0.1924\n","\n","train MAE: 0.2551, evaluate MAE: 0.3982\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 293\n","\tbatch: 100, loss: 0.0738, MAE: 0.2562\n","\tbatch: 200, loss: 0.2143, MAE: 0.4538\n","Training:\t loss: 0.3264, MAE: 0.4380\n","Evaluating:\t loss: 0.2454, MAE: 0.4006\n","train MSE: 0.3264, evaluate MSE: 0.2454\n","\n","train MAE: 0.4380, evaluate MAE: 0.4006\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 294\n","\tbatch: 100, loss: 0.3091, MAE: 0.5224\n","\tbatch: 200, loss: 1.5837, MAE: 1.2279\n","Training:\t loss: 0.6428, MAE: 0.5249\n","Evaluating:\t loss: 0.3063, MAE: 0.4768\n","train MSE: 0.6428, evaluate MSE: 0.3063\n","\n","train MAE: 0.5249, evaluate MAE: 0.4768\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 295\n","\tbatch: 100, loss: 0.0076, MAE: 0.0697\n","\tbatch: 200, loss: 0.6472, MAE: 0.6376\n","Training:\t loss: 0.2307, MAE: 0.3014\n","Evaluating:\t loss: 0.1222, MAE: 0.3229\n","train MSE: 0.2307, evaluate MSE: 0.1222\n","\n","train MAE: 0.3014, evaluate MAE: 0.3229\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 296\n","\tbatch: 100, loss: 0.8168, MAE: 0.8778\n","\tbatch: 200, loss: 0.2185, MAE: 0.4501\n","Training:\t loss: 0.1750, MAE: 0.3135\n","Evaluating:\t loss: 0.5681, MAE: 0.7138\n","train MSE: 0.1750, evaluate MSE: 0.5681\n","\n","train MAE: 0.3135, evaluate MAE: 0.7138\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 297\n","\tbatch: 100, loss: 0.0661, MAE: 0.2410\n","\tbatch: 200, loss: 0.0512, MAE: 0.1890\n","Training:\t loss: 0.3481, MAE: 0.3992\n","Evaluating:\t loss: 0.7220, MAE: 0.7017\n","train MSE: 0.3481, evaluate MSE: 0.7220\n","\n","train MAE: 0.3992, evaluate MAE: 0.7017\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 298\n","\tbatch: 100, loss: 0.1954, MAE: 0.3613\n","\tbatch: 200, loss: 0.8335, MAE: 0.2325\n","Training:\t loss: 27.4769, MAE: 1.9152\n","Evaluating:\t loss: 0.1113, MAE: 0.1481\n","train MSE: 27.4769, evaluate MSE: 0.1113\n","\n","train MAE: 1.9152, evaluate MAE: 0.1481\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 299\n","\tbatch: 100, loss: 0.0543, MAE: 0.1004\n","\tbatch: 200, loss: 0.0330, MAE: 0.0832\n","Training:\t loss: 0.0403, MAE: 0.1012\n","Evaluating:\t loss: 0.0751, MAE: 0.0957\n","train MSE: 0.0403, evaluate MSE: 0.0751\n","\n","train MAE: 0.1012, evaluate MAE: 0.0957\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 300\n","\tbatch: 100, loss: 0.0112, MAE: 0.0670\n","\tbatch: 200, loss: 0.0153, MAE: 0.0785\n","Training:\t loss: 0.0265, MAE: 0.0848\n","Evaluating:\t loss: 0.0440, MAE: 0.0861\n","train MSE: 0.0265, evaluate MSE: 0.0440\n","\n","train MAE: 0.0848, evaluate MAE: 0.0861\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 301\n","\tbatch: 100, loss: 0.0151, MAE: 0.0636\n","\tbatch: 200, loss: 0.0226, MAE: 0.0774\n","Training:\t loss: 0.0212, MAE: 0.0765\n","Evaluating:\t loss: 0.0396, MAE: 0.0721\n","train MSE: 0.0212, evaluate MSE: 0.0396\n","\n","train MAE: 0.0765, evaluate MAE: 0.0721\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 302\n","\tbatch: 100, loss: 0.0159, MAE: 0.0730\n","\tbatch: 200, loss: 0.0080, MAE: 0.0583\n","Training:\t loss: 0.0154, MAE: 0.0682\n","Evaluating:\t loss: 0.0336, MAE: 0.0700\n","train MSE: 0.0154, evaluate MSE: 0.0336\n","\n","train MAE: 0.0682, evaluate MAE: 0.0700\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 303\n","\tbatch: 100, loss: 0.0092, MAE: 0.0584\n","\tbatch: 200, loss: 0.0131, MAE: 0.0785\n","Training:\t loss: 0.0136, MAE: 0.0668\n","Evaluating:\t loss: 0.0333, MAE: 0.0779\n","train MSE: 0.0136, evaluate MSE: 0.0333\n","\n","train MAE: 0.0668, evaluate MAE: 0.0779\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 304\n","\tbatch: 100, loss: 0.0076, MAE: 0.0593\n","\tbatch: 200, loss: 0.0190, MAE: 0.0727\n","Training:\t loss: 0.0120, MAE: 0.0651\n","Evaluating:\t loss: 0.0248, MAE: 0.0594\n","train MSE: 0.0120, evaluate MSE: 0.0248\n","\n","train MAE: 0.0651, evaluate MAE: 0.0594\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 305\n","\tbatch: 100, loss: 0.0086, MAE: 0.0691\n","\tbatch: 200, loss: 0.0098, MAE: 0.0667\n","Training:\t loss: 0.0105, MAE: 0.0607\n","Evaluating:\t loss: 0.0194, MAE: 0.0587\n","train MSE: 0.0105, evaluate MSE: 0.0194\n","\n","train MAE: 0.0607, evaluate MAE: 0.0587\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 306\n","\tbatch: 100, loss: 0.0077, MAE: 0.0664\n","\tbatch: 200, loss: 0.0071, MAE: 0.0594\n","Training:\t loss: 0.0097, MAE: 0.0613\n","Evaluating:\t loss: 0.0173, MAE: 0.0583\n","train MSE: 0.0097, evaluate MSE: 0.0173\n","\n","train MAE: 0.0613, evaluate MAE: 0.0583\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 307\n","\tbatch: 100, loss: 0.0082, MAE: 0.0588\n","\tbatch: 200, loss: 0.0140, MAE: 0.0649\n","Training:\t loss: 0.0123, MAE: 0.0728\n","Evaluating:\t loss: 0.0172, MAE: 0.0491\n","train MSE: 0.0123, evaluate MSE: 0.0172\n","\n","train MAE: 0.0728, evaluate MAE: 0.0491\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 308\n","\tbatch: 100, loss: 0.0367, MAE: 0.1778\n","\tbatch: 200, loss: 0.0091, MAE: 0.0630\n","Training:\t loss: 0.0999, MAE: 0.2166\n","Evaluating:\t loss: 0.0511, MAE: 0.1373\n","train MSE: 0.0999, evaluate MSE: 0.0511\n","\n","train MAE: 0.2166, evaluate MAE: 0.1373\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 309\n","\tbatch: 100, loss: 0.0108, MAE: 0.0730\n","\tbatch: 200, loss: 0.0424, MAE: 0.1872\n","Training:\t loss: 0.2599, MAE: 0.3596\n","Evaluating:\t loss: 0.0776, MAE: 0.2203\n","train MSE: 0.2599, evaluate MSE: 0.0776\n","\n","train MAE: 0.3596, evaluate MAE: 0.2203\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 310\n","\tbatch: 100, loss: 0.0423, MAE: 0.1928\n","\tbatch: 200, loss: 0.1021, MAE: 0.3097\n","Training:\t loss: 0.2449, MAE: 0.3822\n","Evaluating:\t loss: 0.3576, MAE: 0.4674\n","train MSE: 0.2449, evaluate MSE: 0.3576\n","\n","train MAE: 0.3822, evaluate MAE: 0.4674\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 311\n","\tbatch: 100, loss: 0.5983, MAE: 0.7526\n","\tbatch: 200, loss: 0.0705, MAE: 0.2507\n","Training:\t loss: 0.2829, MAE: 0.4296\n","Evaluating:\t loss: 1.0982, MAE: 1.0300\n","train MSE: 0.2829, evaluate MSE: 1.0982\n","\n","train MAE: 0.4296, evaluate MAE: 1.0300\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 312\n","\tbatch: 100, loss: 0.0118, MAE: 0.0767\n","\tbatch: 200, loss: 0.0083, MAE: 0.0661\n","Training:\t loss: 0.2753, MAE: 0.3712\n","Evaluating:\t loss: 0.4671, MAE: 0.6671\n","train MSE: 0.2753, evaluate MSE: 0.4671\n","\n","train MAE: 0.3712, evaluate MAE: 0.6671\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 313\n","\tbatch: 100, loss: 0.6088, MAE: 0.1761\n","\tbatch: 200, loss: 0.7414, MAE: 0.8455\n","Training:\t loss: 0.3102, MAE: 0.4492\n","Evaluating:\t loss: 0.0594, MAE: 0.2035\n","train MSE: 0.3102, evaluate MSE: 0.0594\n","\n","train MAE: 0.4492, evaluate MAE: 0.2035\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 314\n","\tbatch: 100, loss: 0.0294, MAE: 0.1306\n","\tbatch: 200, loss: 0.5588, MAE: 0.7336\n","Training:\t loss: 0.2561, MAE: 0.3610\n","Evaluating:\t loss: 0.1309, MAE: 0.3293\n","train MSE: 0.2561, evaluate MSE: 0.1309\n","\n","train MAE: 0.3610, evaluate MAE: 0.3293\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 315\n","\tbatch: 100, loss: 0.9000, MAE: 0.9256\n","\tbatch: 200, loss: 0.2696, MAE: 0.4974\n","Training:\t loss: 0.3096, MAE: 0.4481\n","Evaluating:\t loss: 1.3958, MAE: 1.1690\n","train MSE: 0.3096, evaluate MSE: 1.3958\n","\n","train MAE: 0.4481, evaluate MAE: 1.1690\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 316\n","\tbatch: 100, loss: 0.3397, MAE: 0.5700\n","\tbatch: 200, loss: 0.3720, MAE: 0.5861\n","Training:\t loss: 0.3768, MAE: 0.4457\n","Evaluating:\t loss: 0.0725, MAE: 0.2289\n","train MSE: 0.3768, evaluate MSE: 0.0725\n","\n","train MAE: 0.4457, evaluate MAE: 0.2289\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 317\n","\tbatch: 100, loss: 0.5193, MAE: 0.6974\n","\tbatch: 200, loss: 2.7844, MAE: 1.6561\n","Training:\t loss: 0.2870, MAE: 0.3831\n","Evaluating:\t loss: 0.2021, MAE: 0.4096\n","train MSE: 0.2870, evaluate MSE: 0.2021\n","\n","train MAE: 0.3831, evaluate MAE: 0.4096\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 318\n","\tbatch: 100, loss: 0.1808, MAE: 0.4156\n","\tbatch: 200, loss: 0.0224, MAE: 0.1314\n","Training:\t loss: 0.2195, MAE: 0.3210\n","Evaluating:\t loss: 0.0680, MAE: 0.2252\n","train MSE: 0.2195, evaluate MSE: 0.0680\n","\n","train MAE: 0.3210, evaluate MAE: 0.2252\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 319\n","\tbatch: 100, loss: 0.3988, MAE: 0.6171\n","\tbatch: 200, loss: 0.1583, MAE: 0.3858\n","Training:\t loss: 0.3168, MAE: 0.4317\n","Evaluating:\t loss: 2.0077, MAE: 1.3748\n","train MSE: 0.3168, evaluate MSE: 2.0077\n","\n","train MAE: 0.4317, evaluate MAE: 1.3748\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 320\n","\tbatch: 100, loss: 0.1113, MAE: 0.2914\n","\tbatch: 200, loss: 0.0406, MAE: 0.1927\n","Training:\t loss: 0.2830, MAE: 0.4034\n","Evaluating:\t loss: 1.4736, MAE: 1.1877\n","train MSE: 0.2830, evaluate MSE: 1.4736\n","\n","train MAE: 0.4034, evaluate MAE: 1.1877\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 321\n","\tbatch: 100, loss: 0.8368, MAE: 0.9033\n","\tbatch: 200, loss: 0.6214, MAE: 0.7614\n","Training:\t loss: 0.3755, MAE: 0.4784\n","Evaluating:\t loss: 0.0725, MAE: 0.1468\n","train MSE: 0.3755, evaluate MSE: 0.0725\n","\n","train MAE: 0.4784, evaluate MAE: 0.1468\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 322\n","\tbatch: 100, loss: 0.1922, MAE: 0.4111\n","\tbatch: 200, loss: 0.0872, MAE: 0.2619\n","Training:\t loss: 0.3051, MAE: 0.3856\n","Evaluating:\t loss: 0.0363, MAE: 0.0922\n","train MSE: 0.3051, evaluate MSE: 0.0363\n","\n","train MAE: 0.3856, evaluate MAE: 0.0922\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 323\n","\tbatch: 100, loss: 0.1191, MAE: 0.2332\n","\tbatch: 200, loss: 1.0788, MAE: 0.9224\n","Training:\t loss: 0.5380, MAE: 0.4641\n","Evaluating:\t loss: 0.2003, MAE: 0.4137\n","train MSE: 0.5380, evaluate MSE: 0.2003\n","\n","train MAE: 0.4641, evaluate MAE: 0.4137\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 324\n","\tbatch: 100, loss: 0.3658, MAE: 0.5698\n","\tbatch: 200, loss: 0.0633, MAE: 0.1868\n","Training:\t loss: 0.2519, MAE: 0.3163\n","Evaluating:\t loss: 0.0426, MAE: 0.1627\n","train MSE: 0.2519, evaluate MSE: 0.0426\n","\n","train MAE: 0.3163, evaluate MAE: 0.1627\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 325\n","\tbatch: 100, loss: 3.5252, MAE: 1.5758\n","\tbatch: 200, loss: 0.0170, MAE: 0.0787\n","Training:\t loss: 0.5165, MAE: 0.4063\n","Evaluating:\t loss: 0.0344, MAE: 0.1077\n","train MSE: 0.5165, evaluate MSE: 0.0344\n","\n","train MAE: 0.4063, evaluate MAE: 0.1077\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 326\n","\tbatch: 100, loss: 0.0119, MAE: 0.0745\n","\tbatch: 200, loss: 0.4202, MAE: 0.6408\n","Training:\t loss: 0.1876, MAE: 0.2800\n","Evaluating:\t loss: 0.0293, MAE: 0.1189\n","train MSE: 0.1876, evaluate MSE: 0.0293\n","\n","train MAE: 0.2800, evaluate MAE: 0.1189\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 327\n","\tbatch: 100, loss: 0.2423, MAE: 0.4830\n","\tbatch: 200, loss: 0.0682, MAE: 0.2391\n","Training:\t loss: 0.1984, MAE: 0.3231\n","Evaluating:\t loss: 0.1049, MAE: 0.2735\n","train MSE: 0.1984, evaluate MSE: 0.1049\n","\n","train MAE: 0.3231, evaluate MAE: 0.2735\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 328\n","\tbatch: 100, loss: 0.1664, MAE: 0.3914\n","\tbatch: 200, loss: 0.0109, MAE: 0.0685\n","Training:\t loss: 0.2950, MAE: 0.3884\n","Evaluating:\t loss: 0.0401, MAE: 0.1591\n","train MSE: 0.2950, evaluate MSE: 0.0401\n","\n","train MAE: 0.3884, evaluate MAE: 0.1591\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 329\n","\tbatch: 100, loss: 0.0798, MAE: 0.2567\n","\tbatch: 200, loss: 0.3593, MAE: 0.5821\n","Training:\t loss: 0.3510, MAE: 0.4262\n","Evaluating:\t loss: 0.0482, MAE: 0.1580\n","train MSE: 0.3510, evaluate MSE: 0.0482\n","\n","train MAE: 0.4262, evaluate MAE: 0.1580\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 330\n","\tbatch: 100, loss: 0.0992, MAE: 0.2544\n","\tbatch: 200, loss: 0.0303, MAE: 0.1473\n","Training:\t loss: 0.2848, MAE: 0.3651\n","Evaluating:\t loss: 0.5966, MAE: 0.7140\n","train MSE: 0.2848, evaluate MSE: 0.5966\n","\n","train MAE: 0.3651, evaluate MAE: 0.7140\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 331\n","\tbatch: 100, loss: 1.3530, MAE: 1.1340\n","\tbatch: 200, loss: 0.0414, MAE: 0.1941\n","Training:\t loss: 0.2578, MAE: 0.2791\n","Evaluating:\t loss: 0.0204, MAE: 0.0962\n","train MSE: 0.2578, evaluate MSE: 0.0204\n","\n","train MAE: 0.2791, evaluate MAE: 0.0962\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 332\n","\tbatch: 100, loss: 0.0967, MAE: 0.2756\n","\tbatch: 200, loss: 0.0529, MAE: 0.2064\n","Training:\t loss: 0.2924, MAE: 0.4290\n","Evaluating:\t loss: 0.0414, MAE: 0.0944\n","train MSE: 0.2924, evaluate MSE: 0.0414\n","\n","train MAE: 0.4290, evaluate MAE: 0.0944\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 333\n","\tbatch: 100, loss: 1.6702, MAE: 1.2346\n","\tbatch: 200, loss: 0.7241, MAE: 0.8321\n","Training:\t loss: 0.2708, MAE: 0.3797\n","Evaluating:\t loss: 0.3103, MAE: 0.3709\n","train MSE: 0.2708, evaluate MSE: 0.3103\n","\n","train MAE: 0.3797, evaluate MAE: 0.3709\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 334\n","\tbatch: 100, loss: 0.0722, MAE: 0.2552\n","\tbatch: 200, loss: 0.1199, MAE: 0.2988\n","Training:\t loss: 0.2912, MAE: 0.3975\n","Evaluating:\t loss: 0.0603, MAE: 0.1830\n","train MSE: 0.2912, evaluate MSE: 0.0603\n","\n","train MAE: 0.3975, evaluate MAE: 0.1830\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 335\n","\tbatch: 100, loss: 0.3642, MAE: 0.5692\n","\tbatch: 200, loss: 0.0223, MAE: 0.1236\n","Training:\t loss: 0.3462, MAE: 0.4273\n","Evaluating:\t loss: 18.4673, MAE: 4.1794\n","train MSE: 0.3462, evaluate MSE: 18.4673\n","\n","train MAE: 0.4273, evaluate MAE: 4.1794\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 336\n","\tbatch: 100, loss: 0.0348, MAE: 0.1440\n","\tbatch: 200, loss: 0.0132, MAE: 0.0700\n","Training:\t loss: 2.8670, MAE: 0.5285\n","Evaluating:\t loss: 0.0357, MAE: 0.0850\n","train MSE: 2.8670, evaluate MSE: 0.0357\n","\n","train MAE: 0.5285, evaluate MAE: 0.0850\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 337\n","\tbatch: 100, loss: 0.0551, MAE: 0.1825\n","\tbatch: 200, loss: 0.0076, MAE: 0.0559\n","Training:\t loss: 0.0327, MAE: 0.1239\n","Evaluating:\t loss: 0.1241, MAE: 0.3348\n","train MSE: 0.0327, evaluate MSE: 0.1241\n","\n","train MAE: 0.1239, evaluate MAE: 0.3348\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 338\n","\tbatch: 100, loss: 0.4792, MAE: 0.6771\n","\tbatch: 200, loss: 0.0442, MAE: 0.1971\n","Training:\t loss: 0.0958, MAE: 0.2263\n","Evaluating:\t loss: 0.2046, MAE: 0.4272\n","train MSE: 0.0958, evaluate MSE: 0.2046\n","\n","train MAE: 0.2263, evaluate MAE: 0.4272\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 339\n","\tbatch: 100, loss: 0.0102, MAE: 0.0585\n","\tbatch: 200, loss: 0.0058, MAE: 0.0491\n","Training:\t loss: 0.1966, MAE: 0.2323\n","Evaluating:\t loss: 0.0176, MAE: 0.0937\n","train MSE: 0.1966, evaluate MSE: 0.0176\n","\n","train MAE: 0.2323, evaluate MAE: 0.0937\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 340\n","\tbatch: 100, loss: 0.0603, MAE: 0.2328\n","\tbatch: 200, loss: 0.1887, MAE: 0.3353\n","Training:\t loss: 0.2247, MAE: 0.3360\n","Evaluating:\t loss: 0.0628, MAE: 0.2033\n","train MSE: 0.2247, evaluate MSE: 0.0628\n","\n","train MAE: 0.3360, evaluate MAE: 0.2033\n","\n","--- time consumption (s): 27\n","\n","------------------------------\n","Epoch 341\n","\tbatch: 100, loss: 0.0715, MAE: 0.2592\n","\tbatch: 200, loss: 0.1634, MAE: 0.3670\n","Training:\t loss: 0.2278, MAE: 0.3428\n","Evaluating:\t loss: 0.0401, MAE: 0.1657\n","train MSE: 0.2278, evaluate MSE: 0.0401\n","\n","train MAE: 0.3428, evaluate MAE: 0.1657\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 342\n","\tbatch: 100, loss: 0.2654, MAE: 0.5084\n","\tbatch: 200, loss: 0.0097, MAE: 0.0781\n","Training:\t loss: 0.1774, MAE: 0.2967\n","Evaluating:\t loss: 0.1733, MAE: 0.3910\n","train MSE: 0.1774, evaluate MSE: 0.1733\n","\n","train MAE: 0.2967, evaluate MAE: 0.3910\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 343\n","\tbatch: 100, loss: 0.0094, MAE: 0.0577\n","\tbatch: 200, loss: 0.1581, MAE: 0.3506\n","Training:\t loss: 0.2979, MAE: 0.4381\n","Evaluating:\t loss: 0.0330, MAE: 0.1312\n","train MSE: 0.2979, evaluate MSE: 0.0330\n","\n","train MAE: 0.4381, evaluate MAE: 0.1312\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 344\n","\tbatch: 100, loss: 1.1354, MAE: 1.0527\n","\tbatch: 200, loss: 1.2997, MAE: 1.0699\n","Training:\t loss: 0.2399, MAE: 0.3611\n","Evaluating:\t loss: 0.0431, MAE: 0.1702\n","train MSE: 0.2399, evaluate MSE: 0.0431\n","\n","train MAE: 0.3611, evaluate MAE: 0.1702\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 345\n","\tbatch: 100, loss: 0.2595, MAE: 0.4971\n","\tbatch: 200, loss: 0.0875, MAE: 0.2272\n","Training:\t loss: 0.2818, MAE: 0.3809\n","Evaluating:\t loss: 0.1298, MAE: 0.3128\n","train MSE: 0.2818, evaluate MSE: 0.1298\n","\n","train MAE: 0.3809, evaluate MAE: 0.3128\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 346\n","\tbatch: 100, loss: 0.2761, MAE: 0.5152\n","\tbatch: 200, loss: 0.0060, MAE: 0.0585\n","Training:\t loss: 0.1539, MAE: 0.2517\n","Evaluating:\t loss: 0.0248, MAE: 0.1289\n","train MSE: 0.1539, evaluate MSE: 0.0248\n","\n","train MAE: 0.2517, evaluate MAE: 0.1289\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 347\n","\tbatch: 100, loss: 0.0075, MAE: 0.0714\n","\tbatch: 200, loss: 0.6093, MAE: 0.7243\n","Training:\t loss: 0.3558, MAE: 0.3817\n","Evaluating:\t loss: 0.2847, MAE: 0.4682\n","train MSE: 0.3558, evaluate MSE: 0.2847\n","\n","train MAE: 0.3817, evaluate MAE: 0.4682\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 348\n","\tbatch: 100, loss: 0.0098, MAE: 0.0750\n","\tbatch: 200, loss: 0.5524, MAE: 0.6217\n","Training:\t loss: 0.2733, MAE: 0.3130\n","Evaluating:\t loss: 0.0337, MAE: 0.1284\n","train MSE: 0.2733, evaluate MSE: 0.0337\n","\n","train MAE: 0.3130, evaluate MAE: 0.1284\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 349\n","\tbatch: 100, loss: 0.0442, MAE: 0.1953\n","\tbatch: 200, loss: 0.0318, MAE: 0.1636\n","Training:\t loss: 0.2150, MAE: 0.3402\n","Evaluating:\t loss: 0.3789, MAE: 0.5882\n","train MSE: 0.2150, evaluate MSE: 0.3789\n","\n","train MAE: 0.3402, evaluate MAE: 0.5882\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 350\n","\tbatch: 100, loss: 0.0141, MAE: 0.0941\n","\tbatch: 200, loss: 0.9023, MAE: 0.8534\n","Training:\t loss: 0.3486, MAE: 0.4159\n","Evaluating:\t loss: 0.0431, MAE: 0.1613\n","train MSE: 0.3486, evaluate MSE: 0.0431\n","\n","train MAE: 0.4159, evaluate MAE: 0.1613\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 351\n","\tbatch: 100, loss: 0.6359, MAE: 0.7836\n","\tbatch: 200, loss: 0.0074, MAE: 0.0548\n","Training:\t loss: 0.2524, MAE: 0.3069\n","Evaluating:\t loss: 1.7140, MAE: 1.2785\n","train MSE: 0.2524, evaluate MSE: 1.7140\n","\n","train MAE: 0.3069, evaluate MAE: 1.2785\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 352\n","\tbatch: 100, loss: 0.0285, MAE: 0.1552\n","\tbatch: 200, loss: 0.0795, MAE: 0.2675\n","Training:\t loss: 0.2373, MAE: 0.3395\n","Evaluating:\t loss: 0.1005, MAE: 0.2675\n","train MSE: 0.2373, evaluate MSE: 0.1005\n","\n","train MAE: 0.3395, evaluate MAE: 0.2675\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 353\n","\tbatch: 100, loss: 0.3207, MAE: 0.5447\n","\tbatch: 200, loss: 0.6542, MAE: 0.7945\n","Training:\t loss: 0.2144, MAE: 0.3527\n","Evaluating:\t loss: 0.0888, MAE: 0.2789\n","train MSE: 0.2144, evaluate MSE: 0.0888\n","\n","train MAE: 0.3527, evaluate MAE: 0.2789\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 354\n","\tbatch: 100, loss: 1.3629, MAE: 1.1315\n","\tbatch: 200, loss: 0.0215, MAE: 0.1197\n","Training:\t loss: 0.2874, MAE: 0.3789\n","Evaluating:\t loss: 0.1299, MAE: 0.2876\n","train MSE: 0.2874, evaluate MSE: 0.1299\n","\n","train MAE: 0.3789, evaluate MAE: 0.2876\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 355\n","\tbatch: 100, loss: 0.0244, MAE: 0.1362\n","\tbatch: 200, loss: 5.6637, MAE: 2.2948\n","Training:\t loss: 0.3822, MAE: 0.4444\n","Evaluating:\t loss: 0.1933, MAE: 0.3094\n","train MSE: 0.3822, evaluate MSE: 0.1933\n","\n","train MAE: 0.4444, evaluate MAE: 0.3094\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 356\n","\tbatch: 100, loss: 0.0373, MAE: 0.1844\n","\tbatch: 200, loss: 1.2065, MAE: 0.9632\n","Training:\t loss: 0.4648, MAE: 0.3833\n","Evaluating:\t loss: 0.0520, MAE: 0.0891\n","train MSE: 0.4648, evaluate MSE: 0.0520\n","\n","train MAE: 0.3833, evaluate MAE: 0.0891\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 357\n","\tbatch: 100, loss: 0.0217, MAE: 0.1079\n","\tbatch: 200, loss: 0.0265, MAE: 0.1459\n","Training:\t loss: 0.0231, MAE: 0.0942\n","Evaluating:\t loss: 0.0582, MAE: 0.1750\n","train MSE: 0.0231, evaluate MSE: 0.0582\n","\n","train MAE: 0.0942, evaluate MAE: 0.1750\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 358\n","\tbatch: 100, loss: 0.3662, MAE: 0.5920\n","\tbatch: 200, loss: 0.0746, MAE: 0.2181\n","Training:\t loss: 0.2478, MAE: 0.3894\n","Evaluating:\t loss: 0.0232, MAE: 0.0706\n","train MSE: 0.2478, evaluate MSE: 0.0232\n","\n","train MAE: 0.3894, evaluate MAE: 0.0706\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 359\n","\tbatch: 100, loss: 0.0352, MAE: 0.1489\n","\tbatch: 200, loss: 0.2127, MAE: 0.4083\n","Training:\t loss: 0.2927, MAE: 0.4011\n","Evaluating:\t loss: 0.0391, MAE: 0.1496\n","train MSE: 0.2927, evaluate MSE: 0.0391\n","\n","train MAE: 0.4011, evaluate MAE: 0.1496\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 360\n","\tbatch: 100, loss: 0.3444, MAE: 0.5788\n","\tbatch: 200, loss: 0.1104, MAE: 0.0822\n","Training:\t loss: 0.2012, MAE: 0.3319\n","Evaluating:\t loss: 0.8469, MAE: 0.8724\n","train MSE: 0.2012, evaluate MSE: 0.8469\n","\n","train MAE: 0.3319, evaluate MAE: 0.8724\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 361\n","\tbatch: 100, loss: 0.0707, MAE: 0.2569\n","\tbatch: 200, loss: 0.0218, MAE: 0.1141\n","Training:\t loss: 0.2882, MAE: 0.4022\n","Evaluating:\t loss: 0.1272, MAE: 0.3176\n","train MSE: 0.2882, evaluate MSE: 0.1272\n","\n","train MAE: 0.4022, evaluate MAE: 0.3176\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 362\n","\tbatch: 100, loss: 0.4776, MAE: 0.2888\n","\tbatch: 200, loss: 0.0419, MAE: 0.1733\n","Training:\t loss: 0.2103, MAE: 0.3348\n","Evaluating:\t loss: 0.0148, MAE: 0.0758\n","train MSE: 0.2103, evaluate MSE: 0.0148\n","\n","train MAE: 0.3348, evaluate MAE: 0.0758\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 363\n","\tbatch: 100, loss: 0.1788, MAE: 0.3598\n","\tbatch: 200, loss: 0.0286, MAE: 0.1365\n","Training:\t loss: 0.2856, MAE: 0.3864\n","Evaluating:\t loss: 0.4276, MAE: 0.6225\n","train MSE: 0.2856, evaluate MSE: 0.4276\n","\n","train MAE: 0.3864, evaluate MAE: 0.6225\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 364\n","\tbatch: 100, loss: 0.0274, MAE: 0.1522\n","\tbatch: 200, loss: 185.7878, MAE: 13.4090\n","Training:\t loss: 8.2044, MAE: 1.1773\n","Evaluating:\t loss: 2.0912, MAE: 0.9946\n","train MSE: 8.2044, evaluate MSE: 2.0912\n","\n","train MAE: 1.1773, evaluate MAE: 0.9946\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 365\n","\tbatch: 100, loss: 0.0717, MAE: 0.1556\n","\tbatch: 200, loss: 0.0336, MAE: 0.1283\n","Training:\t loss: 0.1769, MAE: 0.2164\n","Evaluating:\t loss: 0.0414, MAE: 0.1004\n","train MSE: 0.1769, evaluate MSE: 0.0414\n","\n","train MAE: 0.2164, evaluate MAE: 0.1004\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 366\n","\tbatch: 100, loss: 0.0254, MAE: 0.1018\n","\tbatch: 200, loss: 0.0235, MAE: 0.0983\n","Training:\t loss: 0.0291, MAE: 0.0960\n","Evaluating:\t loss: 0.0312, MAE: 0.0779\n","train MSE: 0.0291, evaluate MSE: 0.0312\n","\n","train MAE: 0.0960, evaluate MAE: 0.0779\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 367\n","\tbatch: 100, loss: 0.0137, MAE: 0.0854\n","\tbatch: 200, loss: 0.0107, MAE: 0.0591\n","Training:\t loss: 0.0161, MAE: 0.0706\n","Evaluating:\t loss: 0.0216, MAE: 0.0772\n","train MSE: 0.0161, evaluate MSE: 0.0216\n","\n","train MAE: 0.0706, evaluate MAE: 0.0772\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 368\n","\tbatch: 100, loss: 0.0161, MAE: 0.0971\n","\tbatch: 200, loss: 0.0106, MAE: 0.0607\n","Training:\t loss: 0.0144, MAE: 0.0699\n","Evaluating:\t loss: 0.0115, MAE: 0.0543\n","train MSE: 0.0144, evaluate MSE: 0.0115\n","\n","train MAE: 0.0699, evaluate MAE: 0.0543\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 369\n","\tbatch: 100, loss: 0.0111, MAE: 0.0716\n","\tbatch: 200, loss: 0.0050, MAE: 0.0498\n","Training:\t loss: 0.0114, MAE: 0.0651\n","Evaluating:\t loss: 0.0198, MAE: 0.0722\n","train MSE: 0.0114, evaluate MSE: 0.0198\n","\n","train MAE: 0.0651, evaluate MAE: 0.0722\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 370\n","\tbatch: 100, loss: 0.0070, MAE: 0.0540\n","\tbatch: 200, loss: 0.0073, MAE: 0.0535\n","Training:\t loss: 0.0120, MAE: 0.0665\n","Evaluating:\t loss: 0.0372, MAE: 0.1263\n","train MSE: 0.0120, evaluate MSE: 0.0372\n","\n","train MAE: 0.0665, evaluate MAE: 0.1263\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 371\n","\tbatch: 100, loss: 0.0348, MAE: 0.1518\n","\tbatch: 200, loss: 0.1307, MAE: 0.3544\n","Training:\t loss: 0.0564, MAE: 0.1686\n","Evaluating:\t loss: 0.0540, MAE: 0.1876\n","train MSE: 0.0564, evaluate MSE: 0.0540\n","\n","train MAE: 0.1686, evaluate MAE: 0.1876\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 372\n","\tbatch: 100, loss: 0.0474, MAE: 0.1946\n","\tbatch: 200, loss: 0.0131, MAE: 0.0813\n","Training:\t loss: 0.1721, MAE: 0.2712\n","Evaluating:\t loss: 0.0165, MAE: 0.0970\n","train MSE: 0.1721, evaluate MSE: 0.0165\n","\n","train MAE: 0.2712, evaluate MAE: 0.0970\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 373\n","\tbatch: 100, loss: 0.0674, MAE: 0.2349\n","\tbatch: 200, loss: 0.4369, MAE: 0.6318\n","Training:\t loss: 0.1652, MAE: 0.3181\n","Evaluating:\t loss: 0.0984, MAE: 0.2644\n","train MSE: 0.1652, evaluate MSE: 0.0984\n","\n","train MAE: 0.3181, evaluate MAE: 0.2644\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 374\n","\tbatch: 100, loss: 0.0077, MAE: 0.0584\n","\tbatch: 200, loss: 0.0908, MAE: 0.2632\n","Training:\t loss: 0.2208, MAE: 0.2633\n","Evaluating:\t loss: 2.2177, MAE: 1.4543\n","train MSE: 0.2208, evaluate MSE: 2.2177\n","\n","train MAE: 0.2633, evaluate MAE: 1.4543\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 375\n","\tbatch: 100, loss: 0.0602, MAE: 0.2357\n","\tbatch: 200, loss: 0.2081, MAE: 0.4336\n","Training:\t loss: 0.2069, MAE: 0.3425\n","Evaluating:\t loss: 0.0291, MAE: 0.1102\n","train MSE: 0.2069, evaluate MSE: 0.0291\n","\n","train MAE: 0.3425, evaluate MAE: 0.1102\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 376\n","\tbatch: 100, loss: 0.0077, MAE: 0.0516\n","\tbatch: 200, loss: 0.0556, MAE: 0.1975\n","Training:\t loss: 0.2656, MAE: 0.3647\n","Evaluating:\t loss: 0.6598, MAE: 0.7814\n","train MSE: 0.2656, evaluate MSE: 0.6598\n","\n","train MAE: 0.3647, evaluate MAE: 0.7814\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 377\n","\tbatch: 100, loss: 0.0077, MAE: 0.0657\n","\tbatch: 200, loss: 0.0406, MAE: 0.1547\n","Training:\t loss: 0.2022, MAE: 0.3017\n","Evaluating:\t loss: 0.0584, MAE: 0.1787\n","train MSE: 0.2022, evaluate MSE: 0.0584\n","\n","train MAE: 0.3017, evaluate MAE: 0.1787\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 378\n","\tbatch: 100, loss: 0.0143, MAE: 0.0924\n","\tbatch: 200, loss: 0.0652, MAE: 0.2459\n","Training:\t loss: 0.2825, MAE: 0.4166\n","Evaluating:\t loss: 0.5720, MAE: 0.6768\n","train MSE: 0.2825, evaluate MSE: 0.5720\n","\n","train MAE: 0.4166, evaluate MAE: 0.6768\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 379\n","\tbatch: 100, loss: 0.0257, MAE: 0.1361\n","\tbatch: 200, loss: 0.0047, MAE: 0.0449\n","Training:\t loss: 0.1784, MAE: 0.2534\n","Evaluating:\t loss: 0.0418, MAE: 0.1485\n","train MSE: 0.1784, evaluate MSE: 0.0418\n","\n","train MAE: 0.2534, evaluate MAE: 0.1485\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 380\n","\tbatch: 100, loss: 0.0695, MAE: 0.2167\n","\tbatch: 200, loss: 0.0568, MAE: 0.2300\n","Training:\t loss: 0.2439, MAE: 0.2902\n","Evaluating:\t loss: 0.2114, MAE: 0.3798\n","train MSE: 0.2439, evaluate MSE: 0.2114\n","\n","train MAE: 0.2902, evaluate MAE: 0.3798\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 381\n","\tbatch: 100, loss: 0.1153, MAE: 0.2472\n","\tbatch: 200, loss: 0.0202, MAE: 0.1314\n","Training:\t loss: 0.2250, MAE: 0.2713\n","Evaluating:\t loss: 0.0260, MAE: 0.1156\n","train MSE: 0.2250, evaluate MSE: 0.0260\n","\n","train MAE: 0.2713, evaluate MAE: 0.1156\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 382\n","\tbatch: 100, loss: 0.0546, MAE: 0.2226\n","\tbatch: 200, loss: 1.6486, MAE: 1.2394\n","Training:\t loss: 0.3099, MAE: 0.4222\n","Evaluating:\t loss: 0.0584, MAE: 0.1605\n","train MSE: 0.3099, evaluate MSE: 0.0584\n","\n","train MAE: 0.4222, evaluate MAE: 0.1605\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 383\n","\tbatch: 100, loss: 0.0212, MAE: 0.1044\n","\tbatch: 200, loss: 0.0472, MAE: 0.1890\n","Training:\t loss: 0.1583, MAE: 0.3004\n","Evaluating:\t loss: 0.4969, MAE: 0.6392\n","train MSE: 0.1583, evaluate MSE: 0.4969\n","\n","train MAE: 0.3004, evaluate MAE: 0.6392\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 384\n","\tbatch: 100, loss: 0.0145, MAE: 0.1036\n","\tbatch: 200, loss: 0.0047, MAE: 0.0507\n","Training:\t loss: 0.2606, MAE: 0.3316\n","Evaluating:\t loss: 0.0383, MAE: 0.1555\n","train MSE: 0.2606, evaluate MSE: 0.0383\n","\n","train MAE: 0.3316, evaluate MAE: 0.1555\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 385\n","\tbatch: 100, loss: 0.1098, MAE: 0.2790\n","\tbatch: 200, loss: 0.0399, MAE: 0.1645\n","Training:\t loss: 0.2371, MAE: 0.3546\n","Evaluating:\t loss: 0.0157, MAE: 0.0664\n","train MSE: 0.2371, evaluate MSE: 0.0157\n","\n","train MAE: 0.3546, evaluate MAE: 0.0664\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 386\n","\tbatch: 100, loss: 0.0136, MAE: 0.0737\n","\tbatch: 200, loss: 0.0303, MAE: 0.0884\n","Training:\t loss: 1.2903, MAE: 0.5359\n","Evaluating:\t loss: 213.1784, MAE: 13.2765\n","train MSE: 1.2903, evaluate MSE: 213.1784\n","\n","train MAE: 0.5359, evaluate MAE: 13.2765\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 387\n","\tbatch: 100, loss: 0.0775, MAE: 0.1584\n","\tbatch: 200, loss: 0.0258, MAE: 0.0888\n","Training:\t loss: 5.4986, MAE: 0.8095\n","Evaluating:\t loss: 0.1515, MAE: 0.0963\n","train MSE: 5.4986, evaluate MSE: 0.1515\n","\n","train MAE: 0.8095, evaluate MAE: 0.0963\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 388\n","\tbatch: 100, loss: 0.0112, MAE: 0.0633\n","\tbatch: 200, loss: 0.0118, MAE: 0.0611\n","Training:\t loss: 0.0244, MAE: 0.0811\n","Evaluating:\t loss: 0.0491, MAE: 0.0754\n","train MSE: 0.0244, evaluate MSE: 0.0491\n","\n","train MAE: 0.0811, evaluate MAE: 0.0754\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 389\n","\tbatch: 100, loss: 0.0117, MAE: 0.0624\n","\tbatch: 200, loss: 0.0083, MAE: 0.0499\n","Training:\t loss: 0.0132, MAE: 0.0610\n","Evaluating:\t loss: 0.0225, MAE: 0.0686\n","train MSE: 0.0132, evaluate MSE: 0.0225\n","\n","train MAE: 0.0610, evaluate MAE: 0.0686\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 390\n","\tbatch: 100, loss: 0.0097, MAE: 0.0630\n","\tbatch: 200, loss: 0.0325, MAE: 0.0578\n","Training:\t loss: 0.0108, MAE: 0.0582\n","Evaluating:\t loss: 0.0168, MAE: 0.0694\n","train MSE: 0.0108, evaluate MSE: 0.0168\n","\n","train MAE: 0.0582, evaluate MAE: 0.0694\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 391\n","\tbatch: 100, loss: 0.0251, MAE: 0.0641\n","\tbatch: 200, loss: 0.0073, MAE: 0.0618\n","Training:\t loss: 0.0118, MAE: 0.0618\n","Evaluating:\t loss: 0.0137, MAE: 0.0537\n","train MSE: 0.0118, evaluate MSE: 0.0137\n","\n","train MAE: 0.0618, evaluate MAE: 0.0537\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 392\n","\tbatch: 100, loss: 0.0063, MAE: 0.0498\n","\tbatch: 200, loss: 0.0048, MAE: 0.0512\n","Training:\t loss: 0.0089, MAE: 0.0567\n","Evaluating:\t loss: 0.0457, MAE: 0.1276\n","train MSE: 0.0089, evaluate MSE: 0.0457\n","\n","train MAE: 0.0567, evaluate MAE: 0.1276\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 393\n","\tbatch: 100, loss: 0.0044, MAE: 0.0516\n","\tbatch: 200, loss: 0.0053, MAE: 0.0549\n","Training:\t loss: 0.0203, MAE: 0.0799\n","Evaluating:\t loss: 0.0165, MAE: 0.0959\n","train MSE: 0.0203, evaluate MSE: 0.0165\n","\n","train MAE: 0.0799, evaluate MAE: 0.0959\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 394\n","\tbatch: 100, loss: 0.0293, MAE: 0.1639\n","\tbatch: 200, loss: 0.0159, MAE: 0.0977\n","Training:\t loss: 0.0849, MAE: 0.2059\n","Evaluating:\t loss: 0.5882, MAE: 0.7430\n","train MSE: 0.0849, evaluate MSE: 0.5882\n","\n","train MAE: 0.2059, evaluate MAE: 0.7430\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 395\n","\tbatch: 100, loss: 0.0310, MAE: 0.1481\n","\tbatch: 200, loss: 0.0830, MAE: 0.2480\n","Training:\t loss: 0.2344, MAE: 0.3291\n","Evaluating:\t loss: 0.0105, MAE: 0.0533\n","train MSE: 0.2344, evaluate MSE: 0.0105\n","\n","train MAE: 0.3291, evaluate MAE: 0.0533\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 396\n","\tbatch: 100, loss: 0.2656, MAE: 0.5030\n","\tbatch: 200, loss: 0.1177, MAE: 0.3003\n","Training:\t loss: 0.2650, MAE: 0.2946\n","Evaluating:\t loss: 0.0137, MAE: 0.0602\n","train MSE: 0.2650, evaluate MSE: 0.0137\n","\n","train MAE: 0.2946, evaluate MAE: 0.0602\n","\n","--- time consumption (s): 27\n","\n","------------------------------\n","Epoch 397\n","\tbatch: 100, loss: 0.0117, MAE: 0.0927\n","\tbatch: 200, loss: 0.2721, MAE: 0.4934\n","Training:\t loss: 0.1100, MAE: 0.2229\n","Evaluating:\t loss: 0.1001, MAE: 0.3014\n","train MSE: 0.1100, evaluate MSE: 0.1001\n","\n","train MAE: 0.2229, evaluate MAE: 0.3014\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 398\n","\tbatch: 100, loss: 0.0383, MAE: 0.1386\n","\tbatch: 200, loss: 0.2146, MAE: 0.4391\n","Training:\t loss: 0.3249, MAE: 0.4152\n","Evaluating:\t loss: 0.0284, MAE: 0.0907\n","train MSE: 0.3249, evaluate MSE: 0.0284\n","\n","train MAE: 0.4152, evaluate MAE: 0.0907\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 399\n","\tbatch: 100, loss: 0.1284, MAE: 0.1736\n","\tbatch: 200, loss: 0.0951, MAE: 0.3010\n","Training:\t loss: 0.1393, MAE: 0.2711\n","Evaluating:\t loss: 0.3617, MAE: 0.5853\n","train MSE: 0.1393, evaluate MSE: 0.3617\n","\n","train MAE: 0.2711, evaluate MAE: 0.5853\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 400\n","\tbatch: 100, loss: 0.1460, MAE: 0.3112\n","\tbatch: 200, loss: 0.0878, MAE: 0.2877\n","Training:\t loss: 0.2128, MAE: 0.3528\n","Evaluating:\t loss: 0.3454, MAE: 0.5573\n","train MSE: 0.2128, evaluate MSE: 0.3454\n","\n","train MAE: 0.3528, evaluate MAE: 0.5573\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 401\n","\tbatch: 100, loss: 0.0680, MAE: 0.2236\n","\tbatch: 200, loss: 0.2470, MAE: 0.4842\n","Training:\t loss: 0.2071, MAE: 0.3789\n","Evaluating:\t loss: 0.3478, MAE: 0.5770\n","train MSE: 0.2071, evaluate MSE: 0.3478\n","\n","train MAE: 0.3789, evaluate MAE: 0.5770\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 402\n","\tbatch: 100, loss: 0.0907, MAE: 0.2889\n","\tbatch: 200, loss: 0.0232, MAE: 0.1232\n","Training:\t loss: 0.2515, MAE: 0.3567\n","Evaluating:\t loss: 0.0133, MAE: 0.0823\n","train MSE: 0.2515, evaluate MSE: 0.0133\n","\n","train MAE: 0.3567, evaluate MAE: 0.0823\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 403\n","\tbatch: 100, loss: 0.0132, MAE: 0.0911\n","\tbatch: 200, loss: 0.8172, MAE: 0.8874\n","Training:\t loss: 0.1901, MAE: 0.3146\n","Evaluating:\t loss: 0.0669, MAE: 0.2263\n","train MSE: 0.1901, evaluate MSE: 0.0669\n","\n","train MAE: 0.3146, evaluate MAE: 0.2263\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 404\n","\tbatch: 100, loss: 0.0258, MAE: 0.1259\n","\tbatch: 200, loss: 0.8175, MAE: 0.7997\n","Training:\t loss: 0.3025, MAE: 0.3868\n","Evaluating:\t loss: 0.0564, MAE: 0.1662\n","train MSE: 0.3025, evaluate MSE: 0.0564\n","\n","train MAE: 0.3868, evaluate MAE: 0.1662\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 405\n","\tbatch: 100, loss: 0.1878, MAE: 0.4014\n","\tbatch: 200, loss: 0.1335, MAE: 0.3462\n","Training:\t loss: 0.1340, MAE: 0.2642\n","Evaluating:\t loss: 0.9217, MAE: 0.9467\n","train MSE: 0.1340, evaluate MSE: 0.9217\n","\n","train MAE: 0.2642, evaluate MAE: 0.9467\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 406\n","\tbatch: 100, loss: 0.5623, MAE: 0.7418\n","\tbatch: 200, loss: 0.1018, MAE: 0.3077\n","Training:\t loss: 0.2850, MAE: 0.3928\n","Evaluating:\t loss: 1.1748, MAE: 1.0252\n","train MSE: 0.2850, evaluate MSE: 1.1748\n","\n","train MAE: 0.3928, evaluate MAE: 1.0252\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 407\n","\tbatch: 100, loss: 0.5141, MAE: 0.5681\n","\tbatch: 200, loss: 0.0179, MAE: 0.1076\n","Training:\t loss: 0.2094, MAE: 0.3357\n","Evaluating:\t loss: 0.2383, MAE: 0.4563\n","train MSE: 0.2094, evaluate MSE: 0.2383\n","\n","train MAE: 0.3357, evaluate MAE: 0.4563\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 408\n","\tbatch: 100, loss: 0.2439, MAE: 0.3780\n","\tbatch: 200, loss: 0.0063, MAE: 0.0428\n","Training:\t loss: 0.2778, MAE: 0.3600\n","Evaluating:\t loss: 0.0317, MAE: 0.1358\n","train MSE: 0.2778, evaluate MSE: 0.0317\n","\n","train MAE: 0.3600, evaluate MAE: 0.1358\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 409\n","\tbatch: 100, loss: 0.0970, MAE: 0.2707\n","\tbatch: 200, loss: 0.0078, MAE: 0.0587\n","Training:\t loss: 0.2871, MAE: 0.3644\n","Evaluating:\t loss: 0.0211, MAE: 0.0772\n","train MSE: 0.2871, evaluate MSE: 0.0211\n","\n","train MAE: 0.3644, evaluate MAE: 0.0772\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 410\n","\tbatch: 100, loss: 0.0292, MAE: 0.1361\n","\tbatch: 200, loss: 0.0338, MAE: 0.1587\n","Training:\t loss: 0.1675, MAE: 0.2256\n","Evaluating:\t loss: 0.1530, MAE: 0.3516\n","train MSE: 0.1675, evaluate MSE: 0.1530\n","\n","train MAE: 0.2256, evaluate MAE: 0.3516\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 411\n","\tbatch: 100, loss: 0.2216, MAE: 0.4179\n","\tbatch: 200, loss: 0.0528, MAE: 0.1781\n","Training:\t loss: 0.1916, MAE: 0.3408\n","Evaluating:\t loss: 0.6431, MAE: 0.7649\n","train MSE: 0.1916, evaluate MSE: 0.6431\n","\n","train MAE: 0.3408, evaluate MAE: 0.7649\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 412\n","\tbatch: 100, loss: 0.0374, MAE: 0.1734\n","\tbatch: 200, loss: 0.2609, MAE: 0.4633\n","Training:\t loss: 0.2351, MAE: 0.3848\n","Evaluating:\t loss: 0.0102, MAE: 0.0640\n","train MSE: 0.2351, evaluate MSE: 0.0102\n","\n","train MAE: 0.3848, evaluate MAE: 0.0640\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 413\n","\tbatch: 100, loss: 0.1230, MAE: 0.3191\n","\tbatch: 200, loss: 0.0608, MAE: 0.2208\n","Training:\t loss: 0.1877, MAE: 0.3396\n","Evaluating:\t loss: 0.0221, MAE: 0.1278\n","train MSE: 0.1877, evaluate MSE: 0.0221\n","\n","train MAE: 0.3396, evaluate MAE: 0.1278\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 414\n","\tbatch: 100, loss: 0.0301, MAE: 0.1609\n","\tbatch: 200, loss: 1.2039, MAE: 0.8659\n","Training:\t loss: 16.3563, MAE: 1.5342\n","Evaluating:\t loss: 0.2797, MAE: 0.3198\n","train MSE: 16.3563, evaluate MSE: 0.2797\n","\n","train MAE: 1.5342, evaluate MAE: 0.3198\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 415\n","\tbatch: 100, loss: 0.1490, MAE: 0.1424\n","\tbatch: 200, loss: 0.0246, MAE: 0.0960\n","Training:\t loss: 0.0615, MAE: 0.1272\n","Evaluating:\t loss: 0.0381, MAE: 0.0952\n","train MSE: 0.0615, evaluate MSE: 0.0381\n","\n","train MAE: 0.1272, evaluate MAE: 0.0952\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 416\n","\tbatch: 100, loss: 0.0202, MAE: 0.0751\n","\tbatch: 200, loss: 0.0142, MAE: 0.0798\n","Training:\t loss: 0.0238, MAE: 0.0849\n","Evaluating:\t loss: 0.0247, MAE: 0.0785\n","train MSE: 0.0238, evaluate MSE: 0.0247\n","\n","train MAE: 0.0849, evaluate MAE: 0.0785\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 417\n","\tbatch: 100, loss: 0.0155, MAE: 0.0657\n","\tbatch: 200, loss: 0.0147, MAE: 0.0655\n","Training:\t loss: 0.0206, MAE: 0.0752\n","Evaluating:\t loss: 0.0209, MAE: 0.0671\n","train MSE: 0.0206, evaluate MSE: 0.0209\n","\n","train MAE: 0.0752, evaluate MAE: 0.0671\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 418\n","\tbatch: 100, loss: 0.0139, MAE: 0.0657\n","\tbatch: 200, loss: 0.0113, MAE: 0.0613\n","Training:\t loss: 0.0131, MAE: 0.0636\n","Evaluating:\t loss: 0.0386, MAE: 0.1247\n","train MSE: 0.0131, evaluate MSE: 0.0386\n","\n","train MAE: 0.0636, evaluate MAE: 0.1247\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 419\n","\tbatch: 100, loss: 0.0099, MAE: 0.0621\n","\tbatch: 200, loss: 0.0067, MAE: 0.0533\n","Training:\t loss: 0.0115, MAE: 0.0620\n","Evaluating:\t loss: 0.0219, MAE: 0.0647\n","train MSE: 0.0115, evaluate MSE: 0.0219\n","\n","train MAE: 0.0620, evaluate MAE: 0.0647\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 420\n","\tbatch: 100, loss: 0.0060, MAE: 0.0553\n","\tbatch: 200, loss: 0.0112, MAE: 0.0698\n","Training:\t loss: 0.0110, MAE: 0.0626\n","Evaluating:\t loss: 0.0161, MAE: 0.0632\n","train MSE: 0.0110, evaluate MSE: 0.0161\n","\n","train MAE: 0.0626, evaluate MAE: 0.0632\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 421\n","\tbatch: 100, loss: 0.0140, MAE: 0.0823\n","\tbatch: 200, loss: 0.0059, MAE: 0.0453\n","Training:\t loss: 0.0123, MAE: 0.0604\n","Evaluating:\t loss: 0.0110, MAE: 0.0594\n","train MSE: 0.0123, evaluate MSE: 0.0110\n","\n","train MAE: 0.0604, evaluate MAE: 0.0594\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 422\n","\tbatch: 100, loss: 0.0109, MAE: 0.0622\n","\tbatch: 200, loss: 0.0035, MAE: 0.0393\n","Training:\t loss: 0.0084, MAE: 0.0545\n","Evaluating:\t loss: 0.0118, MAE: 0.0485\n","train MSE: 0.0084, evaluate MSE: 0.0118\n","\n","train MAE: 0.0545, evaluate MAE: 0.0485\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 423\n","\tbatch: 100, loss: 0.0101, MAE: 0.0499\n","\tbatch: 200, loss: 0.0084, MAE: 0.0663\n","Training:\t loss: 0.0156, MAE: 0.0849\n","Evaluating:\t loss: 0.0454, MAE: 0.1888\n","train MSE: 0.0156, evaluate MSE: 0.0454\n","\n","train MAE: 0.0849, evaluate MAE: 0.1888\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 424\n","\tbatch: 100, loss: 0.0047, MAE: 0.0482\n","\tbatch: 200, loss: 0.2204, MAE: 0.4627\n","Training:\t loss: 0.0785, MAE: 0.2233\n","Evaluating:\t loss: 0.1882, MAE: 0.4058\n","train MSE: 0.0785, evaluate MSE: 0.1882\n","\n","train MAE: 0.2233, evaluate MAE: 0.4058\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 425\n","\tbatch: 100, loss: 0.0581, MAE: 0.0837\n","\tbatch: 200, loss: 0.0112, MAE: 0.0921\n","Training:\t loss: 0.1212, MAE: 0.2860\n","Evaluating:\t loss: 0.1401, MAE: 0.3270\n","train MSE: 0.1212, evaluate MSE: 0.1401\n","\n","train MAE: 0.2860, evaluate MAE: 0.3270\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 426\n","\tbatch: 100, loss: 0.0524, MAE: 0.2128\n","\tbatch: 200, loss: 0.0114, MAE: 0.0915\n","Training:\t loss: 0.1600, MAE: 0.2936\n","Evaluating:\t loss: 0.8816, MAE: 0.9100\n","train MSE: 0.1600, evaluate MSE: 0.8816\n","\n","train MAE: 0.2936, evaluate MAE: 0.9100\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 427\n","\tbatch: 100, loss: 0.0128, MAE: 0.0964\n","\tbatch: 200, loss: 0.0362, MAE: 0.1349\n","Training:\t loss: 0.1731, MAE: 0.3150\n","Evaluating:\t loss: 0.3336, MAE: 0.5588\n","train MSE: 0.1731, evaluate MSE: 0.3336\n","\n","train MAE: 0.3150, evaluate MAE: 0.5588\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 428\n","\tbatch: 100, loss: 0.0572, MAE: 0.2066\n","\tbatch: 200, loss: 0.3991, MAE: 0.6061\n","Training:\t loss: 0.1916, MAE: 0.3389\n","Evaluating:\t loss: 0.0635, MAE: 0.2182\n","train MSE: 0.1916, evaluate MSE: 0.0635\n","\n","train MAE: 0.3389, evaluate MAE: 0.2182\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 429\n","\tbatch: 100, loss: 0.0166, MAE: 0.1111\n","\tbatch: 200, loss: 0.0247, MAE: 0.1342\n","Training:\t loss: 0.2465, MAE: 0.3233\n","Evaluating:\t loss: 0.0136, MAE: 0.0790\n","train MSE: 0.2465, evaluate MSE: 0.0136\n","\n","train MAE: 0.3233, evaluate MAE: 0.0790\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 430\n","\tbatch: 100, loss: 0.3607, MAE: 0.4394\n","\tbatch: 200, loss: 0.0134, MAE: 0.1055\n","Training:\t loss: 0.1239, MAE: 0.2430\n","Evaluating:\t loss: 0.2431, MAE: 0.4594\n","train MSE: 0.1239, evaluate MSE: 0.2431\n","\n","train MAE: 0.2430, evaluate MAE: 0.4594\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 431\n","\tbatch: 100, loss: 1.7672, MAE: 1.3200\n","\tbatch: 200, loss: 0.0929, MAE: 0.1962\n","Training:\t loss: 0.3231, MAE: 0.4142\n","Evaluating:\t loss: 0.0485, MAE: 0.1750\n","train MSE: 0.3231, evaluate MSE: 0.0485\n","\n","train MAE: 0.4142, evaluate MAE: 0.1750\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 432\n","\tbatch: 100, loss: 0.0081, MAE: 0.0633\n","\tbatch: 200, loss: 0.2987, MAE: 0.5124\n","Training:\t loss: 0.2102, MAE: 0.2655\n","Evaluating:\t loss: 0.1491, MAE: 0.3490\n","train MSE: 0.2102, evaluate MSE: 0.1491\n","\n","train MAE: 0.2655, evaluate MAE: 0.3490\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 433\n","\tbatch: 100, loss: 0.0187, MAE: 0.1017\n","\tbatch: 200, loss: 0.0080, MAE: 0.0471\n","Training:\t loss: 0.1538, MAE: 0.2285\n","Evaluating:\t loss: 0.0919, MAE: 0.2580\n","train MSE: 0.1538, evaluate MSE: 0.0919\n","\n","train MAE: 0.2285, evaluate MAE: 0.2580\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 434\n","\tbatch: 100, loss: 0.0206, MAE: 0.1158\n","\tbatch: 200, loss: 0.0122, MAE: 0.0811\n","Training:\t loss: 0.2815, MAE: 0.3744\n","Evaluating:\t loss: 0.0457, MAE: 0.1399\n","train MSE: 0.2815, evaluate MSE: 0.0457\n","\n","train MAE: 0.3744, evaluate MAE: 0.1399\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 435\n","\tbatch: 100, loss: 0.5182, MAE: 0.5566\n","\tbatch: 200, loss: 0.0330, MAE: 0.1453\n","Training:\t loss: 0.2296, MAE: 0.2525\n","Evaluating:\t loss: 0.0286, MAE: 0.0695\n","train MSE: 0.2296, evaluate MSE: 0.0286\n","\n","train MAE: 0.2525, evaluate MAE: 0.0695\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 436\n","\tbatch: 100, loss: 0.1663, MAE: 0.3991\n","\tbatch: 200, loss: 0.3543, MAE: 0.5873\n","Training:\t loss: 0.3427, MAE: 0.3478\n","Evaluating:\t loss: 0.3682, MAE: 0.4006\n","train MSE: 0.3427, evaluate MSE: 0.3682\n","\n","train MAE: 0.3478, evaluate MAE: 0.4006\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 437\n","\tbatch: 100, loss: 0.0205, MAE: 0.0897\n","\tbatch: 200, loss: 0.4038, MAE: 0.5967\n","Training:\t loss: 0.1805, MAE: 0.2625\n","Evaluating:\t loss: 0.1158, MAE: 0.2444\n","train MSE: 0.1805, evaluate MSE: 0.1158\n","\n","train MAE: 0.2625, evaluate MAE: 0.2444\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 438\n","\tbatch: 100, loss: 0.6663, MAE: 0.7677\n","\tbatch: 200, loss: 0.0753, MAE: 0.2345\n","Training:\t loss: 0.2327, MAE: 0.3688\n","Evaluating:\t loss: 0.6422, MAE: 0.7247\n","train MSE: 0.2327, evaluate MSE: 0.6422\n","\n","train MAE: 0.3688, evaluate MAE: 0.7247\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 439\n","\tbatch: 100, loss: 0.0184, MAE: 0.0888\n","\tbatch: 200, loss: 0.2023, MAE: 0.3209\n","Training:\t loss: 0.3567, MAE: 0.3837\n","Evaluating:\t loss: 0.0891, MAE: 0.2091\n","train MSE: 0.3567, evaluate MSE: 0.0891\n","\n","train MAE: 0.3837, evaluate MAE: 0.2091\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 440\n","\tbatch: 100, loss: 0.0079, MAE: 0.0601\n","\tbatch: 200, loss: 0.0465, MAE: 0.1976\n","Training:\t loss: 0.0807, MAE: 0.1896\n","Evaluating:\t loss: 0.4529, MAE: 0.6544\n","train MSE: 0.0807, evaluate MSE: 0.4529\n","\n","train MAE: 0.1896, evaluate MAE: 0.6544\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 441\n","\tbatch: 100, loss: 0.2729, MAE: 0.4619\n","\tbatch: 200, loss: 0.0131, MAE: 0.0898\n","Training:\t loss: 0.2010, MAE: 0.2822\n","Evaluating:\t loss: 0.0104, MAE: 0.0627\n","train MSE: 0.2010, evaluate MSE: 0.0104\n","\n","train MAE: 0.2822, evaluate MAE: 0.0627\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 442\n","\tbatch: 100, loss: 0.4294, MAE: 0.6276\n","\tbatch: 200, loss: 0.1309, MAE: 0.3285\n","Training:\t loss: 0.2093, MAE: 0.3341\n","Evaluating:\t loss: 0.0302, MAE: 0.0842\n","train MSE: 0.2093, evaluate MSE: 0.0302\n","\n","train MAE: 0.3341, evaluate MAE: 0.0842\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 443\n","\tbatch: 100, loss: 0.0078, MAE: 0.0614\n","\tbatch: 200, loss: 0.2442, MAE: 0.4519\n","Training:\t loss: 0.2711, MAE: 0.3617\n","Evaluating:\t loss: 0.0192, MAE: 0.0729\n","train MSE: 0.2711, evaluate MSE: 0.0192\n","\n","train MAE: 0.3617, evaluate MAE: 0.0729\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 444\n","\tbatch: 100, loss: 0.2104, MAE: 0.4387\n","\tbatch: 200, loss: 0.0201, MAE: 0.1260\n","Training:\t loss: 0.3664, MAE: 0.2884\n","Evaluating:\t loss: 0.0160, MAE: 0.0661\n","train MSE: 0.3664, evaluate MSE: 0.0160\n","\n","train MAE: 0.2884, evaluate MAE: 0.0661\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 445\n","\tbatch: 100, loss: 0.0352, MAE: 0.1375\n","\tbatch: 200, loss: 0.0083, MAE: 0.0632\n","Training:\t loss: 0.0620, MAE: 0.1586\n","Evaluating:\t loss: 0.0296, MAE: 0.0737\n","train MSE: 0.0620, evaluate MSE: 0.0296\n","\n","train MAE: 0.1586, evaluate MAE: 0.0737\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 446\n","\tbatch: 100, loss: 0.0182, MAE: 0.1248\n","\tbatch: 200, loss: 0.0100, MAE: 0.0718\n","Training:\t loss: 0.1903, MAE: 0.2802\n","Evaluating:\t loss: 0.0402, MAE: 0.1613\n","train MSE: 0.1903, evaluate MSE: 0.0402\n","\n","train MAE: 0.2802, evaluate MAE: 0.1613\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 447\n","\tbatch: 100, loss: 0.0123, MAE: 0.0852\n","\tbatch: 200, loss: 0.4922, MAE: 0.6835\n","Training:\t loss: 0.2161, MAE: 0.3210\n","Evaluating:\t loss: 0.1767, MAE: 0.3924\n","train MSE: 0.2161, evaluate MSE: 0.1767\n","\n","train MAE: 0.3210, evaluate MAE: 0.3924\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 448\n","\tbatch: 100, loss: 0.0093, MAE: 0.0719\n","\tbatch: 200, loss: 0.1297, MAE: 0.3333\n","Training:\t loss: 0.2011, MAE: 0.2957\n","Evaluating:\t loss: 0.0090, MAE: 0.0514\n","train MSE: 0.2011, evaluate MSE: 0.0090\n","\n","train MAE: 0.2957, evaluate MAE: 0.0514\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 449\n","\tbatch: 100, loss: 0.0028, MAE: 0.0374\n","\tbatch: 200, loss: 0.0918, MAE: 0.2053\n","Training:\t loss: 0.2677, MAE: 0.3276\n","Evaluating:\t loss: 0.0737, MAE: 0.1505\n","train MSE: 0.2677, evaluate MSE: 0.0737\n","\n","train MAE: 0.3276, evaluate MAE: 0.1505\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 450\n","\tbatch: 100, loss: 0.2013, MAE: 0.4114\n","\tbatch: 200, loss: 0.0490, MAE: 0.2098\n","Training:\t loss: 0.1890, MAE: 0.2868\n","Evaluating:\t loss: 0.0211, MAE: 0.0744\n","train MSE: 0.1890, evaluate MSE: 0.0211\n","\n","train MAE: 0.2868, evaluate MAE: 0.0744\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 451\n","\tbatch: 100, loss: 0.0616, MAE: 0.2226\n","\tbatch: 200, loss: 0.0230, MAE: 0.1243\n","Training:\t loss: 0.3448, MAE: 0.3701\n","Evaluating:\t loss: 0.0351, MAE: 0.0972\n","train MSE: 0.3448, evaluate MSE: 0.0351\n","\n","train MAE: 0.3701, evaluate MAE: 0.0972\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 452\n","\tbatch: 100, loss: 0.0375, MAE: 0.1758\n","\tbatch: 200, loss: 0.1035, MAE: 0.2854\n","Training:\t loss: 0.0716, MAE: 0.1714\n","Evaluating:\t loss: 0.0128, MAE: 0.0857\n","train MSE: 0.0716, evaluate MSE: 0.0128\n","\n","train MAE: 0.1714, evaluate MAE: 0.0857\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 453\n","\tbatch: 100, loss: 0.1218, MAE: 0.3208\n","\tbatch: 200, loss: 0.0212, MAE: 0.1064\n","Training:\t loss: 0.1605, MAE: 0.3073\n","Evaluating:\t loss: 0.0229, MAE: 0.1163\n","train MSE: 0.1605, evaluate MSE: 0.0229\n","\n","train MAE: 0.3073, evaluate MAE: 0.1163\n","\n","--- time consumption (s): 26\n","\n","------------------------------\n","Epoch 454\n","\tbatch: 100, loss: 0.0149, MAE: 0.1097\n","\tbatch: 200, loss: 1.6866, MAE: 1.2862\n","Training:\t loss: 0.3232, MAE: 0.3541\n","Evaluating:\t loss: 0.4052, MAE: 0.5878\n","train MSE: 0.3232, evaluate MSE: 0.4052\n","\n","train MAE: 0.3541, evaluate MAE: 0.5878\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 455\n","\tbatch: 100, loss: 0.0165, MAE: 0.0817\n","\tbatch: 200, loss: 0.9996, MAE: 0.9885\n","Training:\t loss: 0.1242, MAE: 0.2144\n","Evaluating:\t loss: 0.2907, MAE: 0.4956\n","train MSE: 0.1242, evaluate MSE: 0.2907\n","\n","train MAE: 0.2144, evaluate MAE: 0.4956\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 456\n","\tbatch: 100, loss: 0.9336, MAE: 0.9356\n","\tbatch: 200, loss: 0.6614, MAE: 0.7498\n","Training:\t loss: 0.1477, MAE: 0.2662\n","Evaluating:\t loss: 0.0252, MAE: 0.1160\n","train MSE: 0.1477, evaluate MSE: 0.0252\n","\n","train MAE: 0.2662, evaluate MAE: 0.1160\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 457\n","\tbatch: 100, loss: 0.0319, MAE: 0.1492\n","\tbatch: 200, loss: 0.0296, MAE: 0.1250\n","Training:\t loss: 0.1762, MAE: 0.3411\n","Evaluating:\t loss: 0.0688, MAE: 0.2087\n","train MSE: 0.1762, evaluate MSE: 0.0688\n","\n","train MAE: 0.3411, evaluate MAE: 0.2087\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 458\n","\tbatch: 100, loss: 0.0193, MAE: 0.1016\n","\tbatch: 200, loss: 0.3348, MAE: 0.4519\n","Training:\t loss: 0.4514, MAE: 0.4786\n","Evaluating:\t loss: 0.0442, MAE: 0.1710\n","train MSE: 0.4514, evaluate MSE: 0.0442\n","\n","train MAE: 0.4786, evaluate MAE: 0.1710\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 459\n","\tbatch: 100, loss: 0.0611, MAE: 0.2289\n","\tbatch: 200, loss: 1.8242, MAE: 1.2823\n","Training:\t loss: 0.1341, MAE: 0.2037\n","Evaluating:\t loss: 0.2358, MAE: 0.3333\n","train MSE: 0.1341, evaluate MSE: 0.2358\n","\n","train MAE: 0.2037, evaluate MAE: 0.3333\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 460\n","\tbatch: 100, loss: 0.1242, MAE: 0.3174\n","\tbatch: 200, loss: 0.2987, MAE: 0.4783\n","Training:\t loss: 0.2535, MAE: 0.3053\n","Evaluating:\t loss: 0.0154, MAE: 0.0566\n","train MSE: 0.2535, evaluate MSE: 0.0154\n","\n","train MAE: 0.3053, evaluate MAE: 0.0566\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 461\n","\tbatch: 100, loss: 0.0528, MAE: 0.1938\n","\tbatch: 200, loss: 0.0108, MAE: 0.0859\n","Training:\t loss: 0.0888, MAE: 0.1959\n","Evaluating:\t loss: 0.1014, MAE: 0.2772\n","train MSE: 0.0888, evaluate MSE: 0.1014\n","\n","train MAE: 0.1959, evaluate MAE: 0.2772\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 462\n","\tbatch: 100, loss: 0.1230, MAE: 0.3276\n","\tbatch: 200, loss: 0.0279, MAE: 0.1496\n","Training:\t loss: 0.1612, MAE: 0.3219\n","Evaluating:\t loss: 0.3890, MAE: 0.6025\n","train MSE: 0.1612, evaluate MSE: 0.3890\n","\n","train MAE: 0.3219, evaluate MAE: 0.6025\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 463\n","\tbatch: 100, loss: 0.0370, MAE: 0.1617\n","\tbatch: 200, loss: 0.1693, MAE: 0.3936\n","Training:\t loss: 0.2929, MAE: 0.4054\n","Evaluating:\t loss: 0.2283, MAE: 0.3800\n","train MSE: 0.2929, evaluate MSE: 0.2283\n","\n","train MAE: 0.4054, evaluate MAE: 0.3800\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 464\n","\tbatch: 100, loss: 0.0750, MAE: 0.1416\n","\tbatch: 200, loss: 0.1213, MAE: 0.3140\n","Training:\t loss: 0.1608, MAE: 0.2695\n","Evaluating:\t loss: 0.0896, MAE: 0.2154\n","train MSE: 0.1608, evaluate MSE: 0.0896\n","\n","train MAE: 0.2695, evaluate MAE: 0.2154\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 465\n","\tbatch: 100, loss: 0.0089, MAE: 0.0692\n","\tbatch: 200, loss: 0.0858, MAE: 0.2671\n","Training:\t loss: 0.1523, MAE: 0.3015\n","Evaluating:\t loss: 0.4609, MAE: 0.6537\n","train MSE: 0.1523, evaluate MSE: 0.4609\n","\n","train MAE: 0.3015, evaluate MAE: 0.6537\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 466\n","\tbatch: 100, loss: 0.4892, MAE: 0.6786\n","\tbatch: 200, loss: 324.3942, MAE: 16.8008\n","Training:\t loss: 14.0949, MAE: 1.3238\n","Evaluating:\t loss: 2.0145, MAE: 1.1297\n","train MSE: 14.0949, evaluate MSE: 2.0145\n","\n","train MAE: 1.3238, evaluate MAE: 1.1297\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 467\n","\tbatch: 100, loss: 0.0781, MAE: 0.1816\n","\tbatch: 200, loss: 0.0397, MAE: 0.1204\n","Training:\t loss: 0.2093, MAE: 0.2291\n","Evaluating:\t loss: 0.0853, MAE: 0.1297\n","train MSE: 0.2093, evaluate MSE: 0.0853\n","\n","train MAE: 0.2291, evaluate MAE: 0.1297\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 468\n","\tbatch: 100, loss: 0.0333, MAE: 0.1163\n","\tbatch: 200, loss: 0.0335, MAE: 0.1246\n","Training:\t loss: 0.0491, MAE: 0.1250\n","Evaluating:\t loss: 0.0600, MAE: 0.1727\n","train MSE: 0.0491, evaluate MSE: 0.0600\n","\n","train MAE: 0.1250, evaluate MAE: 0.1727\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 469\n","\tbatch: 100, loss: 0.0344, MAE: 0.1009\n","\tbatch: 200, loss: 0.0139, MAE: 0.0761\n","Training:\t loss: 0.0306, MAE: 0.1032\n","Evaluating:\t loss: 0.0409, MAE: 0.1272\n","train MSE: 0.0306, evaluate MSE: 0.0409\n","\n","train MAE: 0.1032, evaluate MAE: 0.1272\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 470\n","\tbatch: 100, loss: 0.0661, MAE: 0.1676\n","\tbatch: 200, loss: 0.0457, MAE: 0.1130\n","Training:\t loss: 0.0272, MAE: 0.1095\n","Evaluating:\t loss: 0.0349, MAE: 0.1315\n","train MSE: 0.0272, evaluate MSE: 0.0349\n","\n","train MAE: 0.1095, evaluate MAE: 0.1315\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 471\n","\tbatch: 100, loss: 0.0291, MAE: 0.1508\n","\tbatch: 200, loss: 0.0093, MAE: 0.0646\n","Training:\t loss: 0.0297, MAE: 0.1257\n","Evaluating:\t loss: 0.0323, MAE: 0.1285\n","train MSE: 0.0297, evaluate MSE: 0.0323\n","\n","train MAE: 0.1257, evaluate MAE: 0.1285\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 472\n","\tbatch: 100, loss: 0.0451, MAE: 0.1702\n","\tbatch: 200, loss: 0.0460, MAE: 0.1917\n","Training:\t loss: 0.0448, MAE: 0.1629\n","Evaluating:\t loss: 0.1152, MAE: 0.3140\n","train MSE: 0.0448, evaluate MSE: 0.1152\n","\n","train MAE: 0.1629, evaluate MAE: 0.3140\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 473\n","\tbatch: 100, loss: 0.0150, MAE: 0.0838\n","\tbatch: 200, loss: 0.0357, MAE: 0.1694\n","Training:\t loss: 0.0585, MAE: 0.1753\n","Evaluating:\t loss: 0.1148, MAE: 0.3179\n","train MSE: 0.0585, evaluate MSE: 0.1148\n","\n","train MAE: 0.1753, evaluate MAE: 0.3179\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 474\n","\tbatch: 100, loss: 0.0333, MAE: 0.1622\n","\tbatch: 200, loss: 0.0424, MAE: 0.1886\n","Training:\t loss: 0.0939, MAE: 0.2342\n","Evaluating:\t loss: 0.0376, MAE: 0.1602\n","train MSE: 0.0939, evaluate MSE: 0.0376\n","\n","train MAE: 0.2342, evaluate MAE: 0.1602\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 475\n","\tbatch: 100, loss: 0.0221, MAE: 0.1137\n","\tbatch: 200, loss: 0.0552, MAE: 0.1786\n","Training:\t loss: 0.1396, MAE: 0.2980\n","Evaluating:\t loss: 0.3359, MAE: 0.5541\n","train MSE: 0.1396, evaluate MSE: 0.3359\n","\n","train MAE: 0.2980, evaluate MAE: 0.5541\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 476\n","\tbatch: 100, loss: 0.0465, MAE: 0.1457\n","\tbatch: 200, loss: 0.0165, MAE: 0.0813\n","Training:\t loss: 0.1181, MAE: 0.2715\n","Evaluating:\t loss: 0.2196, MAE: 0.4552\n","train MSE: 0.1181, evaluate MSE: 0.2196\n","\n","train MAE: 0.2715, evaluate MAE: 0.4552\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 477\n","\tbatch: 100, loss: 0.0726, MAE: 0.2540\n","\tbatch: 200, loss: 0.0247, MAE: 0.1250\n","Training:\t loss: 0.1286, MAE: 0.2903\n","Evaluating:\t loss: 0.0141, MAE: 0.0601\n","train MSE: 0.1286, evaluate MSE: 0.0141\n","\n","train MAE: 0.2903, evaluate MAE: 0.0601\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 478\n","\tbatch: 100, loss: 0.1611, MAE: 0.3831\n","\tbatch: 200, loss: 0.0552, MAE: 0.2007\n","Training:\t loss: 0.1376, MAE: 0.2899\n","Evaluating:\t loss: 0.0778, MAE: 0.2609\n","train MSE: 0.1376, evaluate MSE: 0.0778\n","\n","train MAE: 0.2899, evaluate MAE: 0.2609\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 479\n","\tbatch: 100, loss: 0.0098, MAE: 0.0578\n","\tbatch: 200, loss: 0.0188, MAE: 0.0986\n","Training:\t loss: 0.2217, MAE: 0.2886\n","Evaluating:\t loss: 0.0214, MAE: 0.1015\n","train MSE: 0.2217, evaluate MSE: 0.0214\n","\n","train MAE: 0.2886, evaluate MAE: 0.1015\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 480\n","\tbatch: 100, loss: 0.1624, MAE: 0.3742\n","\tbatch: 200, loss: 0.1733, MAE: 0.2971\n","Training:\t loss: 0.1498, MAE: 0.2879\n","Evaluating:\t loss: 0.1924, MAE: 0.4280\n","train MSE: 0.1498, evaluate MSE: 0.1924\n","\n","train MAE: 0.2879, evaluate MAE: 0.4280\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 481\n","\tbatch: 100, loss: 0.2425, MAE: 0.4750\n","\tbatch: 200, loss: 0.2386, MAE: 0.4780\n","Training:\t loss: 0.1612, MAE: 0.3256\n","Evaluating:\t loss: 0.1908, MAE: 0.4204\n","train MSE: 0.1612, evaluate MSE: 0.1908\n","\n","train MAE: 0.3256, evaluate MAE: 0.4204\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 482\n","\tbatch: 100, loss: 0.0544, MAE: 0.2232\n","\tbatch: 200, loss: 0.1548, MAE: 0.3549\n","Training:\t loss: 0.1695, MAE: 0.3176\n","Evaluating:\t loss: 0.0327, MAE: 0.1518\n","train MSE: 0.1695, evaluate MSE: 0.0327\n","\n","train MAE: 0.3176, evaluate MAE: 0.1518\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 483\n","\tbatch: 100, loss: 0.2242, MAE: 0.4308\n","\tbatch: 200, loss: 0.0098, MAE: 0.0632\n","Training:\t loss: 0.1676, MAE: 0.2865\n","Evaluating:\t loss: 0.7297, MAE: 0.8415\n","train MSE: 0.1676, evaluate MSE: 0.7297\n","\n","train MAE: 0.2865, evaluate MAE: 0.8415\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 484\n","\tbatch: 100, loss: 0.0056, MAE: 0.0454\n","\tbatch: 200, loss: 0.0075, MAE: 0.0686\n","Training:\t loss: 0.2139, MAE: 0.2857\n","Evaluating:\t loss: 0.0799, MAE: 0.2118\n","train MSE: 0.2139, evaluate MSE: 0.0799\n","\n","train MAE: 0.2857, evaluate MAE: 0.2118\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 485\n","\tbatch: 100, loss: 0.1319, MAE: 0.2774\n","\tbatch: 200, loss: 0.0638, MAE: 0.2242\n","Training:\t loss: 0.1931, MAE: 0.3214\n","Evaluating:\t loss: 0.0158, MAE: 0.0772\n","train MSE: 0.1931, evaluate MSE: 0.0158\n","\n","train MAE: 0.3214, evaluate MAE: 0.0772\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 486\n","\tbatch: 100, loss: 0.0326, MAE: 0.1420\n","\tbatch: 200, loss: 0.1241, MAE: 0.3295\n","Training:\t loss: 0.2332, MAE: 0.3531\n","Evaluating:\t loss: 0.1812, MAE: 0.3549\n","train MSE: 0.2332, evaluate MSE: 0.1812\n","\n","train MAE: 0.3531, evaluate MAE: 0.3549\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 487\n","\tbatch: 100, loss: 0.0719, MAE: 0.2216\n","\tbatch: 200, loss: 0.0795, MAE: 0.2114\n","Training:\t loss: 0.2115, MAE: 0.3118\n","Evaluating:\t loss: 0.0515, MAE: 0.1268\n","train MSE: 0.2115, evaluate MSE: 0.0515\n","\n","train MAE: 0.3118, evaluate MAE: 0.1268\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 488\n","\tbatch: 100, loss: 0.4937, MAE: 0.6736\n","\tbatch: 200, loss: 1.3000, MAE: 1.1027\n","Training:\t loss: 0.1965, MAE: 0.3238\n","Evaluating:\t loss: 0.1155, MAE: 0.3011\n","train MSE: 0.1965, evaluate MSE: 0.1155\n","\n","train MAE: 0.3238, evaluate MAE: 0.3011\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 489\n","\tbatch: 100, loss: 0.2418, MAE: 0.4604\n","\tbatch: 200, loss: 1.1937, MAE: 1.0319\n","Training:\t loss: 0.1838, MAE: 0.3087\n","Evaluating:\t loss: 0.4864, MAE: 0.6508\n","train MSE: 0.1838, evaluate MSE: 0.4864\n","\n","train MAE: 0.3087, evaluate MAE: 0.6508\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 490\n","\tbatch: 100, loss: 0.4589, MAE: 0.6362\n","\tbatch: 200, loss: 0.1642, MAE: 0.3483\n","Training:\t loss: 0.1795, MAE: 0.3071\n","Evaluating:\t loss: 0.0932, MAE: 0.2732\n","train MSE: 0.1795, evaluate MSE: 0.0932\n","\n","train MAE: 0.3071, evaluate MAE: 0.2732\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 491\n","\tbatch: 100, loss: 0.2456, MAE: 0.4853\n","\tbatch: 200, loss: 0.0628, MAE: 0.2089\n","Training:\t loss: 0.1402, MAE: 0.2912\n","Evaluating:\t loss: 0.0188, MAE: 0.0494\n","train MSE: 0.1402, evaluate MSE: 0.0188\n","\n","train MAE: 0.2912, evaluate MAE: 0.0494\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 492\n","\tbatch: 100, loss: 0.5020, MAE: 0.6963\n","\tbatch: 200, loss: 0.0093, MAE: 0.0762\n","Training:\t loss: 0.1740, MAE: 0.3301\n","Evaluating:\t loss: 0.5215, MAE: 0.7000\n","train MSE: 0.1740, evaluate MSE: 0.5215\n","\n","train MAE: 0.3301, evaluate MAE: 0.7000\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 493\n","\tbatch: 100, loss: 0.2478, MAE: 0.4864\n","\tbatch: 200, loss: 0.0886, MAE: 0.2891\n","Training:\t loss: 0.1656, MAE: 0.3402\n","Evaluating:\t loss: 0.0335, MAE: 0.1127\n","train MSE: 0.1656, evaluate MSE: 0.0335\n","\n","train MAE: 0.3402, evaluate MAE: 0.1127\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 494\n","\tbatch: 100, loss: 0.0106, MAE: 0.0808\n","\tbatch: 200, loss: 0.4192, MAE: 0.6267\n","Training:\t loss: 0.1715, MAE: 0.3132\n","Evaluating:\t loss: 0.1017, MAE: 0.2828\n","train MSE: 0.1715, evaluate MSE: 0.1017\n","\n","train MAE: 0.3132, evaluate MAE: 0.2828\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 495\n","\tbatch: 100, loss: 0.3706, MAE: 0.4972\n","\tbatch: 200, loss: 0.1079, MAE: 0.2808\n","Training:\t loss: 0.2950, MAE: 0.4144\n","Evaluating:\t loss: 0.0268, MAE: 0.1119\n","train MSE: 0.2950, evaluate MSE: 0.0268\n","\n","train MAE: 0.4144, evaluate MAE: 0.1119\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 496\n","\tbatch: 100, loss: 0.0432, MAE: 0.1934\n","\tbatch: 200, loss: 0.0057, MAE: 0.0569\n","Training:\t loss: 6.3004, MAE: 0.8416\n","Evaluating:\t loss: 24.5502, MAE: 4.4289\n","train MSE: 6.3004, evaluate MSE: 24.5502\n","\n","train MAE: 0.8416, evaluate MAE: 4.4289\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 497\n","\tbatch: 100, loss: 0.0644, MAE: 0.1351\n","\tbatch: 200, loss: 0.0243, MAE: 0.0975\n","Training:\t loss: 0.6963, MAE: 0.3318\n","Evaluating:\t loss: 0.1141, MAE: 0.0966\n","train MSE: 0.6963, evaluate MSE: 0.1141\n","\n","train MAE: 0.3318, evaluate MAE: 0.0966\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 498\n","\tbatch: 100, loss: 0.0352, MAE: 0.0883\n","\tbatch: 200, loss: 0.0097, MAE: 0.0672\n","Training:\t loss: 0.0560, MAE: 0.1020\n","Evaluating:\t loss: 0.0947, MAE: 0.1395\n","train MSE: 0.0560, evaluate MSE: 0.0947\n","\n","train MAE: 0.1020, evaluate MAE: 0.1395\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 499\n","\tbatch: 100, loss: 0.0181, MAE: 0.0986\n","\tbatch: 200, loss: 0.0138, MAE: 0.0699\n","Training:\t loss: 0.0297, MAE: 0.0941\n","Evaluating:\t loss: 0.0358, MAE: 0.0739\n","train MSE: 0.0297, evaluate MSE: 0.0358\n","\n","train MAE: 0.0941, evaluate MAE: 0.0739\n","\n","--- time consumption (s): 24\n","\n","------------------------------\n","Epoch 500\n","\tbatch: 100, loss: 0.0149, MAE: 0.0711\n","\tbatch: 200, loss: 0.0129, MAE: 0.0694\n","Training:\t loss: 0.0165, MAE: 0.0728\n","Evaluating:\t loss: 0.0192, MAE: 0.0673\n","train MSE: 0.0165, evaluate MSE: 0.0192\n","\n","train MAE: 0.0728, evaluate MAE: 0.0673\n","\n","--- time consumption (s): 24\n","\n","Best model has been saved! Best model obtained at epoch 422 with eval MAE 0.0485\n","=============== testing ===============\n","MSE on test set: 0.0150\n","MAE on test set: 0.0640\n","R2 score: 1.0000\n"]}],"source":["# 单位：Hatree = 27.2 eV\n","!python main.py -M mgcn -e 500 -lr 1e-4 -type com -o mgcn-com-500-1e-4"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DHl9zBV1ocpd"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1312,"status":"ok","timestamp":1634256120127,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"80kR841dV48n","outputId":"ac22baa9-e7a6-4c2b-f030-d3a2b66d6dc6"},"outputs":[{"name":"stdout","output_type":"stream","text":["Cloning into 'Alchemy'...\n","remote: Enumerating objects: 129, done.\u001b[K\n","remote: Total 129 (delta 0), reused 0 (delta 0), pack-reused 129\u001b[K\n","Receiving objects: 100% (129/129), 43.72 KiB | 3.36 MiB/s, done.\n","Resolving deltas: 100% (69/69), done.\n"]}],"source":["!cd /content/drive/MyDrive/code/Alchemy\n","!git clone https://github.com/tencent-alchemy/Alchemy.git\n","!pip install -r "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6576,"status":"ok","timestamp":1634256208677,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"zJ3ivC4aQWNM","outputId":"1ab49147-5979-4aae-f19a-f8a6fab2fc50"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting torch==1.1.0\n","  Downloading torch-1.1.0-cp37-cp37m-manylinux1_x86_64.whl (676.9 MB)\n","\u001b[K     |██████▊                         | 142.7 MB 1.3 MB/s eta 0:06:48\n","\u001b[31mERROR: Operation cancelled by user\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install -r requirements.txt"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2q-_v9wDQjlv"},"outputs":[],"source":["!cd dgl/"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5264,"status":"ok","timestamp":1634256322883,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"qsRhlL20Q1jK","outputId":"a22519f3-45c6-4272-b40a-f706d5b0008d"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using backend: pytorch\n","start\n","Downloading Alchemy_data/dev.zip from https://alchemy.tencent.com/data/dev.zip...\n","download failed, retrying, 4 attempts left\n","Downloading Alchemy_data/dev.zip from https://alchemy.tencent.com/data/dev.zip...\n","download failed, retrying, 3 attempts left\n","Downloading Alchemy_data/dev.zip from https://alchemy.tencent.com/data/dev.zip...\n","download failed, retrying, 2 attempts left\n","Downloading Alchemy_data/dev.zip from https://alchemy.tencent.com/data/dev.zip...\n","download failed, retrying, 1 attempt left\n","Downloading Alchemy_data/dev.zip from https://alchemy.tencent.com/data/dev.zip...\n","Traceback (most recent call last):\n","  File \"train.py\", line 74, in <module>\n","    train(args.model, int(args.epochs), device)\n","  File \"train.py\", line 17, in train\n","    alchemy_dataset = TencentAlchemyDataset()\n","  File \"/content/drive/My Drive/code/Alchemy/Alchemy/dgl/Alchemy_dataset.py\", line 212, in __init__\n","    path=str(self.zip_file_path))\n","  File \"/usr/local/lib/python3.7/dist-packages/dgl/data/utils.py\", line 161, in download\n","    raise e\n","  File \"/usr/local/lib/python3.7/dist-packages/dgl/data/utils.py\", line 147, in download\n","    raise RuntimeError(\"Failed downloading url %s\" % url)\n","RuntimeError: Failed downloading url https://alchemy.tencent.com/data/dev.zip\n"]}],"source":["!python train.py --model mgcn --epochs 10"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":172,"status":"ok","timestamp":1634256296982,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"KLT4neHNQzX_","outputId":"0701d9fe-3e17-42d2-9b58-bfb1167054c2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Alchemy_dataset.py  layers.py  mgcn.py  mpnn.py  README.md  sch.py  train.py\n"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lhI2i5MCQziB"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"A-u5mulXV4_A"},"outputs":[],"source":["qm9xyz_tar_bz2 = '../data/dsgdb9nsd.xyz.tar.bz2' \n","qm9xyz_dir = '../data/dsgdb9nsd.xyz'\n","qm9_graph_dir = '../data/qm9'\n","if not os.path.exists(qm9xyz_dir):\n","  os.system('mkdir {}'.format(qm9xyz_dir))\n","  os.system('mkdir {}'.format(qm9_graph_dir))\n","  os.system('tar -jxvf {} -C {} > /dev/null'.format(qm9xyz_tar_bz2, qm9xyz_dir))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":151,"status":"ok","timestamp":1634108460612,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"mWwFd8dpV5Ih","outputId":"38aebb09-6f45-4d8a-a808-d80fea96225a"},"outputs":[{"name":"stdout","output_type":"stream","text":["dsgdb9nsd.xyz  dsgdb9nsd.xyz.tar.bz2  esol  esol.csv  qm9  qm9-Hartree\n"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4075,"status":"ok","timestamp":1634160440308,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"FyJ33s6UV5QY","outputId":"bd04fe32-3d76-42c2-af3b-25fb1b2aa008"},"outputs":[{"name":"stderr","output_type":"stream","text":["DGL backend not selected or invalid.  Assuming PyTorch for now.\n"]},{"name":"stdout","output_type":"stream","text":["Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"]},{"name":"stderr","output_type":"stream","text":["Using backend: pytorch\n"]}],"source":["import torch\n","import matplotlib.pyplot as plt\n","import networkx as nx\n","import numpy as np\n","import pandas as pd\n","import random\n","import time\n","import datetime\n","import os\n","import dgl\n","from qm9 import QM9Dataset\n","from torch.utils.data import DataLoader, Dataset\n","from utils import batcher, count_model_parameter\n","from process import train, test, train_and_evaluate\n","from torch import nn, optim\n","from dgl.data.utils import split_dataset\n","from mgcn import MGCNModel\n","from dtnn import EnhancedDTNN\n"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":28542,"status":"ok","timestamp":1634160468850,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"b-9v_4jmKp47","outputId":"a44806d5-6d0a-4924-f3cf-21e38b1b733f"},"outputs":[{"name":"stdout","output_type":"stream","text":["....loaded....\n"]}],"source":["graph_type = 'non'\n","qm9 = QM9Dataset(type=graph_type)\n","# 个人PC这一载入过程需要1分钟"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OpPIwh-sTF5O"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2446,"status":"ok","timestamp":1634160474328,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"RZvRbhv7KrK7","outputId":"d6feb2a8-3253-48e6-a2aa-118545a75dd8"},"outputs":[{"name":"stdout","output_type":"stream","text":["min distance 0.9586066603660583 max distance 10.384771347045898\n"]}],"source":["prop_df = pd.DataFrame(qm9.dict['properties'])\n","prop_df.columns = qm9.prop_names\n","N = len(qm9)\n","dist_extreme = np.array([qm9.get_dist_min_max_with_idx(i) for i in range(N)])\n","dist_min, dist_max = dist_extreme[:, 0].min(), dist_extreme[:, 1].max()\n","print('min distance', dist_min, 'max distance',dist_max)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":315},"executionInfo":{"elapsed":173,"status":"ok","timestamp":1634160475394,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"zWN-qTfsKsoT","outputId":"b7852a01-18e0-46cd-b398-944ad942a249"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>rotational_constant_A</th>\n","      <th>rotational_constant_B</th>\n","      <th>rotational_constant_C</th>\n","      <th>dipole_moment</th>\n","      <th>isotropic_polarizability</th>\n","      <th>homo</th>\n","      <th>lumo</th>\n","      <th>gap</th>\n","      <th>electronic_spatial_extent</th>\n","      <th>zpve</th>\n","      <th>energy_U0</th>\n","      <th>energy_U</th>\n","      <th>enthalpy_H</th>\n","      <th>free_energy</th>\n","      <th>heat_capacity</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>count</th>\n","      <td>133885.000000</td>\n","      <td>133885.000000</td>\n","      <td>133885.000000</td>\n","      <td>133885.000000</td>\n","      <td>133885.000000</td>\n","      <td>133885.000000</td>\n","      <td>133885.000000</td>\n","      <td>133885.000000</td>\n","      <td>133885.000000</td>\n","      <td>133885.000000</td>\n","      <td>133885.000000</td>\n","      <td>133885.000000</td>\n","      <td>133885.000000</td>\n","      <td>133885.000000</td>\n","      <td>133885.000000</td>\n","    </tr>\n","    <tr>\n","      <th>mean</th>\n","      <td>9.814382</td>\n","      <td>1.406097</td>\n","      <td>1.124921</td>\n","      <td>2.706037</td>\n","      <td>75.191296</td>\n","      <td>-6.530099</td>\n","      <td>0.302693</td>\n","      <td>6.832789</td>\n","      <td>1189.527450</td>\n","      <td>4.041554</td>\n","      <td>-11198.682229</td>\n","      <td>-11198.451713</td>\n","      <td>-11198.426021</td>\n","      <td>-11199.591432</td>\n","      <td>31.600676</td>\n","    </tr>\n","    <tr>\n","      <th>std</th>\n","      <td>1809.465666</td>\n","      <td>1.583795</td>\n","      <td>1.095618</td>\n","      <td>1.530394</td>\n","      <td>8.187793</td>\n","      <td>0.602227</td>\n","      <td>1.277196</td>\n","      <td>1.293055</td>\n","      <td>279.757172</td>\n","      <td>0.905429</td>\n","      <td>1090.094394</td>\n","      <td>1090.088437</td>\n","      <td>1090.088437</td>\n","      <td>1090.108281</td>\n","      <td>4.062471</td>\n","    </tr>\n","    <tr>\n","      <th>min</th>\n","      <td>0.000000</td>\n","      <td>0.337120</td>\n","      <td>0.331180</td>\n","      <td>0.000000</td>\n","      <td>6.310000</td>\n","      <td>-11.662800</td>\n","      <td>-4.761993</td>\n","      <td>0.669400</td>\n","      <td>19.000200</td>\n","      <td>0.434049</td>\n","      <td>-19444.387349</td>\n","      <td>-19444.172161</td>\n","      <td>-19444.146473</td>\n","      <td>-19445.314631</td>\n","      <td>6.002000</td>\n","    </tr>\n","    <tr>\n","      <th>25%</th>\n","      <td>2.554430</td>\n","      <td>1.091630</td>\n","      <td>0.910480</td>\n","      <td>1.588700</td>\n","      <td>70.380000</td>\n","      <td>-6.870875</td>\n","      <td>-0.647631</td>\n","      <td>5.885823</td>\n","      <td>1018.322600</td>\n","      <td>3.409287</td>\n","      <td>-11916.245158</td>\n","      <td>-11916.027630</td>\n","      <td>-11916.001915</td>\n","      <td>-11917.163433</td>\n","      <td>28.942000</td>\n","    </tr>\n","    <tr>\n","      <th>50%</th>\n","      <td>3.090360</td>\n","      <td>1.369940</td>\n","      <td>1.078560</td>\n","      <td>2.500000</td>\n","      <td>75.500000</td>\n","      <td>-6.557944</td>\n","      <td>0.326537</td>\n","      <td>6.786520</td>\n","      <td>1147.585800</td>\n","      <td>4.036238</td>\n","      <td>-11370.679236</td>\n","      <td>-11370.477681</td>\n","      <td>-11370.451994</td>\n","      <td>-11371.522054</td>\n","      <td>31.555000</td>\n","    </tr>\n","    <tr>\n","      <th>75%</th>\n","      <td>3.835820</td>\n","      <td>1.653980</td>\n","      <td>1.279540</td>\n","      <td>3.636100</td>\n","      <td>80.520000</td>\n","      <td>-6.223244</td>\n","      <td>1.338800</td>\n","      <td>7.842321</td>\n","      <td>1308.816600</td>\n","      <td>4.657229</td>\n","      <td>-10532.144266</td>\n","      <td>-10531.887935</td>\n","      <td>-10531.862248</td>\n","      <td>-10533.072528</td>\n","      <td>34.276000</td>\n","    </tr>\n","    <tr>\n","      <th>max</th>\n","      <td>619867.683140</td>\n","      <td>437.903860</td>\n","      <td>282.945450</td>\n","      <td>29.556400</td>\n","      <td>196.620000</td>\n","      <td>-2.767398</td>\n","      <td>5.265403</td>\n","      <td>16.928203</td>\n","      <td>3374.753200</td>\n","      <td>7.454396</td>\n","      <td>-1101.487790</td>\n","      <td>-1101.409748</td>\n","      <td>-1101.384033</td>\n","      <td>-1102.022956</td>\n","      <td>46.969000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["       rotational_constant_A  ...  heat_capacity\n","count          133885.000000  ...  133885.000000\n","mean                9.814382  ...      31.600676\n","std              1809.465666  ...       4.062471\n","min                 0.000000  ...       6.002000\n","25%                 2.554430  ...      28.942000\n","50%                 3.090360  ...      31.555000\n","75%                 3.835820  ...      34.276000\n","max            619867.683140  ...      46.969000\n","\n","[8 rows x 15 columns]"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["prop_df.describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":633560,"status":"ok","timestamp":1634155687751,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"6U8LOV6uLBVL","outputId":"332649e3-b5c9-4e0f-cb54-aa12535a5e07"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using backend: pytorch\n","using device: cuda:0\n","....loaded....\n","已从已训练的模型中加载参数！\n","../output/2021-10-13/model_dtnn_conv_3_label_2021-10-13_1634155099.txt\n","==========2021-10-13 19:58:19.151014==========\n","model_type: dtnn\n","number of parameters: 482583\n","batch_size: 256\n","n_conv: 3\n","learngin rate: 0.001\n","device: cuda:0\n","--------------------\n","\n","=============== training & evaluating ===============\n","------------------------------\n","Epoch 1\n","\tbatch: 100, loss: 102234.4531, MAE: 255.4254\n","\tbatch: 200, loss: 72276.0703, MAE: 209.8383\n","\tbatch: 300, loss: 61641.9258, MAE: 196.0275\n","Training:\t loss: 89481.2673, MAE: 236.1329\n","Evaluating:\t loss: 64778.1270, MAE: 203.6710\n","train MSE: 89481.2673, evaluate MSE: 64778.1270\n","train MAE: 236.1329, evaluate MAE: 203.6710\n","--- time consumption (s): 24\n","------------------------------\n","Epoch 2\n","\tbatch: 100, loss: 52646.8203, MAE: 182.3436\n","\tbatch: 200, loss: 46156.0391, MAE: 171.0918\n","\tbatch: 300, loss: 41321.5586, MAE: 162.5411\n","Training:\t loss: 49849.0465, MAE: 176.4362\n","Evaluating:\t loss: 53038.5394, MAE: 186.0858\n","train MSE: 49849.0465, evaluate MSE: 53038.5394\n","train MAE: 176.4362, evaluate MAE: 186.0858\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 3\n","\tbatch: 100, loss: 35857.3047, MAE: 148.6873\n","\tbatch: 200, loss: 40195.1406, MAE: 159.7373\n","\tbatch: 300, loss: 40164.9570, MAE: 160.3968\n","Training:\t loss: 38260.4436, MAE: 155.0287\n","Evaluating:\t loss: 45202.2991, MAE: 171.9587\n","train MSE: 38260.4436, evaluate MSE: 45202.2991\n","train MAE: 155.0287, evaluate MAE: 171.9587\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 4\n","\tbatch: 100, loss: 38277.9766, MAE: 148.3689\n","\tbatch: 200, loss: 38499.0352, MAE: 159.3110\n","\tbatch: 300, loss: 38553.7500, MAE: 161.1461\n","Training:\t loss: 38221.1862, MAE: 155.3141\n","Evaluating:\t loss: 37020.3109, MAE: 154.4489\n","train MSE: 38221.1862, evaluate MSE: 37020.3109\n","train MAE: 155.3141, evaluate MAE: 154.4489\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 5\n","\tbatch: 100, loss: 41317.7891, MAE: 166.2129\n","\tbatch: 200, loss: 35106.7305, MAE: 149.2161\n","\tbatch: 300, loss: 36319.5625, MAE: 146.4366\n","Training:\t loss: 36337.0798, MAE: 151.3980\n","Evaluating:\t loss: 46749.5612, MAE: 175.5788\n","train MSE: 36337.0798, evaluate MSE: 46749.5612\n","train MAE: 151.3980, evaluate MAE: 175.5788\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 6\n","\tbatch: 100, loss: 34094.2578, MAE: 145.1040\n","\tbatch: 200, loss: 37281.0234, MAE: 153.0900\n","\tbatch: 300, loss: 39631.9258, MAE: 160.9995\n","Training:\t loss: 36508.4818, MAE: 151.7872\n","Evaluating:\t loss: 58782.4903, MAE: 200.2429\n","train MSE: 36508.4818, evaluate MSE: 58782.4903\n","train MAE: 151.7872, evaluate MAE: 200.2429\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 7\n","\tbatch: 100, loss: 34183.0547, MAE: 148.9490\n","\tbatch: 200, loss: 34015.3828, MAE: 149.6034\n","\tbatch: 300, loss: 34343.6016, MAE: 144.9109\n","Training:\t loss: 36106.8830, MAE: 150.9167\n","Evaluating:\t loss: 34875.7547, MAE: 147.5418\n","train MSE: 36106.8830, evaluate MSE: 34875.7547\n","train MAE: 150.9167, evaluate MAE: 147.5418\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 8\n","\tbatch: 100, loss: 40728.2656, MAE: 167.7406\n","\tbatch: 200, loss: 32765.4531, MAE: 139.7981\n","\tbatch: 300, loss: 32151.1348, MAE: 146.8948\n","Training:\t loss: 35132.5944, MAE: 148.9695\n","Evaluating:\t loss: 34067.7044, MAE: 146.2689\n","train MSE: 35132.5944, evaluate MSE: 34067.7044\n","train MAE: 148.9695, evaluate MAE: 146.2689\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 9\n","\tbatch: 100, loss: 34622.7891, MAE: 147.8010\n","\tbatch: 200, loss: 35854.9570, MAE: 148.4372\n","\tbatch: 300, loss: 33685.4102, MAE: 143.4023\n","Training:\t loss: 34962.8721, MAE: 148.4190\n","Evaluating:\t loss: 33844.6665, MAE: 146.6537\n","train MSE: 34962.8721, evaluate MSE: 33844.6665\n","train MAE: 148.4190, evaluate MAE: 146.6537\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 10\n","\tbatch: 100, loss: 30248.6133, MAE: 137.2581\n","\tbatch: 200, loss: 29146.7266, MAE: 139.4433\n","\tbatch: 300, loss: 33450.3438, MAE: 143.7392\n","Training:\t loss: 32775.6388, MAE: 143.2086\n","Evaluating:\t loss: 33027.8218, MAE: 143.3065\n","train MSE: 32775.6388, evaluate MSE: 33027.8218\n","train MAE: 143.2086, evaluate MAE: 143.3065\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 11\n","\tbatch: 100, loss: 30268.5469, MAE: 137.0128\n","\tbatch: 200, loss: 36184.9570, MAE: 149.8210\n","\tbatch: 300, loss: 30126.0605, MAE: 135.7633\n","Training:\t loss: 31872.3909, MAE: 141.2897\n","Evaluating:\t loss: 35338.3296, MAE: 148.5613\n","train MSE: 31872.3909, evaluate MSE: 35338.3296\n","train MAE: 141.2897, evaluate MAE: 148.5613\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 12\n","\tbatch: 100, loss: 32960.3672, MAE: 144.0807\n","\tbatch: 200, loss: 30442.1133, MAE: 139.3063\n","\tbatch: 300, loss: 33953.0977, MAE: 144.0911\n","Training:\t loss: 32459.6068, MAE: 142.6005\n","Evaluating:\t loss: 31145.3028, MAE: 139.8933\n","train MSE: 32459.6068, evaluate MSE: 31145.3028\n","train MAE: 142.6005, evaluate MAE: 139.8933\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 13\n","\tbatch: 100, loss: 31254.4805, MAE: 138.0808\n","\tbatch: 200, loss: 37791.2656, MAE: 151.3367\n","\tbatch: 300, loss: 30483.9824, MAE: 138.9886\n","Training:\t loss: 32698.7077, MAE: 143.0439\n","Evaluating:\t loss: 30991.9695, MAE: 139.4708\n","train MSE: 32698.7077, evaluate MSE: 30991.9695\n","train MAE: 143.0439, evaluate MAE: 139.4708\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 14\n","\tbatch: 100, loss: 30044.7812, MAE: 135.8841\n","\tbatch: 200, loss: 39037.7305, MAE: 160.0971\n","\tbatch: 300, loss: 31311.2559, MAE: 138.7088\n","Training:\t loss: 31853.6718, MAE: 141.1190\n","Evaluating:\t loss: 33530.5922, MAE: 144.5462\n","train MSE: 31853.6718, evaluate MSE: 33530.5922\n","train MAE: 141.1190, evaluate MAE: 144.5462\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 15\n","\tbatch: 100, loss: 28633.3066, MAE: 134.0128\n","\tbatch: 200, loss: 29183.8672, MAE: 135.7244\n","\tbatch: 300, loss: 32649.2285, MAE: 142.0270\n","Training:\t loss: 31407.1982, MAE: 140.1713\n","Evaluating:\t loss: 31805.5430, MAE: 140.6526\n","train MSE: 31407.1982, evaluate MSE: 31805.5430\n","train MAE: 140.1713, evaluate MAE: 140.6526\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 16\n","\tbatch: 100, loss: 27324.3906, MAE: 126.0367\n","\tbatch: 200, loss: 37066.2578, MAE: 153.5010\n","\tbatch: 300, loss: 31969.8672, MAE: 145.3604\n","Training:\t loss: 32278.6121, MAE: 142.2497\n","Evaluating:\t loss: 30893.8075, MAE: 139.1859\n","train MSE: 32278.6121, evaluate MSE: 30893.8075\n","train MAE: 142.2497, evaluate MAE: 139.1859\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 17\n","\tbatch: 100, loss: 29651.5781, MAE: 136.3041\n","\tbatch: 200, loss: 27521.0898, MAE: 130.7051\n","\tbatch: 300, loss: 31793.8379, MAE: 137.1277\n","Training:\t loss: 31096.3191, MAE: 139.5075\n","Evaluating:\t loss: 34219.9753, MAE: 146.3102\n","train MSE: 31096.3191, evaluate MSE: 34219.9753\n","train MAE: 139.5075, evaluate MAE: 146.3102\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 18\n","\tbatch: 100, loss: 27200.9805, MAE: 132.1004\n","\tbatch: 200, loss: 31546.4414, MAE: 141.4888\n","\tbatch: 300, loss: 27935.5195, MAE: 129.7454\n","Training:\t loss: 31570.5350, MAE: 140.5381\n","Evaluating:\t loss: 30379.6383, MAE: 138.0187\n","train MSE: 31570.5350, evaluate MSE: 30379.6383\n","train MAE: 140.5381, evaluate MAE: 138.0187\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 19\n","\tbatch: 100, loss: 30351.1914, MAE: 139.4751\n","\tbatch: 200, loss: 32468.8711, MAE: 140.4408\n","\tbatch: 300, loss: 35360.7695, MAE: 149.5488\n","Training:\t loss: 31089.0590, MAE: 139.2729\n","Evaluating:\t loss: 30075.5653, MAE: 137.2992\n","train MSE: 31089.0590, evaluate MSE: 30075.5653\n","train MAE: 139.2729, evaluate MAE: 137.2992\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 20\n","\tbatch: 100, loss: 32225.6602, MAE: 139.5600\n","\tbatch: 200, loss: 27691.0312, MAE: 129.0968\n","\tbatch: 300, loss: 29768.0703, MAE: 138.0290\n","Training:\t loss: 30592.3070, MAE: 138.2708\n","Evaluating:\t loss: 31970.3614, MAE: 140.8151\n","train MSE: 30592.3070, evaluate MSE: 31970.3614\n","train MAE: 138.2708, evaluate MAE: 140.8151\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 21\n","\tbatch: 100, loss: 28277.8359, MAE: 130.3473\n","\tbatch: 200, loss: 37961.3125, MAE: 148.6595\n","\tbatch: 300, loss: 31290.4414, MAE: 138.1179\n","Training:\t loss: 31687.3803, MAE: 140.8434\n","Evaluating:\t loss: 31689.6451, MAE: 141.6465\n","train MSE: 31687.3803, evaluate MSE: 31689.6451\n","train MAE: 140.8434, evaluate MAE: 141.6465\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 22\n","\tbatch: 100, loss: 33640.1094, MAE: 142.7384\n","\tbatch: 200, loss: 29062.8965, MAE: 132.7276\n","\tbatch: 300, loss: 25092.3633, MAE: 126.0486\n","Training:\t loss: 30715.1690, MAE: 138.5191\n","Evaluating:\t loss: 30214.6900, MAE: 137.7038\n","train MSE: 30715.1690, evaluate MSE: 30214.6900\n","train MAE: 138.5191, evaluate MAE: 137.7038\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 23\n","\tbatch: 100, loss: 30577.1230, MAE: 138.8436\n","\tbatch: 200, loss: 34674.8125, MAE: 147.5710\n","\tbatch: 300, loss: 33196.7617, MAE: 143.7753\n","Training:\t loss: 30516.3979, MAE: 138.0821\n","Evaluating:\t loss: 30096.4054, MAE: 137.2190\n","train MSE: 30516.3979, evaluate MSE: 30096.4054\n","train MAE: 138.0821, evaluate MAE: 137.2190\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 24\n","\tbatch: 100, loss: 30122.6934, MAE: 139.9075\n","\tbatch: 200, loss: 25692.5156, MAE: 125.4505\n","\tbatch: 300, loss: 27547.0273, MAE: 126.3778\n","Training:\t loss: 30555.9936, MAE: 138.1928\n","Evaluating:\t loss: 34603.5092, MAE: 147.3582\n","train MSE: 30555.9936, evaluate MSE: 34603.5092\n","train MAE: 138.1928, evaluate MAE: 147.3582\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 25\n","\tbatch: 100, loss: 22177.6133, MAE: 118.9558\n","\tbatch: 200, loss: 32308.9004, MAE: 140.5925\n","\tbatch: 300, loss: 28055.9863, MAE: 132.9970\n","Training:\t loss: 30806.5848, MAE: 138.8304\n","Evaluating:\t loss: 30589.5355, MAE: 137.9639\n","train MSE: 30806.5848, evaluate MSE: 30589.5355\n","train MAE: 138.8304, evaluate MAE: 137.9639\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 26\n","\tbatch: 100, loss: 31072.5938, MAE: 136.6267\n","\tbatch: 200, loss: 28687.8945, MAE: 132.7733\n","\tbatch: 300, loss: 31141.7402, MAE: 136.0494\n","Training:\t loss: 30553.2444, MAE: 138.3868\n","Evaluating:\t loss: 33699.0715, MAE: 146.2806\n","train MSE: 30553.2444, evaluate MSE: 33699.0715\n","train MAE: 138.3868, evaluate MAE: 146.2806\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 27\n","\tbatch: 100, loss: 33662.0625, MAE: 146.1840\n","\tbatch: 200, loss: 31388.6914, MAE: 143.4119\n","\tbatch: 300, loss: 31263.4277, MAE: 137.8435\n","Training:\t loss: 29855.4469, MAE: 136.5747\n","Evaluating:\t loss: 32664.1348, MAE: 144.1850\n","train MSE: 29855.4469, evaluate MSE: 32664.1348\n","train MAE: 136.5747, evaluate MAE: 144.1850\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 28\n","\tbatch: 100, loss: 31541.9727, MAE: 142.6685\n","\tbatch: 200, loss: 27696.8125, MAE: 130.2737\n","\tbatch: 300, loss: 28703.8750, MAE: 134.0447\n","Training:\t loss: 30320.5683, MAE: 137.7351\n","Evaluating:\t loss: 30002.6579, MAE: 137.0471\n","train MSE: 30320.5683, evaluate MSE: 30002.6579\n","train MAE: 137.7351, evaluate MAE: 137.0471\n","--- time consumption (s): 19\n","------------------------------\n","Epoch 29\n","\tbatch: 100, loss: 27656.1895, MAE: 132.4941\n","\tbatch: 200, loss: 28760.5176, MAE: 135.9855\n","\tbatch: 300, loss: 36061.9922, MAE: 155.5551\n","Training:\t loss: 29985.2912, MAE: 136.8839\n","Evaluating:\t loss: 28963.9656, MAE: 134.6723\n","train MSE: 29985.2912, evaluate MSE: 28963.9656\n","train MAE: 136.8839, evaluate MAE: 134.6723\n","--- time consumption (s): 18\n","------------------------------\n","Epoch 30\n","\tbatch: 100, loss: 24938.1016, MAE: 123.3768\n","\tbatch: 200, loss: 36160.1602, MAE: 151.4132\n","\tbatch: 300, loss: 29235.6211, MAE: 135.5222\n","Training:\t loss: 30240.4588, MAE: 137.4785\n","Evaluating:\t loss: 30350.1036, MAE: 137.2802\n","train MSE: 30240.4588, evaluate MSE: 30350.1036\n","train MAE: 137.4785, evaluate MAE: 137.2802\n","--- time consumption (s): 19\n","Best model has been saved! Best model obtained at epoch 29 with eval MAE\n","=============== testing ===============\n","MSE on test set: 30007.8262\n","MAE on test set: 136.1860\n","R2 score: 0.9994\n"]}],"source":["# 当时单位为 cal/mol 时候训练的\n","!python main.py -e 30 -lr 1e-3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1373076,"status":"ok","timestamp":1634162897119,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"neUsem2JTHMP","outputId":"6afea98c-a5c2-47c0-f756-c9d2b86d03d9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using backend: pytorch\n","using device: cuda:0\n","....loaded....\n","已从已训练的模型中加载参数！\n","../output/2021-10-13/model_dtnn_conv_3_label_2021-10-13_1634161557.txt\n","==========2021-10-13 21:45:57.259028==========\n","model_type: dtnn\n","number of parameters: 482583\n","batch_size: 256\n","n_conv: 3\n","learngin rate: 0.005\n","device: cuda:0\n","--------------------\n","\n","=============== training & evaluating ===============\n","------------------------------\n","Epoch 1\n","\tbatch: 100, loss: 5151.0488, MAE: 57.1673\n","\tbatch: 200, loss: 49523.3789, MAE: 182.6954\n","\tbatch: 300, loss: 39066.4609, MAE: 178.8413\n","Training:\t loss: 60380.2584, MAE: 156.8094\n","Evaluating:\t loss: 9033.6444, MAE: 65.3183\n","train MSE: 60380.2584, evaluate MSE: 9033.6444\n","train MAE: 156.8094, evaluate MAE: 65.3183\n","--- time consumption (s): 18\n","------------------------------\n","Epoch 2\n","\tbatch: 100, loss: 4684.1006, MAE: 49.8938\n","\tbatch: 200, loss: 2386.4944, MAE: 37.3590\n","\tbatch: 300, loss: 2248.6853, MAE: 35.4604\n","Training:\t loss: 4096.1460, MAE: 44.2344\n","Evaluating:\t loss: 1886.6692, MAE: 32.0163\n","train MSE: 4096.1460, evaluate MSE: 1886.6692\n","train MAE: 44.2344, evaluate MAE: 32.0163\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 3\n","\tbatch: 100, loss: 843333.5000, MAE: 813.7736\n","\tbatch: 200, loss: 16678.3320, MAE: 103.0252\n","\tbatch: 300, loss: 37438.0742, MAE: 154.7413\n","Training:\t loss: 96349.6491, MAE: 205.0474\n","Evaluating:\t loss: 4373.2932, MAE: 50.1786\n","train MSE: 96349.6491, evaluate MSE: 4373.2932\n","train MAE: 205.0474, evaluate MAE: 50.1786\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 4\n","\tbatch: 100, loss: 2150.2422, MAE: 35.9246\n","\tbatch: 200, loss: 1800.9045, MAE: 32.3298\n","\tbatch: 300, loss: 1731.7803, MAE: 29.4917\n","Training:\t loss: 1758.7760, MAE: 32.5289\n","Evaluating:\t loss: 988.4627, MAE: 23.7960\n","train MSE: 1758.7760, evaluate MSE: 988.4627\n","train MAE: 32.5289, evaluate MAE: 23.7960\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 5\n","\tbatch: 100, loss: 1153.5618, MAE: 23.8458\n","\tbatch: 200, loss: 647.8364, MAE: 19.3945\n","\tbatch: 300, loss: 651.5185, MAE: 19.0139\n","Training:\t loss: 788.1130, MAE: 20.3682\n","Evaluating:\t loss: 620.4958, MAE: 17.4771\n","train MSE: 788.1130, evaluate MSE: 620.4958\n","train MAE: 20.3682, evaluate MAE: 17.4771\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 6\n","\tbatch: 100, loss: 483.0227, MAE: 16.1096\n","\tbatch: 200, loss: 813.5684, MAE: 16.7699\n","\tbatch: 300, loss: 496.9241, MAE: 15.3341\n","Training:\t loss: 551.5691, MAE: 16.0349\n","Evaluating:\t loss: 454.5018, MAE: 14.0663\n","train MSE: 551.5691, evaluate MSE: 454.5018\n","train MAE: 16.0349, evaluate MAE: 14.0663\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 7\n","\tbatch: 100, loss: 471.7519, MAE: 13.9300\n","\tbatch: 200, loss: 690.3838, MAE: 15.4204\n","\tbatch: 300, loss: 287.0685, MAE: 12.6975\n","Training:\t loss: 531.6409, MAE: 14.6196\n","Evaluating:\t loss: 502.7887, MAE: 13.8296\n","train MSE: 531.6409, evaluate MSE: 502.7887\n","train MAE: 14.6196, evaluate MAE: 13.8296\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 8\n","\tbatch: 100, loss: 656.8179, MAE: 14.7762\n","\tbatch: 200, loss: 578.5251, MAE: 14.7719\n","\tbatch: 300, loss: 300.3767, MAE: 10.5626\n","Training:\t loss: 455.0302, MAE: 13.0038\n","Evaluating:\t loss: 403.9890, MAE: 12.4796\n","train MSE: 455.0302, evaluate MSE: 403.9890\n","train MAE: 13.0038, evaluate MAE: 12.4796\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 9\n","\tbatch: 100, loss: 577.9319, MAE: 11.7028\n","\tbatch: 200, loss: 352.8877, MAE: 11.3855\n","\tbatch: 300, loss: 406.6907, MAE: 14.2997\n","Training:\t loss: 361.3993, MAE: 11.6255\n","Evaluating:\t loss: 463.5047, MAE: 16.4792\n","train MSE: 361.3993, evaluate MSE: 463.5047\n","train MAE: 11.6255, evaluate MAE: 16.4792\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 10\n","\tbatch: 100, loss: 334.2657, MAE: 11.1129\n","\tbatch: 200, loss: 244.5551, MAE: 10.0555\n","\tbatch: 300, loss: 377.3399, MAE: 12.2164\n","Training:\t loss: 298.5593, MAE: 10.8262\n","Evaluating:\t loss: 286.4257, MAE: 10.6395\n","train MSE: 298.5593, evaluate MSE: 286.4257\n","train MAE: 10.8262, evaluate MAE: 10.6395\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 11\n","\tbatch: 100, loss: 235.5386, MAE: 10.7507\n","\tbatch: 200, loss: 462.2320, MAE: 18.1932\n","\tbatch: 300, loss: 310.8092, MAE: 11.2728\n","Training:\t loss: 261.7944, MAE: 10.5594\n","Evaluating:\t loss: 411.8024, MAE: 16.3950\n","train MSE: 261.7944, evaluate MSE: 411.8024\n","train MAE: 10.5594, evaluate MAE: 16.3950\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 12\n","\tbatch: 100, loss: 198.5879, MAE: 9.8827\n","\tbatch: 200, loss: 301.0471, MAE: 12.6529\n","\tbatch: 300, loss: 277.9877, MAE: 12.9059\n","Training:\t loss: 358.9303, MAE: 14.0118\n","Evaluating:\t loss: 386.9167, MAE: 16.3696\n","train MSE: 358.9303, evaluate MSE: 386.9167\n","train MAE: 14.0118, evaluate MAE: 16.3696\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 13\n","\tbatch: 100, loss: 256.9565, MAE: 12.1745\n","\tbatch: 200, loss: 90.0845, MAE: 6.8298\n","\tbatch: 300, loss: 2568.2617, MAE: 49.6123\n","Training:\t loss: 1084.9442, MAE: 22.8172\n","Evaluating:\t loss: 709.9236, MAE: 24.1890\n","train MSE: 1084.9442, evaluate MSE: 709.9236\n","train MAE: 22.8172, evaluate MAE: 24.1890\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 14\n","\tbatch: 100, loss: 102.7875, MAE: 7.6999\n","\tbatch: 200, loss: 557.4935, MAE: 21.6028\n","\tbatch: 300, loss: 150.0935, MAE: 9.5923\n","Training:\t loss: 889.0323, MAE: 23.7200\n","Evaluating:\t loss: 250.5868, MAE: 12.5232\n","train MSE: 889.0323, evaluate MSE: 250.5868\n","train MAE: 23.7200, evaluate MAE: 12.5232\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 15\n","\tbatch: 100, loss: 706.6852, MAE: 24.2109\n","\tbatch: 200, loss: 1988.8655, MAE: 43.2609\n","\tbatch: 300, loss: 151.9138, MAE: 9.7757\n","Training:\t loss: 979.3113, MAE: 23.8644\n","Evaluating:\t loss: 132.1101, MAE: 7.0954\n","train MSE: 979.3113, evaluate MSE: 132.1101\n","train MAE: 23.8644, evaluate MAE: 7.0954\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 16\n","\tbatch: 100, loss: 3763.7378, MAE: 59.9450\n","\tbatch: 200, loss: 695.3964, MAE: 24.6832\n","\tbatch: 300, loss: 134.2021, MAE: 7.2520\n","Training:\t loss: 900.2645, MAE: 22.9865\n","Evaluating:\t loss: 1108.7278, MAE: 31.8297\n","train MSE: 900.2645, evaluate MSE: 1108.7278\n","train MAE: 22.9865, evaluate MAE: 31.8297\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 17\n","\tbatch: 100, loss: 87.1163, MAE: 7.0221\n","\tbatch: 200, loss: 6917.7969, MAE: 81.9623\n","\tbatch: 300, loss: 302.5001, MAE: 14.7371\n","Training:\t loss: 926.4763, MAE: 22.1374\n","Evaluating:\t loss: 2301.7899, MAE: 46.7673\n","train MSE: 926.4763, evaluate MSE: 2301.7899\n","train MAE: 22.1374, evaluate MAE: 46.7673\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 18\n","\tbatch: 100, loss: 55.8513, MAE: 5.1611\n","\tbatch: 200, loss: 106.7857, MAE: 8.1720\n","\tbatch: 300, loss: 336.8312, MAE: 15.8344\n","Training:\t loss: 1049.1239, MAE: 26.2067\n","Evaluating:\t loss: 580.0345, MAE: 22.4319\n","train MSE: 1049.1239, evaluate MSE: 580.0345\n","train MAE: 26.2067, evaluate MAE: 22.4319\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 19\n","\tbatch: 100, loss: 65.8628, MAE: 6.1886\n","\tbatch: 200, loss: 901.9224, MAE: 27.7111\n","\tbatch: 300, loss: 199.9327, MAE: 11.4719\n","Training:\t loss: 844.0296, MAE: 22.5329\n","Evaluating:\t loss: 101.4623, MAE: 6.8734\n","train MSE: 844.0296, evaluate MSE: 101.4623\n","train MAE: 22.5329, evaluate MAE: 6.8734\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 20\n","\tbatch: 100, loss: 119.7263, MAE: 5.8607\n","\tbatch: 200, loss: 384.3749, MAE: 18.1614\n","\tbatch: 300, loss: 103.1267, MAE: 8.2724\n","Training:\t loss: 839.3122, MAE: 21.7600\n","Evaluating:\t loss: 525.4585, MAE: 21.5319\n","train MSE: 839.3122, evaluate MSE: 525.4585\n","train MAE: 21.7600, evaluate MAE: 21.5319\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 21\n","\tbatch: 100, loss: 180.0766, MAE: 7.1851\n","\tbatch: 200, loss: 704.7825, MAE: 25.5231\n","\tbatch: 300, loss: 540.9038, MAE: 22.1473\n","Training:\t loss: 855.7718, MAE: 22.7297\n","Evaluating:\t loss: 67.9503, MAE: 5.0105\n","train MSE: 855.7718, evaluate MSE: 67.9503\n","train MAE: 22.7297, evaluate MAE: 5.0105\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 22\n","\tbatch: 100, loss: 143.5214, MAE: 10.7377\n","\tbatch: 200, loss: 2694.3540, MAE: 51.2484\n","\tbatch: 300, loss: 141.8524, MAE: 10.8255\n","Training:\t loss: 886.2820, MAE: 20.5327\n","Evaluating:\t loss: 236.9750, MAE: 13.8041\n","train MSE: 886.2820, evaluate MSE: 236.9750\n","train MAE: 20.5327, evaluate MAE: 13.8041\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 23\n","\tbatch: 100, loss: 416.8856, MAE: 19.3049\n","\tbatch: 200, loss: 366.3584, MAE: 18.2061\n","\tbatch: 300, loss: 212.0360, MAE: 13.3656\n","Training:\t loss: 793.7438, MAE: 22.0335\n","Evaluating:\t loss: 431.5049, MAE: 19.6650\n","train MSE: 793.7438, evaluate MSE: 431.5049\n","train MAE: 22.0335, evaluate MAE: 19.6650\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 24\n","\tbatch: 100, loss: 1505.7483, MAE: 38.0102\n","\tbatch: 200, loss: 1753.8386, MAE: 41.2633\n","\tbatch: 300, loss: 6069.8413, MAE: 76.9471\n","Training:\t loss: 882.7110, MAE: 22.2101\n","Evaluating:\t loss: 556.1956, MAE: 22.6395\n","train MSE: 882.7110, evaluate MSE: 556.1956\n","train MAE: 22.2101, evaluate MAE: 22.6395\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 25\n","\tbatch: 100, loss: 3042.6860, MAE: 54.4645\n","\tbatch: 200, loss: 137.4129, MAE: 10.3553\n","\tbatch: 300, loss: 314.8385, MAE: 16.8119\n","Training:\t loss: 847.1958, MAE: 21.9687\n","Evaluating:\t loss: 119.2866, MAE: 9.3551\n","train MSE: 847.1958, evaluate MSE: 119.2866\n","train MAE: 21.9687, evaluate MAE: 9.3551\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 26\n","\tbatch: 100, loss: 4064.5186, MAE: 62.8332\n","\tbatch: 200, loss: 114.1385, MAE: 9.5071\n","\tbatch: 300, loss: 211.4079, MAE: 13.6931\n","Training:\t loss: 826.0512, MAE: 18.8511\n","Evaluating:\t loss: 477.5769, MAE: 21.0478\n","train MSE: 826.0512, evaluate MSE: 477.5769\n","train MAE: 18.8511, evaluate MAE: 21.0478\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 27\n","\tbatch: 100, loss: 77.5764, MAE: 7.9625\n","\tbatch: 200, loss: 114.5027, MAE: 9.4462\n","\tbatch: 300, loss: 125.7952, MAE: 10.4820\n","Training:\t loss: 768.6737, MAE: 16.6312\n","Evaluating:\t loss: 33.8713, MAE: 3.3063\n","train MSE: 768.6737, evaluate MSE: 33.8713\n","train MAE: 16.6312, evaluate MAE: 3.3063\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 28\n","\tbatch: 100, loss: 26.5423, MAE: 3.7378\n","\tbatch: 200, loss: 641.3204, MAE: 24.8284\n","\tbatch: 300, loss: 113.5959, MAE: 8.7866\n","Training:\t loss: 948.3303, MAE: 18.0190\n","Evaluating:\t loss: 163.5307, MAE: 11.7166\n","train MSE: 948.3303, evaluate MSE: 163.5307\n","train MAE: 18.0190, evaluate MAE: 11.7166\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 29\n","\tbatch: 100, loss: 340.5377, MAE: 17.7136\n","\tbatch: 200, loss: 74.8121, MAE: 7.5540\n","\tbatch: 300, loss: 515.6665, MAE: 21.6442\n","Training:\t loss: 603.0974, MAE: 16.3502\n","Evaluating:\t loss: 2783.7397, MAE: 52.1338\n","train MSE: 603.0974, evaluate MSE: 2783.7397\n","train MAE: 16.3502, evaluate MAE: 52.1338\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 30\n","\tbatch: 100, loss: 3703.9426, MAE: 60.3162\n","\tbatch: 200, loss: 17.4400, MAE: 3.3248\n","\tbatch: 300, loss: 863.4729, MAE: 28.8330\n","Training:\t loss: 719.8803, MAE: 17.4860\n","Evaluating:\t loss: 27.1397, MAE: 3.0459\n","train MSE: 719.8803, evaluate MSE: 27.1397\n","train MAE: 17.4860, evaluate MAE: 3.0459\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 31\n","\tbatch: 100, loss: 116.4387, MAE: 9.8486\n","\tbatch: 200, loss: 28.1974, MAE: 4.0523\n","\tbatch: 300, loss: 436.6228, MAE: 20.2495\n","Training:\t loss: 881.0521, MAE: 17.0092\n","Evaluating:\t loss: 5924.9170, MAE: 76.3277\n","train MSE: 881.0521, evaluate MSE: 5924.9170\n","train MAE: 17.0092, evaluate MAE: 76.3277\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 32\n","\tbatch: 100, loss: 12.5342, MAE: 2.4478\n","\tbatch: 200, loss: 116.0198, MAE: 9.9816\n","\tbatch: 300, loss: 87.2531, MAE: 8.5138\n","Training:\t loss: 672.7432, MAE: 18.5167\n","Evaluating:\t loss: 52.3693, MAE: 6.0075\n","train MSE: 672.7432, evaluate MSE: 52.3693\n","train MAE: 18.5167, evaluate MAE: 6.0075\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 33\n","\tbatch: 100, loss: 48.4626, MAE: 6.2722\n","\tbatch: 200, loss: 135.1510, MAE: 11.0706\n","\tbatch: 300, loss: 50.8330, MAE: 5.7536\n","Training:\t loss: 925.0024, MAE: 20.5124\n","Evaluating:\t loss: 188.9477, MAE: 13.0783\n","train MSE: 925.0024, evaluate MSE: 188.9477\n","train MAE: 20.5124, evaluate MAE: 13.0783\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 34\n","\tbatch: 100, loss: 3623.8389, MAE: 59.8169\n","\tbatch: 200, loss: 1131.8304, MAE: 33.2249\n","\tbatch: 300, loss: 166.0357, MAE: 12.2801\n","Training:\t loss: 643.9999, MAE: 17.6325\n","Evaluating:\t loss: 39.6571, MAE: 5.1975\n","train MSE: 643.9999, evaluate MSE: 39.6571\n","train MAE: 17.6325, evaluate MAE: 5.1975\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 35\n","\tbatch: 100, loss: 125.4433, MAE: 10.4047\n","\tbatch: 200, loss: 37.6169, MAE: 3.8301\n","\tbatch: 300, loss: 20.7957, MAE: 2.6729\n","Training:\t loss: 725.5219, MAE: 18.3924\n","Evaluating:\t loss: 1388.1371, MAE: 36.7535\n","train MSE: 725.5219, evaluate MSE: 1388.1371\n","train MAE: 18.3924, evaluate MAE: 36.7535\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 36\n","\tbatch: 100, loss: 1416.5859, MAE: 36.9893\n","\tbatch: 200, loss: 152.3085, MAE: 11.5915\n","\tbatch: 300, loss: 545.1034, MAE: 23.0528\n","Training:\t loss: 695.4198, MAE: 19.9419\n","Evaluating:\t loss: 2686.5271, MAE: 51.3633\n","train MSE: 695.4198, evaluate MSE: 2686.5271\n","train MAE: 19.9419, evaluate MAE: 51.3633\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 37\n","\tbatch: 100, loss: 86.9333, MAE: 8.6300\n","\tbatch: 200, loss: 1714.7317, MAE: 41.1365\n","\tbatch: 300, loss: 218.4716, MAE: 14.3403\n","Training:\t loss: 648.6768, MAE: 18.5696\n","Evaluating:\t loss: 215.6884, MAE: 14.1600\n","train MSE: 648.6768, evaluate MSE: 215.6884\n","train MAE: 18.5696, evaluate MAE: 14.1600\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 38\n","\tbatch: 100, loss: 31.7354, MAE: 4.7274\n","\tbatch: 200, loss: 1334.4631, MAE: 36.1313\n","\tbatch: 300, loss: 11880.9199, MAE: 108.4129\n","Training:\t loss: 847.8515, MAE: 20.5311\n","Evaluating:\t loss: 20.2258, MAE: 3.1657\n","train MSE: 847.8515, evaluate MSE: 20.2258\n","train MAE: 20.5311, evaluate MAE: 3.1657\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 39\n","\tbatch: 100, loss: 5716.5332, MAE: 75.1442\n","\tbatch: 200, loss: 24.6950, MAE: 3.4975\n","\tbatch: 300, loss: 200.3301, MAE: 13.6980\n","Training:\t loss: 547.6277, MAE: 15.5471\n","Evaluating:\t loss: 18.1500, MAE: 3.0124\n","train MSE: 547.6277, evaluate MSE: 18.1500\n","train MAE: 15.5471, evaluate MAE: 3.0124\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 40\n","\tbatch: 100, loss: 10.8374, MAE: 2.2241\n","\tbatch: 200, loss: 18.3901, MAE: 3.2601\n","\tbatch: 300, loss: 417.0081, MAE: 20.1142\n","Training:\t loss: 825.4076, MAE: 18.2398\n","Evaluating:\t loss: 63.1229, MAE: 6.9397\n","train MSE: 825.4076, evaluate MSE: 63.1229\n","train MAE: 18.2398, evaluate MAE: 6.9397\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 41\n","\tbatch: 100, loss: 957.0504, MAE: 30.5975\n","\tbatch: 200, loss: 1677.8303, MAE: 40.6268\n","\tbatch: 300, loss: 1328.9871, MAE: 36.0185\n","Training:\t loss: 725.1259, MAE: 18.4589\n","Evaluating:\t loss: 18.5442, MAE: 2.7183\n","train MSE: 725.1259, evaluate MSE: 18.5442\n","train MAE: 18.4589, evaluate MAE: 2.7183\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 42\n","\tbatch: 100, loss: 5692.4619, MAE: 74.6200\n","\tbatch: 200, loss: 46.4849, MAE: 6.3861\n","\tbatch: 300, loss: 57.9118, MAE: 7.0724\n","Training:\t loss: 531.3797, MAE: 16.5282\n","Evaluating:\t loss: 350.2473, MAE: 18.3699\n","train MSE: 531.3797, evaluate MSE: 350.2473\n","train MAE: 16.5282, evaluate MAE: 18.3699\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 43\n","\tbatch: 100, loss: 15.9367, MAE: 3.2674\n","\tbatch: 200, loss: 477.3747, MAE: 21.4502\n","\tbatch: 300, loss: 861.0432, MAE: 29.0015\n","Training:\t loss: 654.4620, MAE: 20.6024\n","Evaluating:\t loss: 400.1015, MAE: 19.6641\n","train MSE: 654.4620, evaluate MSE: 400.1015\n","train MAE: 20.6024, evaluate MAE: 19.6641\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 44\n","\tbatch: 100, loss: 165.1151, MAE: 12.5145\n","\tbatch: 200, loss: 3359.6184, MAE: 57.4969\n","\tbatch: 300, loss: 257.1179, MAE: 15.6271\n","Training:\t loss: 775.8500, MAE: 17.6606\n","Evaluating:\t loss: 1915.8698, MAE: 43.3557\n","train MSE: 775.8500, evaluate MSE: 1915.8698\n","train MAE: 17.6606, evaluate MAE: 43.3557\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 45\n","\tbatch: 100, loss: 3886.9407, MAE: 61.7607\n","\tbatch: 200, loss: 3550.4155, MAE: 59.2292\n","\tbatch: 300, loss: 20.2056, MAE: 2.6141\n","Training:\t loss: 649.1621, MAE: 17.1826\n","Evaluating:\t loss: 309.2294, MAE: 17.1763\n","train MSE: 649.1621, evaluate MSE: 309.2294\n","train MAE: 17.1826, evaluate MAE: 17.1763\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 46\n","\tbatch: 100, loss: 5689.1973, MAE: 74.8446\n","\tbatch: 200, loss: 13.0456, MAE: 2.6344\n","\tbatch: 300, loss: 374.2038, MAE: 19.0060\n","Training:\t loss: 643.2957, MAE: 16.4622\n","Evaluating:\t loss: 122.9024, MAE: 10.5629\n","train MSE: 643.2957, evaluate MSE: 122.9024\n","train MAE: 16.4622, evaluate MAE: 10.5629\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 47\n","\tbatch: 100, loss: 168.9897, MAE: 12.3546\n","\tbatch: 200, loss: 24.1404, MAE: 3.8329\n","\tbatch: 300, loss: 372.0457, MAE: 19.0866\n","Training:\t loss: 636.2104, MAE: 18.4598\n","Evaluating:\t loss: 392.5685, MAE: 19.4371\n","train MSE: 636.2104, evaluate MSE: 392.5685\n","train MAE: 18.4598, evaluate MAE: 19.4371\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 48\n","\tbatch: 100, loss: 791.5469, MAE: 27.7562\n","\tbatch: 200, loss: 3716.4741, MAE: 60.4702\n","\tbatch: 300, loss: 2570.6367, MAE: 50.3838\n","Training:\t loss: 570.4680, MAE: 18.0417\n","Evaluating:\t loss: 771.6551, MAE: 27.3648\n","train MSE: 570.4680, evaluate MSE: 771.6551\n","train MAE: 18.0417, evaluate MAE: 27.3648\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 49\n","\tbatch: 100, loss: 10.8672, MAE: 2.0247\n","\tbatch: 200, loss: 37.7920, MAE: 5.1510\n","\tbatch: 300, loss: 146.9905, MAE: 11.7486\n","Training:\t loss: 644.4949, MAE: 15.5436\n","Evaluating:\t loss: 720.5434, MAE: 26.5110\n","train MSE: 644.4949, evaluate MSE: 720.5434\n","train MAE: 15.5436, evaluate MAE: 26.5110\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 50\n","\tbatch: 100, loss: 148.9049, MAE: 11.6966\n","\tbatch: 200, loss: 66.2800, MAE: 7.6758\n","\tbatch: 300, loss: 225.7889, MAE: 14.6775\n","Training:\t loss: 646.0104, MAE: 18.5297\n","Evaluating:\t loss: 422.4438, MAE: 20.0115\n","train MSE: 646.0104, evaluate MSE: 422.4438\n","train MAE: 18.5297, evaluate MAE: 20.0115\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 51\n","\tbatch: 100, loss: 66.3340, MAE: 7.5972\n","\tbatch: 200, loss: 794.8516, MAE: 27.4368\n","\tbatch: 300, loss: 65481.4609, MAE: 231.5923\n","Training:\t loss: 27034.7836, MAE: 83.2949\n","Evaluating:\t loss: 5081.8626, MAE: 49.1567\n","train MSE: 27034.7836, evaluate MSE: 5081.8626\n","train MAE: 83.2949, evaluate MAE: 49.1567\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 52\n","\tbatch: 100, loss: 2877.4355, MAE: 37.4645\n","\tbatch: 200, loss: 381.3091, MAE: 14.6694\n","\tbatch: 300, loss: 489.5372, MAE: 15.9914\n","Training:\t loss: 6278.1853, MAE: 46.4166\n","Evaluating:\t loss: 66996.3480, MAE: 232.7584\n","train MSE: 6278.1853, evaluate MSE: 66996.3480\n","train MAE: 46.4166, evaluate MAE: 232.7584\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 53\n","\tbatch: 100, loss: 6124.2593, MAE: 60.1902\n","\tbatch: 200, loss: 31527.8008, MAE: 160.1544\n","\tbatch: 300, loss: 10182.5742, MAE: 76.1072\n","Training:\t loss: 20856.8301, MAE: 93.3494\n","Evaluating:\t loss: 6312.9500, MAE: 51.4222\n","train MSE: 20856.8301, evaluate MSE: 6312.9500\n","train MAE: 93.3494, evaluate MAE: 51.4222\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 54\n","\tbatch: 100, loss: 166209.1562, MAE: 402.6466\n","\tbatch: 200, loss: 10616.8809, MAE: 87.0375\n","\tbatch: 300, loss: 6418.4521, MAE: 69.6801\n","Training:\t loss: 44222.8610, MAE: 131.7134\n","Evaluating:\t loss: 1928.3684, MAE: 32.8181\n","train MSE: 44222.8610, evaluate MSE: 1928.3684\n","train MAE: 131.7134, evaluate MAE: 32.8181\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 55\n","\tbatch: 100, loss: 1957.3918, MAE: 30.2275\n","\tbatch: 200, loss: 1211.3015, MAE: 24.9507\n","\tbatch: 300, loss: 976.3535, MAE: 22.4799\n","Training:\t loss: 1321.9409, MAE: 26.8395\n","Evaluating:\t loss: 904.0213, MAE: 22.4137\n","train MSE: 1321.9409, evaluate MSE: 904.0213\n","train MAE: 26.8395, evaluate MAE: 22.4137\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 56\n","\tbatch: 100, loss: 910.5109, MAE: 22.1927\n","\tbatch: 200, loss: 672.7378, MAE: 20.4401\n","\tbatch: 300, loss: 549.1852, MAE: 17.6836\n","Training:\t loss: 706.9142, MAE: 19.9549\n","Evaluating:\t loss: 510.6177, MAE: 17.2092\n","train MSE: 706.9142, evaluate MSE: 510.6177\n","train MAE: 19.9549, evaluate MAE: 17.2092\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 57\n","\tbatch: 100, loss: 413.7535, MAE: 16.0724\n","\tbatch: 200, loss: 278.9924, MAE: 13.1390\n","\tbatch: 300, loss: 396.9474, MAE: 14.6894\n","Training:\t loss: 385.4812, MAE: 14.8154\n","Evaluating:\t loss: 286.7661, MAE: 12.6321\n","train MSE: 385.4812, evaluate MSE: 286.7661\n","train MAE: 14.8154, evaluate MAE: 12.6321\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 58\n","\tbatch: 100, loss: 213.6314, MAE: 11.0811\n","\tbatch: 200, loss: 160.4564, MAE: 9.8678\n","\tbatch: 300, loss: 179.8904, MAE: 9.8371\n","Training:\t loss: 226.7139, MAE: 11.1268\n","Evaluating:\t loss: 200.5084, MAE: 10.6409\n","train MSE: 226.7139, evaluate MSE: 200.5084\n","train MAE: 11.1268, evaluate MAE: 10.6409\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 59\n","\tbatch: 100, loss: 128.5221, MAE: 8.6204\n","\tbatch: 200, loss: 159.5702, MAE: 9.1801\n","\tbatch: 300, loss: 144.6810, MAE: 8.9523\n","Training:\t loss: 172.4023, MAE: 9.5554\n","Evaluating:\t loss: 148.0315, MAE: 8.7318\n","train MSE: 172.4023, evaluate MSE: 148.0315\n","train MAE: 9.5554, evaluate MAE: 8.7318\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 60\n","\tbatch: 100, loss: 199.2416, MAE: 9.4292\n","\tbatch: 200, loss: 188.7332, MAE: 9.9735\n","\tbatch: 300, loss: 142.2838, MAE: 8.1797\n","Training:\t loss: 140.8256, MAE: 8.5506\n","Evaluating:\t loss: 242.1714, MAE: 12.9400\n","train MSE: 140.8256, evaluate MSE: 242.1714\n","train MAE: 8.5506, evaluate MAE: 12.9400\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 61\n","\tbatch: 100, loss: 111.0551, MAE: 7.6099\n","\tbatch: 200, loss: 139.5409, MAE: 8.9747\n","\tbatch: 300, loss: 105.2219, MAE: 7.2624\n","Training:\t loss: 120.4527, MAE: 7.9017\n","Evaluating:\t loss: 108.8716, MAE: 7.5980\n","train MSE: 120.4527, evaluate MSE: 108.8716\n","train MAE: 7.9017, evaluate MAE: 7.5980\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 62\n","\tbatch: 100, loss: 98.2528, MAE: 7.1748\n","\tbatch: 200, loss: 107.4309, MAE: 7.0075\n","\tbatch: 300, loss: 142.4394, MAE: 9.5273\n","Training:\t loss: 100.4559, MAE: 7.2178\n","Evaluating:\t loss: 86.8737, MAE: 6.6277\n","train MSE: 100.4559, evaluate MSE: 86.8737\n","train MAE: 7.2178, evaluate MAE: 6.6277\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 63\n","\tbatch: 100, loss: 115.6551, MAE: 8.0674\n","\tbatch: 200, loss: 69.6036, MAE: 6.4539\n","\tbatch: 300, loss: 62.4060, MAE: 5.7623\n","Training:\t loss: 86.6481, MAE: 6.7302\n","Evaluating:\t loss: 68.6292, MAE: 5.8010\n","train MSE: 86.6481, evaluate MSE: 68.6292\n","train MAE: 6.7302, evaluate MAE: 5.8010\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 64\n","\tbatch: 100, loss: 78.6316, MAE: 5.9251\n","\tbatch: 200, loss: 81.7743, MAE: 6.6017\n","\tbatch: 300, loss: 56.8229, MAE: 5.8178\n","Training:\t loss: 78.0311, MAE: 6.4254\n","Evaluating:\t loss: 68.1925, MAE: 5.9941\n","train MSE: 78.0311, evaluate MSE: 68.1925\n","train MAE: 6.4254, evaluate MAE: 5.9941\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 65\n","\tbatch: 100, loss: 73.3903, MAE: 5.5302\n","\tbatch: 200, loss: 46.8653, MAE: 5.4164\n","\tbatch: 300, loss: 144.1175, MAE: 10.6584\n","Training:\t loss: 266.9977, MAE: 12.2743\n","Evaluating:\t loss: 119.4627, MAE: 9.2765\n","train MSE: 266.9977, evaluate MSE: 119.4627\n","train MAE: 12.2743, evaluate MAE: 9.2765\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 66\n","\tbatch: 100, loss: 365.5365, MAE: 18.2492\n","\tbatch: 200, loss: 29.6843, MAE: 4.2048\n","\tbatch: 300, loss: 142.3212, MAE: 10.6709\n","Training:\t loss: 398.0884, MAE: 14.7560\n","Evaluating:\t loss: 58.9545, MAE: 5.7848\n","train MSE: 398.0884, evaluate MSE: 58.9545\n","train MAE: 14.7560, evaluate MAE: 5.7848\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 67\n","\tbatch: 100, loss: 35.7718, MAE: 4.5547\n","\tbatch: 200, loss: 118.2659, MAE: 9.5139\n","\tbatch: 300, loss: 3573.5005, MAE: 59.3250\n","Training:\t loss: 467.9872, MAE: 17.4499\n","Evaluating:\t loss: 36.0497, MAE: 3.8818\n","train MSE: 467.9872, evaluate MSE: 36.0497\n","train MAE: 17.4499, evaluate MAE: 3.8818\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 68\n","\tbatch: 100, loss: 313.4409, MAE: 16.9882\n","\tbatch: 200, loss: 23.3119, MAE: 3.1332\n","\tbatch: 300, loss: 352.2885, MAE: 17.9226\n","Training:\t loss: 336.8645, MAE: 14.4663\n","Evaluating:\t loss: 124.6140, MAE: 9.9822\n","train MSE: 336.8645, evaluate MSE: 124.6140\n","train MAE: 14.4663, evaluate MAE: 9.9822\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 69\n","\tbatch: 100, loss: 237.1510, MAE: 14.0272\n","\tbatch: 200, loss: 349.2644, MAE: 18.2160\n","\tbatch: 300, loss: 507.0656, MAE: 22.1479\n","Training:\t loss: 398.6360, MAE: 15.7895\n","Evaluating:\t loss: 673.5669, MAE: 25.4732\n","train MSE: 398.6360, evaluate MSE: 673.5669\n","train MAE: 15.7895, evaluate MAE: 25.4732\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 70\n","\tbatch: 100, loss: 32.2688, MAE: 3.8419\n","\tbatch: 200, loss: 186.5738, MAE: 12.6890\n","\tbatch: 300, loss: 166.7604, MAE: 12.3496\n","Training:\t loss: 403.1981, MAE: 15.1878\n","Evaluating:\t loss: 485.1421, MAE: 21.5398\n","train MSE: 403.1981, evaluate MSE: 485.1421\n","train MAE: 15.1878, evaluate MAE: 21.5398\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 71\n","\tbatch: 100, loss: 53.1048, MAE: 6.6153\n","\tbatch: 200, loss: 141.9689, MAE: 11.3276\n","\tbatch: 300, loss: 73.5625, MAE: 7.8526\n","Training:\t loss: 384.8443, MAE: 16.0459\n","Evaluating:\t loss: 337.2705, MAE: 17.8275\n","train MSE: 384.8443, evaluate MSE: 337.2705\n","train MAE: 16.0459, evaluate MAE: 17.8275\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 72\n","\tbatch: 100, loss: 17.3432, MAE: 3.5622\n","\tbatch: 200, loss: 450.0299, MAE: 20.8379\n","\tbatch: 300, loss: 165.5353, MAE: 12.4212\n","Training:\t loss: 366.6105, MAE: 15.7939\n","Evaluating:\t loss: 153.0738, MAE: 11.5799\n","train MSE: 366.6105, evaluate MSE: 153.0738\n","train MAE: 15.7939, evaluate MAE: 11.5799\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 73\n","\tbatch: 100, loss: 1338.0354, MAE: 36.0006\n","\tbatch: 200, loss: 286.7863, MAE: 16.6275\n","\tbatch: 300, loss: 54.0836, MAE: 6.9411\n","Training:\t loss: 364.4666, MAE: 14.4597\n","Evaluating:\t loss: 57.6728, MAE: 6.5552\n","train MSE: 364.4666, evaluate MSE: 57.6728\n","train MAE: 14.4597, evaluate MAE: 6.5552\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 74\n","\tbatch: 100, loss: 103.0770, MAE: 9.3083\n","\tbatch: 200, loss: 10.1109, MAE: 2.2378\n","\tbatch: 300, loss: 580.8885, MAE: 23.8480\n","Training:\t loss: 398.9573, MAE: 14.3851\n","Evaluating:\t loss: 97.8430, MAE: 9.1080\n","train MSE: 398.9573, evaluate MSE: 97.8430\n","train MAE: 14.3851, evaluate MAE: 9.1080\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 75\n","\tbatch: 100, loss: 38.0497, MAE: 4.8520\n","\tbatch: 200, loss: 39.7314, MAE: 4.3239\n","\tbatch: 300, loss: 4.6740, MAE: 1.7078\n","Training:\t loss: 1061.9032, MAE: 12.5728\n","Evaluating:\t loss: 18.4971, MAE: 1.9504\n","train MSE: 1061.9032, evaluate MSE: 18.4971\n","train MAE: 12.5728, evaluate MAE: 1.9504\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 76\n","\tbatch: 100, loss: 14.4548, MAE: 2.5033\n","\tbatch: 200, loss: 43.1839, MAE: 5.9870\n","\tbatch: 300, loss: 8.4241, MAE: 1.7683\n","Training:\t loss: 24.9365, MAE: 3.1157\n","Evaluating:\t loss: 17.4985, MAE: 1.8071\n","train MSE: 24.9365, evaluate MSE: 17.4985\n","train MAE: 3.1157, evaluate MAE: 1.8071\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 77\n","\tbatch: 100, loss: 21.6879, MAE: 2.0504\n","\tbatch: 200, loss: 188.6664, MAE: 12.9056\n","\tbatch: 300, loss: 18.8909, MAE: 4.0456\n","Training:\t loss: 330.7204, MAE: 13.7433\n","Evaluating:\t loss: 52.6155, MAE: 6.2100\n","train MSE: 330.7204, evaluate MSE: 52.6155\n","train MAE: 13.7433, evaluate MAE: 6.2100\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 78\n","\tbatch: 100, loss: 1858.9994, MAE: 42.9050\n","\tbatch: 200, loss: 11.6219, MAE: 2.7456\n","\tbatch: 300, loss: 107.7858, MAE: 10.1981\n","Training:\t loss: 306.3896, MAE: 11.4251\n","Evaluating:\t loss: 43.2674, MAE: 5.5627\n","train MSE: 306.3896, evaluate MSE: 43.2674\n","train MAE: 11.4251, evaluate MAE: 5.5627\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 79\n","\tbatch: 100, loss: 105.0176, MAE: 9.8004\n","\tbatch: 200, loss: 27.2982, MAE: 4.2512\n","\tbatch: 300, loss: 3.0570, MAE: 1.2229\n","Training:\t loss: 395.1155, MAE: 13.7767\n","Evaluating:\t loss: 72.7903, MAE: 7.6511\n","train MSE: 395.1155, evaluate MSE: 72.7903\n","train MAE: 13.7767, evaluate MAE: 7.6511\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 80\n","\tbatch: 100, loss: 14.6379, MAE: 2.9225\n","\tbatch: 200, loss: 344.6701, MAE: 18.3623\n","\tbatch: 300, loss: 31.6580, MAE: 2.9153\n","Training:\t loss: 365.1403, MAE: 13.3883\n","Evaluating:\t loss: 25.1525, MAE: 3.6219\n","train MSE: 365.1403, evaluate MSE: 25.1525\n","train MAE: 13.3883, evaluate MAE: 3.6219\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 81\n","\tbatch: 100, loss: 2.7160, MAE: 1.1677\n","\tbatch: 200, loss: 23.4952, MAE: 4.0223\n","\tbatch: 300, loss: 27.0058, MAE: 4.1365\n","Training:\t loss: 334.1324, MAE: 10.4486\n","Evaluating:\t loss: 195.8228, MAE: 13.3184\n","train MSE: 334.1324, evaluate MSE: 195.8228\n","train MAE: 10.4486, evaluate MAE: 13.3184\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 82\n","\tbatch: 100, loss: 1380.7158, MAE: 36.7832\n","\tbatch: 200, loss: 1383.5911, MAE: 30.4426\n","\tbatch: 300, loss: 553.9126, MAE: 17.9960\n","Training:\t loss: 5524.0230, MAE: 32.5569\n","Evaluating:\t loss: 397.2867, MAE: 15.5306\n","train MSE: 5524.0230, evaluate MSE: 397.2867\n","train MAE: 32.5569, evaluate MAE: 15.5306\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 83\n","\tbatch: 100, loss: 516.2774, MAE: 14.7043\n","\tbatch: 200, loss: 204.6641, MAE: 10.5993\n","\tbatch: 300, loss: 250.2139, MAE: 10.2341\n","Training:\t loss: 263.8954, MAE: 11.4580\n","Evaluating:\t loss: 196.3656, MAE: 10.5470\n","train MSE: 263.8954, evaluate MSE: 196.3656\n","train MAE: 11.4580, evaluate MAE: 10.5470\n","--- time consumption (s): 15\n","------------------------------\n","Epoch 84\n","\tbatch: 100, loss: 56727.9727, MAE: 228.9603\n","\tbatch: 200, loss: 2661.6714, MAE: 41.6138\n","\tbatch: 300, loss: 33606.6758, MAE: 170.7015\n","Training:\t loss: 25254.6911, MAE: 109.6187\n","Evaluating:\t loss: 4377.3698, MAE: 46.3918\n","train MSE: 25254.6911, evaluate MSE: 4377.3698\n","train MAE: 109.6187, evaluate MAE: 46.3918\n","--- time consumption (s): 16\n","------------------------------\n","Epoch 85\n","\tbatch: 100, loss: 2419.8235, MAE: 30.9466\n","\tbatch: 200, loss: 590.1459, MAE: 17.1271\n","\tbatch: 300, loss: 5283.6826, MAE: 59.2318\n","Training:\t loss: 5519.2134, MAE: 47.7970\n","Evaluating:\t loss: 2325.5165, MAE: 33.6850\n","train MSE: 5519.2134, evaluate MSE: 2325.5165\n","train MAE: 47.7970, evaluate MAE: 33.6850\n","--- time consumption (s): 15\n","Best model has been saved! Best model obtained at epoch 76 with eval MAE\n","=============== testing ===============\n","MSE on test set: 2475.0146\n","MAE on test set: 34.4065\n","R2 score: 0.9980\n"]}],"source":["# 单位为 eV\n","!python main.py -e 100 -lr 5e-3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1308207,"status":"ok","timestamp":1634165400716,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"coDcffT1rXWg","outputId":"6d7079b6-0364-4fce-a524-0e9dd6f5a95a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using backend: pytorch\n","using device: cuda:0\n","....loaded....\n","../output/2021-10-13/model_dtnn_conv_3_label_2021-10-13_1634164127.txt\n","==========2021-10-13 22:28:46.806747==========\n","model_type: dtnn\n","number of parameters: 482583\n","batch_size: 256\n","n_conv: 3\n","learngin rate: 0.0001\n","device: cuda:0\n","--------------------\n","\n","=============== training & evaluating ===============\n","------------------------------\n","Epoch 1\n","\tbatch: 100, loss: 1902.4270, MAE: 30.7643\n","\tbatch: 200, loss: 986.7223, MAE: 25.7369\n","\tbatch: 300, loss: 1064.6967, MAE: 25.6117\n","Training:\t loss: 11067.0558, MAE: 40.4484\n","Evaluating:\t loss: 972.1478, MAE: 23.3745\n","train MSE: 11067.0558, evaluate MSE: 972.1478\n","train MAE: 40.4484, evaluate MAE: 23.3745\n","--- time consumption (s): 65\n","------------------------------\n","Epoch 2\n","\tbatch: 100, loss: 733.0386, MAE: 20.8446\n","\tbatch: 200, loss: 640.6901, MAE: 19.1278\n","\tbatch: 300, loss: 486.5796, MAE: 17.0544\n","Training:\t loss: 748.5292, MAE: 20.4072\n","Evaluating:\t loss: 562.5721, MAE: 17.5104\n","train MSE: 748.5292, evaluate MSE: 562.5721\n","train MAE: 20.4072, evaluate MAE: 17.5104\n","--- time consumption (s): 63\n","------------------------------\n","Epoch 3\n","\tbatch: 100, loss: 519.4294, MAE: 17.4278\n","\tbatch: 200, loss: 392.6147, MAE: 14.9273\n","\tbatch: 300, loss: 402.8220, MAE: 14.8655\n","Training:\t loss: 502.2395, MAE: 16.7152\n","Evaluating:\t loss: 393.8073, MAE: 14.8221\n","train MSE: 502.2395, evaluate MSE: 393.8073\n","train MAE: 16.7152, evaluate MAE: 14.8221\n","--- time consumption (s): 63\n","------------------------------\n","Epoch 4\n","\tbatch: 100, loss: 417.3703, MAE: 15.2171\n","\tbatch: 200, loss: 349.7189, MAE: 14.9513\n","\tbatch: 300, loss: 542.7266, MAE: 14.6057\n","Training:\t loss: 365.3766, MAE: 14.2607\n","Evaluating:\t loss: 348.5332, MAE: 13.9702\n","train MSE: 365.3766, evaluate MSE: 348.5332\n","train MAE: 14.2607, evaluate MAE: 13.9702\n","--- time consumption (s): 63\n","------------------------------\n","Epoch 5\n","\tbatch: 100, loss: 343.0955, MAE: 14.0208\n","\tbatch: 200, loss: 292.0366, MAE: 12.8243\n","\tbatch: 300, loss: 246.4496, MAE: 12.0261\n","Training:\t loss: 319.3991, MAE: 13.3073\n","Evaluating:\t loss: 267.2573, MAE: 12.0682\n","train MSE: 319.3991, evaluate MSE: 267.2573\n","train MAE: 13.3073, evaluate MAE: 12.0682\n","--- time consumption (s): 63\n","------------------------------\n","Epoch 6\n","\tbatch: 100, loss: 207.1606, MAE: 11.2656\n","\tbatch: 200, loss: 201.1364, MAE: 10.5981\n","\tbatch: 300, loss: 293.6597, MAE: 12.9574\n","Training:\t loss: 245.3992, MAE: 11.6148\n","Evaluating:\t loss: 254.3666, MAE: 12.0105\n","train MSE: 245.3992, evaluate MSE: 254.3666\n","train MAE: 11.6148, evaluate MAE: 12.0105\n","--- time consumption (s): 63\n","------------------------------\n","Epoch 7\n","\tbatch: 100, loss: 296.1379, MAE: 12.5614\n","\tbatch: 200, loss: 243.0668, MAE: 12.2605\n","\tbatch: 300, loss: 216.3935, MAE: 11.5230\n","Training:\t loss: 263.1338, MAE: 12.1826\n","Evaluating:\t loss: 222.5217, MAE: 11.1327\n","train MSE: 263.1338, evaluate MSE: 222.5217\n","train MAE: 12.1826, evaluate MAE: 11.1327\n","--- time consumption (s): 63\n","------------------------------\n","Epoch 8\n","\tbatch: 100, loss: 143.8955, MAE: 9.4088\n","\tbatch: 200, loss: 215.9228, MAE: 11.2358\n","\tbatch: 300, loss: 158.9062, MAE: 9.9423\n","Training:\t loss: 205.9878, MAE: 10.7443\n","Evaluating:\t loss: 190.9537, MAE: 10.2541\n","train MSE: 205.9878, evaluate MSE: 190.9537\n","train MAE: 10.7443, evaluate MAE: 10.2541\n","--- time consumption (s): 63\n","------------------------------\n","Epoch 9\n","\tbatch: 100, loss: 202.5904, MAE: 11.2605\n","\tbatch: 200, loss: 157.4117, MAE: 9.5801\n","\tbatch: 300, loss: 156.1998, MAE: 9.4880\n","Training:\t loss: 164.7653, MAE: 9.4976\n","Evaluating:\t loss: 171.2962, MAE: 9.9350\n","train MSE: 164.7653, evaluate MSE: 171.2962\n","train MAE: 9.4976, evaluate MAE: 9.9350\n","--- time consumption (s): 63\n","------------------------------\n","Epoch 10\n","\tbatch: 100, loss: 132.9440, MAE: 8.6645\n","\tbatch: 200, loss: 109.1806, MAE: 8.0926\n","\tbatch: 300, loss: 142.2782, MAE: 8.4300\n","Training:\t loss: 149.2442, MAE: 8.8850\n","Evaluating:\t loss: 138.8431, MAE: 8.7169\n","train MSE: 149.2442, evaluate MSE: 138.8431\n","train MAE: 8.8850, evaluate MAE: 8.7169\n","--- time consumption (s): 63\n","------------------------------\n","Epoch 11\n","\tbatch: 100, loss: 115.5002, MAE: 8.4100\n","\tbatch: 200, loss: 135.6626, MAE: 8.6060\n","\tbatch: 300, loss: 103.1587, MAE: 7.5425\n","Training:\t loss: 127.3330, MAE: 8.2097\n","Evaluating:\t loss: 111.6655, MAE: 7.6443\n","train MSE: 127.3330, evaluate MSE: 111.6655\n","train MAE: 8.2097, evaluate MAE: 7.6443\n","--- time consumption (s): 63\n","------------------------------\n","Epoch 12\n","\tbatch: 100, loss: 155.9488, MAE: 9.6265\n","\tbatch: 200, loss: 87.2176, MAE: 7.0880\n","\tbatch: 300, loss: 133.3185, MAE: 8.6749\n","Training:\t loss: 121.5623, MAE: 8.0169\n","Evaluating:\t loss: 101.1183, MAE: 7.3229\n","train MSE: 121.5623, evaluate MSE: 101.1183\n","train MAE: 8.0169, evaluate MAE: 7.3229\n","--- time consumption (s): 62\n","------------------------------\n","Epoch 13\n","\tbatch: 100, loss: 101.3866, MAE: 7.1242\n","\tbatch: 200, loss: 133.0466, MAE: 8.8208\n","\tbatch: 300, loss: 110.2411, MAE: 7.6542\n","Training:\t loss: 108.5152, MAE: 7.5206\n","Evaluating:\t loss: 98.6135, MAE: 7.1318\n","train MSE: 108.5152, evaluate MSE: 98.6135\n","train MAE: 7.5206, evaluate MAE: 7.1318\n","--- time consumption (s): 62\n","------------------------------\n","Epoch 14\n","\tbatch: 100, loss: 97.6271, MAE: 7.6601\n","\tbatch: 200, loss: 85.6456, MAE: 6.9806\n","\tbatch: 300, loss: 82.9694, MAE: 6.4044\n","Training:\t loss: 91.5045, MAE: 6.8995\n","Evaluating:\t loss: 88.7390, MAE: 6.7814\n","train MSE: 91.5045, evaluate MSE: 88.7390\n","train MAE: 6.8995, evaluate MAE: 6.7814\n","--- time consumption (s): 62\n","------------------------------\n","Epoch 15\n","\tbatch: 100, loss: 149.6305, MAE: 8.2568\n","\tbatch: 200, loss: 117.1646, MAE: 8.5994\n","\tbatch: 300, loss: 105.1870, MAE: 7.8363\n","Training:\t loss: 120.0132, MAE: 8.1482\n","Evaluating:\t loss: 77.9020, MAE: 6.4138\n","train MSE: 120.0132, evaluate MSE: 77.9020\n","train MAE: 8.1482, evaluate MAE: 6.4138\n","--- time consumption (s): 62\n","------------------------------\n","Epoch 16\n","\tbatch: 100, loss: 87.0169, MAE: 6.8717\n","\tbatch: 200, loss: 82.3458, MAE: 6.6242\n","\tbatch: 300, loss: 67.5952, MAE: 6.1381\n","Training:\t loss: 82.0548, MAE: 6.5640\n","Evaluating:\t loss: 86.4851, MAE: 7.0353\n","train MSE: 82.0548, evaluate MSE: 86.4851\n","train MAE: 6.5640, evaluate MAE: 7.0353\n","--- time consumption (s): 62\n","------------------------------\n","Epoch 17\n","\tbatch: 100, loss: 64.3245, MAE: 6.3402\n","\tbatch: 200, loss: 69.7136, MAE: 5.8647\n","\tbatch: 300, loss: 94.0370, MAE: 6.9746\n","Training:\t loss: 68.6189, MAE: 5.9840\n","Evaluating:\t loss: 63.1206, MAE: 5.7743\n","train MSE: 68.6189, evaluate MSE: 63.1206\n","train MAE: 5.9840, evaluate MAE: 5.7743\n","--- time consumption (s): 62\n","------------------------------\n","Epoch 18\n","\tbatch: 100, loss: 83.6205, MAE: 6.9272\n","\tbatch: 200, loss: 76.0529, MAE: 6.5030\n","\tbatch: 300, loss: 53.7341, MAE: 5.4425\n","Training:\t loss: 93.8563, MAE: 7.0122\n","Evaluating:\t loss: 128.0541, MAE: 9.4096\n","train MSE: 93.8563, evaluate MSE: 128.0541\n","train MAE: 7.0122, evaluate MAE: 9.4096\n","--- time consumption (s): 62\n","------------------------------\n","Epoch 19\n","\tbatch: 100, loss: 201.5338, MAE: 11.3325\n","\tbatch: 200, loss: 188.3009, MAE: 10.8457\n","\tbatch: 300, loss: 58.8150, MAE: 5.6003\n","Training:\t loss: 131.7932, MAE: 8.3325\n","Evaluating:\t loss: 71.9690, MAE: 6.0851\n","train MSE: 131.7932, evaluate MSE: 71.9690\n","train MAE: 8.3325, evaluate MAE: 6.0851\n","--- time consumption (s): 62\n","------------------------------\n","Epoch 20\n","\tbatch: 100, loss: 38.9239, MAE: 4.3081\n","\tbatch: 200, loss: 39.6982, MAE: 4.4451\n","\tbatch: 300, loss: 53.5929, MAE: 5.1841\n","Training:\t loss: 55.2643, MAE: 5.1212\n","Evaluating:\t loss: 63.3429, MAE: 5.5654\n","train MSE: 55.2643, evaluate MSE: 63.3429\n","train MAE: 5.1212, evaluate MAE: 5.5654\n","--- time consumption (s): 62\n","Best model has been saved! Best model obtained at epoch 20 with eval MAE\n","=============== testing ===============\n","MSE on test set: 61.6312\n","MAE on test set: 5.5663\n","R2 score: 0.9623\n"]}],"source":["# 完全图DTNN，单位 Hartree\n","!python main.py -type com -lr 1e-4 -e 20"]},{"cell_type":"markdown","metadata":{"id":"DK7yoqJ5Y-bG"},"source":["## Enhanced-DTNN"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AO0wwUA_KeWM"},"outputs":[],"source":["graph_type = 'non'\n","qm9 = QM9Dataset(type=graph_type)\n","# 个人PC这一载入过程需要1分钟"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":2600,"status":"ok","timestamp":1634108968213,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"3MKPgbY0V5Q-","outputId":"87b6ad5e-1dea-40f9-f214-95a627986de9"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using backend: pytorch\n","usage: main.py [-h] [-i IDX_LABEL] [-dn DIM_NODE] [-de DIM_EDGE] [-lr LR]\n","               [-b BATCH_SIZE] [-n N_CONV] [-e EPOCHS] [-M MODEL] [-opt OPT]\n","               [-cuda CUDA] [-type TYPE]\n","\n","optional arguments:\n","  -h, --help            show this help message and exit\n","  -i IDX_LABEL, --idx_label IDX_LABEL\n","                        index choice from 12 labels (default value (12) is the\n","                        energy U0)\n","  -dn DIM_NODE, --dim_node DIM_NODE\n","                        dim of nodes features after embedded\n","  -de DIM_EDGE, --dim_edge DIM_EDGE\n","                        dim of edges features after type embedded\n","  -lr LR                learning rate of Adam optimizer\n","  -b BATCH_SIZE, --batch_size BATCH_SIZE\n","                        batch size of samples\n","  -n N_CONV, --n_conv N_CONV\n","                        number of convolution layers\n","  -e EPOCHS, --epochs EPOCHS\n","                        epochs for training\n","  -M MODEL, --model MODEL\n","                        select a model: dtnn, mgcn or schnet\n","  -opt OPT              optimizer type\n","  -cuda CUDA            select a GPU to train model\n","  -type TYPE            which modeling type, optional: [non, com]\n"]}],"source":["!python main.py -h"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fLUM2yauV5Rt"},"outputs":[],"source":["# prop_names = [A, B, C, mu, alpha, homo, lumo, gap, r2, zpve, U0, U, H, G, Cv]  # 15 labels\n","# units = [1.0, 1.0, 1.0, Debye, Bohr ** 3, Hartree, Hartree, Hartree, Bohr ** 2, Hartree, Hartree, Hartree, Hartree, Hartree, 1.0]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":736,"status":"ok","timestamp":1634237684761,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"Vc2ILE42gGxf","outputId":"885be26c-1e86-4198-a727-5884279efb96"},"outputs":[{"name":"stdout","output_type":"stream","text":["    parser.add_argument('-o', '--out_dir', type=str, default='output', help='output directory')\r\n","    out_dir = args.out_dir\r\n","    model_dir = '../{}/{}/'.format(out_dir, graph_type)\r\n","    res_dir = '../{}/{}-{}-{}/'.format(out_dir, str(datetime.date.today()), model_type, idx_label)\r\n"]}],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1449,"status":"ok","timestamp":1634109421983,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"-dmWaYGQV5Sp","outputId":"634dfcb6-d979-459d-8015-bfb1fe53984b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using backend: pytorch\n","Traceback (most recent call last):\n","  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n","  File \"<frozen importlib._bootstrap_external>\", line 728, in exec_module\n","  File \"<frozen importlib._bootstrap>\", line 219, in _call_with_frames_removed\n","  File \"/usr/local/lib/python3.7/dist-packages/dgl/utils/__init__.py\", line 3, in <module>\n","    from .data import *\n","  File \"/usr/local/lib/python3.7/dist-packages/dgl/utils/data.py\", line 4, in <module>\n","    import networkx as nx\n","  File \"/usr/local/lib/python3.7/dist-packages/networkx/__init__.py\", line 82, in <module>\n","    from networkx import linalg\n","  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n","  File \"<frozen importlib._bootstrap_external>\", line 724, in exec_module\n","  File \"<frozen importlib._bootstrap_external>\", line 818, in get_code\n","  File \"<frozen importlib._bootstrap_external>\", line 917, in get_data\n","KeyboardInterrupt\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"main.py\", line 9, in <module>\n","    from dgl.data import split_dataset\n","  File \"/usr/local/lib/python3.7/dist-packages/dgl/__init__.py\", line 13, in <module>\n","    from .backend import load_backend, backend_name\n","  File \"/usr/local/lib/python3.7/dist-packages/dgl/backend/__init__.py\", line 95, in <module>\n","    load_backend(get_preferred_backend())\n","  File \"/usr/local/lib/python3.7/dist-packages/dgl/backend/__init__.py\", line 46, in load_backend\n","    mod = importlib.import_module('.%s' % mod_name, __name__)\n","  File \"/usr/lib/python3.7/importlib/__init__.py\", line 127, in import_module\n","    return _bootstrap._gcd_import(name[level:], package, level)\n","  File \"/usr/local/lib/python3.7/dist-packages/dgl/backend/pytorch/__init__.py\", line 1, in <module>\n","    from .tensor import *\n","  File \"/usr/local/lib/python3.7/dist-packages/dgl/backend/pytorch/tensor.py\", line 13, in <module>\n","    from ...function.base import TargetCode\n","  File \"/usr/local/lib/python3.7/dist-packages/dgl/function/__init__.py\", line 5, in <module>\n","    from .message import *\n","  File \"/usr/local/lib/python3.7/dist-packages/dgl/function/message.py\", line 8, in <module>\n","    from .._deprecate.runtime import ir\n","  File \"/usr/local/lib/python3.7/dist-packages/dgl/_deprecate/runtime/__init__.py\", line 4, in <module>\n","    from . import scheduler\n","  File \"/usr/local/lib/python3.7/dist-packages/dgl/_deprecate/runtime/scheduler.py\", line 4, in <module>\n","    from ... import utils\n","  File \"<frozen importlib._bootstrap>\", line 983, in _find_and_load\n","  File \"<frozen importlib._bootstrap>\", line 967, in _find_and_load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 677, in _load_unlocked\n","  File \"<frozen importlib._bootstrap>\", line 321, in __exit__\n","KeyboardInterrupt\n"]}],"source":["!python main.py -e 300 -i 12 "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-WWG1lQECVy2"},"outputs":[],"source":["# 3层卷积,SGD优化（没有动量）\n","!python main.py -e 300 -i 13 -opt sgd -lr 1e-3"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5092,"status":"ok","timestamp":1634237126712,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"b5j4QoxkV5TV","outputId":"e169d319-176b-4a46-9411-aa1f890c3f1c"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using backend: pytorch\n","using device: cuda:0\n","Traceback (most recent call last):\n","  File \"main.py\", line 82, in <module>\n","    qm9 = QM9Dataset(type=graph_type)\n","  File \"/content/drive/My Drive/code/graduation-project/src/qm9.py\", line 62, in __init__\n","    super(QM9Dataset, self).__init__(name='qm9', raw_dir=raw_dir)  # 至此 self.save_path 为 '../data/qm9'\n","  File \"/usr/local/lib/python3.7/dist-packages/dgl/data/dgl_dataset.py\", line 93, in __init__\n","    self._load()\n","  File \"/usr/local/lib/python3.7/dist-packages/dgl/data/dgl_dataset.py\", line 165, in _load\n","    self.load()\n","  File \"/content/drive/My Drive/code/graduation-project/src/qm9.py\", line 230, in load\n","    self.graphs, label_dict = dgl.load_graphs(graph_path)\n","  File \"/usr/local/lib/python3.7/dist-packages/dgl/data/graph_serialize.py\", line 182, in load_graphs\n","    return load_graph_v2(filename, idx_list)\n","  File \"/usr/local/lib/python3.7/dist-packages/dgl/data/graph_serialize.py\", line 192, in load_graph_v2\n","    heterograph_list = _CAPI_LoadGraphFiles_V2(filename, idx_list)\n","KeyboardInterrupt\n"]}],"source":["# 3层卷积,Adam优化\n","!python main.py -e 300 -i 13"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"i-LE-K6XV5T_"},"outputs":[],"source":["!python main.py -e 300 -i 14"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kqmsoxs8V5Uo"},"outputs":[],"source":["!python main.py -e 300 -i 11"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"88bAJpHAacxg"},"outputs":[],"source":["!python main.py -e 300 -i 110"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":205,"status":"ok","timestamp":1634108912931,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"f0sg2MIFac4d","outputId":"aca11ed1-c32c-44d8-d812-313a576a8659"},"outputs":[{"name":"stdout","output_type":"stream","text":["        fnames = [os.path.join(data_path, fname)\r\n","        fnames = sorted(fnames, key=lambda x: (int(re.sub(\"\\D\", \"\", x)), x))\r\n","        N = len(self.fnames)  # 133885\r\n","        for i, fname in enumerate(fnames):\r\n","        return {'fnames': fnames, 'Smiles': Smiles, 'InChI': InChI, 'properties': properties,\r\n"]}],"source":["!cat qm9.py | grep fnames"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Mfizcy_nac62"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kEay_Y2dKEt3"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4URPCVFmKEx_"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"dhIcZCsiKFLO"},"source":["##DTNN 参数对比 "]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":303,"status":"ok","timestamp":1634237894991,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"HisUehVJKguw","outputId":"6a35d07c-d762-4852-b69c-89f849ef3be7"},"outputs":[{"name":"stdout","output_type":"stream","text":["cat: mai.py: No such file or directory\n"]}],"source":["!cat mai.py | grep out_dir"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":333774,"status":"ok","timestamp":1634238293619,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"US0Px2KTKG0v","outputId":"49bd2368-a623-4a21-a310-6f4c2362659b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using backend: pytorch\n","using device: cuda:0\n","....loaded....\n","../adam_64/2021-10-14-dtnn-12/model_dtnn_conv_3_label_2021-10-14_1634237995.txt\n","==========2021-10-14 18:59:55.067282==========\n","model_type: dtnn\n","number of parameters: 597933\n","batch_size: 64\n","n_conv: 3\n","learngin rate: 0.0005\n","device: cuda:0\n","--------------------\n","\n","=============== training & evaluating ===============\n","------------------------------\n","Epoch 1\n","\tbatch: 100, loss: 9281584.0000, MAE: 2680.8784\n","\tbatch: 200, loss: 6757380.0000, MAE: 2089.6189\n","\tbatch: 300, loss: 5672971.0000, MAE: 1959.3998\n","\tbatch: 400, loss: 6057883.5000, MAE: 2005.8723\n","\tbatch: 500, loss: 3682449.5000, MAE: 1552.6205\n","\tbatch: 600, loss: 1086739.5000, MAE: 843.0853\n","\tbatch: 700, loss: 718960.1875, MAE: 631.2051\n","\tbatch: 800, loss: 471673.8750, MAE: 502.2536\n","\tbatch: 900, loss: 774159.6250, MAE: 588.9655\n","\tbatch: 1000, loss: 367075.3125, MAE: 462.8758\n","\tbatch: 1100, loss: 366902.3438, MAE: 448.7347\n","\tbatch: 1200, loss: 201311.8594, MAE: 327.8249\n","\tbatch: 1300, loss: 578632.0000, MAE: 383.0891\n","\tbatch: 1400, loss: 111786.1406, MAE: 243.5644\n","\tbatch: 1500, loss: 67087.2109, MAE: 228.7494\n","\tbatch: 1600, loss: 55836.8594, MAE: 149.8201\n","\tbatch: 1700, loss: 92647.7734, MAE: 128.7117\n","\tbatch: 1800, loss: 270519.5938, MAE: 235.0358\n","Training:\t loss: 4733990.4865, MAE: 1074.6455\n","Evaluating:\t loss: 80965.2512, MAE: 134.8336\n","train MSE: 4733990.4865, evaluate MSE: 80965.2512\n","\n","train MAE: 1074.6455, evaluate MAE: 134.8336\n","\n","--- time consumption (s): 47\n","\n","------------------------------\n","Epoch 2\n","\tbatch: 100, loss: 263328.4062, MAE: 169.5315\n","\tbatch: 200, loss: 18809.7949, MAE: 108.3155\n","\tbatch: 300, loss: 24343.5391, MAE: 92.3484\n","\tbatch: 400, loss: 31134.0371, MAE: 146.9776\n","\tbatch: 500, loss: 10084.9463, MAE: 68.0829\n","\tbatch: 600, loss: 104154.1250, MAE: 121.9936\n","\tbatch: 700, loss: 21443.6094, MAE: 84.5056\n","\tbatch: 800, loss: 8430.3789, MAE: 66.5454\n","\tbatch: 900, loss: 9504.3369, MAE: 68.2425\n","\tbatch: 1000, loss: 14988.9170, MAE: 93.1026\n","\tbatch: 1100, loss: 12758.7715, MAE: 90.3101\n","\tbatch: 1200, loss: 20173.7422, MAE: 94.8507\n","\tbatch: 1300, loss: 116106.2891, MAE: 258.5035\n","\tbatch: 1400, loss: 9150.7881, MAE: 63.9793\n","\tbatch: 1500, loss: 6832.0010, MAE: 62.2988\n","\tbatch: 1600, loss: 16012.6748, MAE: 85.4797\n","\tbatch: 1700, loss: 8263.1240, MAE: 64.6487\n","\tbatch: 1800, loss: 103757.9062, MAE: 117.8996\n","Training:\t loss: 51944.2196, MAE: 103.1306\n","Evaluating:\t loss: 15440.3114, MAE: 59.1246\n","train MSE: 51944.2196, evaluate MSE: 15440.3114\n","\n","train MAE: 103.1306, evaluate MAE: 59.1246\n","\n","--- time consumption (s): 44\n","\n","------------------------------\n","Epoch 3\n","\tbatch: 100, loss: 4561.2705, MAE: 49.4923\n","\tbatch: 200, loss: 8497.4062, MAE: 60.8251\n","\tbatch: 300, loss: 49618.1719, MAE: 75.9222\n","\tbatch: 400, loss: 38633.4688, MAE: 161.3427\n","\tbatch: 500, loss: 28658.4727, MAE: 133.8912\n","\tbatch: 600, loss: 17093.4922, MAE: 102.1129\n","\tbatch: 700, loss: 12356.1035, MAE: 79.0010\n","\tbatch: 800, loss: 9389.2598, MAE: 77.9099\n","\tbatch: 900, loss: 44440.2031, MAE: 177.7609\n","\tbatch: 1000, loss: 94503.2109, MAE: 180.6106\n","\tbatch: 1100, loss: 51333.7852, MAE: 131.8149\n","\tbatch: 1200, loss: 34143.5469, MAE: 143.9931\n","\tbatch: 1300, loss: 7470.3755, MAE: 72.3366\n","\tbatch: 1400, loss: 10301.9844, MAE: 77.7867\n","\tbatch: 1500, loss: 9249.5039, MAE: 66.9948\n","\tbatch: 1600, loss: 10926.9863, MAE: 78.9579\n","\tbatch: 1700, loss: 7405.3560, MAE: 67.4220\n","\tbatch: 1800, loss: 7183.0635, MAE: 70.0184\n","Training:\t loss: 25190.9346, MAE: 95.3733\n","Evaluating:\t loss: 11493.9954, MAE: 71.7790\n","train MSE: 25190.9346, evaluate MSE: 11493.9954\n","\n","train MAE: 95.3733, evaluate MAE: 71.7790\n","\n","--- time consumption (s): 44\n","\n","------------------------------\n","Epoch 4\n","\tbatch: 100, loss: 5873.7939, MAE: 62.1915\n","\tbatch: 200, loss: 6639.9819, MAE: 63.5117\n","\tbatch: 300, loss: 4521.0107, MAE: 53.9597\n","\tbatch: 400, loss: 15225.8438, MAE: 99.6933\n","\tbatch: 500, loss: 8473.6943, MAE: 71.9907\n","\tbatch: 600, loss: 8590.2676, MAE: 75.7262\n","\tbatch: 700, loss: 37429.0000, MAE: 162.3332\n","\tbatch: 800, loss: 14177.6016, MAE: 92.3697\n","\tbatch: 900, loss: 710787.0000, MAE: 725.5070\n","\tbatch: 1000, loss: 34043.0820, MAE: 150.4247\n","\tbatch: 1100, loss: 55549.7656, MAE: 165.7933\n","\tbatch: 1200, loss: 31485.6992, MAE: 148.3590\n","\tbatch: 1300, loss: 21461.1816, MAE: 110.9233\n","\tbatch: 1400, loss: 13154.2393, MAE: 96.3079\n","\tbatch: 1500, loss: 9623.9932, MAE: 63.1342\n","\tbatch: 1600, loss: 37773.3750, MAE: 162.0748\n","\tbatch: 1700, loss: 10597.0293, MAE: 73.5900\n","\tbatch: 1800, loss: 13485.2432, MAE: 89.7398\n","Training:\t loss: 36925.6540, MAE: 125.0061\n","Evaluating:\t loss: 11824.9131, MAE: 80.7395\n","train MSE: 36925.6540, evaluate MSE: 11824.9131\n","\n","train MAE: 125.0061, evaluate MAE: 80.7395\n","\n","--- time consumption (s): 44\n","\n","------------------------------\n","Epoch 5\n","\tbatch: 100, loss: 30162.9746, MAE: 139.6151\n","\tbatch: 200, loss: 17698.5508, MAE: 94.6724\n","\tbatch: 300, loss: 103744.5859, MAE: 229.9301\n","\tbatch: 400, loss: 32404.4238, MAE: 137.5094\n","\tbatch: 500, loss: 13666.1426, MAE: 91.3935\n","\tbatch: 600, loss: 12863.2109, MAE: 87.3882\n","\tbatch: 700, loss: 7869.1865, MAE: 73.0858\n","\tbatch: 800, loss: 11221.2812, MAE: 85.9861\n","\tbatch: 900, loss: 9475.2383, MAE: 81.8579\n","\tbatch: 1000, loss: 8513.5088, MAE: 71.8102\n","\tbatch: 1100, loss: 15486.0195, MAE: 90.6001\n","\tbatch: 1200, loss: 103884.2656, MAE: 271.2629\n","\tbatch: 1300, loss: 25427.5977, MAE: 129.8960\n","\tbatch: 1400, loss: 10802.2568, MAE: 75.5954\n","\tbatch: 1500, loss: 20689.3281, MAE: 113.3751\n","\tbatch: 1600, loss: 12623.9766, MAE: 81.5986\n","\tbatch: 1700, loss: 8369.8828, MAE: 68.5777\n","\tbatch: 1800, loss: 8017.6260, MAE: 62.3167\n","Training:\t loss: 30099.3358, MAE: 114.5937\n","Evaluating:\t loss: 9522.7638, MAE: 72.7501\n","train MSE: 30099.3358, evaluate MSE: 9522.7638\n","\n","train MAE: 114.5937, evaluate MAE: 72.7501\n","\n","--- time consumption (s): 44\n","\n","------------------------------\n","Epoch 6\n","\tbatch: 100, loss: 8420.5312, MAE: 62.2398\n","\tbatch: 200, loss: 24164.5469, MAE: 122.8266\n","\tbatch: 300, loss: 20227.2109, MAE: 108.1975\n","\tbatch: 400, loss: 5819.0142, MAE: 61.5681\n","\tbatch: 500, loss: 3785.2642, MAE: 46.7127\n","\tbatch: 600, loss: 3033.7051, MAE: 43.9060\n","\tbatch: 700, loss: 6416.6914, MAE: 62.7548\n","\tbatch: 800, loss: 5274.9980, MAE: 57.5731\n","\tbatch: 900, loss: 6667.3701, MAE: 64.5541\n","\tbatch: 1000, loss: 9989.4473, MAE: 80.1101\n","\tbatch: 1100, loss: 10812.5029, MAE: 82.9035\n","\tbatch: 1200, loss: 165608.7812, MAE: 390.4351\n","\tbatch: 1300, loss: 14547.5381, MAE: 90.9831\n","\tbatch: 1400, loss: 10510.9834, MAE: 77.1944\n","\tbatch: 1500, loss: 6163.1816, MAE: 54.9793\n","\tbatch: 1600, loss: 2797.6096, MAE: 40.2121\n","\tbatch: 1700, loss: 51198.7969, MAE: 170.3516\n","\tbatch: 1800, loss: 12500.3965, MAE: 81.1693\n","Training:\t loss: 16776.8739, MAE: 86.5755\n","Evaluating:\t loss: 8523.2484, MAE: 63.1248\n","train MSE: 16776.8739, evaluate MSE: 8523.2484\n","\n","train MAE: 86.5755, evaluate MAE: 63.1248\n","\n","--- time consumption (s): 44\n","\n","------------------------------\n","Epoch 7\n","\tbatch: 100, loss: 3079.3892, MAE: 45.0692\n","\tbatch: 200, loss: 18093.9121, MAE: 72.2825\n","\tbatch: 300, loss: 9382.7070, MAE: 72.6227\n","\tbatch: 400, loss: 3315.5908, MAE: 43.3608\n","\tbatch: 500, loss: 3996.5107, MAE: 42.9030\n","\tbatch: 600, loss: 11790.9004, MAE: 57.9149\n","\tbatch: 700, loss: 2567.7354, MAE: 35.9818\n","\tbatch: 800, loss: 6265.9727, MAE: 51.5647\n","\tbatch: 900, loss: 3259.6428, MAE: 40.3567\n","\tbatch: 1000, loss: 4216.6362, MAE: 43.5353\n","\n"]}],"source":["!python main.py -lr 5e-4 -e 20 -o adam_64"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":441261,"status":"ok","timestamp":1634252327638,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"GUoMGCInLF04","outputId":"7821713a-befd-44da-8d57-819807f02e77"},"outputs":[{"name":"stdout","output_type":"stream","text":["DGL backend not selected or invalid.  Assuming PyTorch for now.\n","Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n","Using backend: pytorch\n","using device: cuda:0\n","....loaded....\n","../adam_256/2021-10-14-dtnn-12/model_dtnn_conv_3_label_2021-10-14_1634251944.txt\n","==========2021-10-14 22:52:23.991611==========\n","model_type: dtnn\n","number of parameters: 597933\n","batch_size: 256\n","n_conv: 3\n","learngin rate: 0.005\n","device: cuda:0\n","--------------------\n","\n","=============== training & evaluating ===============\n","------------------------------\n","Epoch 1\n","\tbatch: 100, loss: 4992530.5000, MAE: 1791.8781\n","\tbatch: 200, loss: 3253759.5000, MAE: 1464.8647\n","\tbatch: 300, loss: 876554.7500, MAE: 736.6097\n","\tbatch: 400, loss: 665584.0625, MAE: 631.2014\n","Training:\t loss: 4634169.0123, MAE: 1388.5971\n","Evaluating:\t loss: 693693.1007, MAE: 656.1892\n","train MSE: 4634169.0123, evaluate MSE: 693693.1007\n","\n","train MAE: 1388.5971, evaluate MAE: 656.1892\n","\n","--- time consumption (s): 21\n","\n","------------------------------\n","Epoch 2\n","\tbatch: 100, loss: 561256.2500, MAE: 602.8066\n","\tbatch: 200, loss: 344841.3438, MAE: 455.7165\n","\tbatch: 300, loss: 303987.1875, MAE: 431.4991\n","\tbatch: 400, loss: 195157.5312, MAE: 348.9232\n","Training:\t loss: 377229.8137, MAE: 468.7721\n","Evaluating:\t loss: 129099.4644, MAE: 285.3781\n","train MSE: 377229.8137, evaluate MSE: 129099.4644\n","\n","train MAE: 468.7721, evaluate MAE: 285.3781\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 3\n","\tbatch: 100, loss: 72018.3359, MAE: 209.6308\n","\tbatch: 200, loss: 49886.1250, MAE: 180.7183\n","\tbatch: 300, loss: 27868.8125, MAE: 133.4314\n","\tbatch: 400, loss: 16045.3027, MAE: 101.6901\n","Training:\t loss: 57344.2284, MAE: 181.0417\n","Evaluating:\t loss: 23293.0553, MAE: 122.5640\n","train MSE: 57344.2284, evaluate MSE: 23293.0553\n","\n","train MAE: 181.0417, evaluate MAE: 122.5640\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 4\n","\tbatch: 100, loss: 40676.3398, MAE: 166.7923\n","\tbatch: 200, loss: 11886.5195, MAE: 89.3649\n","\tbatch: 300, loss: 6998.0566, MAE: 66.2910\n","\tbatch: 400, loss: 4503.1992, MAE: 54.0101\n","Training:\t loss: 46995.9840, MAE: 128.7317\n","Evaluating:\t loss: 4742.8768, MAE: 51.3292\n","train MSE: 46995.9840, evaluate MSE: 4742.8768\n","\n","train MAE: 128.7317, evaluate MAE: 51.3292\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 5\n","\tbatch: 100, loss: 4343.0322, MAE: 53.8485\n","\tbatch: 200, loss: 3271.3379, MAE: 40.6618\n","\tbatch: 300, loss: 3111.1377, MAE: 40.7696\n","\tbatch: 400, loss: 3037.5615, MAE: 41.6259\n","Training:\t loss: 3284.0894, MAE: 43.1365\n","Evaluating:\t loss: 2702.9462, MAE: 38.3485\n","train MSE: 3284.0894, evaluate MSE: 2702.9462\n","\n","train MAE: 43.1365, evaluate MAE: 38.3485\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 6\n","\tbatch: 100, loss: 2800.4102, MAE: 38.2294\n","\tbatch: 200, loss: 1932.9934, MAE: 34.1090\n","\tbatch: 300, loss: 1967.7280, MAE: 32.7639\n","\tbatch: 400, loss: 1986.8149, MAE: 30.0031\n","Training:\t loss: 2157.7087, MAE: 33.4118\n","Evaluating:\t loss: 1729.3002, MAE: 29.7915\n","train MSE: 2157.7087, evaluate MSE: 1729.3002\n","\n","train MAE: 33.4118, evaluate MAE: 29.7915\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 7\n","\tbatch: 100, loss: 1534.0074, MAE: 28.4155\n","\tbatch: 200, loss: 1174.5674, MAE: 24.5116\n","\tbatch: 300, loss: 1025.5570, MAE: 22.8451\n","\tbatch: 400, loss: 1310.4855, MAE: 22.0113\n","Training:\t loss: 1373.3660, MAE: 25.3386\n","Evaluating:\t loss: 986.8902, MAE: 22.1056\n","train MSE: 1373.3660, evaluate MSE: 986.8902\n","\n","train MAE: 25.3386, evaluate MAE: 22.1056\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 8\n","\tbatch: 100, loss: 472.2753, MAE: 17.0946\n","\tbatch: 200, loss: 488.4261, MAE: 16.5579\n","\tbatch: 300, loss: 417.9166, MAE: 14.9390\n","\tbatch: 400, loss: 880.4401, MAE: 21.4481\n","Training:\t loss: 882.6773, MAE: 19.2675\n","Evaluating:\t loss: 628.2562, MAE: 16.9026\n","train MSE: 882.6773, evaluate MSE: 628.2562\n","\n","train MAE: 19.2675, evaluate MAE: 16.9026\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 9\n","\tbatch: 100, loss: 2709.3975, MAE: 45.0691\n","\tbatch: 200, loss: 579.3179, MAE: 18.7038\n","\tbatch: 300, loss: 2281.6042, MAE: 31.6433\n","\tbatch: 400, loss: 1033.1680, MAE: 25.0229\n","Training:\t loss: 1929.2772, MAE: 27.5215\n","Evaluating:\t loss: 1040.0647, MAE: 24.1135\n","train MSE: 1929.2772, evaluate MSE: 1040.0647\n","\n","train MAE: 27.5215, evaluate MAE: 24.1135\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 10\n","\tbatch: 100, loss: 1263.1072, MAE: 24.1202\n","\tbatch: 200, loss: 798.8438, MAE: 21.8909\n","\tbatch: 300, loss: 763.8980, MAE: 18.5897\n","\tbatch: 400, loss: 1420.9487, MAE: 25.7795\n","Training:\t loss: 1200.8175, MAE: 23.4691\n","Evaluating:\t loss: 708.6434, MAE: 17.8542\n","train MSE: 1200.8175, evaluate MSE: 708.6434\n","\n","train MAE: 23.4691, evaluate MAE: 17.8542\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 11\n","\tbatch: 100, loss: 396.7350, MAE: 14.2621\n","\tbatch: 200, loss: 378.0352, MAE: 13.1256\n","\tbatch: 300, loss: 2124.7136, MAE: 36.4300\n","\tbatch: 400, loss: 42850.9453, MAE: 166.8491\n","Training:\t loss: 55809.0454, MAE: 105.1557\n","Evaluating:\t loss: 154252.9375, MAE: 355.1318\n","train MSE: 55809.0454, evaluate MSE: 154252.9375\n","\n","train MAE: 105.1557, evaluate MAE: 355.1318\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 12\n","\tbatch: 100, loss: 23214.7559, MAE: 121.7823\n","\tbatch: 200, loss: 11573.4062, MAE: 86.5863\n","\tbatch: 300, loss: 3702.4167, MAE: 45.1589\n","\tbatch: 400, loss: 3056.7114, MAE: 41.7427\n","Training:\t loss: 20753.1538, MAE: 95.6281\n","Evaluating:\t loss: 2749.4622, MAE: 37.3709\n","train MSE: 20753.1538, evaluate MSE: 2749.4622\n","\n","train MAE: 95.6281, evaluate MAE: 37.3709\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 13\n","\tbatch: 100, loss: 5828.5615, MAE: 53.9192\n","\tbatch: 200, loss: 6003.6226, MAE: 58.0790\n","\tbatch: 300, loss: 2766.7075, MAE: 39.4841\n","\tbatch: 400, loss: 3658.4460, MAE: 46.1903\n","Training:\t loss: 8107.7380, MAE: 61.4297\n","Evaluating:\t loss: 6482.1553, MAE: 62.8012\n","train MSE: 8107.7380, evaluate MSE: 6482.1553\n","\n","train MAE: 61.4297, evaluate MAE: 62.8012\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 14\n","\tbatch: 100, loss: 6546.7109, MAE: 61.6301\n","\tbatch: 200, loss: 67932.0938, MAE: 213.2741\n","\tbatch: 300, loss: 10120.4590, MAE: 76.2583\n","\tbatch: 400, loss: 6200.2759, MAE: 61.6840\n","Training:\t loss: 18208.1768, MAE: 83.5772\n","Evaluating:\t loss: 4849.0988, MAE: 49.3997\n","train MSE: 18208.1768, evaluate MSE: 4849.0988\n","\n","train MAE: 83.5772, evaluate MAE: 49.3997\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 15\n","\tbatch: 100, loss: 4259.2393, MAE: 49.8545\n","\tbatch: 200, loss: 50692.0312, MAE: 210.7750\n","\tbatch: 300, loss: 3287.3164, MAE: 41.7581\n","\tbatch: 400, loss: 2525.6699, MAE: 38.2679\n","Training:\t loss: 11252.0300, MAE: 63.8600\n","Evaluating:\t loss: 3898.1296, MAE: 49.8216\n","train MSE: 11252.0300, evaluate MSE: 3898.1296\n","\n","train MAE: 63.8600, evaluate MAE: 49.8216\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 16\n","\tbatch: 100, loss: 1465.8101, MAE: 28.8046\n","\tbatch: 200, loss: 966.8386, MAE: 24.0396\n","\tbatch: 300, loss: 1219.6736, MAE: 22.3214\n","\tbatch: 400, loss: 8018.5312, MAE: 78.9329\n","Training:\t loss: 6501.3649, MAE: 53.0195\n","Evaluating:\t loss: 15049.9473, MAE: 112.0738\n","train MSE: 6501.3649, evaluate MSE: 15049.9473\n","\n","train MAE: 53.0195, evaluate MAE: 112.0738\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 17\n","\tbatch: 100, loss: 890.2253, MAE: 20.0840\n","\tbatch: 200, loss: 1294.2843, MAE: 21.9696\n","\tbatch: 300, loss: 1171.6221, MAE: 20.1155\n","\tbatch: 400, loss: 903.4470, MAE: 18.3728\n","Training:\t loss: 1417.7091, MAE: 23.1726\n","Evaluating:\t loss: 1027.2325, MAE: 21.1899\n","train MSE: 1417.7091, evaluate MSE: 1027.2325\n","\n","train MAE: 23.1726, evaluate MAE: 21.1899\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 18\n","\tbatch: 100, loss: 631.5246, MAE: 16.6881\n","\tbatch: 200, loss: 1204.9180, MAE: 23.1399\n","\tbatch: 300, loss: 1255.4458, MAE: 26.5398\n","\tbatch: 400, loss: 596.7308, MAE: 16.3951\n","Training:\t loss: 1605.6063, MAE: 24.1128\n","Evaluating:\t loss: 671.5306, MAE: 15.7741\n","train MSE: 1605.6063, evaluate MSE: 671.5306\n","\n","train MAE: 24.1128, evaluate MAE: 15.7741\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 19\n","\tbatch: 100, loss: 809.7203, MAE: 17.6556\n","\tbatch: 200, loss: 52070.1953, MAE: 204.9145\n","\tbatch: 300, loss: 4128.1240, MAE: 45.3126\n","\tbatch: 400, loss: 9164.7441, MAE: 77.0616\n","Training:\t loss: 23441.9378, MAE: 99.0028\n","Evaluating:\t loss: 4794.3447, MAE: 49.4128\n","train MSE: 23441.9378, evaluate MSE: 4794.3447\n","\n","train MAE: 99.0028, evaluate MAE: 49.4128\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 20\n","\tbatch: 100, loss: 40420.3750, MAE: 193.6297\n","\tbatch: 200, loss: 2518.0457, MAE: 43.2346\n","\tbatch: 300, loss: 1424.4407, MAE: 26.5276\n","\tbatch: 400, loss: 1324.7367, MAE: 27.6197\n","Training:\t loss: 4779.4591, MAE: 46.8735\n","Evaluating:\t loss: 1014.5223, MAE: 21.4035\n","train MSE: 4779.4591, evaluate MSE: 1014.5223\n","\n","train MAE: 46.8735, evaluate MAE: 21.4035\n","\n","--- time consumption (s): 18\n","\n","Best model has been saved! Best model obtained at epoch 18 with eval MAE\n","=============== testing ===============\n","MSE on test set: 1060.9823\n","MAE on test set: 21.8875\n","R2 score: 0.9991\n"]}],"source":["!python main.py -lr 5e-3 -e 20 -b 256 -o adam_256"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":506756,"status":"ok","timestamp":1634252834390,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"H7XXD_1cLSMm","outputId":"c3c9e571-af7e-46ea-c0df-c8f39e3355dd"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using backend: pytorch\n","using device: cuda:0\n","....loaded....\n","../adam_256_conv_4/2021-10-14-dtnn-12/model_dtnn_conv_4_label_2021-10-14_1634252359.txt\n","==========2021-10-14 22:59:18.899267==========\n","model_type: dtnn\n","number of parameters: 773677\n","batch_size: 256\n","n_conv: 4\n","learngin rate: 0.005\n","device: cuda:0\n","--------------------\n","\n","=============== training & evaluating ===============\n","------------------------------\n","Epoch 1\n","\tbatch: 100, loss: 5105898.5000, MAE: 1767.2605\n","\tbatch: 200, loss: 4635973.0000, MAE: 1699.6874\n","\tbatch: 300, loss: 2507288.0000, MAE: 1246.3035\n","\tbatch: 400, loss: 835830.5000, MAE: 676.8503\n","Training:\t loss: 5474559.1639, MAE: 1587.0325\n","Evaluating:\t loss: 430636.7373, MAE: 496.5937\n","train MSE: 5474559.1639, evaluate MSE: 430636.7373\n","\n","train MAE: 1587.0325, evaluate MAE: 496.5937\n","\n","--- time consumption (s): 26\n","\n","------------------------------\n","Epoch 2\n","\tbatch: 100, loss: 2184502.0000, MAE: 1267.1382\n","\tbatch: 200, loss: 289050.3125, MAE: 425.4476\n","\tbatch: 300, loss: 152973.9688, MAE: 303.4996\n","\tbatch: 400, loss: 131537.1875, MAE: 285.1610\n","Training:\t loss: 382885.3177, MAE: 451.7977\n","Evaluating:\t loss: 121977.5252, MAE: 270.8207\n","train MSE: 382885.3177, evaluate MSE: 121977.5252\n","\n","train MAE: 451.7977, evaluate MAE: 270.8207\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 3\n","\tbatch: 100, loss: 103955.0000, MAE: 239.7110\n","\tbatch: 200, loss: 72254.6875, MAE: 217.0353\n","\tbatch: 300, loss: 49317.6797, MAE: 177.8431\n","\tbatch: 400, loss: 32674.6621, MAE: 140.4693\n","Training:\t loss: 66524.9441, MAE: 195.1986\n","Evaluating:\t loss: 32739.2986, MAE: 137.4965\n","train MSE: 66524.9441, evaluate MSE: 32739.2986\n","\n","train MAE: 195.1986, evaluate MAE: 137.4965\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 4\n","\tbatch: 100, loss: 39086.7266, MAE: 148.5139\n","\tbatch: 200, loss: 36175.2891, MAE: 153.9744\n","\tbatch: 300, loss: 45201.3477, MAE: 167.1019\n","\tbatch: 400, loss: 21985.6094, MAE: 112.5055\n","Training:\t loss: 39631.1485, MAE: 148.4744\n","Evaluating:\t loss: 23936.4675, MAE: 117.8503\n","train MSE: 39631.1485, evaluate MSE: 23936.4675\n","\n","train MAE: 148.4744, evaluate MAE: 117.8503\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 5\n","\tbatch: 100, loss: 13200.8262, MAE: 89.7877\n","\tbatch: 200, loss: 10392.4512, MAE: 77.3763\n","\tbatch: 300, loss: 12778.7002, MAE: 82.8443\n","\tbatch: 400, loss: 12032.1904, MAE: 79.1211\n","Training:\t loss: 13699.8447, MAE: 85.1436\n","Evaluating:\t loss: 8772.4512, MAE: 69.4975\n","train MSE: 13699.8447, evaluate MSE: 8772.4512\n","\n","train MAE: 85.1436, evaluate MAE: 69.4975\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 6\n","\tbatch: 100, loss: 6300.8525, MAE: 64.5034\n","\tbatch: 200, loss: 5536.8877, MAE: 52.4284\n","\tbatch: 300, loss: 3541.7900, MAE: 42.3491\n","\tbatch: 400, loss: 2241.2712, MAE: 37.6214\n","Training:\t loss: 5566.2309, MAE: 52.5464\n","Evaluating:\t loss: 3042.7037, MAE: 35.9065\n","train MSE: 5566.2309, evaluate MSE: 3042.7037\n","\n","train MAE: 52.5464, evaluate MAE: 35.9065\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 7\n","\tbatch: 100, loss: 5426.4155, MAE: 58.3465\n","\tbatch: 200, loss: 2820.4912, MAE: 31.0432\n","\tbatch: 300, loss: 4119.3491, MAE: 30.3388\n","\tbatch: 400, loss: 3657.2722, MAE: 38.1185\n","Training:\t loss: 2830.2597, MAE: 33.9286\n","Evaluating:\t loss: 2652.5560, MAE: 33.8074\n","train MSE: 2830.2597, evaluate MSE: 2652.5560\n","\n","train MAE: 33.9286, evaluate MAE: 33.8074\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 8\n","\tbatch: 100, loss: 2890.2407, MAE: 37.2546\n","\tbatch: 200, loss: 1741.5134, MAE: 27.4400\n","\tbatch: 300, loss: 2550.3647, MAE: 29.1481\n","\tbatch: 400, loss: 1887.2939, MAE: 24.7505\n","Training:\t loss: 2180.9893, MAE: 29.5597\n","Evaluating:\t loss: 1339.6660, MAE: 20.8111\n","train MSE: 2180.9893, evaluate MSE: 1339.6660\n","\n","train MAE: 29.5597, evaluate MAE: 20.8111\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 9\n","\tbatch: 100, loss: 2153.5862, MAE: 32.5009\n","\tbatch: 200, loss: 1783.2554, MAE: 29.8209\n","\tbatch: 300, loss: 47352.6055, MAE: 200.1754\n","\tbatch: 400, loss: 10521.7109, MAE: 81.7674\n","Training:\t loss: 7476.3105, MAE: 54.9721\n","Evaluating:\t loss: 4363.9291, MAE: 50.6297\n","train MSE: 7476.3105, evaluate MSE: 4363.9291\n","\n","train MAE: 54.9721, evaluate MAE: 50.6297\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 10\n","\tbatch: 100, loss: 3862.6836, MAE: 42.5896\n","\tbatch: 200, loss: 5181.8047, MAE: 57.7586\n","\tbatch: 300, loss: 857.0839, MAE: 21.1296\n","\tbatch: 400, loss: 972.4368, MAE: 21.5844\n","Training:\t loss: 3615.9185, MAE: 41.5566\n","Evaluating:\t loss: 3291.2405, MAE: 43.7768\n","train MSE: 3615.9185, evaluate MSE: 3291.2405\n","\n","train MAE: 41.5566, evaluate MAE: 43.7768\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 11\n","\tbatch: 100, loss: 3285.2734, MAE: 44.4887\n","\tbatch: 200, loss: 1304.7612, MAE: 26.0711\n","\tbatch: 300, loss: 115229.1250, MAE: 315.9549\n","\tbatch: 400, loss: 8004.7422, MAE: 79.6943\n","Training:\t loss: 5581.6314, MAE: 50.9553\n","Evaluating:\t loss: 631.9780, MAE: 18.9778\n","train MSE: 5581.6314, evaluate MSE: 631.9780\n","\n","train MAE: 50.9553, evaluate MAE: 18.9778\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 12\n","\tbatch: 100, loss: 228207.3750, MAE: 429.5468\n","\tbatch: 200, loss: 62259.3594, MAE: 202.7924\n","\tbatch: 300, loss: 82471.2344, MAE: 235.0451\n","\tbatch: 400, loss: 14024.8369, MAE: 93.0920\n","Training:\t loss: 178795.5255, MAE: 251.2976\n","Evaluating:\t loss: 13851.2336, MAE: 92.6913\n","train MSE: 178795.5255, evaluate MSE: 13851.2336\n","\n","train MAE: 251.2976, evaluate MAE: 92.6913\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 13\n","\tbatch: 100, loss: 8941.6533, MAE: 74.3217\n","\tbatch: 200, loss: 5693.7949, MAE: 59.9427\n","\tbatch: 300, loss: 5048.8862, MAE: 57.4202\n","\tbatch: 400, loss: 7476.5830, MAE: 70.3993\n","Training:\t loss: 7811.4151, MAE: 67.5746\n","Evaluating:\t loss: 3320.1533, MAE: 43.6002\n","train MSE: 7811.4151, evaluate MSE: 3320.1533\n","\n","train MAE: 67.5746, evaluate MAE: 43.6002\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 14\n","\tbatch: 100, loss: 3007.4805, MAE: 39.1502\n","\tbatch: 200, loss: 1350.0408, MAE: 26.9119\n","\tbatch: 300, loss: 1020.6124, MAE: 24.8778\n","\tbatch: 400, loss: 981.0915, MAE: 22.9391\n","Training:\t loss: 2645.8272, MAE: 34.1874\n","Evaluating:\t loss: 783.7500, MAE: 20.7639\n","train MSE: 2645.8272, evaluate MSE: 783.7500\n","\n","train MAE: 34.1874, evaluate MAE: 20.7639\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 15\n","\tbatch: 100, loss: 636.7158, MAE: 18.7830\n","\tbatch: 200, loss: 11342.4863, MAE: 93.8319\n","\tbatch: 300, loss: 1401.2991, MAE: 28.7542\n","\tbatch: 400, loss: 920.0406, MAE: 21.3990\n","Training:\t loss: 5949.5036, MAE: 45.2660\n","Evaluating:\t loss: 701.2573, MAE: 18.8032\n","train MSE: 5949.5036, evaluate MSE: 701.2573\n","\n","train MAE: 45.2660, evaluate MAE: 18.8032\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 16\n","\tbatch: 100, loss: 614.6628, MAE: 18.3435\n","\tbatch: 200, loss: 970.2811, MAE: 25.2329\n","\tbatch: 300, loss: 651.3839, MAE: 19.1659\n","\tbatch: 400, loss: 2049.8943, MAE: 38.1705\n","Training:\t loss: 1782.9583, MAE: 28.1584\n","Evaluating:\t loss: 855.4682, MAE: 22.9201\n","train MSE: 1782.9583, evaluate MSE: 855.4682\n","\n","train MAE: 28.1584, evaluate MAE: 22.9201\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 17\n","\tbatch: 100, loss: 404.8101, MAE: 15.5444\n","\tbatch: 200, loss: 364.9278, MAE: 13.8197\n","\tbatch: 300, loss: 300.6321, MAE: 12.7296\n","\tbatch: 400, loss: 273.2140, MAE: 12.8163\n","Training:\t loss: 837.6441, MAE: 18.6648\n","Evaluating:\t loss: 249.2721, MAE: 11.7392\n","train MSE: 837.6441, evaluate MSE: 249.2721\n","\n","train MAE: 18.6648, evaluate MAE: 11.7392\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 18\n","\tbatch: 100, loss: 279.0895, MAE: 12.6365\n","\tbatch: 200, loss: 286.0961, MAE: 12.8084\n","\tbatch: 300, loss: 182.1939, MAE: 10.4851\n","\tbatch: 400, loss: 128.0963, MAE: 8.7942\n","Training:\t loss: 242.8604, MAE: 11.5322\n","Evaluating:\t loss: 169.1627, MAE: 9.7470\n","train MSE: 242.8604, evaluate MSE: 169.1627\n","\n","train MAE: 11.5322, evaluate MAE: 9.7470\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 19\n","\tbatch: 100, loss: 208.1888, MAE: 10.2319\n","\tbatch: 200, loss: 178.8879, MAE: 10.6654\n","\tbatch: 300, loss: 122.3667, MAE: 8.1685\n","\tbatch: 400, loss: 90.7486, MAE: 6.4633\n","Training:\t loss: 155.3339, MAE: 8.9170\n","Evaluating:\t loss: 60.4797, MAE: 5.6376\n","train MSE: 155.3339, evaluate MSE: 60.4797\n","\n","train MAE: 8.9170, evaluate MAE: 5.6376\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 20\n","\tbatch: 100, loss: 57.9536, MAE: 5.2664\n","\tbatch: 200, loss: 50.0697, MAE: 5.2244\n","\tbatch: 300, loss: 57.8809, MAE: 5.1993\n","\tbatch: 400, loss: 149.3262, MAE: 5.8765\n","Training:\t loss: 61.5771, MAE: 5.5103\n","Evaluating:\t loss: 58.7320, MAE: 5.7695\n","train MSE: 61.5771, evaluate MSE: 58.7320\n","\n","train MAE: 5.5103, evaluate MAE: 5.7695\n","\n","--- time consumption (s): 23\n","\n","Best model has been saved! Best model obtained at epoch 19 with eval MAE\n","=============== testing ===============\n","MSE on test set: 65.6258\n","MAE on test set: 5.8856\n","R2 score: 0.9999\n"]}],"source":["!python main.py -lr 5e-3 -e 20 -b 256 -n 4 -o adam_256_conv_4  "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Ne_QHaLLF3G"},"outputs":[],"source":["!python main.py -lr 1e-3 -e 20 -o sgd_64"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OrfZZcOqVzDu"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"4IDnvDb_Vzjl"},"source":["## DTNN模型更改"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":235967,"status":"ok","timestamp":1634258428043,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"7Y6JiywdVz1h","outputId":"8b149c23-7402-4a87-889e-299095814479"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using backend: pytorch\n","using device: cuda:0\n","....loaded....\n","已从已训练的模型中加载参数！\n","../base_dtnn/2021-10-15-dtnn-12/model_dtnn_conv_3_label_2021-10-15_1634258224.txt\n","==========2021-10-15 00:37:03.905519==========\n","model_type: dtnn\n","number of parameters: 597933\n","batch_size: 256\n","n_conv: 3\n","learngin rate: 0.01\n","device: cuda:0\n","--------------------\n","\n","=============== training & evaluating ===============\n","------------------------------\n","Epoch 1\n","\tbatch: 100, loss: 208526.9219, MAE: 355.2313\n","\tbatch: 200, loss: 147603.4219, MAE: 291.6897\n","\tbatch: 300, loss: 63789.6172, MAE: 198.4639\n","\tbatch: 400, loss: 39214.6094, MAE: 147.4131\n","Training:\t loss: 167067.1305, MAE: 261.7123\n","Evaluating:\t loss: 97353.7483, MAE: 205.2692\n","train MSE: 167067.1305, evaluate MSE: 97353.7483\n","\n","train MAE: 261.7123, evaluate MAE: 205.2692\n","\n","--- time consumption (s): 22\n","\n","------------------------------\n","Epoch 2\n","\tbatch: 100, loss: 84908.1094, MAE: 155.5485\n","\tbatch: 200, loss: 35995.9219, MAE: 121.7577\n","\tbatch: 300, loss: 123260.7812, MAE: 191.5077\n","\tbatch: 400, loss: 138889.5000, MAE: 136.0490\n","Training:\t loss: 78782.3700, MAE: 149.9641\n","Evaluating:\t loss: 100199.3343, MAE: 207.7735\n","train MSE: 78782.3700, evaluate MSE: 100199.3343\n","\n","train MAE: 149.9641, evaluate MAE: 207.7735\n","\n","--- time consumption (s): 19\n","\n","------------------------------\n","Epoch 3\n","\tbatch: 100, loss: 32396.9062, MAE: 99.7320\n","\tbatch: 200, loss: 19973.6055, MAE: 79.9865\n","\tbatch: 300, loss: 33400.1211, MAE: 117.1553\n","\tbatch: 400, loss: 60128.7227, MAE: 123.2598\n","Training:\t loss: 65170.0061, MAE: 132.2255\n","Evaluating:\t loss: 47742.1880, MAE: 122.5417\n","train MSE: 65170.0061, evaluate MSE: 47742.1880\n","\n","train MAE: 132.2255, evaluate MAE: 122.5417\n","\n","--- time consumption (s): 19\n","\n","------------------------------\n","Epoch 4\n","\tbatch: 100, loss: 23903.3789, MAE: 103.8466\n","\tbatch: 200, loss: 50229.9922, MAE: 96.7710\n","\tbatch: 300, loss: 30365.6328, MAE: 136.2771\n","\tbatch: 400, loss: 42199.6719, MAE: 134.9534\n","Training:\t loss: 50808.5270, MAE: 117.2552\n","Evaluating:\t loss: 43189.9154, MAE: 115.6978\n","train MSE: 50808.5270, evaluate MSE: 43189.9154\n","\n","train MAE: 117.2552, evaluate MAE: 115.6978\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 5\n","\tbatch: 100, loss: 10649.9229, MAE: 68.5977\n","\tbatch: 200, loss: 34223.3047, MAE: 86.8922\n","\tbatch: 300, loss: 49916.8320, MAE: 89.0308\n","\tbatch: 400, loss: 55933.1094, MAE: 88.6660\n","Training:\t loss: 36759.0414, MAE: 84.3819\n","Evaluating:\t loss: 25955.9533, MAE: 68.9303\n","train MSE: 36759.0414, evaluate MSE: 25955.9533\n","\n","train MAE: 84.3819, evaluate MAE: 68.9303\n","\n","--- time consumption (s): 19\n","\n","------------------------------\n","Epoch 6\n","\tbatch: 100, loss: 11069.9512, MAE: 61.5018\n","\tbatch: 200, loss: 5826.1221, MAE: 51.2550\n","\tbatch: 300, loss: 8803.3262, MAE: 57.8728\n","\tbatch: 400, loss: 27704.4453, MAE: 65.1919\n","Training:\t loss: 30439.2463, MAE: 69.1473\n","Evaluating:\t loss: 25767.2213, MAE: 66.7649\n","train MSE: 30439.2463, evaluate MSE: 25767.2213\n","\n","train MAE: 69.1473, evaluate MAE: 66.7649\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 7\n","\tbatch: 100, loss: 4494.1504, MAE: 45.8198\n","\tbatch: 200, loss: 14337.6885, MAE: 62.5997\n","\tbatch: 300, loss: 24071.6016, MAE: 64.0930\n","\tbatch: 400, loss: 50561.0469, MAE: 99.7837\n","Training:\t loss: 28695.8325, MAE: 67.0315\n","Evaluating:\t loss: 25994.6103, MAE: 64.8548\n","train MSE: 28695.8325, evaluate MSE: 25994.6103\n","\n","train MAE: 67.0315, evaluate MAE: 64.8548\n","\n","--- time consumption (s): 18\n","\n","------------------------------\n","Epoch 8\n","\tbatch: 100, loss: 7650.3496, MAE: 46.9863\n","\tbatch: 200, loss: 22456.3359, MAE: 64.5335\n","\tbatch: 300, loss: 34240.1094, MAE: 112.5197\n","\tbatch: 400, loss: 33226.7852, MAE: 65.1863\n","Training:\t loss: 25937.6362, MAE: 64.1196\n","Evaluating:\t loss: 18823.9563, MAE: 52.7828\n","train MSE: 25937.6362, evaluate MSE: 18823.9563\n","\n","train MAE: 64.1196, evaluate MAE: 52.7828\n","\n","--- time consumption (s): 19\n","\n","------------------------------\n","Epoch 9\n","\tbatch: 100, loss: 4669.0649, MAE: 42.2962\n","\tbatch: 200, loss: 15601.9004, MAE: 55.0770\n","\tbatch: 300, loss: 19542.0254, MAE: 48.0984\n","\tbatch: 400, loss: 32274.3672, MAE: 56.3555\n","Training:\t loss: 21041.8546, MAE: 52.7237\n","Evaluating:\t loss: 15185.4262, MAE: 48.8565\n","train MSE: 21041.8546, evaluate MSE: 15185.4262\n","\n","train MAE: 52.7237, evaluate MAE: 48.8565\n","\n","--- time consumption (s): 19\n","\n","------------------------------\n","Epoch 10\n","\tbatch: 100, loss: 13217.1572, MAE: 61.8863\n","\tbatch: 200, loss: 29726.0312, MAE: 63.7929\n","\tbatch: 300, loss: 24124.2930, MAE: 73.3179\n","\tbatch: 400, loss: 20350.9375, MAE: 63.9271\n","Training:\t loss: 23315.1134, MAE: 69.9358\n","Evaluating:\t loss: 17864.8717, MAE: 59.0161\n","train MSE: 23315.1134, evaluate MSE: 17864.8717\n","\n","train MAE: 69.9358, evaluate MAE: 59.0161\n","\n","--- time consumption (s): 19\n","\n","Best model has been saved! Best model obtained at epoch 9 with eval MAE\n","=============== testing ===============\n","MSE on test set: 20484.7949\n","MAE on test set: 59.7008\n","R2 score: 0.9829\n"]}],"source":["# Baseline\n","# nconv=3, epoch=30, lr=5e-3\n","!python main.py -e 30 -lr 1e-2 -o base_dtnn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":512483,"status":"ok","timestamp":1634268209633,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"-7LhUgeFVz3x","outputId":"beb4d76a-8019-41f2-d366-ca03227b4269"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using backend: pytorch\n","using device: cuda:0\n","....loaded....\n","已从已训练的模型中加载参数！\n","../multi_read_dtnn/2021-10-15-dtnn-12/model_dtnn_conv_4_label_2021-10-15_1634267729.txt\n","==========2021-10-15 03:15:28.808781==========\n","model_type: dtnn\n","number of parameters: 821293\n","batch_size: 256\n","n_conv: 4\n","learngin rate: 5e-05\n","device: cuda:0\n","--------------------\n","\n","=============== training & evaluating ===============\n","------------------------------\n","Epoch 1\n","\tbatch: 100, loss: 557.9711, MAE: 13.4536\n","\tbatch: 200, loss: 243.4922, MAE: 10.7419\n","\tbatch: 300, loss: 848.1695, MAE: 14.0242\n","\tbatch: 400, loss: 243.0813, MAE: 9.6763\n","Training:\t loss: 1934.4098, MAE: 18.3541\n","Evaluating:\t loss: 490.3124, MAE: 12.0669\n","train MSE: 1934.4098, evaluate MSE: 490.3124\n","\n","train MAE: 18.3541, evaluate MAE: 12.0669\n","\n","--- time consumption (s): 26\n","\n","------------------------------\n","Epoch 2\n","\tbatch: 100, loss: 260.9153, MAE: 10.5757\n","\tbatch: 200, loss: 339.5661, MAE: 11.6830\n","\tbatch: 300, loss: 180.9996, MAE: 9.8995\n","\tbatch: 400, loss: 281.6005, MAE: 10.9262\n","Training:\t loss: 488.6972, MAE: 10.7331\n","Evaluating:\t loss: 457.6019, MAE: 11.4455\n","train MSE: 488.6972, evaluate MSE: 457.6019\n","\n","train MAE: 10.7331, evaluate MAE: 11.4455\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 3\n","\tbatch: 100, loss: 148.1099, MAE: 8.8867\n","\tbatch: 200, loss: 353.0622, MAE: 11.2099\n","\tbatch: 300, loss: 304.1541, MAE: 11.6361\n","\tbatch: 400, loss: 332.1996, MAE: 10.0674\n","Training:\t loss: 515.1579, MAE: 11.5388\n","Evaluating:\t loss: 520.8990, MAE: 12.6478\n","train MSE: 515.1579, evaluate MSE: 520.8990\n","\n","train MAE: 11.5388, evaluate MAE: 12.6478\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 4\n","\tbatch: 100, loss: 285.3272, MAE: 10.9554\n","\tbatch: 200, loss: 570.4984, MAE: 18.4165\n","\tbatch: 300, loss: 307.8709, MAE: 13.4790\n","\tbatch: 400, loss: 231.0031, MAE: 9.7559\n","Training:\t loss: 549.0445, MAE: 12.5658\n","Evaluating:\t loss: 482.6207, MAE: 12.5031\n","train MSE: 549.0445, evaluate MSE: 482.6207\n","\n","train MAE: 12.5658, evaluate MAE: 12.5031\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 5\n","\tbatch: 100, loss: 471.4044, MAE: 13.2998\n","\tbatch: 200, loss: 342.5645, MAE: 12.9161\n","\tbatch: 300, loss: 252.8580, MAE: 10.3595\n","\tbatch: 400, loss: 543.9259, MAE: 16.9906\n","Training:\t loss: 594.7120, MAE: 13.6612\n","Evaluating:\t loss: 506.9718, MAE: 12.9831\n","train MSE: 594.7120, evaluate MSE: 506.9718\n","\n","train MAE: 13.6612, evaluate MAE: 12.9831\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 6\n","\tbatch: 100, loss: 263.2478, MAE: 10.6569\n","\tbatch: 200, loss: 1231.4744, MAE: 26.3504\n","\tbatch: 300, loss: 2618.3962, MAE: 27.5150\n","\tbatch: 400, loss: 1997.8894, MAE: 24.7820\n","Training:\t loss: 3718.9075, MAE: 30.6427\n","Evaluating:\t loss: 1113.4086, MAE: 19.1441\n","train MSE: 3718.9075, evaluate MSE: 1113.4086\n","\n","train MAE: 30.6427, evaluate MAE: 19.1441\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 7\n","\tbatch: 100, loss: 820.3711, MAE: 17.6440\n","\tbatch: 200, loss: 770.6028, MAE: 16.3832\n","\tbatch: 300, loss: 821.8568, MAE: 16.6938\n","\tbatch: 400, loss: 703.3855, MAE: 15.2117\n","Training:\t loss: 815.1598, MAE: 16.3431\n","Evaluating:\t loss: 576.9303, MAE: 14.0273\n","train MSE: 815.1598, evaluate MSE: 576.9303\n","\n","train MAE: 16.3431, evaluate MAE: 14.0273\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 8\n","\tbatch: 100, loss: 775.4717, MAE: 15.9640\n","\tbatch: 200, loss: 349.0244, MAE: 13.2602\n","\tbatch: 300, loss: 323.1443, MAE: 12.6123\n","\tbatch: 400, loss: 537.6335, MAE: 14.5833\n","Training:\t loss: 641.3553, MAE: 14.2545\n","Evaluating:\t loss: 522.9605, MAE: 12.9372\n","train MSE: 641.3553, evaluate MSE: 522.9605\n","\n","train MAE: 14.2545, evaluate MAE: 12.9372\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 9\n","\tbatch: 100, loss: 664.3532, MAE: 17.4898\n","\tbatch: 200, loss: 349.1848, MAE: 13.1539\n","\tbatch: 300, loss: 456.6245, MAE: 15.1548\n","\tbatch: 400, loss: 264.4753, MAE: 11.5277\n","Training:\t loss: 634.7429, MAE: 14.3456\n","Evaluating:\t loss: 447.3423, MAE: 12.0289\n","train MSE: 634.7429, evaluate MSE: 447.3423\n","\n","train MAE: 14.3456, evaluate MAE: 12.0289\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 10\n","\tbatch: 100, loss: 199.9984, MAE: 10.0864\n","\tbatch: 200, loss: 1317.9414, MAE: 19.0029\n","\tbatch: 300, loss: 359.6031, MAE: 13.6127\n","\tbatch: 400, loss: 336.7177, MAE: 12.7568\n","Training:\t loss: 577.1293, MAE: 13.9154\n","Evaluating:\t loss: 494.1342, MAE: 12.3248\n","train MSE: 577.1293, evaluate MSE: 494.1342\n","\n","train MAE: 13.9154, evaluate MAE: 12.3248\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 11\n","\tbatch: 100, loss: 944.1772, MAE: 20.1525\n","\tbatch: 200, loss: 30704.9121, MAE: 22.7489\n","\tbatch: 300, loss: 181.9474, MAE: 9.9351\n","\tbatch: 400, loss: 315.1537, MAE: 11.5980\n","Training:\t loss: 539.4806, MAE: 13.2271\n","Evaluating:\t loss: 862.5062, MAE: 21.5366\n","train MSE: 539.4806, evaluate MSE: 862.5062\n","\n","train MAE: 13.2271, evaluate MAE: 21.5366\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 12\n","\tbatch: 100, loss: 466.9024, MAE: 13.8721\n","\tbatch: 200, loss: 1145.7625, MAE: 27.2367\n","\tbatch: 300, loss: 563.1826, MAE: 17.1350\n","\tbatch: 400, loss: 584.7931, MAE: 13.3268\n","Training:\t loss: 637.9333, MAE: 15.3035\n","Evaluating:\t loss: 415.4090, MAE: 11.8363\n","train MSE: 637.9333, evaluate MSE: 415.4090\n","\n","train MAE: 15.3035, evaluate MAE: 11.8363\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 13\n","\tbatch: 100, loss: 450.8059, MAE: 13.8092\n","\tbatch: 200, loss: 303.0341, MAE: 12.7346\n","\tbatch: 300, loss: 567.6205, MAE: 17.6331\n","\tbatch: 400, loss: 302.8676, MAE: 11.5857\n","Training:\t loss: 488.8816, MAE: 12.8629\n","Evaluating:\t loss: 649.8162, MAE: 18.0412\n","train MSE: 488.8816, evaluate MSE: 649.8162\n","\n","train MAE: 12.8629, evaluate MAE: 18.0412\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 14\n","\tbatch: 100, loss: 357.7956, MAE: 10.3422\n","\tbatch: 200, loss: 365.7594, MAE: 13.3587\n","\tbatch: 300, loss: 213.4419, MAE: 10.3415\n","\tbatch: 400, loss: 238.8544, MAE: 11.5393\n","Training:\t loss: 498.5331, MAE: 13.0301\n","Evaluating:\t loss: 509.6434, MAE: 13.4848\n","train MSE: 498.5331, evaluate MSE: 509.6434\n","\n","train MAE: 13.0301, evaluate MAE: 13.4848\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 15\n","\tbatch: 100, loss: 286.8609, MAE: 12.4126\n","\tbatch: 200, loss: 288.7502, MAE: 11.2405\n","\tbatch: 300, loss: 243.0598, MAE: 9.7111\n","\tbatch: 400, loss: 286.7331, MAE: 13.4405\n","Training:\t loss: 626.9856, MAE: 15.3647\n","Evaluating:\t loss: 634.3355, MAE: 16.2617\n","train MSE: 626.9856, evaluate MSE: 634.3355\n","\n","train MAE: 15.3647, evaluate MAE: 16.2617\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 16\n","\tbatch: 100, loss: 169.8380, MAE: 9.3913\n","\tbatch: 200, loss: 622.9829, MAE: 19.6203\n","\tbatch: 300, loss: 340.8706, MAE: 14.6379\n","\tbatch: 400, loss: 338.9684, MAE: 13.7463\n","Training:\t loss: 436.7248, MAE: 11.9837\n","Evaluating:\t loss: 483.2061, MAE: 13.8489\n","train MSE: 436.7248, evaluate MSE: 483.2061\n","\n","train MAE: 11.9837, evaluate MAE: 13.8489\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 17\n","\tbatch: 100, loss: 334.0046, MAE: 11.9280\n","\tbatch: 200, loss: 191.9068, MAE: 10.4384\n","\tbatch: 300, loss: 471.2681, MAE: 15.8478\n","\tbatch: 400, loss: 235.9356, MAE: 10.9639\n","Training:\t loss: 452.3708, MAE: 12.5444\n","Evaluating:\t loss: 612.0344, MAE: 18.5831\n","train MSE: 452.3708, evaluate MSE: 612.0344\n","\n","train MAE: 12.5444, evaluate MAE: 18.5831\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 18\n","\tbatch: 100, loss: 266.5868, MAE: 11.8807\n","\tbatch: 200, loss: 235.3894, MAE: 10.3686\n","\tbatch: 300, loss: 467.5312, MAE: 12.0758\n","\tbatch: 400, loss: 352.3723, MAE: 12.5834\n","Training:\t loss: 455.4692, MAE: 12.6719\n","Evaluating:\t loss: 424.2978, MAE: 11.7085\n","train MSE: 455.4692, evaluate MSE: 424.2978\n","\n","train MAE: 12.6719, evaluate MAE: 11.7085\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 19\n","\tbatch: 100, loss: 470.1950, MAE: 14.8273\n","\tbatch: 200, loss: 595.9025, MAE: 12.7907\n","\tbatch: 300, loss: 303.4557, MAE: 10.4149\n","\tbatch: 400, loss: 244.0345, MAE: 9.3907\n","Training:\t loss: 471.7219, MAE: 13.0807\n","Evaluating:\t loss: 386.6788, MAE: 10.5080\n","train MSE: 471.7219, evaluate MSE: 386.6788\n","\n","train MAE: 13.0807, evaluate MAE: 10.5080\n","\n","--- time consumption (s): 23\n","\n","------------------------------\n","Epoch 20\n","\tbatch: 100, loss: 452.4775, MAE: 17.7314\n","\tbatch: 200, loss: 209.8867, MAE: 11.0298\n","\tbatch: 300, loss: 209.0672, MAE: 9.9394\n","\tbatch: 400, loss: 304.9047, MAE: 10.9797\n","Training:\t loss: 413.3056, MAE: 11.7469\n","Evaluating:\t loss: 522.5053, MAE: 12.0788\n","train MSE: 413.3056, evaluate MSE: 522.5053\n","\n","train MAE: 11.7469, evaluate MAE: 12.0788\n","\n","--- time consumption (s): 23\n","\n","Best model has been saved! Best model obtained at epoch 19 with eval MAE\n","=============== testing ===============\n","MSE on test set: 525.5048\n","MAE on test set: 11.5493\n","R2 score: 0.9996\n"]}],"source":["# 多层读出\n","!python main.py -e 20 -n 4 -lr 5e-5 -o multi_read_dtnn"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nuwCbWQNVz6Y"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"-xE_zP5mZCdN"},"source":["## MGCN"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":146585,"status":"ok","timestamp":1634161152137,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"LYHWJILqV5VY","outputId":"ab5fc204-19c4-4cf0-a3e5-bc418358c46a"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using backend: pytorch\n","using device: cuda:0\n","....loaded....\n","已从已训练的模型中加载参数！\n","../output/2021-10-13/model_mgcn_conv_3_label_2021-10-13_1634161039.txt\n","==========2021-10-13 21:37:18.804298==========\n","model_type: mgcn\n","number of parameters: 739232\n","batch_size: 256\n","n_conv: 3\n","learngin rate: 0.001\n","device: cuda:0\n","--------------------\n","\n","=============== training & evaluating ===============\n","------------------------------\n","Epoch 1\n","\tbatch: 100, loss: 210753.5625, MAE: 371.3241\n","\tbatch: 200, loss: 149983.4062, MAE: 307.9058\n","\tbatch: 300, loss: 89733.5547, MAE: 240.5446\n","Training:\t loss: 578220.7382, MAE: 416.8715\n","Evaluating:\t loss: 117956.2506, MAE: 284.2276\n","train MSE: 578220.7382, evaluate MSE: 117956.2506\n","train MAE: 416.8715, evaluate MAE: 284.2276\n","--- time consumption (s): 13\n","------------------------------\n","Epoch 2\n","\tbatch: 100, loss: 45770.7695, MAE: 163.2992\n","\tbatch: 200, loss: 28737.4805, MAE: 126.4939\n","\tbatch: 300, loss: 28829.4219, MAE: 137.6505\n","Training:\t loss: 55434.2461, MAE: 176.3495\n","Evaluating:\t loss: 31926.2377, MAE: 140.4199\n","train MSE: 55434.2461, evaluate MSE: 31926.2377\n","train MAE: 176.3495, evaluate MAE: 140.4199\n","--- time consumption (s): 10\n","------------------------------\n","Epoch 3\n","\tbatch: 100, loss: 21839.1699, MAE: 116.9739\n","\tbatch: 200, loss: 29027.7539, MAE: 144.8846\n","\tbatch: 300, loss: 10053.9238, MAE: 80.0215\n","Training:\t loss: 22292.2745, MAE: 109.4261\n","Evaluating:\t loss: 13753.7139, MAE: 85.8898\n","train MSE: 22292.2745, evaluate MSE: 13753.7139\n","train MAE: 109.4261, evaluate MAE: 85.8898\n","--- time consumption (s): 10\n","------------------------------\n","Epoch 4\n","\tbatch: 100, loss: 17983.1250, MAE: 119.6890\n","\tbatch: 200, loss: 8829.3164, MAE: 59.9043\n","\tbatch: 300, loss: 16668.1426, MAE: 101.0590\n","Training:\t loss: 20552.8891, MAE: 107.1388\n","Evaluating:\t loss: 20496.3433, MAE: 121.9875\n","train MSE: 20552.8891, evaluate MSE: 20496.3433\n","train MAE: 107.1388, evaluate MAE: 121.9875\n","--- time consumption (s): 10\n","------------------------------\n","Epoch 5\n","\tbatch: 100, loss: 5371.9570, MAE: 51.1811\n","\tbatch: 200, loss: 21601.4023, MAE: 129.6595\n","\tbatch: 300, loss: 4972.4863, MAE: 54.1921\n","Training:\t loss: 19500.2934, MAE: 104.6647\n","Evaluating:\t loss: 10850.0139, MAE: 76.3715\n","train MSE: 19500.2934, evaluate MSE: 10850.0139\n","train MAE: 104.6647, evaluate MAE: 76.3715\n","--- time consumption (s): 10\n","------------------------------\n","Epoch 6\n","\tbatch: 100, loss: 6670.6533, MAE: 48.3008\n","\tbatch: 200, loss: 37511.0078, MAE: 149.3434\n","\tbatch: 300, loss: 8582.3242, MAE: 65.4738\n","Training:\t loss: 19756.5316, MAE: 101.1236\n","Evaluating:\t loss: 9554.4244, MAE: 70.1555\n","train MSE: 19756.5316, evaluate MSE: 9554.4244\n","train MAE: 101.1236, evaluate MAE: 70.1555\n","--- time consumption (s): 10\n","------------------------------\n","Epoch 7\n","\tbatch: 100, loss: 18608.4434, MAE: 107.4736\n","\tbatch: 200, loss: 18401.6816, MAE: 118.6616\n","\tbatch: 300, loss: 21436.9492, MAE: 126.3191\n","Training:\t loss: 16625.9158, MAE: 98.3318\n","Evaluating:\t loss: 6281.2997, MAE: 50.0122\n","train MSE: 16625.9158, evaluate MSE: 6281.2997\n","train MAE: 98.3318, evaluate MAE: 50.0122\n","--- time consumption (s): 10\n","------------------------------\n","Epoch 8\n","\tbatch: 100, loss: 10597.9424, MAE: 79.9591\n","\tbatch: 200, loss: 8017.2744, MAE: 67.4027\n","\tbatch: 300, loss: 10200.7441, MAE: 71.7320\n","Training:\t loss: 14825.0538, MAE: 91.5055\n","Evaluating:\t loss: 7507.3226, MAE: 62.7093\n","train MSE: 14825.0538, evaluate MSE: 7507.3226\n","train MAE: 91.5055, evaluate MAE: 62.7093\n","--- time consumption (s): 10\n","------------------------------\n","Epoch 9\n","\tbatch: 100, loss: 29698.9941, MAE: 164.6049\n","\tbatch: 200, loss: 12532.7783, MAE: 99.1248\n","\tbatch: 300, loss: 4359.5806, MAE: 43.8575\n","Training:\t loss: 19779.6694, MAE: 99.9227\n","Evaluating:\t loss: 22416.5307, MAE: 133.2981\n","train MSE: 19779.6694, evaluate MSE: 22416.5307\n","train MAE: 99.9227, evaluate MAE: 133.2981\n","--- time consumption (s): 9\n","------------------------------\n","Epoch 10\n","\tbatch: 100, loss: 36521.3984, MAE: 183.1099\n","\tbatch: 200, loss: 7882.8535, MAE: 71.9034\n","\tbatch: 300, loss: 7050.2793, MAE: 63.5391\n","Training:\t loss: 16028.6467, MAE: 91.6132\n","Evaluating:\t loss: 15653.2162, MAE: 105.3901\n","train MSE: 16028.6467, evaluate MSE: 15653.2162\n","train MAE: 91.6132, evaluate MAE: 105.3901\n","--- time consumption (s): 9\n","Best model has been saved! Best model obtained at epoch 7 with eval MAE\n","=============== testing ===============\n","MSE on test set: 15866.0186\n","MAE on test set: 105.5338\n","R2 score: 0.9869\n"]}],"source":["# 单位为 eV\n","!python main.py -e 10 -lr 1e-3 -M mgcn"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":35},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1634160335197,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"EZMhhFrxV5WU","outputId":"614d53a5-5a8f-462d-9e64-84101e6c3d24"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content'"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import os \n","os.getcwd()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":461645,"status":"ok","timestamp":1634163844890,"user":{"displayName":"杨朝辉","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"06729079918662690657"},"user_tz":420},"id":"p6AF_Ss6i9eD","outputId":"8535ae7f-2491-4b8b-a567-3ad428857549"},"outputs":[{"name":"stdout","output_type":"stream","text":["Using backend: pytorch\n","using device: cuda:0\n","....loaded....\n","../output/2021-10-13/model_mgcn_conv_3_label_2021-10-13_1634163418.txt\n","==========2021-10-13 22:16:57.543688==========\n","model_type: mgcn\n","number of parameters: 738847\n","batch_size: 256\n","n_conv: 3\n","learngin rate: 0.0001\n","device: cuda:0\n","--------------------\n","\n","=============== training & evaluating ===============\n","------------------------------\n","Epoch 1\n","\tbatch: 100, loss: 548.9412, MAE: 9.5436\n","\tbatch: 200, loss: 185.5016, MAE: 8.0772\n","\tbatch: 300, loss: 43.2640, MAE: 3.9683\n","Training:\t loss: 6131.3238, MAE: 29.0211\n","Evaluating:\t loss: 67.2877, MAE: 4.6234\n","train MSE: 6131.3238, evaluate MSE: 67.2877\n","train MAE: 29.0211, evaluate MAE: 4.6234\n","--- time consumption (s): 23\n","------------------------------\n","Epoch 2\n","\tbatch: 100, loss: 44.6170, MAE: 5.3988\n","\tbatch: 200, loss: 35.3238, MAE: 4.8574\n","\tbatch: 300, loss: 29.1675, MAE: 2.7102\n","Training:\t loss: 51.2047, MAE: 4.3378\n","Evaluating:\t loss: 20.8030, MAE: 2.0689\n","train MSE: 51.2047, evaluate MSE: 20.8030\n","train MAE: 4.3378, evaluate MAE: 2.0689\n","--- time consumption (s): 20\n","------------------------------\n","Epoch 3\n","\tbatch: 100, loss: 8.8903, MAE: 1.5021\n","\tbatch: 200, loss: 92.8452, MAE: 8.8661\n","\tbatch: 300, loss: 82.2921, MAE: 8.7333\n","Training:\t loss: 38.4211, MAE: 3.6779\n","Evaluating:\t loss: 43.7038, MAE: 5.8205\n","train MSE: 38.4211, evaluate MSE: 43.7038\n","train MAE: 3.6779, evaluate MAE: 5.8205\n","--- time consumption (s): 20\n","------------------------------\n","Epoch 4\n","\tbatch: 100, loss: 6.6618, MAE: 1.8360\n","\tbatch: 200, loss: 14.3871, MAE: 1.2169\n","\tbatch: 300, loss: 4.3150, MAE: 1.6235\n","Training:\t loss: 14.8851, MAE: 2.1195\n","Evaluating:\t loss: 36.3655, MAE: 5.2099\n","train MSE: 14.8851, evaluate MSE: 36.3655\n","train MAE: 2.1195, evaluate MAE: 5.2099\n","--- time consumption (s): 20\n","------------------------------\n","Epoch 5\n","\tbatch: 100, loss: 2.7926, MAE: 1.0412\n","\tbatch: 200, loss: 5.2536, MAE: 1.5118\n","\tbatch: 300, loss: 9.1889, MAE: 2.2695\n","Training:\t loss: 17.4842, MAE: 2.3729\n","Evaluating:\t loss: 6.1266, MAE: 1.4175\n","train MSE: 17.4842, evaluate MSE: 6.1266\n","train MAE: 2.3729, evaluate MAE: 1.4175\n","--- time consumption (s): 20\n","------------------------------\n","Epoch 6\n","\tbatch: 100, loss: 3.4749, MAE: 1.2775\n","\tbatch: 200, loss: 1.6203, MAE: 0.7692\n","\tbatch: 300, loss: 9.7723, MAE: 1.8937\n","Training:\t loss: 16.0017, MAE: 2.6593\n","Evaluating:\t loss: 6.7778, MAE: 1.8738\n","train MSE: 16.0017, evaluate MSE: 6.7778\n","train MAE: 2.6593, evaluate MAE: 1.8738\n","--- time consumption (s): 20\n","------------------------------\n","Epoch 7\n","\tbatch: 100, loss: 4.1641, MAE: 1.0334\n","\tbatch: 200, loss: 8.1445, MAE: 1.8792\n","\tbatch: 300, loss: 3.9563, MAE: 1.5470\n","Training:\t loss: 18.4340, MAE: 2.8757\n","Evaluating:\t loss: 5.8079, MAE: 1.5334\n","train MSE: 18.4340, evaluate MSE: 5.8079\n","train MAE: 2.8757, evaluate MAE: 1.5334\n","--- time consumption (s): 20\n","------------------------------\n","Epoch 8\n","\tbatch: 100, loss: 2.3112, MAE: 1.1491\n","\tbatch: 200, loss: 11.7361, MAE: 3.1816\n","\tbatch: 300, loss: 269.0672, MAE: 16.0276\n","Training:\t loss: 13.0568, MAE: 1.9614\n","Evaluating:\t loss: 5.3166, MAE: 1.6906\n","train MSE: 13.0568, evaluate MSE: 5.3166\n","train MAE: 1.9614, evaluate MAE: 1.6906\n","--- time consumption (s): 20\n","------------------------------\n","Epoch 9\n","\tbatch: 100, loss: 2.0001, MAE: 1.0124\n","\tbatch: 200, loss: 5.0024, MAE: 1.9901\n","\tbatch: 300, loss: 1.7669, MAE: 1.0232\n","Training:\t loss: 8.6223, MAE: 1.7907\n","Evaluating:\t loss: 4.6212, MAE: 1.3168\n","train MSE: 8.6223, evaluate MSE: 4.6212\n","train MAE: 1.7907, evaluate MAE: 1.3168\n","--- time consumption (s): 20\n","------------------------------\n","Epoch 10\n","\tbatch: 100, loss: 1.5330, MAE: 0.8693\n","\tbatch: 200, loss: 1.2423, MAE: 0.5310\n","\tbatch: 300, loss: 17.5033, MAE: 3.9615\n","Training:\t loss: 12.3965, MAE: 2.0183\n","Evaluating:\t loss: 3.8032, MAE: 1.3138\n","train MSE: 12.3965, evaluate MSE: 3.8032\n","train MAE: 2.0183, evaluate MAE: 1.3138\n","--- time consumption (s): 20\n","------------------------------\n","Epoch 11\n","\tbatch: 100, loss: 3.8062, MAE: 1.7912\n","\tbatch: 200, loss: 0.7204, MAE: 0.4749\n","\tbatch: 300, loss: 1.7510, MAE: 0.8192\n","Training:\t loss: 9.6695, MAE: 1.9981\n","Evaluating:\t loss: 24.3207, MAE: 4.3385\n","train MSE: 9.6695, evaluate MSE: 24.3207\n","train MAE: 1.9981, evaluate MAE: 4.3385\n","--- time consumption (s): 20\n","------------------------------\n","Epoch 12\n","\tbatch: 100, loss: 2.5516, MAE: 1.4677\n","\tbatch: 200, loss: 2.9884, MAE: 1.3546\n","\tbatch: 300, loss: 2.8145, MAE: 1.6008\n","Training:\t loss: 9.6740, MAE: 1.9815\n","Evaluating:\t loss: 2.2962, MAE: 0.9397\n","train MSE: 9.6740, evaluate MSE: 2.2962\n","train MAE: 1.9815, evaluate MAE: 0.9397\n","--- time consumption (s): 20\n","------------------------------\n","Epoch 13\n","\tbatch: 100, loss: 6.7077, MAE: 2.4297\n","\tbatch: 200, loss: 1.0332, MAE: 0.7203\n","\tbatch: 300, loss: 16.5110, MAE: 0.8363\n","Training:\t loss: 9.1979, MAE: 2.0916\n","Evaluating:\t loss: 9.4897, MAE: 2.8021\n","train MSE: 9.1979, evaluate MSE: 9.4897\n","train MAE: 2.0916, evaluate MAE: 2.8021\n","--- time consumption (s): 20\n","------------------------------\n","Epoch 14\n","\tbatch: 100, loss: 30.4780, MAE: 5.3548\n","\tbatch: 200, loss: 7.0900, MAE: 2.5047\n","\tbatch: 300, loss: 0.8375, MAE: 0.4603\n","Training:\t loss: 8.1355, MAE: 2.0174\n","Evaluating:\t loss: 2.1386, MAE: 0.9475\n","train MSE: 8.1355, evaluate MSE: 2.1386\n","train MAE: 2.0174, evaluate MAE: 0.9475\n","--- time consumption (s): 20\n","------------------------------\n","Epoch 15\n","\tbatch: 100, loss: 11.2651, MAE: 3.2358\n","\tbatch: 200, loss: 9.4765, MAE: 2.8303\n","\tbatch: 300, loss: 24.5749, MAE: 4.8816\n","Training:\t loss: 8.4819, MAE: 2.1610\n","Evaluating:\t loss: 6.2079, MAE: 1.9246\n","train MSE: 8.4819, evaluate MSE: 6.2079\n","train MAE: 2.1610, evaluate MAE: 1.9246\n","--- time consumption (s): 20\n","------------------------------\n","Epoch 16\n","\tbatch: 100, loss: 30.1175, MAE: 5.1164\n","\tbatch: 200, loss: 4.9284, MAE: 1.4078\n","\tbatch: 300, loss: 18.4369, MAE: 4.1985\n","Training:\t loss: 6.8959, MAE: 1.9215\n","Evaluating:\t loss: 2.7696, MAE: 0.8248\n","train MSE: 6.8959, evaluate MSE: 2.7696\n","train MAE: 1.9215, evaluate MAE: 0.8248\n","--- time consumption (s): 20\n","------------------------------\n","Epoch 17\n","\tbatch: 100, loss: 1.0421, MAE: 0.9103\n","\tbatch: 200, loss: 0.4330, MAE: 0.4157\n","\tbatch: 300, loss: 1.5875, MAE: 0.9757\n","Training:\t loss: 6.7665, MAE: 1.7247\n","Evaluating:\t loss: 19.4715, MAE: 4.1113\n","train MSE: 6.7665, evaluate MSE: 19.4715\n","train MAE: 1.7247, evaluate MAE: 4.1113\n","--- time consumption (s): 20\n","------------------------------\n","Epoch 18\n","\tbatch: 100, loss: 2.1344, MAE: 0.8548\n","\tbatch: 200, loss: 1.1181, MAE: 0.7610\n","\tbatch: 300, loss: 6.6186, MAE: 2.3715\n","Training:\t loss: 7.7757, MAE: 1.6672\n","Evaluating:\t loss: 1.6208, MAE: 1.0072\n","train MSE: 7.7757, evaluate MSE: 1.6208\n","train MAE: 1.6672, evaluate MAE: 1.0072\n","--- time consumption (s): 20\n","------------------------------\n","Epoch 19\n","\tbatch: 100, loss: 0.3941, MAE: 0.5073\n","\tbatch: 200, loss: 29.1961, MAE: 5.2296\n","\tbatch: 300, loss: 0.4331, MAE: 0.4882\n","Training:\t loss: 7.5508, MAE: 1.8735\n","Evaluating:\t loss: 4.1303, MAE: 1.3244\n","train MSE: 7.5508, evaluate MSE: 4.1303\n","train MAE: 1.8735, evaluate MAE: 1.3244\n","--- time consumption (s): 20\n","------------------------------\n","Epoch 20\n","\tbatch: 100, loss: 0.9165, MAE: 0.7088\n","\tbatch: 200, loss: 81.0700, MAE: 8.6709\n","\tbatch: 300, loss: 0.6416, MAE: 0.7422\n","Training:\t loss: 7.4907, MAE: 1.6863\n","Evaluating:\t loss: 19.4049, MAE: 3.4662\n","train MSE: 7.4907, evaluate MSE: 19.4049\n","train MAE: 1.6863, evaluate MAE: 3.4662\n","--- time consumption (s): 20\n","Best model has been saved! Best model obtained at epoch 16 with eval MAE\n","=============== testing ===============\n","MSE on test set: 19.9999\n","MAE on test set: 3.4950\n","R2 score: 0.9878\n"]}],"source":["# 完全图 MGCN，单位 Hatree\n","!python main.py -type com -lr 1e-4 -e 20 -M mgcn\n"]}],"metadata":{"accelerator":"GPU","colab":{"authorship_tag":"ABX9TyP12c5BGCrUnhDSgzIU+1x5","collapsed_sections":[],"machine_shape":"hm","mount_file_id":"105SF-KdDO6cmsEejw17njlQobPJK4WXZ","name":"main.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}
